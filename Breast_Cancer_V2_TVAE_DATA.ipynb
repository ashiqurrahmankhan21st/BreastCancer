{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashiqurrahmankhan21st/BreastCancer/blob/main/Breast_Cancer_V2_TVAE_DATA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EUMYU_d6_J-X"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "#import keras_metrics\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from sklearn.inspection import PartialDependenceDisplay\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#original data\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/ashiqurrahmankhan21st/BreastCancer/main/tvae_SDV_BreastCancer.csv\")\n",
        "del df['Unnamed: 0']\n",
        "df"
      ],
      "metadata": {
        "id": "Ntdqq4T_aGXN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "outputId": "b883d707-0903-48fe-afa9-68886c5d0e4e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     diagnosis  radius_mean  texture_mean  perimeter_mean   area_mean  \\\n",
              "0            B     9.866787     14.637137       63.409325  283.713730   \n",
              "1            B    12.885053     21.506004       79.229176  336.364127   \n",
              "2            B    11.165762     15.516346       84.076405  356.413321   \n",
              "3            B    12.271667     19.807824       68.534578  428.143496   \n",
              "4            B     7.454015     12.357933       51.167853  202.087605   \n",
              "...        ...          ...           ...             ...         ...   \n",
              "9995         B    11.653797     19.591590       66.871153  347.640448   \n",
              "9996         B    12.779385     13.799951       71.689730  568.975097   \n",
              "9997         B    12.144682     17.091324       72.648862  363.638743   \n",
              "9998         B    11.440653     14.876270       83.906545  447.719512   \n",
              "9999         B    12.327089     21.793296       90.006683  585.450805   \n",
              "\n",
              "      smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0            0.084223          0.046159        0.016544             0.020951   \n",
              "1            0.081238          0.061742        0.030052             0.025329   \n",
              "2            0.112075          0.064143        0.012986             0.000000   \n",
              "3            0.088438          0.031222        0.028840             0.018988   \n",
              "4            0.088588          0.052791        0.051511             0.013281   \n",
              "...               ...               ...             ...                  ...   \n",
              "9995         0.114469          0.153040        0.098849             0.020412   \n",
              "9996         0.102959          0.126075        0.107483             0.026956   \n",
              "9997         0.115953          0.122028        0.112376             0.031809   \n",
              "9998         0.101748          0.135110        0.069284             0.093306   \n",
              "9999         0.097919          0.170219        0.093106             0.028075   \n",
              "\n",
              "      symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
              "0          0.170999  ...     13.174990      18.064878        79.308249   \n",
              "1          0.169469  ...     15.764673      27.487070        81.358017   \n",
              "2          0.159183  ...     12.177383      34.227039        87.682893   \n",
              "3          0.144926  ...     14.332578      18.433072        68.255508   \n",
              "4          0.174599  ...     10.671485      18.960872        60.949763   \n",
              "...             ...  ...           ...            ...              ...   \n",
              "9995       0.171224  ...     13.364227      31.212963        75.105110   \n",
              "9996       0.176738  ...     14.636441      25.387452        81.755763   \n",
              "9997       0.145315  ...     12.978866      21.222782        88.692189   \n",
              "9998       0.198483  ...     14.864455      19.688309       104.210820   \n",
              "9999       0.185964  ...     12.195219      29.697275        77.443915   \n",
              "\n",
              "      area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
              "0     368.916148          0.152767           0.166851         0.158809   \n",
              "1     726.979378          0.112737           0.137944         0.120542   \n",
              "2     644.261133          0.125459           0.256056         0.112901   \n",
              "3     505.092414          0.092259           0.116755         0.059426   \n",
              "4     340.397278          0.127406           0.107711         0.110993   \n",
              "...          ...               ...                ...              ...   \n",
              "9995  309.445867          0.150710           0.268134         0.244718   \n",
              "9996  675.860482          0.160312           0.562150         0.291571   \n",
              "9997  534.210501          0.185600           0.492610         0.452870   \n",
              "9998  711.314226          0.158937           0.555026         0.211123   \n",
              "9999  449.710078          0.147902           0.498236         0.346742   \n",
              "\n",
              "      concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
              "0                 0.035439        0.288579                 0.073689  \n",
              "1                 0.071356        0.271750                 0.068861  \n",
              "2                 0.045699        0.301039                 0.055040  \n",
              "3                 0.044334        0.235016                 0.079151  \n",
              "4                 0.000000        0.299682                 0.069818  \n",
              "...                    ...             ...                      ...  \n",
              "9995              0.056089        0.251965                 0.088369  \n",
              "9996              0.173512        0.298970                 0.102903  \n",
              "9997              0.090011        0.243860                 0.143752  \n",
              "9998              0.186335        0.263381                 0.072269  \n",
              "9999              0.067868        0.252371                 0.084630  \n",
              "\n",
              "[10000 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f01a2a2f-1a04-4bb9-8e97-46a08ca2ea3d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B</td>\n",
              "      <td>9.866787</td>\n",
              "      <td>14.637137</td>\n",
              "      <td>63.409325</td>\n",
              "      <td>283.713730</td>\n",
              "      <td>0.084223</td>\n",
              "      <td>0.046159</td>\n",
              "      <td>0.016544</td>\n",
              "      <td>0.020951</td>\n",
              "      <td>0.170999</td>\n",
              "      <td>...</td>\n",
              "      <td>13.174990</td>\n",
              "      <td>18.064878</td>\n",
              "      <td>79.308249</td>\n",
              "      <td>368.916148</td>\n",
              "      <td>0.152767</td>\n",
              "      <td>0.166851</td>\n",
              "      <td>0.158809</td>\n",
              "      <td>0.035439</td>\n",
              "      <td>0.288579</td>\n",
              "      <td>0.073689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B</td>\n",
              "      <td>12.885053</td>\n",
              "      <td>21.506004</td>\n",
              "      <td>79.229176</td>\n",
              "      <td>336.364127</td>\n",
              "      <td>0.081238</td>\n",
              "      <td>0.061742</td>\n",
              "      <td>0.030052</td>\n",
              "      <td>0.025329</td>\n",
              "      <td>0.169469</td>\n",
              "      <td>...</td>\n",
              "      <td>15.764673</td>\n",
              "      <td>27.487070</td>\n",
              "      <td>81.358017</td>\n",
              "      <td>726.979378</td>\n",
              "      <td>0.112737</td>\n",
              "      <td>0.137944</td>\n",
              "      <td>0.120542</td>\n",
              "      <td>0.071356</td>\n",
              "      <td>0.271750</td>\n",
              "      <td>0.068861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B</td>\n",
              "      <td>11.165762</td>\n",
              "      <td>15.516346</td>\n",
              "      <td>84.076405</td>\n",
              "      <td>356.413321</td>\n",
              "      <td>0.112075</td>\n",
              "      <td>0.064143</td>\n",
              "      <td>0.012986</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.159183</td>\n",
              "      <td>...</td>\n",
              "      <td>12.177383</td>\n",
              "      <td>34.227039</td>\n",
              "      <td>87.682893</td>\n",
              "      <td>644.261133</td>\n",
              "      <td>0.125459</td>\n",
              "      <td>0.256056</td>\n",
              "      <td>0.112901</td>\n",
              "      <td>0.045699</td>\n",
              "      <td>0.301039</td>\n",
              "      <td>0.055040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B</td>\n",
              "      <td>12.271667</td>\n",
              "      <td>19.807824</td>\n",
              "      <td>68.534578</td>\n",
              "      <td>428.143496</td>\n",
              "      <td>0.088438</td>\n",
              "      <td>0.031222</td>\n",
              "      <td>0.028840</td>\n",
              "      <td>0.018988</td>\n",
              "      <td>0.144926</td>\n",
              "      <td>...</td>\n",
              "      <td>14.332578</td>\n",
              "      <td>18.433072</td>\n",
              "      <td>68.255508</td>\n",
              "      <td>505.092414</td>\n",
              "      <td>0.092259</td>\n",
              "      <td>0.116755</td>\n",
              "      <td>0.059426</td>\n",
              "      <td>0.044334</td>\n",
              "      <td>0.235016</td>\n",
              "      <td>0.079151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B</td>\n",
              "      <td>7.454015</td>\n",
              "      <td>12.357933</td>\n",
              "      <td>51.167853</td>\n",
              "      <td>202.087605</td>\n",
              "      <td>0.088588</td>\n",
              "      <td>0.052791</td>\n",
              "      <td>0.051511</td>\n",
              "      <td>0.013281</td>\n",
              "      <td>0.174599</td>\n",
              "      <td>...</td>\n",
              "      <td>10.671485</td>\n",
              "      <td>18.960872</td>\n",
              "      <td>60.949763</td>\n",
              "      <td>340.397278</td>\n",
              "      <td>0.127406</td>\n",
              "      <td>0.107711</td>\n",
              "      <td>0.110993</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.299682</td>\n",
              "      <td>0.069818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>B</td>\n",
              "      <td>11.653797</td>\n",
              "      <td>19.591590</td>\n",
              "      <td>66.871153</td>\n",
              "      <td>347.640448</td>\n",
              "      <td>0.114469</td>\n",
              "      <td>0.153040</td>\n",
              "      <td>0.098849</td>\n",
              "      <td>0.020412</td>\n",
              "      <td>0.171224</td>\n",
              "      <td>...</td>\n",
              "      <td>13.364227</td>\n",
              "      <td>31.212963</td>\n",
              "      <td>75.105110</td>\n",
              "      <td>309.445867</td>\n",
              "      <td>0.150710</td>\n",
              "      <td>0.268134</td>\n",
              "      <td>0.244718</td>\n",
              "      <td>0.056089</td>\n",
              "      <td>0.251965</td>\n",
              "      <td>0.088369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>B</td>\n",
              "      <td>12.779385</td>\n",
              "      <td>13.799951</td>\n",
              "      <td>71.689730</td>\n",
              "      <td>568.975097</td>\n",
              "      <td>0.102959</td>\n",
              "      <td>0.126075</td>\n",
              "      <td>0.107483</td>\n",
              "      <td>0.026956</td>\n",
              "      <td>0.176738</td>\n",
              "      <td>...</td>\n",
              "      <td>14.636441</td>\n",
              "      <td>25.387452</td>\n",
              "      <td>81.755763</td>\n",
              "      <td>675.860482</td>\n",
              "      <td>0.160312</td>\n",
              "      <td>0.562150</td>\n",
              "      <td>0.291571</td>\n",
              "      <td>0.173512</td>\n",
              "      <td>0.298970</td>\n",
              "      <td>0.102903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>B</td>\n",
              "      <td>12.144682</td>\n",
              "      <td>17.091324</td>\n",
              "      <td>72.648862</td>\n",
              "      <td>363.638743</td>\n",
              "      <td>0.115953</td>\n",
              "      <td>0.122028</td>\n",
              "      <td>0.112376</td>\n",
              "      <td>0.031809</td>\n",
              "      <td>0.145315</td>\n",
              "      <td>...</td>\n",
              "      <td>12.978866</td>\n",
              "      <td>21.222782</td>\n",
              "      <td>88.692189</td>\n",
              "      <td>534.210501</td>\n",
              "      <td>0.185600</td>\n",
              "      <td>0.492610</td>\n",
              "      <td>0.452870</td>\n",
              "      <td>0.090011</td>\n",
              "      <td>0.243860</td>\n",
              "      <td>0.143752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>B</td>\n",
              "      <td>11.440653</td>\n",
              "      <td>14.876270</td>\n",
              "      <td>83.906545</td>\n",
              "      <td>447.719512</td>\n",
              "      <td>0.101748</td>\n",
              "      <td>0.135110</td>\n",
              "      <td>0.069284</td>\n",
              "      <td>0.093306</td>\n",
              "      <td>0.198483</td>\n",
              "      <td>...</td>\n",
              "      <td>14.864455</td>\n",
              "      <td>19.688309</td>\n",
              "      <td>104.210820</td>\n",
              "      <td>711.314226</td>\n",
              "      <td>0.158937</td>\n",
              "      <td>0.555026</td>\n",
              "      <td>0.211123</td>\n",
              "      <td>0.186335</td>\n",
              "      <td>0.263381</td>\n",
              "      <td>0.072269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>B</td>\n",
              "      <td>12.327089</td>\n",
              "      <td>21.793296</td>\n",
              "      <td>90.006683</td>\n",
              "      <td>585.450805</td>\n",
              "      <td>0.097919</td>\n",
              "      <td>0.170219</td>\n",
              "      <td>0.093106</td>\n",
              "      <td>0.028075</td>\n",
              "      <td>0.185964</td>\n",
              "      <td>...</td>\n",
              "      <td>12.195219</td>\n",
              "      <td>29.697275</td>\n",
              "      <td>77.443915</td>\n",
              "      <td>449.710078</td>\n",
              "      <td>0.147902</td>\n",
              "      <td>0.498236</td>\n",
              "      <td>0.346742</td>\n",
              "      <td>0.067868</td>\n",
              "      <td>0.252371</td>\n",
              "      <td>0.084630</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f01a2a2f-1a04-4bb9-8e97-46a08ca2ea3d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f01a2a2f-1a04-4bb9-8e97-46a08ca2ea3d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f01a2a2f-1a04-4bb9-8e97-46a08ca2ea3d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(df['diagnosis']).copy()\n",
        "X = df.drop(columns=['diagnosis']).copy()\n",
        "X = StandardScaler().fit_transform(X).copy()"
      ],
      "metadata": {
        "id": "4cimS259ti6F"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['diagnosis'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bv9sG-P8M1Fe",
        "outputId": "3cdb4190-be5f-45c0-ab94-4210fc263d20"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "B    6166\n",
              "M    3834\n",
              "Name: diagnosis, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "#X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=123)\n",
        "print(\"Original data : \",df.shape)\n",
        "print(\"tarin         : \",X_train.shape)\n",
        "print(\"test          : \",X_test.shape[0])\n",
        "#print(\"validation    : \",X_val.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpyVwv13CTut",
        "outputId": "a3665bee-d4f0-4e70-ad67-dd0daeee494f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original data :  (10000, 31)\n",
            "tarin         :  (8000, 30)\n",
            "test          :  2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM\n",
        "svm = SVC(C=0.1, gamma='auto', kernel = 'rbf')\n",
        "svm.fit(X_train, y_train)\n",
        "STr = svm.score(X_train, y_train)\n",
        "STe = svm.score(X_test, y_test)\n",
        "y_pred_svm = svm.predict(X_test)"
      ],
      "metadata": {
        "id": "wnRYFOkyEEZ9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ANN\n",
        "tf.random.set_seed(123)\n",
        "ANNmodel = Sequential()\n",
        "ANNmodel.add(Dense(30, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "ANNmodel.add(Dense(10, activation='relu'))\n",
        "ANNmodel.add(Dense(1, activation='sigmoid'))\n",
        "ANNmodel.compile(loss='BinaryCrossentropy', optimizer='adam', metrics=['accuracy']) #tf.keras.metrics.Precision(), tf.keras.metrics.Recall()\n",
        "ANNmodel.fit(X_train,y_train, batch_size = 128, epochs = 20, validation_split = 0.1)\n",
        "ATr = ANNmodel.evaluate(X_train,y_train,verbose=0)[1]\n",
        "ATe = ANNmodel.evaluate(X_test,y_test,verbose=0)[1]\n",
        "y_pred_ANN = (ANNmodel.predict(X_test) > 0.5).astype(\"int32\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZX7DbN-OIyu",
        "outputId": "c4b659c9-bcac-4a07-d8ed-a6a80fdff7b4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "57/57 [==============================] - 2s 14ms/step - loss: 0.4079 - accuracy: 0.7556 - val_loss: 0.2681 - val_accuracy: 0.9112\n",
            "Epoch 2/20\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1989 - accuracy: 0.9253 - val_loss: 0.1612 - val_accuracy: 0.9362\n",
            "Epoch 3/20\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.1477 - accuracy: 0.9396 - val_loss: 0.1327 - val_accuracy: 0.9450\n",
            "Epoch 4/20\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.1315 - accuracy: 0.9447 - val_loss: 0.1231 - val_accuracy: 0.9463\n",
            "Epoch 5/20\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.1244 - accuracy: 0.9478 - val_loss: 0.1196 - val_accuracy: 0.9438\n",
            "Epoch 6/20\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1209 - accuracy: 0.9496 - val_loss: 0.1163 - val_accuracy: 0.9463\n",
            "Epoch 7/20\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.1179 - accuracy: 0.9504 - val_loss: 0.1151 - val_accuracy: 0.9475\n",
            "Epoch 8/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1161 - accuracy: 0.9519 - val_loss: 0.1153 - val_accuracy: 0.9488\n",
            "Epoch 9/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1140 - accuracy: 0.9529 - val_loss: 0.1146 - val_accuracy: 0.9488\n",
            "Epoch 10/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1122 - accuracy: 0.9531 - val_loss: 0.1134 - val_accuracy: 0.9475\n",
            "Epoch 11/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1109 - accuracy: 0.9543 - val_loss: 0.1158 - val_accuracy: 0.9475\n",
            "Epoch 12/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1101 - accuracy: 0.9549 - val_loss: 0.1142 - val_accuracy: 0.9475\n",
            "Epoch 13/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1084 - accuracy: 0.9558 - val_loss: 0.1138 - val_accuracy: 0.9475\n",
            "Epoch 14/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1072 - accuracy: 0.9567 - val_loss: 0.1132 - val_accuracy: 0.9500\n",
            "Epoch 15/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1057 - accuracy: 0.9565 - val_loss: 0.1143 - val_accuracy: 0.9488\n",
            "Epoch 16/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1045 - accuracy: 0.9568 - val_loss: 0.1134 - val_accuracy: 0.9513\n",
            "Epoch 17/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1037 - accuracy: 0.9574 - val_loss: 0.1142 - val_accuracy: 0.9525\n",
            "Epoch 18/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1024 - accuracy: 0.9581 - val_loss: 0.1117 - val_accuracy: 0.9500\n",
            "Epoch 19/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1014 - accuracy: 0.9589 - val_loss: 0.1122 - val_accuracy: 0.9500\n",
            "Epoch 20/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1003 - accuracy: 0.9572 - val_loss: 0.1141 - val_accuracy: 0.9488\n",
            "63/63 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XGBoost\n",
        "params = {\n",
        "            'objective':'binary:logistic',\n",
        "            'max_depth': 7,\n",
        "            'alpha': 10,\n",
        "            'learning_rate': 1,\n",
        "            'n_estimators':100\n",
        "        }\n",
        "xgb = XGBClassifier(objective='binary:logistic',max_depth= 7,alpha= 10,learning_rate= 1,n_estimators=100)\n",
        "xgb.fit(X_train, y_train)\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "XTr = accuracy_score(y_train, xgb.predict(X_train))\n",
        "XTe = accuracy_score(y_test, xgb.predict(X_test))\n",
        "XTr,XTe"
      ],
      "metadata": {
        "id": "PCP82YZ9RjgJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee1f3e37-4664-4242-aeb8-cb38f18d8dd1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.98825, 0.9455)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#KNN\n",
        "# Define the range of n_neighbors values to test\n",
        "n_neighbors_values = [1,3, 5, 7, 9, 11]\n",
        "\n",
        "best_accuracy = 0.0\n",
        "best_n_neighbors = None\n",
        "\n",
        "for n_neighbors in n_neighbors_values:\n",
        "    print(\"Number of Neighbors:\", n_neighbors)\n",
        "\n",
        "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    y_pred_knn = knn.predict(X_test)\n",
        "\n",
        "    train_accuracy = accuracy_score(y_train, knn.predict(X_train))\n",
        "    test_accuracy = accuracy_score(y_test, knn.predict(X_test))\n",
        "\n",
        "    print('KNN model train accuracy score: {0:0.4f}'.format(train_accuracy))\n",
        "    print('KNN model test accuracy score: {0:0.4f}'.format(test_accuracy))\n",
        "    print()\n",
        "\n",
        "    # Check if the current test accuracy is better than the previous best\n",
        "    if test_accuracy > best_accuracy:\n",
        "        best_accuracy = test_accuracy\n",
        "        best_n_neighbors = n_neighbors\n",
        "print(\"best neighbours: \", best_n_neighbors)\n",
        "knn = KNeighborsClassifier(n_neighbors=best_n_neighbors)\n",
        "knn.fit(X_train, y_train)\n",
        "KTr = accuracy_score(y_train, knn.predict(X_train))\n",
        "KTe = accuracy_score(y_test, knn.predict(X_test))\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "KTr,KTe\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Y_6b33A1imy",
        "outputId": "9ab62b0d-d17f-40b0-a600-de114e66134d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Neighbors: 1\n",
            "KNN model train accuracy score: 1.0000\n",
            "KNN model test accuracy score: 0.9180\n",
            "\n",
            "Number of Neighbors: 3\n",
            "KNN model train accuracy score: 0.9629\n",
            "KNN model test accuracy score: 0.9340\n",
            "\n",
            "Number of Neighbors: 5\n",
            "KNN model train accuracy score: 0.9549\n",
            "KNN model test accuracy score: 0.9445\n",
            "\n",
            "Number of Neighbors: 7\n",
            "KNN model train accuracy score: 0.9537\n",
            "KNN model test accuracy score: 0.9440\n",
            "\n",
            "Number of Neighbors: 9\n",
            "KNN model train accuracy score: 0.9523\n",
            "KNN model test accuracy score: 0.9445\n",
            "\n",
            "Number of Neighbors: 11\n",
            "KNN model train accuracy score: 0.9499\n",
            "KNN model test accuracy score: 0.9410\n",
            "\n",
            "best neighbours:  5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.954875, 0.9445)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RF\n",
        "rf = RandomForestClassifier(n_estimators= 500,max_features = 'sqrt', max_samples = 100, random_state=123)\n",
        "rf.fit(X_train, y_train)\n",
        "RTr = accuracy_score(y_train, rf.predict(X_train))\n",
        "RTe = accuracy_score(y_test, rf.predict(X_test))\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "RTr,RTe"
      ],
      "metadata": {
        "id": "k_kyk_E92bSX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7e89f6c-809d-46c9-cf26-4cb45bc164b8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.943875, 0.9505)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LR\n",
        "lr = LogisticRegression(C= 0.1 , penalty='l1', solver='liblinear', max_iter = 1000, random_state=123)\n",
        "lr.fit(X_train, y_train)\n",
        "LTr = accuracy_score(y_train, lr.predict(X_train))\n",
        "LTe = accuracy_score(y_test, lr.predict(X_test))\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "LTr,LTe"
      ],
      "metadata": {
        "id": "OWkZmwL23Fm_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e998dfae-378b-4ff2-b7ab-d708ee277f26"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.95, 0.95)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E9_l6r5f0w5n"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CVal(ML):\n",
        "\n",
        "  df = pd.read_csv(\"https://raw.githubusercontent.com/ashiqurrahmankhan21st/BreastCancer/main/tvae_SDV_BreastCancer.csv\")\n",
        "  del df['Unnamed: 0']\n",
        "\n",
        "  s = 0\n",
        "  e = round(df.shape[0]*.2)\n",
        "\n",
        "  y_pred = []\n",
        "  y_original = []\n",
        "\n",
        "  for i in range(5):\n",
        "\n",
        "    test_set  = df.iloc[s:e,:]\n",
        "    train_set = df.drop(test_set.index)\n",
        "\n",
        "    X_train = StandardScaler().fit_transform(train_set.drop(columns=['diagnosis'])).copy()\n",
        "    y_train = encoder.fit_transform(train_set['diagnosis']).copy()\n",
        "    X_test = StandardScaler().fit_transform(test_set.drop(columns=['diagnosis'])).copy()\n",
        "    y_test = encoder.fit_transform(test_set['diagnosis']).copy()\n",
        "\n",
        "    #svm = SVC(C=0.1, gamma='auto', kernel = 'rbf')\n",
        "    ML.fit(X_train, y_train)\n",
        "    y_pred_ML = ML.predict(X_test)\n",
        "\n",
        "\n",
        "    y_pred.append(y_pred_ML)\n",
        "    y_original.append(y_test)\n",
        "\n",
        "    s = e\n",
        "    e = e + round(df.shape[0]*.2)\n",
        "    if e-s < round(df.shape[0]*.2):\n",
        "      e = df.shape[0]+1\n",
        "\n",
        "  y_pred_final = []\n",
        "  y_original_final = []\n",
        "\n",
        "  try:\n",
        "    for i in range(5):\n",
        "      for j in range(round(df.shape[0]*.2)):\n",
        "        y_pred_final.append(y_pred[i][j])\n",
        "        y_original_final.append(y_original[i][j])\n",
        "  except:\n",
        "    pass\n",
        "  return y_pred_final"
      ],
      "metadata": {
        "id": "XqaJZ1Mb0xAe"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CValANN():\n",
        "\n",
        "  df = pd.read_csv(\"https://raw.githubusercontent.com/ashiqurrahmankhan21st/BreastCancer/main/tvae_SDV_BreastCancer.csv\")\n",
        "  del df['Unnamed: 0']\n",
        "\n",
        "  s = 0\n",
        "  e = round(df.shape[0]*.2)\n",
        "\n",
        "  y_pred = []\n",
        "  y_original = []\n",
        "\n",
        "  for i in range(5):\n",
        "\n",
        "    test_set  = df.iloc[s:e,:]\n",
        "    train_set = df.drop(test_set.index)\n",
        "\n",
        "    X_train = StandardScaler().fit_transform(train_set.drop(columns=['diagnosis'])).copy()\n",
        "    y_train = encoder.fit_transform(train_set['diagnosis']).copy()\n",
        "    X_test = StandardScaler().fit_transform(test_set.drop(columns=['diagnosis'])).copy()\n",
        "    y_test = encoder.fit_transform(test_set['diagnosis']).copy()\n",
        "\n",
        "    #svm = SVC(C=0.1, gamma='auto', kernel = 'rbf')\n",
        "    tf.random.set_seed(123)\n",
        "    ANNmodel = Sequential()\n",
        "    ANNmodel.add(Dense(30, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "    ANNmodel.add(Dense(10, activation='relu'))\n",
        "    ANNmodel.add(Dense(1, activation='sigmoid'))\n",
        "    ANNmodel.compile(loss='BinaryCrossentropy', optimizer='adam', metrics=['accuracy']) #tf.keras.metrics.Precision(), tf.keras.metrics.Recall()\n",
        "    ANNmodel.fit(X_train,y_train, batch_size = 128, epochs = 20, validation_split = 0.1)\n",
        "    y_pred_ANN = (ANNmodel.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "\n",
        "    y_pred.append(y_pred_ANN)\n",
        "    y_original.append(y_test)\n",
        "\n",
        "    s = e\n",
        "    e = e + round(df.shape[0]*.2)\n",
        "    if e-s < round(df.shape[0]*.2):\n",
        "      e = df.shape[0]\n",
        "\n",
        "  y_pred_fina = []\n",
        "  y_original_final = []\n",
        "\n",
        "  try:\n",
        "    for i in range(5):\n",
        "      for j in range(round(df.shape[0]*.2)):\n",
        "        y_pred_fina.append(y_pred[i][j])\n",
        "        y_original_final.append(y_original[i][j])\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  y_pred_final = []\n",
        "\n",
        "  for i in range(len(y_pred_fina)):\n",
        "    y_pred_final.append(y_pred_fina[i][0])\n",
        "\n",
        "  return y_pred_final"
      ],
      "metadata": {
        "id": "jRa_a7EY0y6B"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newdata = pd.DataFrame({\n",
        "    \"SVM\": CVal(SVC(C=0.1, gamma='auto', kernel = 'rbf'))\n",
        "})\n",
        "newdata[\"KNN\"] = CVal(KNeighborsClassifier(n_neighbors=3))\n",
        "newdata[\"RF\"]  = CVal(RandomForestClassifier(n_estimators= 500,max_features = 'sqrt', max_samples = 100, random_state=123))\n",
        "newdata['LR']  = CVal(LogisticRegression(C= 0.1 , penalty='l1', solver='liblinear', max_iter = 1000, random_state=123))\n",
        "newdata[\"ANN\"] = CValANN()\n",
        "newdata[\"XGB\"] = CVal(XGBClassifier(objective='binary:logistic',max_depth= 7,alpha= 10,learning_rate= 1,n_estimators=100))\n",
        "newdata['y_test'] = encoder.fit_transform(df['diagnosis']).copy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CGgdO1V0zA9",
        "outputId": "17a4ec08-232f-436d-88f0-fc04d5e9e529"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "57/57 [==============================] - 1s 6ms/step - loss: 0.3894 - accuracy: 0.8478 - val_loss: 0.2342 - val_accuracy: 0.9212\n",
            "Epoch 2/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1783 - accuracy: 0.9347 - val_loss: 0.1528 - val_accuracy: 0.9413\n",
            "Epoch 3/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1378 - accuracy: 0.9431 - val_loss: 0.1337 - val_accuracy: 0.9500\n",
            "Epoch 4/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1267 - accuracy: 0.9463 - val_loss: 0.1273 - val_accuracy: 0.9550\n",
            "Epoch 5/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1214 - accuracy: 0.9496 - val_loss: 0.1240 - val_accuracy: 0.9525\n",
            "Epoch 6/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1185 - accuracy: 0.9508 - val_loss: 0.1213 - val_accuracy: 0.9538\n",
            "Epoch 7/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1157 - accuracy: 0.9510 - val_loss: 0.1204 - val_accuracy: 0.9538\n",
            "Epoch 8/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1139 - accuracy: 0.9524 - val_loss: 0.1181 - val_accuracy: 0.9525\n",
            "Epoch 9/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1116 - accuracy: 0.9528 - val_loss: 0.1179 - val_accuracy: 0.9550\n",
            "Epoch 10/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1103 - accuracy: 0.9532 - val_loss: 0.1173 - val_accuracy: 0.9525\n",
            "Epoch 11/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1086 - accuracy: 0.9542 - val_loss: 0.1170 - val_accuracy: 0.9538\n",
            "Epoch 12/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1076 - accuracy: 0.9543 - val_loss: 0.1166 - val_accuracy: 0.9513\n",
            "Epoch 13/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1069 - accuracy: 0.9536 - val_loss: 0.1163 - val_accuracy: 0.9538\n",
            "Epoch 14/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1050 - accuracy: 0.9550 - val_loss: 0.1162 - val_accuracy: 0.9525\n",
            "Epoch 15/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1037 - accuracy: 0.9565 - val_loss: 0.1168 - val_accuracy: 0.9525\n",
            "Epoch 16/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1026 - accuracy: 0.9574 - val_loss: 0.1165 - val_accuracy: 0.9538\n",
            "Epoch 17/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1014 - accuracy: 0.9576 - val_loss: 0.1163 - val_accuracy: 0.9525\n",
            "Epoch 18/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1003 - accuracy: 0.9569 - val_loss: 0.1163 - val_accuracy: 0.9513\n",
            "Epoch 19/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0992 - accuracy: 0.9599 - val_loss: 0.1157 - val_accuracy: 0.9538\n",
            "Epoch 20/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0982 - accuracy: 0.9599 - val_loss: 0.1163 - val_accuracy: 0.9525\n",
            "63/63 [==============================] - 0s 1ms/step\n",
            "Epoch 1/20\n",
            "57/57 [==============================] - 1s 6ms/step - loss: 0.4259 - accuracy: 0.8656 - val_loss: 0.2488 - val_accuracy: 0.9225\n",
            "Epoch 2/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1859 - accuracy: 0.9301 - val_loss: 0.1566 - val_accuracy: 0.9388\n",
            "Epoch 3/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9383 - val_loss: 0.1357 - val_accuracy: 0.9438\n",
            "Epoch 4/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1316 - accuracy: 0.9439 - val_loss: 0.1276 - val_accuracy: 0.9463\n",
            "Epoch 5/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1249 - accuracy: 0.9465 - val_loss: 0.1232 - val_accuracy: 0.9488\n",
            "Epoch 6/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1208 - accuracy: 0.9479 - val_loss: 0.1210 - val_accuracy: 0.9538\n",
            "Epoch 7/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1172 - accuracy: 0.9497 - val_loss: 0.1200 - val_accuracy: 0.9513\n",
            "Epoch 8/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1149 - accuracy: 0.9504 - val_loss: 0.1188 - val_accuracy: 0.9500\n",
            "Epoch 9/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1125 - accuracy: 0.9508 - val_loss: 0.1195 - val_accuracy: 0.9500\n",
            "Epoch 10/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1110 - accuracy: 0.9510 - val_loss: 0.1184 - val_accuracy: 0.9500\n",
            "Epoch 11/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1091 - accuracy: 0.9525 - val_loss: 0.1191 - val_accuracy: 0.9513\n",
            "Epoch 12/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1082 - accuracy: 0.9522 - val_loss: 0.1185 - val_accuracy: 0.9500\n",
            "Epoch 13/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1065 - accuracy: 0.9524 - val_loss: 0.1183 - val_accuracy: 0.9488\n",
            "Epoch 14/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1053 - accuracy: 0.9538 - val_loss: 0.1182 - val_accuracy: 0.9500\n",
            "Epoch 15/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1038 - accuracy: 0.9544 - val_loss: 0.1192 - val_accuracy: 0.9513\n",
            "Epoch 16/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1028 - accuracy: 0.9543 - val_loss: 0.1185 - val_accuracy: 0.9488\n",
            "Epoch 17/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1013 - accuracy: 0.9546 - val_loss: 0.1188 - val_accuracy: 0.9513\n",
            "Epoch 18/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1004 - accuracy: 0.9551 - val_loss: 0.1195 - val_accuracy: 0.9500\n",
            "Epoch 19/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.0993 - accuracy: 0.9549 - val_loss: 0.1197 - val_accuracy: 0.9488\n",
            "Epoch 20/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0989 - accuracy: 0.9557 - val_loss: 0.1203 - val_accuracy: 0.9513\n",
            "63/63 [==============================] - 0s 1ms/step\n",
            "Epoch 1/20\n",
            "57/57 [==============================] - 1s 6ms/step - loss: 0.4105 - accuracy: 0.8351 - val_loss: 0.3153 - val_accuracy: 0.9062\n",
            "Epoch 2/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.2310 - accuracy: 0.9258 - val_loss: 0.1713 - val_accuracy: 0.9388\n",
            "Epoch 3/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1501 - accuracy: 0.9404 - val_loss: 0.1321 - val_accuracy: 0.9413\n",
            "Epoch 4/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1296 - accuracy: 0.9454 - val_loss: 0.1235 - val_accuracy: 0.9450\n",
            "Epoch 5/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1217 - accuracy: 0.9474 - val_loss: 0.1206 - val_accuracy: 0.9438\n",
            "Epoch 6/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1172 - accuracy: 0.9489 - val_loss: 0.1193 - val_accuracy: 0.9438\n",
            "Epoch 7/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1135 - accuracy: 0.9504 - val_loss: 0.1184 - val_accuracy: 0.9450\n",
            "Epoch 8/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1112 - accuracy: 0.9517 - val_loss: 0.1177 - val_accuracy: 0.9450\n",
            "Epoch 9/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1089 - accuracy: 0.9525 - val_loss: 0.1168 - val_accuracy: 0.9500\n",
            "Epoch 10/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1073 - accuracy: 0.9532 - val_loss: 0.1158 - val_accuracy: 0.9488\n",
            "Epoch 11/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1056 - accuracy: 0.9539 - val_loss: 0.1169 - val_accuracy: 0.9488\n",
            "Epoch 12/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1045 - accuracy: 0.9547 - val_loss: 0.1159 - val_accuracy: 0.9475\n",
            "Epoch 13/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1032 - accuracy: 0.9560 - val_loss: 0.1151 - val_accuracy: 0.9513\n",
            "Epoch 14/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1018 - accuracy: 0.9557 - val_loss: 0.1146 - val_accuracy: 0.9513\n",
            "Epoch 15/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1008 - accuracy: 0.9557 - val_loss: 0.1153 - val_accuracy: 0.9500\n",
            "Epoch 16/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.0995 - accuracy: 0.9567 - val_loss: 0.1145 - val_accuracy: 0.9488\n",
            "Epoch 17/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0984 - accuracy: 0.9575 - val_loss: 0.1145 - val_accuracy: 0.9500\n",
            "Epoch 18/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0977 - accuracy: 0.9578 - val_loss: 0.1144 - val_accuracy: 0.9488\n",
            "Epoch 19/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0965 - accuracy: 0.9568 - val_loss: 0.1142 - val_accuracy: 0.9500\n",
            "Epoch 20/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0961 - accuracy: 0.9588 - val_loss: 0.1143 - val_accuracy: 0.9475\n",
            "63/63 [==============================] - 0s 2ms/step\n",
            "Epoch 1/20\n",
            "57/57 [==============================] - 1s 6ms/step - loss: 0.4286 - accuracy: 0.8075 - val_loss: 0.2618 - val_accuracy: 0.9062\n",
            "Epoch 2/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1934 - accuracy: 0.9324 - val_loss: 0.1683 - val_accuracy: 0.9413\n",
            "Epoch 3/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1417 - accuracy: 0.9444 - val_loss: 0.1426 - val_accuracy: 0.9388\n",
            "Epoch 4/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1256 - accuracy: 0.9476 - val_loss: 0.1344 - val_accuracy: 0.9438\n",
            "Epoch 5/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1192 - accuracy: 0.9503 - val_loss: 0.1313 - val_accuracy: 0.9463\n",
            "Epoch 6/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1161 - accuracy: 0.9514 - val_loss: 0.1303 - val_accuracy: 0.9475\n",
            "Epoch 7/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1139 - accuracy: 0.9522 - val_loss: 0.1300 - val_accuracy: 0.9513\n",
            "Epoch 8/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1127 - accuracy: 0.9521 - val_loss: 0.1290 - val_accuracy: 0.9500\n",
            "Epoch 9/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1102 - accuracy: 0.9529 - val_loss: 0.1280 - val_accuracy: 0.9488\n",
            "Epoch 10/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1092 - accuracy: 0.9532 - val_loss: 0.1272 - val_accuracy: 0.9500\n",
            "Epoch 11/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1082 - accuracy: 0.9538 - val_loss: 0.1268 - val_accuracy: 0.9500\n",
            "Epoch 12/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1069 - accuracy: 0.9542 - val_loss: 0.1266 - val_accuracy: 0.9500\n",
            "Epoch 13/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1059 - accuracy: 0.9547 - val_loss: 0.1263 - val_accuracy: 0.9475\n",
            "Epoch 14/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1049 - accuracy: 0.9554 - val_loss: 0.1256 - val_accuracy: 0.9488\n",
            "Epoch 15/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1040 - accuracy: 0.9560 - val_loss: 0.1257 - val_accuracy: 0.9488\n",
            "Epoch 16/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1029 - accuracy: 0.9565 - val_loss: 0.1252 - val_accuracy: 0.9475\n",
            "Epoch 17/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1020 - accuracy: 0.9557 - val_loss: 0.1253 - val_accuracy: 0.9463\n",
            "Epoch 18/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1009 - accuracy: 0.9579 - val_loss: 0.1254 - val_accuracy: 0.9450\n",
            "Epoch 19/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1001 - accuracy: 0.9581 - val_loss: 0.1253 - val_accuracy: 0.9475\n",
            "Epoch 20/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0995 - accuracy: 0.9581 - val_loss: 0.1255 - val_accuracy: 0.9450\n",
            "63/63 [==============================] - 0s 1ms/step\n",
            "Epoch 1/20\n",
            "57/57 [==============================] - 1s 6ms/step - loss: 0.4056 - accuracy: 0.8203 - val_loss: 0.2187 - val_accuracy: 0.9287\n",
            "Epoch 2/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1893 - accuracy: 0.9265 - val_loss: 0.1498 - val_accuracy: 0.9438\n",
            "Epoch 3/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9413 - val_loss: 0.1287 - val_accuracy: 0.9488\n",
            "Epoch 4/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1279 - accuracy: 0.9478 - val_loss: 0.1216 - val_accuracy: 0.9488\n",
            "Epoch 5/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1205 - accuracy: 0.9497 - val_loss: 0.1181 - val_accuracy: 0.9538\n",
            "Epoch 6/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1155 - accuracy: 0.9526 - val_loss: 0.1176 - val_accuracy: 0.9538\n",
            "Epoch 7/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1119 - accuracy: 0.9522 - val_loss: 0.1166 - val_accuracy: 0.9538\n",
            "Epoch 8/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1101 - accuracy: 0.9526 - val_loss: 0.1163 - val_accuracy: 0.9550\n",
            "Epoch 9/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1076 - accuracy: 0.9550 - val_loss: 0.1131 - val_accuracy: 0.9563\n",
            "Epoch 10/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1063 - accuracy: 0.9553 - val_loss: 0.1132 - val_accuracy: 0.9550\n",
            "Epoch 11/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1049 - accuracy: 0.9550 - val_loss: 0.1131 - val_accuracy: 0.9525\n",
            "Epoch 12/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1036 - accuracy: 0.9560 - val_loss: 0.1146 - val_accuracy: 0.9475\n",
            "Epoch 13/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1019 - accuracy: 0.9574 - val_loss: 0.1121 - val_accuracy: 0.9538\n",
            "Epoch 14/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1010 - accuracy: 0.9571 - val_loss: 0.1133 - val_accuracy: 0.9513\n",
            "Epoch 15/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1000 - accuracy: 0.9578 - val_loss: 0.1111 - val_accuracy: 0.9563\n",
            "Epoch 16/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0988 - accuracy: 0.9578 - val_loss: 0.1147 - val_accuracy: 0.9475\n",
            "Epoch 17/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0981 - accuracy: 0.9579 - val_loss: 0.1145 - val_accuracy: 0.9488\n",
            "Epoch 18/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0970 - accuracy: 0.9592 - val_loss: 0.1145 - val_accuracy: 0.9475\n",
            "Epoch 19/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0960 - accuracy: 0.9589 - val_loss: 0.1138 - val_accuracy: 0.9500\n",
            "Epoch 20/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0949 - accuracy: 0.9607 - val_loss: 0.1146 - val_accuracy: 0.9463\n",
            "63/63 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newdata.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "05ryfvyLzFVK",
        "outputId": "87b58981-daf2-4beb-d0f1-5d3dac8e03dd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   SVM  KNN  RF  LR  ANN  XGB  y_test\n",
              "0    0    0   0   0    0    0       0\n",
              "1    0    0   0   0    0    0       0\n",
              "2    0    0   0   0    0    0       0\n",
              "3    0    0   0   0    0    0       0\n",
              "4    0    0   0   0    0    0       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e5776ce8-d41b-4ee3-868b-0c89069d5b9b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SVM</th>\n",
              "      <th>KNN</th>\n",
              "      <th>RF</th>\n",
              "      <th>LR</th>\n",
              "      <th>ANN</th>\n",
              "      <th>XGB</th>\n",
              "      <th>y_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5776ce8-d41b-4ee3-868b-0c89069d5b9b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e5776ce8-d41b-4ee3-868b-0c89069d5b9b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e5776ce8-d41b-4ee3-868b-0c89069d5b9b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the DNN model\n",
        "DNNX = newdata.drop(columns=['y_test']).copy()\n",
        "DNNY = newdata.y_test.copy()\n",
        "DX_train, DX_test, Dy_train, Dy_test = train_test_split(\n",
        "    DNNX, DNNY, test_size=0.2, random_state=123)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(30, activation='relu', input_shape=DNNX.shape[1:]),\n",
        "    tf.keras.layers.Dense(25, activation='relu'),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dense(15, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(DX_train, Dy_train, epochs=500, batch_size=64, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4kf97a3yX15",
        "outputId": "d3090ed4-9fef-4c6c-b606-5a866af30572"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "100/100 [==============================] - 2s 5ms/step - loss: 0.5943 - accuracy: 0.9377 - val_loss: 0.4625 - val_accuracy: 0.9419\n",
            "Epoch 2/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.9448 - val_loss: 0.4202 - val_accuracy: 0.9475\n",
            "Epoch 3/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.9497 - val_loss: 0.3982 - val_accuracy: 0.9531\n",
            "Epoch 4/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.9497 - val_loss: 0.3716 - val_accuracy: 0.9525\n",
            "Epoch 5/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.3829 - accuracy: 0.9506 - val_loss: 0.3533 - val_accuracy: 0.9519\n",
            "Epoch 6/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.3644 - accuracy: 0.9511 - val_loss: 0.3374 - val_accuracy: 0.9519\n",
            "Epoch 7/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3472 - accuracy: 0.9506 - val_loss: 0.3227 - val_accuracy: 0.9519\n",
            "Epoch 8/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.3318 - accuracy: 0.9517 - val_loss: 0.3100 - val_accuracy: 0.9519\n",
            "Epoch 9/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.3180 - accuracy: 0.9500 - val_loss: 0.3128 - val_accuracy: 0.9525\n",
            "Epoch 10/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.3058 - accuracy: 0.9509 - val_loss: 0.2844 - val_accuracy: 0.9519\n",
            "Epoch 11/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2928 - accuracy: 0.9511 - val_loss: 0.2783 - val_accuracy: 0.9519\n",
            "Epoch 12/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2827 - accuracy: 0.9514 - val_loss: 0.2654 - val_accuracy: 0.9525\n",
            "Epoch 13/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2726 - accuracy: 0.9517 - val_loss: 0.2559 - val_accuracy: 0.9519\n",
            "Epoch 14/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2632 - accuracy: 0.9516 - val_loss: 0.2472 - val_accuracy: 0.9519\n",
            "Epoch 15/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2554 - accuracy: 0.9519 - val_loss: 0.2387 - val_accuracy: 0.9519\n",
            "Epoch 16/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2475 - accuracy: 0.9517 - val_loss: 0.2328 - val_accuracy: 0.9525\n",
            "Epoch 17/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2400 - accuracy: 0.9520 - val_loss: 0.2256 - val_accuracy: 0.9488\n",
            "Epoch 18/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2342 - accuracy: 0.9525 - val_loss: 0.2204 - val_accuracy: 0.9494\n",
            "Epoch 19/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2282 - accuracy: 0.9520 - val_loss: 0.2145 - val_accuracy: 0.9494\n",
            "Epoch 20/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2223 - accuracy: 0.9530 - val_loss: 0.2074 - val_accuracy: 0.9488\n",
            "Epoch 21/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2172 - accuracy: 0.9523 - val_loss: 0.2054 - val_accuracy: 0.9494\n",
            "Epoch 22/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2125 - accuracy: 0.9516 - val_loss: 0.1988 - val_accuracy: 0.9494\n",
            "Epoch 23/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2080 - accuracy: 0.9523 - val_loss: 0.1938 - val_accuracy: 0.9494\n",
            "Epoch 24/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2027 - accuracy: 0.9523 - val_loss: 0.1911 - val_accuracy: 0.9494\n",
            "Epoch 25/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1996 - accuracy: 0.9531 - val_loss: 0.1906 - val_accuracy: 0.9525\n",
            "Epoch 26/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1957 - accuracy: 0.9516 - val_loss: 0.1854 - val_accuracy: 0.9525\n",
            "Epoch 27/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1927 - accuracy: 0.9522 - val_loss: 0.1814 - val_accuracy: 0.9500\n",
            "Epoch 28/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1894 - accuracy: 0.9523 - val_loss: 0.1809 - val_accuracy: 0.9519\n",
            "Epoch 29/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1892 - accuracy: 0.9527 - val_loss: 0.1740 - val_accuracy: 0.9519\n",
            "Epoch 30/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1834 - accuracy: 0.9522 - val_loss: 0.1724 - val_accuracy: 0.9488\n",
            "Epoch 31/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1815 - accuracy: 0.9523 - val_loss: 0.1743 - val_accuracy: 0.9525\n",
            "Epoch 32/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1792 - accuracy: 0.9522 - val_loss: 0.1684 - val_accuracy: 0.9494\n",
            "Epoch 33/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1774 - accuracy: 0.9530 - val_loss: 0.1692 - val_accuracy: 0.9525\n",
            "Epoch 34/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1746 - accuracy: 0.9530 - val_loss: 0.1640 - val_accuracy: 0.9488\n",
            "Epoch 35/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1728 - accuracy: 0.9530 - val_loss: 0.1615 - val_accuracy: 0.9488\n",
            "Epoch 36/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1711 - accuracy: 0.9527 - val_loss: 0.1615 - val_accuracy: 0.9463\n",
            "Epoch 37/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1701 - accuracy: 0.9530 - val_loss: 0.1598 - val_accuracy: 0.9525\n",
            "Epoch 38/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1679 - accuracy: 0.9527 - val_loss: 0.1628 - val_accuracy: 0.9525\n",
            "Epoch 39/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1668 - accuracy: 0.9533 - val_loss: 0.1598 - val_accuracy: 0.9519\n",
            "Epoch 40/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1653 - accuracy: 0.9516 - val_loss: 0.1539 - val_accuracy: 0.9500\n",
            "Epoch 41/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1640 - accuracy: 0.9527 - val_loss: 0.1532 - val_accuracy: 0.9506\n",
            "Epoch 42/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1634 - accuracy: 0.9523 - val_loss: 0.1540 - val_accuracy: 0.9519\n",
            "Epoch 43/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1621 - accuracy: 0.9528 - val_loss: 0.1522 - val_accuracy: 0.9531\n",
            "Epoch 44/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1612 - accuracy: 0.9533 - val_loss: 0.1512 - val_accuracy: 0.9488\n",
            "Epoch 45/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1601 - accuracy: 0.9517 - val_loss: 0.1504 - val_accuracy: 0.9519\n",
            "Epoch 46/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1592 - accuracy: 0.9525 - val_loss: 0.1494 - val_accuracy: 0.9519\n",
            "Epoch 47/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1588 - accuracy: 0.9530 - val_loss: 0.1590 - val_accuracy: 0.9531\n",
            "Epoch 48/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1580 - accuracy: 0.9531 - val_loss: 0.1477 - val_accuracy: 0.9494\n",
            "Epoch 49/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1571 - accuracy: 0.9531 - val_loss: 0.1476 - val_accuracy: 0.9531\n",
            "Epoch 50/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1566 - accuracy: 0.9528 - val_loss: 0.1488 - val_accuracy: 0.9531\n",
            "Epoch 51/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1555 - accuracy: 0.9527 - val_loss: 0.1477 - val_accuracy: 0.9531\n",
            "Epoch 52/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1554 - accuracy: 0.9531 - val_loss: 0.1450 - val_accuracy: 0.9531\n",
            "Epoch 53/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1544 - accuracy: 0.9533 - val_loss: 0.1445 - val_accuracy: 0.9519\n",
            "Epoch 54/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1543 - accuracy: 0.9530 - val_loss: 0.1464 - val_accuracy: 0.9519\n",
            "Epoch 55/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1539 - accuracy: 0.9522 - val_loss: 0.1438 - val_accuracy: 0.9544\n",
            "Epoch 56/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1537 - accuracy: 0.9525 - val_loss: 0.1443 - val_accuracy: 0.9544\n",
            "Epoch 57/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1539 - accuracy: 0.9523 - val_loss: 0.1453 - val_accuracy: 0.9544\n",
            "Epoch 58/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1528 - accuracy: 0.9542 - val_loss: 0.1437 - val_accuracy: 0.9519\n",
            "Epoch 59/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1522 - accuracy: 0.9531 - val_loss: 0.1426 - val_accuracy: 0.9544\n",
            "Epoch 60/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1530 - accuracy: 0.9528 - val_loss: 0.1446 - val_accuracy: 0.9519\n",
            "Epoch 61/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1514 - accuracy: 0.9530 - val_loss: 0.1480 - val_accuracy: 0.9519\n",
            "Epoch 62/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1535 - accuracy: 0.9522 - val_loss: 0.1444 - val_accuracy: 0.9519\n",
            "Epoch 63/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1527 - accuracy: 0.9522 - val_loss: 0.1439 - val_accuracy: 0.9544\n",
            "Epoch 64/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1511 - accuracy: 0.9533 - val_loss: 0.1433 - val_accuracy: 0.9469\n",
            "Epoch 65/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1515 - accuracy: 0.9528 - val_loss: 0.1428 - val_accuracy: 0.9544\n",
            "Epoch 66/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1511 - accuracy: 0.9530 - val_loss: 0.1467 - val_accuracy: 0.9544\n",
            "Epoch 67/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1507 - accuracy: 0.9538 - val_loss: 0.1430 - val_accuracy: 0.9475\n",
            "Epoch 68/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1505 - accuracy: 0.9527 - val_loss: 0.1420 - val_accuracy: 0.9513\n",
            "Epoch 69/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1503 - accuracy: 0.9544 - val_loss: 0.1417 - val_accuracy: 0.9531\n",
            "Epoch 70/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1501 - accuracy: 0.9525 - val_loss: 0.1429 - val_accuracy: 0.9544\n",
            "Epoch 71/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1511 - accuracy: 0.9519 - val_loss: 0.1421 - val_accuracy: 0.9519\n",
            "Epoch 72/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1499 - accuracy: 0.9533 - val_loss: 0.1471 - val_accuracy: 0.9544\n",
            "Epoch 73/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1506 - accuracy: 0.9525 - val_loss: 0.1492 - val_accuracy: 0.9538\n",
            "Epoch 74/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1504 - accuracy: 0.9527 - val_loss: 0.1416 - val_accuracy: 0.9544\n",
            "Epoch 75/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1494 - accuracy: 0.9534 - val_loss: 0.1412 - val_accuracy: 0.9544\n",
            "Epoch 76/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1497 - accuracy: 0.9539 - val_loss: 0.1416 - val_accuracy: 0.9531\n",
            "Epoch 77/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1492 - accuracy: 0.9541 - val_loss: 0.1418 - val_accuracy: 0.9519\n",
            "Epoch 78/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1499 - accuracy: 0.9536 - val_loss: 0.1413 - val_accuracy: 0.9519\n",
            "Epoch 79/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1495 - accuracy: 0.9538 - val_loss: 0.1420 - val_accuracy: 0.9544\n",
            "Epoch 80/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1491 - accuracy: 0.9536 - val_loss: 0.1412 - val_accuracy: 0.9519\n",
            "Epoch 81/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1496 - accuracy: 0.9534 - val_loss: 0.1462 - val_accuracy: 0.9538\n",
            "Epoch 82/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1507 - accuracy: 0.9531 - val_loss: 0.1424 - val_accuracy: 0.9544\n",
            "Epoch 83/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1491 - accuracy: 0.9531 - val_loss: 0.1447 - val_accuracy: 0.9531\n",
            "Epoch 84/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1491 - accuracy: 0.9527 - val_loss: 0.1418 - val_accuracy: 0.9531\n",
            "Epoch 85/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1496 - accuracy: 0.9530 - val_loss: 0.1459 - val_accuracy: 0.9519\n",
            "Epoch 86/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1506 - accuracy: 0.9533 - val_loss: 0.1417 - val_accuracy: 0.9494\n",
            "Epoch 87/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1504 - accuracy: 0.9531 - val_loss: 0.1436 - val_accuracy: 0.9538\n",
            "Epoch 88/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1494 - accuracy: 0.9516 - val_loss: 0.1405 - val_accuracy: 0.9544\n",
            "Epoch 89/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1490 - accuracy: 0.9528 - val_loss: 0.1406 - val_accuracy: 0.9519\n",
            "Epoch 90/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1496 - accuracy: 0.9545 - val_loss: 0.1423 - val_accuracy: 0.9544\n",
            "Epoch 91/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1491 - accuracy: 0.9525 - val_loss: 0.1458 - val_accuracy: 0.9538\n",
            "Epoch 92/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1495 - accuracy: 0.9539 - val_loss: 0.1415 - val_accuracy: 0.9544\n",
            "Epoch 93/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1495 - accuracy: 0.9533 - val_loss: 0.1410 - val_accuracy: 0.9519\n",
            "Epoch 94/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9541 - val_loss: 0.1427 - val_accuracy: 0.9469\n",
            "Epoch 95/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1489 - accuracy: 0.9547 - val_loss: 0.1412 - val_accuracy: 0.9494\n",
            "Epoch 96/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1488 - accuracy: 0.9530 - val_loss: 0.1420 - val_accuracy: 0.9519\n",
            "Epoch 97/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1495 - accuracy: 0.9533 - val_loss: 0.1432 - val_accuracy: 0.9544\n",
            "Epoch 98/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1498 - accuracy: 0.9527 - val_loss: 0.1412 - val_accuracy: 0.9531\n",
            "Epoch 99/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1487 - accuracy: 0.9539 - val_loss: 0.1414 - val_accuracy: 0.9513\n",
            "Epoch 100/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1486 - accuracy: 0.9538 - val_loss: 0.1430 - val_accuracy: 0.9519\n",
            "Epoch 101/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1488 - accuracy: 0.9548 - val_loss: 0.1416 - val_accuracy: 0.9544\n",
            "Epoch 102/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1490 - accuracy: 0.9527 - val_loss: 0.1420 - val_accuracy: 0.9513\n",
            "Epoch 103/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1497 - accuracy: 0.9530 - val_loss: 0.1413 - val_accuracy: 0.9544\n",
            "Epoch 104/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1494 - accuracy: 0.9534 - val_loss: 0.1435 - val_accuracy: 0.9544\n",
            "Epoch 105/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1486 - accuracy: 0.9539 - val_loss: 0.1449 - val_accuracy: 0.9519\n",
            "Epoch 106/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1486 - accuracy: 0.9525 - val_loss: 0.1409 - val_accuracy: 0.9519\n",
            "Epoch 107/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1487 - accuracy: 0.9538 - val_loss: 0.1434 - val_accuracy: 0.9538\n",
            "Epoch 108/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1485 - accuracy: 0.9531 - val_loss: 0.1467 - val_accuracy: 0.9538\n",
            "Epoch 109/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1483 - accuracy: 0.9530 - val_loss: 0.1411 - val_accuracy: 0.9544\n",
            "Epoch 110/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1489 - accuracy: 0.9534 - val_loss: 0.1483 - val_accuracy: 0.9544\n",
            "Epoch 111/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1487 - accuracy: 0.9539 - val_loss: 0.1421 - val_accuracy: 0.9513\n",
            "Epoch 112/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1483 - accuracy: 0.9542 - val_loss: 0.1411 - val_accuracy: 0.9544\n",
            "Epoch 113/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1490 - accuracy: 0.9538 - val_loss: 0.1450 - val_accuracy: 0.9544\n",
            "Epoch 114/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1480 - accuracy: 0.9534 - val_loss: 0.1425 - val_accuracy: 0.9531\n",
            "Epoch 115/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1489 - accuracy: 0.9533 - val_loss: 0.1438 - val_accuracy: 0.9544\n",
            "Epoch 116/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1485 - accuracy: 0.9528 - val_loss: 0.1404 - val_accuracy: 0.9513\n",
            "Epoch 117/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1483 - accuracy: 0.9539 - val_loss: 0.1441 - val_accuracy: 0.9531\n",
            "Epoch 118/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1495 - accuracy: 0.9536 - val_loss: 0.1423 - val_accuracy: 0.9494\n",
            "Epoch 119/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1488 - accuracy: 0.9538 - val_loss: 0.1424 - val_accuracy: 0.9538\n",
            "Epoch 120/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1490 - accuracy: 0.9539 - val_loss: 0.1423 - val_accuracy: 0.9531\n",
            "Epoch 121/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1484 - accuracy: 0.9545 - val_loss: 0.1417 - val_accuracy: 0.9519\n",
            "Epoch 122/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1493 - accuracy: 0.9538 - val_loss: 0.1412 - val_accuracy: 0.9513\n",
            "Epoch 123/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1489 - accuracy: 0.9533 - val_loss: 0.1427 - val_accuracy: 0.9531\n",
            "Epoch 124/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1493 - accuracy: 0.9528 - val_loss: 0.1459 - val_accuracy: 0.9519\n",
            "Epoch 125/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1488 - accuracy: 0.9542 - val_loss: 0.1432 - val_accuracy: 0.9544\n",
            "Epoch 126/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1484 - accuracy: 0.9541 - val_loss: 0.1434 - val_accuracy: 0.9544\n",
            "Epoch 127/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1484 - accuracy: 0.9539 - val_loss: 0.1429 - val_accuracy: 0.9544\n",
            "Epoch 128/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1483 - accuracy: 0.9534 - val_loss: 0.1428 - val_accuracy: 0.9469\n",
            "Epoch 129/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1488 - accuracy: 0.9536 - val_loss: 0.1460 - val_accuracy: 0.9531\n",
            "Epoch 130/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1491 - accuracy: 0.9531 - val_loss: 0.1436 - val_accuracy: 0.9531\n",
            "Epoch 131/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9531 - val_loss: 0.1412 - val_accuracy: 0.9544\n",
            "Epoch 132/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9538 - val_loss: 0.1421 - val_accuracy: 0.9525\n",
            "Epoch 133/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1487 - accuracy: 0.9542 - val_loss: 0.1434 - val_accuracy: 0.9544\n",
            "Epoch 134/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1488 - accuracy: 0.9528 - val_loss: 0.1452 - val_accuracy: 0.9538\n",
            "Epoch 135/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9541 - val_loss: 0.1421 - val_accuracy: 0.9469\n",
            "Epoch 136/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1484 - accuracy: 0.9528 - val_loss: 0.1411 - val_accuracy: 0.9550\n",
            "Epoch 137/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1489 - accuracy: 0.9533 - val_loss: 0.1454 - val_accuracy: 0.9538\n",
            "Epoch 138/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1490 - accuracy: 0.9527 - val_loss: 0.1443 - val_accuracy: 0.9531\n",
            "Epoch 139/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1494 - accuracy: 0.9544 - val_loss: 0.1429 - val_accuracy: 0.9544\n",
            "Epoch 140/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9534 - val_loss: 0.1423 - val_accuracy: 0.9494\n",
            "Epoch 141/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1493 - accuracy: 0.9538 - val_loss: 0.1437 - val_accuracy: 0.9538\n",
            "Epoch 142/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1483 - accuracy: 0.9539 - val_loss: 0.1421 - val_accuracy: 0.9544\n",
            "Epoch 143/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1484 - accuracy: 0.9530 - val_loss: 0.1415 - val_accuracy: 0.9500\n",
            "Epoch 144/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9533 - val_loss: 0.1427 - val_accuracy: 0.9538\n",
            "Epoch 145/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1485 - accuracy: 0.9548 - val_loss: 0.1417 - val_accuracy: 0.9519\n",
            "Epoch 146/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1484 - accuracy: 0.9541 - val_loss: 0.1410 - val_accuracy: 0.9544\n",
            "Epoch 147/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1485 - accuracy: 0.9536 - val_loss: 0.1453 - val_accuracy: 0.9538\n",
            "Epoch 148/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.1483 - accuracy: 0.9534 - val_loss: 0.1425 - val_accuracy: 0.9519\n",
            "Epoch 149/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1490 - accuracy: 0.9539 - val_loss: 0.1417 - val_accuracy: 0.9519\n",
            "Epoch 150/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1482 - accuracy: 0.9542 - val_loss: 0.1421 - val_accuracy: 0.9538\n",
            "Epoch 151/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1485 - accuracy: 0.9530 - val_loss: 0.1416 - val_accuracy: 0.9519\n",
            "Epoch 152/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9538 - val_loss: 0.1445 - val_accuracy: 0.9538\n",
            "Epoch 153/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1489 - accuracy: 0.9534 - val_loss: 0.1414 - val_accuracy: 0.9544\n",
            "Epoch 154/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9533 - val_loss: 0.1428 - val_accuracy: 0.9538\n",
            "Epoch 155/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1486 - accuracy: 0.9520 - val_loss: 0.1409 - val_accuracy: 0.9550\n",
            "Epoch 156/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1488 - accuracy: 0.9539 - val_loss: 0.1413 - val_accuracy: 0.9544\n",
            "Epoch 157/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1478 - accuracy: 0.9550 - val_loss: 0.1434 - val_accuracy: 0.9525\n",
            "Epoch 158/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9531 - val_loss: 0.1411 - val_accuracy: 0.9519\n",
            "Epoch 159/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1487 - accuracy: 0.9533 - val_loss: 0.1417 - val_accuracy: 0.9550\n",
            "Epoch 160/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9542 - val_loss: 0.1425 - val_accuracy: 0.9544\n",
            "Epoch 161/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1482 - accuracy: 0.9538 - val_loss: 0.1416 - val_accuracy: 0.9550\n",
            "Epoch 162/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9545 - val_loss: 0.1424 - val_accuracy: 0.9525\n",
            "Epoch 163/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1484 - accuracy: 0.9530 - val_loss: 0.1433 - val_accuracy: 0.9525\n",
            "Epoch 164/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1484 - accuracy: 0.9542 - val_loss: 0.1438 - val_accuracy: 0.9519\n",
            "Epoch 165/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1487 - accuracy: 0.9541 - val_loss: 0.1447 - val_accuracy: 0.9538\n",
            "Epoch 166/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1483 - accuracy: 0.9533 - val_loss: 0.1426 - val_accuracy: 0.9538\n",
            "Epoch 167/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1483 - accuracy: 0.9536 - val_loss: 0.1418 - val_accuracy: 0.9544\n",
            "Epoch 168/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1486 - accuracy: 0.9530 - val_loss: 0.1427 - val_accuracy: 0.9538\n",
            "Epoch 169/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1489 - accuracy: 0.9534 - val_loss: 0.1440 - val_accuracy: 0.9544\n",
            "Epoch 170/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9544 - val_loss: 0.1439 - val_accuracy: 0.9544\n",
            "Epoch 171/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1486 - accuracy: 0.9525 - val_loss: 0.1440 - val_accuracy: 0.9544\n",
            "Epoch 172/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1483 - accuracy: 0.9542 - val_loss: 0.1421 - val_accuracy: 0.9525\n",
            "Epoch 173/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9527 - val_loss: 0.1435 - val_accuracy: 0.9463\n",
            "Epoch 174/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9553 - val_loss: 0.1433 - val_accuracy: 0.9519\n",
            "Epoch 175/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9538 - val_loss: 0.1419 - val_accuracy: 0.9519\n",
            "Epoch 176/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9538 - val_loss: 0.1449 - val_accuracy: 0.9544\n",
            "Epoch 177/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1490 - accuracy: 0.9534 - val_loss: 0.1416 - val_accuracy: 0.9513\n",
            "Epoch 178/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1486 - accuracy: 0.9530 - val_loss: 0.1438 - val_accuracy: 0.9531\n",
            "Epoch 179/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1487 - accuracy: 0.9539 - val_loss: 0.1415 - val_accuracy: 0.9525\n",
            "Epoch 180/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1487 - accuracy: 0.9536 - val_loss: 0.1436 - val_accuracy: 0.9475\n",
            "Epoch 181/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1489 - accuracy: 0.9538 - val_loss: 0.1416 - val_accuracy: 0.9550\n",
            "Epoch 182/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1485 - accuracy: 0.9538 - val_loss: 0.1422 - val_accuracy: 0.9538\n",
            "Epoch 183/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1481 - accuracy: 0.9538 - val_loss: 0.1443 - val_accuracy: 0.9531\n",
            "Epoch 184/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1481 - accuracy: 0.9536 - val_loss: 0.1474 - val_accuracy: 0.9538\n",
            "Epoch 185/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1492 - accuracy: 0.9533 - val_loss: 0.1444 - val_accuracy: 0.9538\n",
            "Epoch 186/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1485 - accuracy: 0.9527 - val_loss: 0.1428 - val_accuracy: 0.9531\n",
            "Epoch 187/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1485 - accuracy: 0.9533 - val_loss: 0.1424 - val_accuracy: 0.9538\n",
            "Epoch 188/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1488 - accuracy: 0.9541 - val_loss: 0.1424 - val_accuracy: 0.9544\n",
            "Epoch 189/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1495 - accuracy: 0.9536 - val_loss: 0.1428 - val_accuracy: 0.9544\n",
            "Epoch 190/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1484 - accuracy: 0.9539 - val_loss: 0.1419 - val_accuracy: 0.9519\n",
            "Epoch 191/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1483 - accuracy: 0.9545 - val_loss: 0.1434 - val_accuracy: 0.9544\n",
            "Epoch 192/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1484 - accuracy: 0.9545 - val_loss: 0.1419 - val_accuracy: 0.9544\n",
            "Epoch 193/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9541 - val_loss: 0.1411 - val_accuracy: 0.9519\n",
            "Epoch 194/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1485 - accuracy: 0.9530 - val_loss: 0.1425 - val_accuracy: 0.9550\n",
            "Epoch 195/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1478 - accuracy: 0.9539 - val_loss: 0.1433 - val_accuracy: 0.9525\n",
            "Epoch 196/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1487 - accuracy: 0.9541 - val_loss: 0.1435 - val_accuracy: 0.9525\n",
            "Epoch 197/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9538 - val_loss: 0.1438 - val_accuracy: 0.9538\n",
            "Epoch 198/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9531 - val_loss: 0.1418 - val_accuracy: 0.9519\n",
            "Epoch 199/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1477 - accuracy: 0.9538 - val_loss: 0.1423 - val_accuracy: 0.9544\n",
            "Epoch 200/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1483 - accuracy: 0.9533 - val_loss: 0.1416 - val_accuracy: 0.9519\n",
            "Epoch 201/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9541 - val_loss: 0.1426 - val_accuracy: 0.9488\n",
            "Epoch 202/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1486 - accuracy: 0.9547 - val_loss: 0.1418 - val_accuracy: 0.9550\n",
            "Epoch 203/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9541 - val_loss: 0.1435 - val_accuracy: 0.9519\n",
            "Epoch 204/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1485 - accuracy: 0.9536 - val_loss: 0.1437 - val_accuracy: 0.9519\n",
            "Epoch 205/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9539 - val_loss: 0.1434 - val_accuracy: 0.9538\n",
            "Epoch 206/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1471 - accuracy: 0.9550 - val_loss: 0.1459 - val_accuracy: 0.9469\n",
            "Epoch 207/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1489 - accuracy: 0.9522 - val_loss: 0.1438 - val_accuracy: 0.9531\n",
            "Epoch 208/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1483 - accuracy: 0.9538 - val_loss: 0.1454 - val_accuracy: 0.9531\n",
            "Epoch 209/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9536 - val_loss: 0.1430 - val_accuracy: 0.9538\n",
            "Epoch 210/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9536 - val_loss: 0.1449 - val_accuracy: 0.9544\n",
            "Epoch 211/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9533 - val_loss: 0.1427 - val_accuracy: 0.9544\n",
            "Epoch 212/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1483 - accuracy: 0.9536 - val_loss: 0.1451 - val_accuracy: 0.9519\n",
            "Epoch 213/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1478 - accuracy: 0.9530 - val_loss: 0.1471 - val_accuracy: 0.9538\n",
            "Epoch 214/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1484 - accuracy: 0.9534 - val_loss: 0.1438 - val_accuracy: 0.9525\n",
            "Epoch 215/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1482 - accuracy: 0.9542 - val_loss: 0.1433 - val_accuracy: 0.9519\n",
            "Epoch 216/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1475 - accuracy: 0.9541 - val_loss: 0.1444 - val_accuracy: 0.9538\n",
            "Epoch 217/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1477 - accuracy: 0.9547 - val_loss: 0.1427 - val_accuracy: 0.9538\n",
            "Epoch 218/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1486 - accuracy: 0.9541 - val_loss: 0.1422 - val_accuracy: 0.9538\n",
            "Epoch 219/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1493 - accuracy: 0.9534 - val_loss: 0.1419 - val_accuracy: 0.9550\n",
            "Epoch 220/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9530 - val_loss: 0.1430 - val_accuracy: 0.9519\n",
            "Epoch 221/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1483 - accuracy: 0.9534 - val_loss: 0.1426 - val_accuracy: 0.9538\n",
            "Epoch 222/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1489 - accuracy: 0.9542 - val_loss: 0.1429 - val_accuracy: 0.9538\n",
            "Epoch 223/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9534 - val_loss: 0.1425 - val_accuracy: 0.9531\n",
            "Epoch 224/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9542 - val_loss: 0.1412 - val_accuracy: 0.9544\n",
            "Epoch 225/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1481 - accuracy: 0.9536 - val_loss: 0.1464 - val_accuracy: 0.9538\n",
            "Epoch 226/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9536 - val_loss: 0.1420 - val_accuracy: 0.9513\n",
            "Epoch 227/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9544 - val_loss: 0.1448 - val_accuracy: 0.9538\n",
            "Epoch 228/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9514 - val_loss: 0.1422 - val_accuracy: 0.9513\n",
            "Epoch 229/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9517 - val_loss: 0.1491 - val_accuracy: 0.9538\n",
            "Epoch 230/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1486 - accuracy: 0.9545 - val_loss: 0.1422 - val_accuracy: 0.9544\n",
            "Epoch 231/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9533 - val_loss: 0.1428 - val_accuracy: 0.9538\n",
            "Epoch 232/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9534 - val_loss: 0.1440 - val_accuracy: 0.9519\n",
            "Epoch 233/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1486 - accuracy: 0.9525 - val_loss: 0.1455 - val_accuracy: 0.9538\n",
            "Epoch 234/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9539 - val_loss: 0.1427 - val_accuracy: 0.9531\n",
            "Epoch 235/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9539 - val_loss: 0.1421 - val_accuracy: 0.9550\n",
            "Epoch 236/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9542 - val_loss: 0.1449 - val_accuracy: 0.9538\n",
            "Epoch 237/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1487 - accuracy: 0.9530 - val_loss: 0.1427 - val_accuracy: 0.9550\n",
            "Epoch 238/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1485 - accuracy: 0.9542 - val_loss: 0.1438 - val_accuracy: 0.9538\n",
            "Epoch 239/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9536 - val_loss: 0.1443 - val_accuracy: 0.9531\n",
            "Epoch 240/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9545 - val_loss: 0.1411 - val_accuracy: 0.9550\n",
            "Epoch 241/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9539 - val_loss: 0.1422 - val_accuracy: 0.9544\n",
            "Epoch 242/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9545 - val_loss: 0.1417 - val_accuracy: 0.9544\n",
            "Epoch 243/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9534 - val_loss: 0.1423 - val_accuracy: 0.9544\n",
            "Epoch 244/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1473 - accuracy: 0.9539 - val_loss: 0.1518 - val_accuracy: 0.9506\n",
            "Epoch 245/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9545 - val_loss: 0.1429 - val_accuracy: 0.9538\n",
            "Epoch 246/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1484 - accuracy: 0.9536 - val_loss: 0.1453 - val_accuracy: 0.9513\n",
            "Epoch 247/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9550 - val_loss: 0.1477 - val_accuracy: 0.9538\n",
            "Epoch 248/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9553 - val_loss: 0.1468 - val_accuracy: 0.9513\n",
            "Epoch 249/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1474 - accuracy: 0.9539 - val_loss: 0.1425 - val_accuracy: 0.9519\n",
            "Epoch 250/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1485 - accuracy: 0.9533 - val_loss: 0.1431 - val_accuracy: 0.9544\n",
            "Epoch 251/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1480 - accuracy: 0.9533 - val_loss: 0.1430 - val_accuracy: 0.9538\n",
            "Epoch 252/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1476 - accuracy: 0.9542 - val_loss: 0.1433 - val_accuracy: 0.9544\n",
            "Epoch 253/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1476 - accuracy: 0.9539 - val_loss: 0.1426 - val_accuracy: 0.9544\n",
            "Epoch 254/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9531 - val_loss: 0.1423 - val_accuracy: 0.9550\n",
            "Epoch 255/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1476 - accuracy: 0.9539 - val_loss: 0.1417 - val_accuracy: 0.9550\n",
            "Epoch 256/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9538 - val_loss: 0.1422 - val_accuracy: 0.9544\n",
            "Epoch 257/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9539 - val_loss: 0.1432 - val_accuracy: 0.9531\n",
            "Epoch 258/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9527 - val_loss: 0.1440 - val_accuracy: 0.9538\n",
            "Epoch 259/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9541 - val_loss: 0.1425 - val_accuracy: 0.9525\n",
            "Epoch 260/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9528 - val_loss: 0.1433 - val_accuracy: 0.9538\n",
            "Epoch 261/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9536 - val_loss: 0.1431 - val_accuracy: 0.9525\n",
            "Epoch 262/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1483 - accuracy: 0.9542 - val_loss: 0.1419 - val_accuracy: 0.9550\n",
            "Epoch 263/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1478 - accuracy: 0.9544 - val_loss: 0.1503 - val_accuracy: 0.9538\n",
            "Epoch 264/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1484 - accuracy: 0.9531 - val_loss: 0.1427 - val_accuracy: 0.9544\n",
            "Epoch 265/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9545 - val_loss: 0.1425 - val_accuracy: 0.9550\n",
            "Epoch 266/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9538 - val_loss: 0.1428 - val_accuracy: 0.9544\n",
            "Epoch 267/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9542 - val_loss: 0.1458 - val_accuracy: 0.9538\n",
            "Epoch 268/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1487 - accuracy: 0.9538 - val_loss: 0.1452 - val_accuracy: 0.9538\n",
            "Epoch 269/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9542 - val_loss: 0.1439 - val_accuracy: 0.9538\n",
            "Epoch 270/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9538 - val_loss: 0.1454 - val_accuracy: 0.9538\n",
            "Epoch 271/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1473 - accuracy: 0.9550 - val_loss: 0.1435 - val_accuracy: 0.9463\n",
            "Epoch 272/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9530 - val_loss: 0.1459 - val_accuracy: 0.9538\n",
            "Epoch 273/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9538 - val_loss: 0.1430 - val_accuracy: 0.9544\n",
            "Epoch 274/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9534 - val_loss: 0.1430 - val_accuracy: 0.9550\n",
            "Epoch 275/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9538 - val_loss: 0.1425 - val_accuracy: 0.9544\n",
            "Epoch 276/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1479 - accuracy: 0.9539 - val_loss: 0.1424 - val_accuracy: 0.9550\n",
            "Epoch 277/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9531 - val_loss: 0.1438 - val_accuracy: 0.9544\n",
            "Epoch 278/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9542 - val_loss: 0.1422 - val_accuracy: 0.9544\n",
            "Epoch 279/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1473 - accuracy: 0.9539 - val_loss: 0.1430 - val_accuracy: 0.9544\n",
            "Epoch 280/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9541 - val_loss: 0.1418 - val_accuracy: 0.9544\n",
            "Epoch 281/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9539 - val_loss: 0.1441 - val_accuracy: 0.9513\n",
            "Epoch 282/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9531 - val_loss: 0.1434 - val_accuracy: 0.9538\n",
            "Epoch 283/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1479 - accuracy: 0.9539 - val_loss: 0.1435 - val_accuracy: 0.9538\n",
            "Epoch 284/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1477 - accuracy: 0.9539 - val_loss: 0.1446 - val_accuracy: 0.9488\n",
            "Epoch 285/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1479 - accuracy: 0.9533 - val_loss: 0.1428 - val_accuracy: 0.9544\n",
            "Epoch 286/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1477 - accuracy: 0.9534 - val_loss: 0.1470 - val_accuracy: 0.9538\n",
            "Epoch 287/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.1476 - accuracy: 0.9541 - val_loss: 0.1427 - val_accuracy: 0.9513\n",
            "Epoch 288/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1473 - accuracy: 0.9539 - val_loss: 0.1458 - val_accuracy: 0.9538\n",
            "Epoch 289/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1477 - accuracy: 0.9539 - val_loss: 0.1427 - val_accuracy: 0.9544\n",
            "Epoch 290/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1479 - accuracy: 0.9536 - val_loss: 0.1435 - val_accuracy: 0.9538\n",
            "Epoch 291/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1483 - accuracy: 0.9539 - val_loss: 0.1456 - val_accuracy: 0.9538\n",
            "Epoch 292/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9538 - val_loss: 0.1441 - val_accuracy: 0.9538\n",
            "Epoch 293/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1478 - accuracy: 0.9542 - val_loss: 0.1426 - val_accuracy: 0.9513\n",
            "Epoch 294/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9534 - val_loss: 0.1433 - val_accuracy: 0.9544\n",
            "Epoch 295/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1489 - accuracy: 0.9541 - val_loss: 0.1444 - val_accuracy: 0.9519\n",
            "Epoch 296/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9541 - val_loss: 0.1434 - val_accuracy: 0.9513\n",
            "Epoch 297/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1489 - accuracy: 0.9534 - val_loss: 0.1440 - val_accuracy: 0.9538\n",
            "Epoch 298/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1478 - accuracy: 0.9531 - val_loss: 0.1476 - val_accuracy: 0.9538\n",
            "Epoch 299/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9533 - val_loss: 0.1422 - val_accuracy: 0.9550\n",
            "Epoch 300/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9534 - val_loss: 0.1425 - val_accuracy: 0.9544\n",
            "Epoch 301/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1481 - accuracy: 0.9541 - val_loss: 0.1429 - val_accuracy: 0.9538\n",
            "Epoch 302/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1488 - accuracy: 0.9534 - val_loss: 0.1428 - val_accuracy: 0.9538\n",
            "Epoch 303/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1485 - accuracy: 0.9531 - val_loss: 0.1425 - val_accuracy: 0.9550\n",
            "Epoch 304/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1476 - accuracy: 0.9542 - val_loss: 0.1425 - val_accuracy: 0.9550\n",
            "Epoch 305/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1483 - accuracy: 0.9541 - val_loss: 0.1441 - val_accuracy: 0.9544\n",
            "Epoch 306/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9531 - val_loss: 0.1417 - val_accuracy: 0.9550\n",
            "Epoch 307/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9542 - val_loss: 0.1427 - val_accuracy: 0.9544\n",
            "Epoch 308/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9544 - val_loss: 0.1435 - val_accuracy: 0.9488\n",
            "Epoch 309/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9539 - val_loss: 0.1431 - val_accuracy: 0.9544\n",
            "Epoch 310/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1478 - accuracy: 0.9533 - val_loss: 0.1429 - val_accuracy: 0.9506\n",
            "Epoch 311/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1476 - accuracy: 0.9545 - val_loss: 0.1435 - val_accuracy: 0.9538\n",
            "Epoch 312/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1478 - accuracy: 0.9541 - val_loss: 0.1431 - val_accuracy: 0.9538\n",
            "Epoch 313/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1477 - accuracy: 0.9541 - val_loss: 0.1429 - val_accuracy: 0.9531\n",
            "Epoch 314/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1478 - accuracy: 0.9539 - val_loss: 0.1438 - val_accuracy: 0.9538\n",
            "Epoch 315/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9542 - val_loss: 0.1421 - val_accuracy: 0.9544\n",
            "Epoch 316/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1474 - accuracy: 0.9542 - val_loss: 0.1465 - val_accuracy: 0.9538\n",
            "Epoch 317/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.1475 - accuracy: 0.9538 - val_loss: 0.1431 - val_accuracy: 0.9538\n",
            "Epoch 318/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1483 - accuracy: 0.9536 - val_loss: 0.1426 - val_accuracy: 0.9544\n",
            "Epoch 319/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1477 - accuracy: 0.9538 - val_loss: 0.1438 - val_accuracy: 0.9519\n",
            "Epoch 320/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1477 - accuracy: 0.9539 - val_loss: 0.1434 - val_accuracy: 0.9531\n",
            "Epoch 321/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1474 - accuracy: 0.9533 - val_loss: 0.1431 - val_accuracy: 0.9544\n",
            "Epoch 322/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1473 - accuracy: 0.9538 - val_loss: 0.1431 - val_accuracy: 0.9544\n",
            "Epoch 323/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1486 - accuracy: 0.9545 - val_loss: 0.1426 - val_accuracy: 0.9550\n",
            "Epoch 324/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1478 - accuracy: 0.9536 - val_loss: 0.1435 - val_accuracy: 0.9544\n",
            "Epoch 325/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1478 - accuracy: 0.9541 - val_loss: 0.1433 - val_accuracy: 0.9519\n",
            "Epoch 326/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9531 - val_loss: 0.1430 - val_accuracy: 0.9544\n",
            "Epoch 327/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1483 - accuracy: 0.9530 - val_loss: 0.1449 - val_accuracy: 0.9538\n",
            "Epoch 328/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1480 - accuracy: 0.9530 - val_loss: 0.1461 - val_accuracy: 0.9525\n",
            "Epoch 329/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1478 - accuracy: 0.9538 - val_loss: 0.1421 - val_accuracy: 0.9544\n",
            "Epoch 330/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9539 - val_loss: 0.1439 - val_accuracy: 0.9544\n",
            "Epoch 331/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1476 - accuracy: 0.9536 - val_loss: 0.1433 - val_accuracy: 0.9538\n",
            "Epoch 332/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1476 - accuracy: 0.9538 - val_loss: 0.1428 - val_accuracy: 0.9544\n",
            "Epoch 333/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9545 - val_loss: 0.1437 - val_accuracy: 0.9500\n",
            "Epoch 334/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1481 - accuracy: 0.9538 - val_loss: 0.1431 - val_accuracy: 0.9544\n",
            "Epoch 335/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9541 - val_loss: 0.1418 - val_accuracy: 0.9538\n",
            "Epoch 336/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1474 - accuracy: 0.9538 - val_loss: 0.1421 - val_accuracy: 0.9513\n",
            "Epoch 337/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9544 - val_loss: 0.1422 - val_accuracy: 0.9544\n",
            "Epoch 338/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9533 - val_loss: 0.1428 - val_accuracy: 0.9544\n",
            "Epoch 339/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9530 - val_loss: 0.1442 - val_accuracy: 0.9538\n",
            "Epoch 340/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9541 - val_loss: 0.1431 - val_accuracy: 0.9538\n",
            "Epoch 341/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9531 - val_loss: 0.1457 - val_accuracy: 0.9538\n",
            "Epoch 342/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9534 - val_loss: 0.1423 - val_accuracy: 0.9550\n",
            "Epoch 343/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1478 - accuracy: 0.9528 - val_loss: 0.1434 - val_accuracy: 0.9525\n",
            "Epoch 344/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9538 - val_loss: 0.1445 - val_accuracy: 0.9538\n",
            "Epoch 345/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9541 - val_loss: 0.1434 - val_accuracy: 0.9544\n",
            "Epoch 346/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1478 - accuracy: 0.9530 - val_loss: 0.1427 - val_accuracy: 0.9544\n",
            "Epoch 347/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9534 - val_loss: 0.1476 - val_accuracy: 0.9538\n",
            "Epoch 348/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1474 - accuracy: 0.9541 - val_loss: 0.1436 - val_accuracy: 0.9538\n",
            "Epoch 349/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1478 - accuracy: 0.9539 - val_loss: 0.1437 - val_accuracy: 0.9525\n",
            "Epoch 350/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1477 - accuracy: 0.9536 - val_loss: 0.1427 - val_accuracy: 0.9544\n",
            "Epoch 351/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1477 - accuracy: 0.9541 - val_loss: 0.1434 - val_accuracy: 0.9519\n",
            "Epoch 352/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1481 - accuracy: 0.9545 - val_loss: 0.1431 - val_accuracy: 0.9544\n",
            "Epoch 353/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1478 - accuracy: 0.9536 - val_loss: 0.1422 - val_accuracy: 0.9550\n",
            "Epoch 354/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1483 - accuracy: 0.9531 - val_loss: 0.1439 - val_accuracy: 0.9550\n",
            "Epoch 355/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1478 - accuracy: 0.9542 - val_loss: 0.1451 - val_accuracy: 0.9538\n",
            "Epoch 356/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1474 - accuracy: 0.9527 - val_loss: 0.1431 - val_accuracy: 0.9531\n",
            "Epoch 357/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1480 - accuracy: 0.9531 - val_loss: 0.1434 - val_accuracy: 0.9538\n",
            "Epoch 358/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9539 - val_loss: 0.1435 - val_accuracy: 0.9544\n",
            "Epoch 359/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1474 - accuracy: 0.9542 - val_loss: 0.1418 - val_accuracy: 0.9550\n",
            "Epoch 360/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9533 - val_loss: 0.1452 - val_accuracy: 0.9538\n",
            "Epoch 361/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9539 - val_loss: 0.1436 - val_accuracy: 0.9550\n",
            "Epoch 362/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1469 - accuracy: 0.9544 - val_loss: 0.1457 - val_accuracy: 0.9513\n",
            "Epoch 363/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1478 - accuracy: 0.9539 - val_loss: 0.1440 - val_accuracy: 0.9550\n",
            "Epoch 364/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1485 - accuracy: 0.9534 - val_loss: 0.1424 - val_accuracy: 0.9544\n",
            "Epoch 365/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9541 - val_loss: 0.1428 - val_accuracy: 0.9544\n",
            "Epoch 366/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1475 - accuracy: 0.9544 - val_loss: 0.1440 - val_accuracy: 0.9538\n",
            "Epoch 367/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1483 - accuracy: 0.9545 - val_loss: 0.1429 - val_accuracy: 0.9544\n",
            "Epoch 368/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1480 - accuracy: 0.9541 - val_loss: 0.1466 - val_accuracy: 0.9538\n",
            "Epoch 369/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1478 - accuracy: 0.9541 - val_loss: 0.1436 - val_accuracy: 0.9531\n",
            "Epoch 370/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1474 - accuracy: 0.9533 - val_loss: 0.1431 - val_accuracy: 0.9488\n",
            "Epoch 371/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1474 - accuracy: 0.9545 - val_loss: 0.1434 - val_accuracy: 0.9538\n",
            "Epoch 372/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9544 - val_loss: 0.1449 - val_accuracy: 0.9525\n",
            "Epoch 373/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1489 - accuracy: 0.9534 - val_loss: 0.1506 - val_accuracy: 0.9525\n",
            "Epoch 374/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1484 - accuracy: 0.9528 - val_loss: 0.1439 - val_accuracy: 0.9550\n",
            "Epoch 375/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1471 - accuracy: 0.9538 - val_loss: 0.1429 - val_accuracy: 0.9513\n",
            "Epoch 376/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9539 - val_loss: 0.1424 - val_accuracy: 0.9544\n",
            "Epoch 377/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1474 - accuracy: 0.9539 - val_loss: 0.1439 - val_accuracy: 0.9550\n",
            "Epoch 378/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9536 - val_loss: 0.1473 - val_accuracy: 0.9513\n",
            "Epoch 379/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9538 - val_loss: 0.1451 - val_accuracy: 0.9538\n",
            "Epoch 380/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1477 - accuracy: 0.9542 - val_loss: 0.1448 - val_accuracy: 0.9538\n",
            "Epoch 381/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1474 - accuracy: 0.9541 - val_loss: 0.1429 - val_accuracy: 0.9550\n",
            "Epoch 382/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1484 - accuracy: 0.9538 - val_loss: 0.1438 - val_accuracy: 0.9538\n",
            "Epoch 383/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1478 - accuracy: 0.9538 - val_loss: 0.1433 - val_accuracy: 0.9544\n",
            "Epoch 384/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1473 - accuracy: 0.9544 - val_loss: 0.1433 - val_accuracy: 0.9531\n",
            "Epoch 385/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1483 - accuracy: 0.9539 - val_loss: 0.1430 - val_accuracy: 0.9519\n",
            "Epoch 386/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1479 - accuracy: 0.9531 - val_loss: 0.1432 - val_accuracy: 0.9544\n",
            "Epoch 387/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1476 - accuracy: 0.9533 - val_loss: 0.1429 - val_accuracy: 0.9544\n",
            "Epoch 388/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1474 - accuracy: 0.9539 - val_loss: 0.1424 - val_accuracy: 0.9550\n",
            "Epoch 389/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9538 - val_loss: 0.1433 - val_accuracy: 0.9519\n",
            "Epoch 390/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1490 - accuracy: 0.9538 - val_loss: 0.1442 - val_accuracy: 0.9488\n",
            "Epoch 391/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9545 - val_loss: 0.1450 - val_accuracy: 0.9538\n",
            "Epoch 392/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9533 - val_loss: 0.1427 - val_accuracy: 0.9544\n",
            "Epoch 393/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9534 - val_loss: 0.1442 - val_accuracy: 0.9538\n",
            "Epoch 394/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1474 - accuracy: 0.9541 - val_loss: 0.1432 - val_accuracy: 0.9513\n",
            "Epoch 395/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9533 - val_loss: 0.1432 - val_accuracy: 0.9531\n",
            "Epoch 396/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1474 - accuracy: 0.9534 - val_loss: 0.1425 - val_accuracy: 0.9550\n",
            "Epoch 397/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1481 - accuracy: 0.9541 - val_loss: 0.1427 - val_accuracy: 0.9550\n",
            "Epoch 398/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9539 - val_loss: 0.1423 - val_accuracy: 0.9550\n",
            "Epoch 399/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9536 - val_loss: 0.1430 - val_accuracy: 0.9544\n",
            "Epoch 400/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1487 - accuracy: 0.9542 - val_loss: 0.1427 - val_accuracy: 0.9544\n",
            "Epoch 401/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9533 - val_loss: 0.1438 - val_accuracy: 0.9538\n",
            "Epoch 402/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9542 - val_loss: 0.1424 - val_accuracy: 0.9544\n",
            "Epoch 403/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9536 - val_loss: 0.1435 - val_accuracy: 0.9519\n",
            "Epoch 404/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1474 - accuracy: 0.9544 - val_loss: 0.1430 - val_accuracy: 0.9513\n",
            "Epoch 405/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9533 - val_loss: 0.1447 - val_accuracy: 0.9538\n",
            "Epoch 406/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9542 - val_loss: 0.1420 - val_accuracy: 0.9544\n",
            "Epoch 407/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9547 - val_loss: 0.1444 - val_accuracy: 0.9531\n",
            "Epoch 408/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1478 - accuracy: 0.9538 - val_loss: 0.1461 - val_accuracy: 0.9525\n",
            "Epoch 409/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1478 - accuracy: 0.9533 - val_loss: 0.1426 - val_accuracy: 0.9544\n",
            "Epoch 410/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1475 - accuracy: 0.9544 - val_loss: 0.1443 - val_accuracy: 0.9544\n",
            "Epoch 411/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1474 - accuracy: 0.9534 - val_loss: 0.1459 - val_accuracy: 0.9538\n",
            "Epoch 412/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9541 - val_loss: 0.1438 - val_accuracy: 0.9538\n",
            "Epoch 413/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1474 - accuracy: 0.9544 - val_loss: 0.1434 - val_accuracy: 0.9550\n",
            "Epoch 414/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1474 - accuracy: 0.9536 - val_loss: 0.1433 - val_accuracy: 0.9544\n",
            "Epoch 415/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9533 - val_loss: 0.1420 - val_accuracy: 0.9544\n",
            "Epoch 416/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1485 - accuracy: 0.9533 - val_loss: 0.1426 - val_accuracy: 0.9513\n",
            "Epoch 417/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1472 - accuracy: 0.9534 - val_loss: 0.1430 - val_accuracy: 0.9531\n",
            "Epoch 418/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1468 - accuracy: 0.9534 - val_loss: 0.1432 - val_accuracy: 0.9488\n",
            "Epoch 419/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1475 - accuracy: 0.9541 - val_loss: 0.1426 - val_accuracy: 0.9544\n",
            "Epoch 420/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1477 - accuracy: 0.9533 - val_loss: 0.1428 - val_accuracy: 0.9550\n",
            "Epoch 421/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1474 - accuracy: 0.9539 - val_loss: 0.1430 - val_accuracy: 0.9550\n",
            "Epoch 422/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9541 - val_loss: 0.1439 - val_accuracy: 0.9538\n",
            "Epoch 423/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1476 - accuracy: 0.9541 - val_loss: 0.1431 - val_accuracy: 0.9550\n",
            "Epoch 424/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1478 - accuracy: 0.9539 - val_loss: 0.1432 - val_accuracy: 0.9544\n",
            "Epoch 425/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1472 - accuracy: 0.9544 - val_loss: 0.1434 - val_accuracy: 0.9519\n",
            "Epoch 426/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9539 - val_loss: 0.1441 - val_accuracy: 0.9544\n",
            "Epoch 427/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9542 - val_loss: 0.1429 - val_accuracy: 0.9531\n",
            "Epoch 428/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9538 - val_loss: 0.1466 - val_accuracy: 0.9538\n",
            "Epoch 429/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1482 - accuracy: 0.9539 - val_loss: 0.1441 - val_accuracy: 0.9519\n",
            "Epoch 430/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9539 - val_loss: 0.1450 - val_accuracy: 0.9538\n",
            "Epoch 431/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1474 - accuracy: 0.9548 - val_loss: 0.1429 - val_accuracy: 0.9544\n",
            "Epoch 432/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9534 - val_loss: 0.1456 - val_accuracy: 0.9538\n",
            "Epoch 433/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9542 - val_loss: 0.1451 - val_accuracy: 0.9513\n",
            "Epoch 434/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1473 - accuracy: 0.9541 - val_loss: 0.1435 - val_accuracy: 0.9544\n",
            "Epoch 435/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9538 - val_loss: 0.1428 - val_accuracy: 0.9544\n",
            "Epoch 436/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9539 - val_loss: 0.1438 - val_accuracy: 0.9538\n",
            "Epoch 437/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1474 - accuracy: 0.9544 - val_loss: 0.1439 - val_accuracy: 0.9550\n",
            "Epoch 438/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1474 - accuracy: 0.9536 - val_loss: 0.1426 - val_accuracy: 0.9550\n",
            "Epoch 439/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9541 - val_loss: 0.1423 - val_accuracy: 0.9544\n",
            "Epoch 440/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1480 - accuracy: 0.9538 - val_loss: 0.1431 - val_accuracy: 0.9544\n",
            "Epoch 441/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1473 - accuracy: 0.9538 - val_loss: 0.1425 - val_accuracy: 0.9550\n",
            "Epoch 442/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9530 - val_loss: 0.1432 - val_accuracy: 0.9544\n",
            "Epoch 443/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9538 - val_loss: 0.1449 - val_accuracy: 0.9519\n",
            "Epoch 444/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9533 - val_loss: 0.1443 - val_accuracy: 0.9538\n",
            "Epoch 445/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9541 - val_loss: 0.1436 - val_accuracy: 0.9531\n",
            "Epoch 446/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9528 - val_loss: 0.1483 - val_accuracy: 0.9525\n",
            "Epoch 447/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1481 - accuracy: 0.9541 - val_loss: 0.1435 - val_accuracy: 0.9538\n",
            "Epoch 448/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1474 - accuracy: 0.9538 - val_loss: 0.1434 - val_accuracy: 0.9544\n",
            "Epoch 449/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1469 - accuracy: 0.9541 - val_loss: 0.1429 - val_accuracy: 0.9544\n",
            "Epoch 450/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1475 - accuracy: 0.9539 - val_loss: 0.1468 - val_accuracy: 0.9538\n",
            "Epoch 451/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1468 - accuracy: 0.9523 - val_loss: 0.1483 - val_accuracy: 0.9525\n",
            "Epoch 452/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1474 - accuracy: 0.9536 - val_loss: 0.1432 - val_accuracy: 0.9544\n",
            "Epoch 453/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1476 - accuracy: 0.9538 - val_loss: 0.1430 - val_accuracy: 0.9544\n",
            "Epoch 454/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1476 - accuracy: 0.9534 - val_loss: 0.1439 - val_accuracy: 0.9488\n",
            "Epoch 455/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1485 - accuracy: 0.9528 - val_loss: 0.1428 - val_accuracy: 0.9544\n",
            "Epoch 456/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1478 - accuracy: 0.9541 - val_loss: 0.1435 - val_accuracy: 0.9550\n",
            "Epoch 457/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1481 - accuracy: 0.9538 - val_loss: 0.1425 - val_accuracy: 0.9550\n",
            "Epoch 458/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1477 - accuracy: 0.9534 - val_loss: 0.1428 - val_accuracy: 0.9550\n",
            "Epoch 459/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1478 - accuracy: 0.9542 - val_loss: 0.1432 - val_accuracy: 0.9550\n",
            "Epoch 460/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9541 - val_loss: 0.1446 - val_accuracy: 0.9538\n",
            "Epoch 461/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1478 - accuracy: 0.9542 - val_loss: 0.1452 - val_accuracy: 0.9538\n",
            "Epoch 462/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9559 - val_loss: 0.1453 - val_accuracy: 0.9513\n",
            "Epoch 463/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9542 - val_loss: 0.1497 - val_accuracy: 0.9513\n",
            "Epoch 464/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1478 - accuracy: 0.9530 - val_loss: 0.1432 - val_accuracy: 0.9544\n",
            "Epoch 465/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9534 - val_loss: 0.1444 - val_accuracy: 0.9519\n",
            "Epoch 466/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9533 - val_loss: 0.1432 - val_accuracy: 0.9544\n",
            "Epoch 467/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9545 - val_loss: 0.1449 - val_accuracy: 0.9544\n",
            "Epoch 468/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1468 - accuracy: 0.9527 - val_loss: 0.1458 - val_accuracy: 0.9463\n",
            "Epoch 469/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9541 - val_loss: 0.1436 - val_accuracy: 0.9550\n",
            "Epoch 470/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9545 - val_loss: 0.1430 - val_accuracy: 0.9544\n",
            "Epoch 471/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9534 - val_loss: 0.1431 - val_accuracy: 0.9544\n",
            "Epoch 472/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1474 - accuracy: 0.9536 - val_loss: 0.1430 - val_accuracy: 0.9544\n",
            "Epoch 473/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9536 - val_loss: 0.1439 - val_accuracy: 0.9519\n",
            "Epoch 474/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1472 - accuracy: 0.9545 - val_loss: 0.1445 - val_accuracy: 0.9544\n",
            "Epoch 475/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1476 - accuracy: 0.9548 - val_loss: 0.1434 - val_accuracy: 0.9544\n",
            "Epoch 476/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1473 - accuracy: 0.9544 - val_loss: 0.1432 - val_accuracy: 0.9513\n",
            "Epoch 477/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1486 - accuracy: 0.9538 - val_loss: 0.1442 - val_accuracy: 0.9531\n",
            "Epoch 478/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1473 - accuracy: 0.9531 - val_loss: 0.1437 - val_accuracy: 0.9519\n",
            "Epoch 479/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9538 - val_loss: 0.1443 - val_accuracy: 0.9531\n",
            "Epoch 480/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1483 - accuracy: 0.9530 - val_loss: 0.1437 - val_accuracy: 0.9544\n",
            "Epoch 481/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9538 - val_loss: 0.1446 - val_accuracy: 0.9538\n",
            "Epoch 482/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1476 - accuracy: 0.9541 - val_loss: 0.1436 - val_accuracy: 0.9544\n",
            "Epoch 483/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1482 - accuracy: 0.9536 - val_loss: 0.1463 - val_accuracy: 0.9538\n",
            "Epoch 484/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1472 - accuracy: 0.9541 - val_loss: 0.1425 - val_accuracy: 0.9544\n",
            "Epoch 485/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1476 - accuracy: 0.9544 - val_loss: 0.1436 - val_accuracy: 0.9544\n",
            "Epoch 486/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1477 - accuracy: 0.9541 - val_loss: 0.1437 - val_accuracy: 0.9513\n",
            "Epoch 487/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1475 - accuracy: 0.9534 - val_loss: 0.1428 - val_accuracy: 0.9544\n",
            "Epoch 488/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1471 - accuracy: 0.9536 - val_loss: 0.1449 - val_accuracy: 0.9538\n",
            "Epoch 489/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1475 - accuracy: 0.9544 - val_loss: 0.1449 - val_accuracy: 0.9538\n",
            "Epoch 490/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9544 - val_loss: 0.1451 - val_accuracy: 0.9544\n",
            "Epoch 491/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9545 - val_loss: 0.1455 - val_accuracy: 0.9513\n",
            "Epoch 492/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1474 - accuracy: 0.9538 - val_loss: 0.1457 - val_accuracy: 0.9538\n",
            "Epoch 493/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1473 - accuracy: 0.9544 - val_loss: 0.1452 - val_accuracy: 0.9538\n",
            "Epoch 494/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1470 - accuracy: 0.9538 - val_loss: 0.1437 - val_accuracy: 0.9531\n",
            "Epoch 495/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9545 - val_loss: 0.1437 - val_accuracy: 0.9544\n",
            "Epoch 496/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9547 - val_loss: 0.1454 - val_accuracy: 0.9475\n",
            "Epoch 497/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1478 - accuracy: 0.9541 - val_loss: 0.1471 - val_accuracy: 0.9538\n",
            "Epoch 498/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1471 - accuracy: 0.9542 - val_loss: 0.1433 - val_accuracy: 0.9550\n",
            "Epoch 499/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1473 - accuracy: 0.9548 - val_loss: 0.1453 - val_accuracy: 0.9538\n",
            "Epoch 500/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9533 - val_loss: 0.1460 - val_accuracy: 0.9538\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcca88fbfd0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#y_pred_DNN = (model.predict(DNNX) > 0.5).astype(\"int32\")\n",
        "DTr = model.evaluate(DX_train, Dy_train,verbose=0)[1]\n",
        "DTe = model.evaluate(DX_test, Dy_test,verbose=0)[1]\n",
        "DTr,DTe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhG0YCbhASH9",
        "outputId": "d8739b9f-7ff3-45f9-e430-c45f869dcedd"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9543750286102295, 0.9505000114440918)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = pd.DataFrame(\n",
        "    {\n",
        "    \"SVM\":[STr,STe],\n",
        "    \"KNN\":[KTr,KTe],\n",
        "    \"RF\" :[RTr,RTe],\n",
        "    \"LR\" :[LTr,LTe],\n",
        "    \"ANN\":[ATr,ATe],\n",
        "    \"XGB\":[XTr,XTe],\n",
        "    \"DNN\":[DTr,DTe]})\n",
        "acc.index = [\"train\", \"test\"]\n",
        "acc = acc.T\n",
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "v_YjlCdOO1JY",
        "outputId": "f3b7e32e-60d2-4280-afbc-c76dab6919b1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        train    test\n",
              "SVM  0.950500  0.9500\n",
              "KNN  0.954875  0.9445\n",
              "RF   0.943875  0.9505\n",
              "LR   0.950000  0.9500\n",
              "ANN  0.958250  0.9490\n",
              "XGB  0.988250  0.9455\n",
              "DNN  0.954375  0.9505"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-271705c7-9f19-4dac-901c-9c810118732d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>0.950500</td>\n",
              "      <td>0.9500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>0.954875</td>\n",
              "      <td>0.9445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>0.943875</td>\n",
              "      <td>0.9505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LR</th>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.9500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ANN</th>\n",
              "      <td>0.958250</td>\n",
              "      <td>0.9490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGB</th>\n",
              "      <td>0.988250</td>\n",
              "      <td>0.9455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DNN</th>\n",
              "      <td>0.954375</td>\n",
              "      <td>0.9505</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-271705c7-9f19-4dac-901c-9c810118732d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-271705c7-9f19-4dac-901c-9c810118732d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-271705c7-9f19-4dac-901c-9c810118732d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **AutoML Individual and AutoML DNN**"
      ],
      "metadata": {
        "id": "nJaAMLDKKfKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#H2O AutoML"
      ],
      "metadata": {
        "id": "EhNt_UkjDKcV"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h2o\n",
        "import h2o\n",
        "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
        "h2o.init()\n",
        "from h2o.model.segment_models import H2OFrame\n",
        "from h2o.automl import H2OAutoML\n",
        "print(\"All Library Loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 891
        },
        "id": "iwMF9ROeDOzF",
        "outputId": "8a9f00a0-40fa-431b-9001-97c808bda125"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting h2o\n",
            "  Downloading h2o-3.40.0.4.tar.gz (177.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from h2o) (2.27.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from h2o) (0.8.10)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from h2o) (0.18.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (3.4)\n",
            "Building wheels for collected packages: h2o\n",
            "  Building wheel for h2o (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for h2o: filename=h2o-3.40.0.4-py2.py3-none-any.whl size=177697886 sha256=cc83dde99239ee57a773f5b59476ee64ffa6ca3322fdccc1b235de4b6338edf5\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/f2/b0/5bb4d702a0467e82d77c45088db3eef25114c26b0eec8e7f6a\n",
            "Successfully built h2o\n",
            "Installing collected packages: h2o\n",
            "Successfully installed h2o-3.40.0.4\n",
            "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
            "Attempting to start a local H2O server...\n",
            "  Java Version: openjdk version \"11.0.19\" 2023-04-18; OpenJDK Runtime Environment (build 11.0.19+7-post-Ubuntu-0ubuntu120.04.1); OpenJDK 64-Bit Server VM (build 11.0.19+7-post-Ubuntu-0ubuntu120.04.1, mixed mode, sharing)\n",
            "  Starting server from /usr/local/lib/python3.10/dist-packages/h2o/backend/bin/h2o.jar\n",
            "  Ice root: /tmp/tmp5drtoj3v\n",
            "  JVM stdout: /tmp/tmp5drtoj3v/h2o_unknownUser_started_from_python.out\n",
            "  JVM stderr: /tmp/tmp5drtoj3v/h2o_unknownUser_started_from_python.err\n",
            "  Server is running at http://127.0.0.1:54321\n",
            "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "--------------------------  -----------------------------------------------------------------------------------------\n",
              "H2O_cluster_uptime:         03 secs\n",
              "H2O_cluster_timezone:       Etc/UTC\n",
              "H2O_data_parsing_timezone:  UTC\n",
              "H2O_cluster_version:        3.40.0.4\n",
              "H2O_cluster_version_age:    1 month and 24 days\n",
              "H2O_cluster_name:           H2O_from_python_unknownUser_kv91fi\n",
              "H2O_cluster_total_nodes:    1\n",
              "H2O_cluster_free_memory:    3.170 Gb\n",
              "H2O_cluster_total_cores:    2\n",
              "H2O_cluster_allowed_cores:  2\n",
              "H2O_cluster_status:         locked, healthy\n",
              "H2O_connection_url:         http://127.0.0.1:54321\n",
              "H2O_connection_proxy:       {\"http\": null, \"https\": null, \"colab_language_server\": \"/usr/colab/bin/language_service\"}\n",
              "H2O_internal_security:      False\n",
              "Python_version:             3.10.12 final\n",
              "--------------------------  -----------------------------------------------------------------------------------------"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "#h2o-table-1.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-1 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-1 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-1 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-1 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-1 .h2o-table th,\n",
              "#h2o-table-1 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption></caption>\n",
              "    <thead></thead>\n",
              "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
              "<td>03 secs</td></tr>\n",
              "<tr><td>H2O_cluster_timezone:</td>\n",
              "<td>Etc/UTC</td></tr>\n",
              "<tr><td>H2O_data_parsing_timezone:</td>\n",
              "<td>UTC</td></tr>\n",
              "<tr><td>H2O_cluster_version:</td>\n",
              "<td>3.40.0.4</td></tr>\n",
              "<tr><td>H2O_cluster_version_age:</td>\n",
              "<td>1 month and 24 days</td></tr>\n",
              "<tr><td>H2O_cluster_name:</td>\n",
              "<td>H2O_from_python_unknownUser_kv91fi</td></tr>\n",
              "<tr><td>H2O_cluster_total_nodes:</td>\n",
              "<td>1</td></tr>\n",
              "<tr><td>H2O_cluster_free_memory:</td>\n",
              "<td>3.170 Gb</td></tr>\n",
              "<tr><td>H2O_cluster_total_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_allowed_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_status:</td>\n",
              "<td>locked, healthy</td></tr>\n",
              "<tr><td>H2O_connection_url:</td>\n",
              "<td>http://127.0.0.1:54321</td></tr>\n",
              "<tr><td>H2O_connection_proxy:</td>\n",
              "<td>{\"http\": null, \"https\": null, \"colab_language_server\": \"/usr/colab/bin/language_service\"}</td></tr>\n",
              "<tr><td>H2O_internal_security:</td>\n",
              "<td>False</td></tr>\n",
              "<tr><td>Python_version:</td>\n",
              "<td>3.10.12 final</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Library Loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hdf = h2o.H2OFrame(df)\n",
        "hdf[\"diagnosis\"] = hdf[\"diagnosis\"].asfactor()\n",
        "hdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "kWdoOLbsF2qs",
        "outputId": "eea3bf93-0743-43d9-d255-9dc05e87d3e5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "diagnosis      radius_mean    texture_mean    perimeter_mean    area_mean    smoothness_mean    compactness_mean    concavity_mean    concave points_mean    symmetry_mean    fractal_dimension_mean    radius_se    texture_se    perimeter_se    area_se    smoothness_se    compactness_se    concavity_se    concave points_se    symmetry_se    fractal_dimension_se    radius_worst    texture_worst    perimeter_worst    area_worst    smoothness_worst    compactness_worst    concavity_worst    concave points_worst    symmetry_worst    fractal_dimension_worst\n",
              "-----------  -------------  --------------  ----------------  -----------  -----------------  ------------------  ----------------  ---------------------  ---------------  ------------------------  -----------  ------------  --------------  ---------  ---------------  ----------------  --------------  -------------------  -------------  ----------------------  --------------  ---------------  -----------------  ------------  ------------------  -------------------  -----------------  ----------------------  ----------------  -------------------------\n",
              "B                  9.86679         14.6371           63.4093      283.714          0.0842235           0.0461586         0.0165442              0.020951          0.170999                 0.061904      0.196404      1.00641         1.91702     16.4105       0.0074197         0.00692129      0.0208046            0.0106783      0.0172378               0.00376954         13.175           18.0649            79.3082       368.916           0.152767              0.166851          0.158809                0.0354395          0.288579                  0.0736893\n",
              "B                 12.8851          21.506            79.2292      336.364          0.081238            0.0617422         0.0300517              0.0253286         0.169469                 0.0589068     0.250136      1.744           0.895149    47.6705       0.0082782         0.0119276       0.0158724            0.0123251      0.0175385               0.00348929         15.7647          27.4871            81.358        726.979           0.112737              0.137944          0.120542                0.0713561          0.27175                   0.0688606\n",
              "B                 11.1658          15.5163           84.0764      356.413          0.112075            0.0641426         0.0129859              0                 0.159183                 0.0613379     0.307996      1.2269          1.56486     24.6257       0.00638495        0.0113454       0.0159683            0.0120709      0.0167701               0.00291682         12.1774          34.227             87.6829       644.261           0.125459              0.256056          0.112901                0.0456988          0.301039                  0.05504\n",
              "B                 12.2717          19.8078           68.5346      428.143          0.0884378           0.0312218         0.0288395              0.0189883         0.144926                 0.0588046     0.209406      0.786333        1.0728      11.2904       0.00616231        0.0103851       0.00481783           0.00586316     0.0147128               0.00129108         14.3326          18.4331            68.2555       505.092           0.0922589             0.116755          0.0594256               0.0443338          0.235016                  0.0791511\n",
              "B                  7.45401         12.3579           51.1679      202.088          0.0885881           0.0527914         0.0515111              0.013281          0.174599                 0.0736429     0.267514      1.7397          2.34676     18.6761       0.0171761         0.0198472       0.00661763           0.0122161      0.0300026               0.0058092          10.6715          18.9609            60.9498       340.397           0.127406              0.107711          0.110993                0                  0.299682                  0.0698175\n",
              "M                 20.5425          26.1736          149.665      1114.11           0.0958109           0.148418          0.115732               0.0737386         0.189129                 0.056928      0.373582      1.2271          2.4978       6.802        0.0054044         0.0111564       0.0178621            0.0112478      0.0115698               0.00271985         24.646           33.5566           128.668       1210.34            0.106323              0.115128          0.254393                0.172223           0.284705                  0.0789862\n",
              "M                 19.202           18.6212          138.317      1002.11           0.08681             0.149834          0.160905               0.0646703         0.170388                 0.0573179     1.10481       0.880552        8.98095    110.52         0.00972965        0.025898        0.057444             0.0177253      0.017309                0.00506447         24.1097          27.3391           147.726       1365.4             0.12564               0.127264          0.502525                0.168771           0.303725                  0.0718625\n",
              "B                 14.1486          14.3429           87.9893      434.929          0.0851832           0.058786          0.0201                 0.0251016         0.145936                 0.0559584     0.21357       0.51991         1.72606     33.2341       0.00272614        0.0167954       0.00021051           0.0063697      0.0128895               0.00238041         13.2726          24.7526           106.707        644.191           0.0971447             0.136527          0.130863                0.0660844          0.188851                  0.0719091\n",
              "M                 19.392           22.1191          123.558      1145.91           0.107064            0.148671          0.0650008              0.0549573         0.155104                 0.0532631     0.548277      0.994942        1.55479     35.988        0.00648556        0.0113865       0.0332146            0.0125249      0.012637                0.00344146         21.9918          33.9526           116.587       1652.41            0.13531               0.372403          0.309631                0.216026           0.23314                   0.0682725\n",
              "M                 20.9458          20.1877          142.645      1132.84           0.0839485           0.127151          0.0691208              0.0913646         0.149046                 0.056304      0.589907      0.845669        3.39574     64.4287       0.00544602        0.0175367       0.0500399            0.00713789     0.00899769              0.00364937         24.1051          20.9021           150.1         1862.37            0.120703              0.158036          0.227143                0.174872           0.30507                   0.0798406\n",
              "[10000 rows x 31 columns]\n"
            ],
            "text/html": [
              "<table class='dataframe'>\n",
              "<thead>\n",
              "<tr><th>diagnosis  </th><th style=\"text-align: right;\">  radius_mean</th><th style=\"text-align: right;\">  texture_mean</th><th style=\"text-align: right;\">  perimeter_mean</th><th style=\"text-align: right;\">  area_mean</th><th style=\"text-align: right;\">  smoothness_mean</th><th style=\"text-align: right;\">  compactness_mean</th><th style=\"text-align: right;\">  concavity_mean</th><th style=\"text-align: right;\">  concave points_mean</th><th style=\"text-align: right;\">  symmetry_mean</th><th style=\"text-align: right;\">  fractal_dimension_mean</th><th style=\"text-align: right;\">  radius_se</th><th style=\"text-align: right;\">  texture_se</th><th style=\"text-align: right;\">  perimeter_se</th><th style=\"text-align: right;\">  area_se</th><th style=\"text-align: right;\">  smoothness_se</th><th style=\"text-align: right;\">  compactness_se</th><th style=\"text-align: right;\">  concavity_se</th><th style=\"text-align: right;\">  concave points_se</th><th style=\"text-align: right;\">  symmetry_se</th><th style=\"text-align: right;\">  fractal_dimension_se</th><th style=\"text-align: right;\">  radius_worst</th><th style=\"text-align: right;\">  texture_worst</th><th style=\"text-align: right;\">  perimeter_worst</th><th style=\"text-align: right;\">  area_worst</th><th style=\"text-align: right;\">  smoothness_worst</th><th style=\"text-align: right;\">  compactness_worst</th><th style=\"text-align: right;\">  concavity_worst</th><th style=\"text-align: right;\">  concave points_worst</th><th style=\"text-align: right;\">  symmetry_worst</th><th style=\"text-align: right;\">  fractal_dimension_worst</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>B          </td><td style=\"text-align: right;\">      9.86679</td><td style=\"text-align: right;\">       14.6371</td><td style=\"text-align: right;\">         63.4093</td><td style=\"text-align: right;\">    283.714</td><td style=\"text-align: right;\">        0.0842235</td><td style=\"text-align: right;\">         0.0461586</td><td style=\"text-align: right;\">       0.0165442</td><td style=\"text-align: right;\">            0.020951 </td><td style=\"text-align: right;\">       0.170999</td><td style=\"text-align: right;\">               0.061904 </td><td style=\"text-align: right;\">   0.196404</td><td style=\"text-align: right;\">    1.00641 </td><td style=\"text-align: right;\">      1.91702 </td><td style=\"text-align: right;\">  16.4105</td><td style=\"text-align: right;\">     0.0074197 </td><td style=\"text-align: right;\">      0.00692129</td><td style=\"text-align: right;\">    0.0208046 </td><td style=\"text-align: right;\">         0.0106783 </td><td style=\"text-align: right;\">   0.0172378 </td><td style=\"text-align: right;\">            0.00376954</td><td style=\"text-align: right;\">       13.175 </td><td style=\"text-align: right;\">        18.0649</td><td style=\"text-align: right;\">          79.3082</td><td style=\"text-align: right;\">     368.916</td><td style=\"text-align: right;\">         0.152767 </td><td style=\"text-align: right;\">           0.166851</td><td style=\"text-align: right;\">        0.158809 </td><td style=\"text-align: right;\">             0.0354395</td><td style=\"text-align: right;\">        0.288579</td><td style=\"text-align: right;\">                0.0736893</td></tr>\n",
              "<tr><td>B          </td><td style=\"text-align: right;\">     12.8851 </td><td style=\"text-align: right;\">       21.506 </td><td style=\"text-align: right;\">         79.2292</td><td style=\"text-align: right;\">    336.364</td><td style=\"text-align: right;\">        0.081238 </td><td style=\"text-align: right;\">         0.0617422</td><td style=\"text-align: right;\">       0.0300517</td><td style=\"text-align: right;\">            0.0253286</td><td style=\"text-align: right;\">       0.169469</td><td style=\"text-align: right;\">               0.0589068</td><td style=\"text-align: right;\">   0.250136</td><td style=\"text-align: right;\">    1.744   </td><td style=\"text-align: right;\">      0.895149</td><td style=\"text-align: right;\">  47.6705</td><td style=\"text-align: right;\">     0.0082782 </td><td style=\"text-align: right;\">      0.0119276 </td><td style=\"text-align: right;\">    0.0158724 </td><td style=\"text-align: right;\">         0.0123251 </td><td style=\"text-align: right;\">   0.0175385 </td><td style=\"text-align: right;\">            0.00348929</td><td style=\"text-align: right;\">       15.7647</td><td style=\"text-align: right;\">        27.4871</td><td style=\"text-align: right;\">          81.358 </td><td style=\"text-align: right;\">     726.979</td><td style=\"text-align: right;\">         0.112737 </td><td style=\"text-align: right;\">           0.137944</td><td style=\"text-align: right;\">        0.120542 </td><td style=\"text-align: right;\">             0.0713561</td><td style=\"text-align: right;\">        0.27175 </td><td style=\"text-align: right;\">                0.0688606</td></tr>\n",
              "<tr><td>B          </td><td style=\"text-align: right;\">     11.1658 </td><td style=\"text-align: right;\">       15.5163</td><td style=\"text-align: right;\">         84.0764</td><td style=\"text-align: right;\">    356.413</td><td style=\"text-align: right;\">        0.112075 </td><td style=\"text-align: right;\">         0.0641426</td><td style=\"text-align: right;\">       0.0129859</td><td style=\"text-align: right;\">            0        </td><td style=\"text-align: right;\">       0.159183</td><td style=\"text-align: right;\">               0.0613379</td><td style=\"text-align: right;\">   0.307996</td><td style=\"text-align: right;\">    1.2269  </td><td style=\"text-align: right;\">      1.56486 </td><td style=\"text-align: right;\">  24.6257</td><td style=\"text-align: right;\">     0.00638495</td><td style=\"text-align: right;\">      0.0113454 </td><td style=\"text-align: right;\">    0.0159683 </td><td style=\"text-align: right;\">         0.0120709 </td><td style=\"text-align: right;\">   0.0167701 </td><td style=\"text-align: right;\">            0.00291682</td><td style=\"text-align: right;\">       12.1774</td><td style=\"text-align: right;\">        34.227 </td><td style=\"text-align: right;\">          87.6829</td><td style=\"text-align: right;\">     644.261</td><td style=\"text-align: right;\">         0.125459 </td><td style=\"text-align: right;\">           0.256056</td><td style=\"text-align: right;\">        0.112901 </td><td style=\"text-align: right;\">             0.0456988</td><td style=\"text-align: right;\">        0.301039</td><td style=\"text-align: right;\">                0.05504  </td></tr>\n",
              "<tr><td>B          </td><td style=\"text-align: right;\">     12.2717 </td><td style=\"text-align: right;\">       19.8078</td><td style=\"text-align: right;\">         68.5346</td><td style=\"text-align: right;\">    428.143</td><td style=\"text-align: right;\">        0.0884378</td><td style=\"text-align: right;\">         0.0312218</td><td style=\"text-align: right;\">       0.0288395</td><td style=\"text-align: right;\">            0.0189883</td><td style=\"text-align: right;\">       0.144926</td><td style=\"text-align: right;\">               0.0588046</td><td style=\"text-align: right;\">   0.209406</td><td style=\"text-align: right;\">    0.786333</td><td style=\"text-align: right;\">      1.0728  </td><td style=\"text-align: right;\">  11.2904</td><td style=\"text-align: right;\">     0.00616231</td><td style=\"text-align: right;\">      0.0103851 </td><td style=\"text-align: right;\">    0.00481783</td><td style=\"text-align: right;\">         0.00586316</td><td style=\"text-align: right;\">   0.0147128 </td><td style=\"text-align: right;\">            0.00129108</td><td style=\"text-align: right;\">       14.3326</td><td style=\"text-align: right;\">        18.4331</td><td style=\"text-align: right;\">          68.2555</td><td style=\"text-align: right;\">     505.092</td><td style=\"text-align: right;\">         0.0922589</td><td style=\"text-align: right;\">           0.116755</td><td style=\"text-align: right;\">        0.0594256</td><td style=\"text-align: right;\">             0.0443338</td><td style=\"text-align: right;\">        0.235016</td><td style=\"text-align: right;\">                0.0791511</td></tr>\n",
              "<tr><td>B          </td><td style=\"text-align: right;\">      7.45401</td><td style=\"text-align: right;\">       12.3579</td><td style=\"text-align: right;\">         51.1679</td><td style=\"text-align: right;\">    202.088</td><td style=\"text-align: right;\">        0.0885881</td><td style=\"text-align: right;\">         0.0527914</td><td style=\"text-align: right;\">       0.0515111</td><td style=\"text-align: right;\">            0.013281 </td><td style=\"text-align: right;\">       0.174599</td><td style=\"text-align: right;\">               0.0736429</td><td style=\"text-align: right;\">   0.267514</td><td style=\"text-align: right;\">    1.7397  </td><td style=\"text-align: right;\">      2.34676 </td><td style=\"text-align: right;\">  18.6761</td><td style=\"text-align: right;\">     0.0171761 </td><td style=\"text-align: right;\">      0.0198472 </td><td style=\"text-align: right;\">    0.00661763</td><td style=\"text-align: right;\">         0.0122161 </td><td style=\"text-align: right;\">   0.0300026 </td><td style=\"text-align: right;\">            0.0058092 </td><td style=\"text-align: right;\">       10.6715</td><td style=\"text-align: right;\">        18.9609</td><td style=\"text-align: right;\">          60.9498</td><td style=\"text-align: right;\">     340.397</td><td style=\"text-align: right;\">         0.127406 </td><td style=\"text-align: right;\">           0.107711</td><td style=\"text-align: right;\">        0.110993 </td><td style=\"text-align: right;\">             0        </td><td style=\"text-align: right;\">        0.299682</td><td style=\"text-align: right;\">                0.0698175</td></tr>\n",
              "<tr><td>M          </td><td style=\"text-align: right;\">     20.5425 </td><td style=\"text-align: right;\">       26.1736</td><td style=\"text-align: right;\">        149.665 </td><td style=\"text-align: right;\">   1114.11 </td><td style=\"text-align: right;\">        0.0958109</td><td style=\"text-align: right;\">         0.148418 </td><td style=\"text-align: right;\">       0.115732 </td><td style=\"text-align: right;\">            0.0737386</td><td style=\"text-align: right;\">       0.189129</td><td style=\"text-align: right;\">               0.056928 </td><td style=\"text-align: right;\">   0.373582</td><td style=\"text-align: right;\">    1.2271  </td><td style=\"text-align: right;\">      2.4978  </td><td style=\"text-align: right;\">   6.802 </td><td style=\"text-align: right;\">     0.0054044 </td><td style=\"text-align: right;\">      0.0111564 </td><td style=\"text-align: right;\">    0.0178621 </td><td style=\"text-align: right;\">         0.0112478 </td><td style=\"text-align: right;\">   0.0115698 </td><td style=\"text-align: right;\">            0.00271985</td><td style=\"text-align: right;\">       24.646 </td><td style=\"text-align: right;\">        33.5566</td><td style=\"text-align: right;\">         128.668 </td><td style=\"text-align: right;\">    1210.34 </td><td style=\"text-align: right;\">         0.106323 </td><td style=\"text-align: right;\">           0.115128</td><td style=\"text-align: right;\">        0.254393 </td><td style=\"text-align: right;\">             0.172223 </td><td style=\"text-align: right;\">        0.284705</td><td style=\"text-align: right;\">                0.0789862</td></tr>\n",
              "<tr><td>M          </td><td style=\"text-align: right;\">     19.202  </td><td style=\"text-align: right;\">       18.6212</td><td style=\"text-align: right;\">        138.317 </td><td style=\"text-align: right;\">   1002.11 </td><td style=\"text-align: right;\">        0.08681  </td><td style=\"text-align: right;\">         0.149834 </td><td style=\"text-align: right;\">       0.160905 </td><td style=\"text-align: right;\">            0.0646703</td><td style=\"text-align: right;\">       0.170388</td><td style=\"text-align: right;\">               0.0573179</td><td style=\"text-align: right;\">   1.10481 </td><td style=\"text-align: right;\">    0.880552</td><td style=\"text-align: right;\">      8.98095 </td><td style=\"text-align: right;\"> 110.52  </td><td style=\"text-align: right;\">     0.00972965</td><td style=\"text-align: right;\">      0.025898  </td><td style=\"text-align: right;\">    0.057444  </td><td style=\"text-align: right;\">         0.0177253 </td><td style=\"text-align: right;\">   0.017309  </td><td style=\"text-align: right;\">            0.00506447</td><td style=\"text-align: right;\">       24.1097</td><td style=\"text-align: right;\">        27.3391</td><td style=\"text-align: right;\">         147.726 </td><td style=\"text-align: right;\">    1365.4  </td><td style=\"text-align: right;\">         0.12564  </td><td style=\"text-align: right;\">           0.127264</td><td style=\"text-align: right;\">        0.502525 </td><td style=\"text-align: right;\">             0.168771 </td><td style=\"text-align: right;\">        0.303725</td><td style=\"text-align: right;\">                0.0718625</td></tr>\n",
              "<tr><td>B          </td><td style=\"text-align: right;\">     14.1486 </td><td style=\"text-align: right;\">       14.3429</td><td style=\"text-align: right;\">         87.9893</td><td style=\"text-align: right;\">    434.929</td><td style=\"text-align: right;\">        0.0851832</td><td style=\"text-align: right;\">         0.058786 </td><td style=\"text-align: right;\">       0.0201   </td><td style=\"text-align: right;\">            0.0251016</td><td style=\"text-align: right;\">       0.145936</td><td style=\"text-align: right;\">               0.0559584</td><td style=\"text-align: right;\">   0.21357 </td><td style=\"text-align: right;\">    0.51991 </td><td style=\"text-align: right;\">      1.72606 </td><td style=\"text-align: right;\">  33.2341</td><td style=\"text-align: right;\">     0.00272614</td><td style=\"text-align: right;\">      0.0167954 </td><td style=\"text-align: right;\">    0.00021051</td><td style=\"text-align: right;\">         0.0063697 </td><td style=\"text-align: right;\">   0.0128895 </td><td style=\"text-align: right;\">            0.00238041</td><td style=\"text-align: right;\">       13.2726</td><td style=\"text-align: right;\">        24.7526</td><td style=\"text-align: right;\">         106.707 </td><td style=\"text-align: right;\">     644.191</td><td style=\"text-align: right;\">         0.0971447</td><td style=\"text-align: right;\">           0.136527</td><td style=\"text-align: right;\">        0.130863 </td><td style=\"text-align: right;\">             0.0660844</td><td style=\"text-align: right;\">        0.188851</td><td style=\"text-align: right;\">                0.0719091</td></tr>\n",
              "<tr><td>M          </td><td style=\"text-align: right;\">     19.392  </td><td style=\"text-align: right;\">       22.1191</td><td style=\"text-align: right;\">        123.558 </td><td style=\"text-align: right;\">   1145.91 </td><td style=\"text-align: right;\">        0.107064 </td><td style=\"text-align: right;\">         0.148671 </td><td style=\"text-align: right;\">       0.0650008</td><td style=\"text-align: right;\">            0.0549573</td><td style=\"text-align: right;\">       0.155104</td><td style=\"text-align: right;\">               0.0532631</td><td style=\"text-align: right;\">   0.548277</td><td style=\"text-align: right;\">    0.994942</td><td style=\"text-align: right;\">      1.55479 </td><td style=\"text-align: right;\">  35.988 </td><td style=\"text-align: right;\">     0.00648556</td><td style=\"text-align: right;\">      0.0113865 </td><td style=\"text-align: right;\">    0.0332146 </td><td style=\"text-align: right;\">         0.0125249 </td><td style=\"text-align: right;\">   0.012637  </td><td style=\"text-align: right;\">            0.00344146</td><td style=\"text-align: right;\">       21.9918</td><td style=\"text-align: right;\">        33.9526</td><td style=\"text-align: right;\">         116.587 </td><td style=\"text-align: right;\">    1652.41 </td><td style=\"text-align: right;\">         0.13531  </td><td style=\"text-align: right;\">           0.372403</td><td style=\"text-align: right;\">        0.309631 </td><td style=\"text-align: right;\">             0.216026 </td><td style=\"text-align: right;\">        0.23314 </td><td style=\"text-align: right;\">                0.0682725</td></tr>\n",
              "<tr><td>M          </td><td style=\"text-align: right;\">     20.9458 </td><td style=\"text-align: right;\">       20.1877</td><td style=\"text-align: right;\">        142.645 </td><td style=\"text-align: right;\">   1132.84 </td><td style=\"text-align: right;\">        0.0839485</td><td style=\"text-align: right;\">         0.127151 </td><td style=\"text-align: right;\">       0.0691208</td><td style=\"text-align: right;\">            0.0913646</td><td style=\"text-align: right;\">       0.149046</td><td style=\"text-align: right;\">               0.056304 </td><td style=\"text-align: right;\">   0.589907</td><td style=\"text-align: right;\">    0.845669</td><td style=\"text-align: right;\">      3.39574 </td><td style=\"text-align: right;\">  64.4287</td><td style=\"text-align: right;\">     0.00544602</td><td style=\"text-align: right;\">      0.0175367 </td><td style=\"text-align: right;\">    0.0500399 </td><td style=\"text-align: right;\">         0.00713789</td><td style=\"text-align: right;\">   0.00899769</td><td style=\"text-align: right;\">            0.00364937</td><td style=\"text-align: right;\">       24.1051</td><td style=\"text-align: right;\">        20.9021</td><td style=\"text-align: right;\">         150.1   </td><td style=\"text-align: right;\">    1862.37 </td><td style=\"text-align: right;\">         0.120703 </td><td style=\"text-align: right;\">           0.158036</td><td style=\"text-align: right;\">        0.227143 </td><td style=\"text-align: right;\">             0.174872 </td><td style=\"text-align: right;\">        0.30507 </td><td style=\"text-align: right;\">                0.0798406</td></tr>\n",
              "</tbody>\n",
              "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[10000 rows x 31 columns]</pre>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hy = \"diagnosis\"\n",
        "hx = hdf.columns\n",
        "hx.remove(hy)"
      ],
      "metadata": {
        "id": "X-QiglXeF_XE"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, valid = hdf.split_frame(ratios=[.8], seed=123)"
      ],
      "metadata": {
        "id": "NVoFNbYCGxGh"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aml = H2OAutoML(max_models = 10, seed = 123, verbosity=\"info\", nfolds=10, sort_metric='accuracy')"
      ],
      "metadata": {
        "id": "7JNO6XnVHH5P"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aml.train(x = hx, y = hy, training_frame = train, validation_frame = valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Lbo606kFH4Zc",
        "outputId": "f25caa0b-19b5-42ae-986a-737e1937439f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoML progress: |\n",
            "22:12:08.376: Project: AutoML_1_20230621_221208\n",
            "22:12:08.381: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n",
            "22:12:08.384: Setting stopping tolerance adaptively based on the training frame: 0.011167086836213468\n",
            "22:12:08.385: Build control seed: 123\n",
            "22:12:08.386: training frame: Frame key: AutoML_1_20230621_221208_training_py_3_sid_8e4e    cols: 31    rows: 8019  chunks: 2    size: 1930732  checksum: -5210069067940660864\n",
            "22:12:08.386: validation frame: Frame key: py_4_sid_8e4e    cols: 31    rows: 1981  chunks: 2    size: 480857  checksum: 738344009934439224\n",
            "22:12:08.386: leaderboard frame: NULL\n",
            "22:12:08.386: blending frame: NULL\n",
            "22:12:08.386: response column: diagnosis\n",
            "22:12:08.386: fold column: null\n",
            "22:12:08.387: weights column: null\n",
            "22:12:08.447: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (7g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (7g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (6g, 60w)]}, {StackedEnsemble : [monotonic (9g, 10w), best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
            "22:12:08.490: AutoML job created: 2023.06.21 22:12:08.306\n",
            "22:12:08.492: AutoML build started: 2023.06.21 22:12:08.491\n",
            "22:12:08.531: AutoML: starting XGBoost_1_AutoML_1_20230621_221208 model training\n",
            "\n",
            "██\n",
            "22:12:41.318: New leader: XGBoost_1_AutoML_1_20230621_221208, accuracy: 0.9491208380097269\n",
            "22:12:41.326: AutoML: starting GLM_1_AutoML_1_20230621_221208 model training\n",
            "\n",
            "███\n",
            "22:12:59.893: AutoML: starting GBM_1_AutoML_1_20230621_221208 model training\n",
            "\n",
            "██\n",
            "22:14:07.203: AutoML: starting XGBoost_2_AutoML_1_20230621_221208 model training\n",
            "\n",
            "█\n",
            "22:14:28.391: AutoML: starting DRF_1_AutoML_1_20230621_221208 model training\n",
            "\n",
            "███\n",
            "22:14:59.631: AutoML: starting GBM_2_AutoML_1_20230621_221208 model training\n",
            "\n",
            "█\n",
            "22:15:38.188: AutoML: starting GBM_3_AutoML_1_20230621_221208 model training\n",
            "\n",
            "█\n",
            "22:16:15.135: AutoML: starting GBM_4_AutoML_1_20230621_221208 model training\n",
            "\n",
            "█\n",
            "22:16:57.360: AutoML: starting XGBoost_3_AutoML_1_20230621_221208 model training\n",
            "\n",
            "█\n",
            "22:17:14.350: AutoML: starting XRT_1_AutoML_1_20230621_221208 model training\n",
            "\n",
            "██\n",
            "22:17:49.717: New leader: XRT_1_AutoML_1_20230621_221208, accuracy: 0.9482479112108742\n",
            "22:17:49.720: No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'monotonic'.\n",
            "22:17:49.734: AutoML: starting StackedEnsemble_BestOfFamily_1_AutoML_1_20230621_221208 model training\n",
            "\n",
            "███\n",
            "22:18:02.739: AutoML: starting StackedEnsemble_AllModels_1_AutoML_1_20230621_221208 model training\n",
            "\n",
            "███████████████████████████████████████████| (done) 100%\n",
            "\n",
            "22:18:20.399: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GLM : [def_1 (1g, 10w)]}, {GBM : [def_5 (1g, 10w)]}, {XGBoost : [def_1 (2g, 10w)]}, {DRF : [def_1 (2g, 10w)]}, {GBM : [def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w)]}, {XGBoost : [def_3 (3g, 10w)]}, {DRF : [XRT (3g, 10w)]}, {StackedEnsemble : [best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
            "22:18:20.399: AutoML build stopped: 2023.06.21 22:18:20.399\n",
            "22:18:20.399: AutoML build done: built 10 models\n",
            "22:18:20.399: AutoML duration:  6 min 11.908 sec\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model Details\n",
              "=============\n",
              "H2ORandomForestEstimator : Distributed Random Forest\n",
              "Model Key: XRT_1_AutoML_1_20230621_221208\n",
              "\n",
              "\n",
              "Model Summary: \n",
              "    number_of_trees    number_of_internal_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n",
              "--  -----------------  --------------------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n",
              "    44                 44                          197575                 16           20           18.6818       322           387           352.682\n",
              "\n",
              "ModelMetricsBinomial: drf\n",
              "** Reported on train data. **\n",
              "\n",
              "MSE: 0.041742776868105666\n",
              "RMSE: 0.20431049133146753\n",
              "LogLoss: 0.18373419051793238\n",
              "Mean Per-Class Error: 0.0575781811330931\n",
              "AUC: 0.9872121269052022\n",
              "AUCPR: 0.9815838197399517\n",
              "Gini: 0.9744242538104044\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4615384615384616\n",
              "       B     M     Error    Rate\n",
              "-----  ----  ----  -------  --------------\n",
              "B      4714  253   0.0509   (253.0/4967.0)\n",
              "M      196   2856  0.0642   (196.0/3052.0)\n",
              "Total  4910  3109  0.056    (449.0/8019.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.461538     0.927122  108\n",
              "max f2                       0.24         0.94815   159\n",
              "max f0point5                 0.652174     0.943885  64\n",
              "max accuracy                 0.461538     0.944008  108\n",
              "max precision                1            0.998828  0\n",
              "max recall                   0            1         274\n",
              "max specificity              1            0.999597  0\n",
              "max absolute_mcc             0.461538     0.881769  108\n",
              "max min_per_class_accuracy   0.428571     0.942017  113\n",
              "max mean_per_class_accuracy  0.384615     0.94358   124\n",
              "max tns                      1            4965      0\n",
              "max fns                      1            1347      0\n",
              "max fps                      0            4967      274\n",
              "max tps                      0            3052      274\n",
              "max tnr                      1            0.999597  0\n",
              "max fnr                      1            0.44135   0\n",
              "max fpr                      0            1         274\n",
              "max tpr                      0            1         274\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 38.06 %, avg score: 37.96 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.212869                    1                  2.62438    2.62438            0.998828         1           0.998828                    1                   0.55865         0.55865                    162.438   162.438            0.558247\n",
              "2        0.300162                    0.8                2.52236    2.59471            0.96             0.894995    0.987536                    0.969463            0.220183        0.778834                   152.236   159.471            0.772794\n",
              "3        0.400923                    0.4                1.69419    2.36839            0.644802         0.603894    0.9014                      0.877587            0.170708        0.949541                   69.419    136.839            0.88572\n",
              "4        0.501309                    0.105263           0.40799    1.97582            0.15528          0.230421    0.75199                     0.747993            0.0409567       0.990498                   -59.201   97.5822            0.789773\n",
              "5        1                           0                  0.0190538  1                  0.00725181       0.00926727  0.380596                    0.379597            0.00950197      1                          -98.0946  0                  0\n",
              "\n",
              "ModelMetricsBinomial: drf\n",
              "** Reported on validation data. **\n",
              "\n",
              "MSE: 0.044211270195100294\n",
              "RMSE: 0.21026476213360215\n",
              "LogLoss: 0.1610109017476356\n",
              "Mean Per-Class Error: 0.06374504329055117\n",
              "AUC: 0.987230940532285\n",
              "AUCPR: 0.9826571285713736\n",
              "Gini: 0.97446188106457\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5020661150867289\n",
              "       B     M    Error    Rate\n",
              "-----  ----  ---  -------  --------------\n",
              "B      1155  44   0.0367   (44.0/1199.0)\n",
              "M      71    711  0.0908   (71.0/782.0)\n",
              "Total  1226  755  0.0581   (115.0/1981.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.502066     0.925179  28\n",
              "max f2                       0.261364     0.945577  55\n",
              "max f0point5                 0.592657     0.946656  20\n",
              "max accuracy                 0.522915     0.942453  26\n",
              "max precision                1            1         0\n",
              "max recall                   0            1         97\n",
              "max specificity              1            1         0\n",
              "max absolute_mcc             0.522915     0.879317  26\n",
              "max min_per_class_accuracy   0.432006     0.936061  38\n",
              "max mean_per_class_accuracy  0.433884     0.939034  35\n",
              "max tns                      1            1199      0\n",
              "max fns                      1            433       0\n",
              "max fps                      0            1199      97\n",
              "max tps                      0            782       97\n",
              "max tnr                      1            1         0\n",
              "max fnr                      1            0.553708  0\n",
              "max fpr                      0            1         97\n",
              "max tpr                      0            1         97\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 39.48 %, avg score: 38.88 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.176174                    1                  2.53325     2.53325            1                1            1                           1                   0.446292        0.446292                   153.325   153.325            0.446292\n",
              "2        0.212519                    0.977273           2.53325     2.53325            1                0.977273     1                           0.996113            0.0920716       0.538363                   153.325   153.325            0.538363\n",
              "3        0.303382                    0.795455           2.47695     2.51639            0.977778         0.894823     0.993344                    0.965777            0.225064        0.763427                   147.695   151.639            0.760091\n",
              "4        0.402322                    0.454545           1.70607     2.31711            0.673469         0.615698     0.91468                     0.879685            0.168798        0.932225                   70.6065   131.711            0.875511\n",
              "5        0.507824                    0.136364           0.533315    1.94652            0.210526         0.270607     0.76839                     0.753147            0.056266        0.988491                   -46.6685  94.6522            0.794162\n",
              "6        0.633518                    0.0227273          0.0813895   1.57647            0.0321285        0.0501141    0.622311                    0.613661            0.0102302       0.998721                   -91.8611  57.6468            0.603392\n",
              "7        1                           0                  0.00348932  1                  0.00137741       4.33006e-05  0.39475                     0.388781            0.00127877      1                          -99.6511  0                  0\n",
              "\n",
              "ModelMetricsBinomial: drf\n",
              "** Reported on cross-validation data. **\n",
              "\n",
              "MSE: 0.03898470525935156\n",
              "RMSE: 0.19744544881903853\n",
              "LogLoss: 0.14274403270840974\n",
              "Mean Per-Class Error: 0.056429446140068354\n",
              "AUC: 0.9901730187256865\n",
              "AUCPR: 0.9851653844865583\n",
              "Gini: 0.980346037451373\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5333333333333333\n",
              "       B     M     Error    Rate\n",
              "-----  ----  ----  -------  --------------\n",
              "B      4784  183   0.0368   (183.0/4967.0)\n",
              "M      232   2820  0.076    (232.0/3052.0)\n",
              "Total  5016  3003  0.0518   (415.0/8019.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.533333     0.931462  80\n",
              "max f2                       0.28         0.953548  132\n",
              "max f0point5                 0.64         0.949291  59\n",
              "max accuracy                 0.533333     0.948248  80\n",
              "max precision                0.933333     0.999484  9\n",
              "max recall                   0            1         202\n",
              "max specificity              1            0.999799  0\n",
              "max absolute_mcc             0.533333     0.889971  80\n",
              "max min_per_class_accuracy   0.44         0.945239  96\n",
              "max mean_per_class_accuracy  0.400465     0.947216  104\n",
              "max tns                      1            4966      0\n",
              "max fns                      1            1656      0\n",
              "max fps                      0            4967      202\n",
              "max tps                      0            3052      202\n",
              "max tnr                      1            0.999799  0\n",
              "max fnr                      1            0.542595  0\n",
              "max fpr                      0            1         202\n",
              "max tpr                      0            1         202\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 38.06 %, avg score: 38.03 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.174211                    1                  2.62558     2.62558            0.999284         1            0.999284                    1                   0.457405        0.457405                   162.558   162.558            0.457204\n",
              "2        0.202644                    0.971429           2.62746     2.62584            1                0.978596     0.999385                    0.996997            0.0747051       0.53211                    162.746   162.584            0.531909\n",
              "3        0.300786                    0.78               2.54733     2.60022            0.969504         0.895454     0.989635                    0.963865            0.25            0.78211                    154.733   160.022            0.777077\n",
              "4        0.40429                     0.4                1.69044     2.36731            0.643373         0.599281     0.900987                    0.870526            0.174967        0.957077                   69.0436   136.731            0.892451\n",
              "5        0.51141                     0.1                0.354814    1.94577            0.135041         0.217784     0.740551                    0.733802            0.0380079       0.995085                   -64.5186  94.5766            0.780871\n",
              "6        0.633745                    0.02               0.0348185   1.57689            0.0132518        0.0407945    0.600157                    0.600028            0.0042595       0.999345                   -96.5182  57.6888            0.590245\n",
              "7        1                           0                  0.00178921  1                  0.000680967      6.80967e-06  0.380596                    0.380267            0.000655308     1                          -99.8211  0                  0\n",
              "\n",
              "Cross-Validation Metrics Summary: \n",
              "                         mean       sd          cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid    cv_6_valid    cv_7_valid    cv_8_valid    cv_9_valid    cv_10_valid\n",
              "-----------------------  ---------  ----------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  -------------\n",
              "accuracy                 0.950992   0.00454777  0.955112      0.945137      0.950125      0.945137      0.951372      0.948878      0.956359      0.955112      0.946384      0.956305\n",
              "auc                      0.990222   0.0018713   0.99344       0.989633      0.99025       0.987282      0.989987      0.990011      0.992795      0.990331      0.987918      0.990573\n",
              "err                      0.0490079  0.00454777  0.0448878     0.0548628     0.0498753     0.0548628     0.0486284     0.0511222     0.0436409     0.0448878     0.053616      0.0436954\n",
              "err_count                39.3       3.653       36            44            40            44            39            41            35            36            43            35\n",
              "f0point5                 0.935877   0.0165531   0.964126      0.909968      0.934195      0.942029      0.916612      0.9257        0.939415      0.943396      0.928526      0.954806\n",
              "f1                       0.935454   0.00699281  0.934783      0.927869      0.940828      0.921986      0.934233      0.936826      0.940375      0.941558      0.9312        0.944882\n",
              "f2                       0.935488   0.0171474   0.907173      0.946488      0.947557      0.902778      0.952545      0.948222      0.941337      0.939728      0.93389       0.935162\n",
              "lift_top_group           2.6318     0.134172    2.76552       2.71864       2.4012        2.74658       2.77276       2.52201       2.7372        2.59547       2.57878       2.47988\n",
              "logloss                  0.142941   0.0197233   0.115235      0.131696      0.173168      0.140276      0.1682        0.136001      0.118814      0.140949      0.141814      0.163256\n",
              "max_per_class_error      0.0701453  0.0216841   0.110345      0.0631164     0.0512821     0.109589      0.0563107     0.0557851     0.0580205     0.0614887     0.0643087     0.0712074\n",
              "mcc                      0.89661    0.0096192   0.903395      0.884918      0.897923      0.881077      0.896878      0.894429      0.905963      0.905134      0.887307      0.90908\n",
              "mean_per_class_accuracy  0.947898   0.00654281  0.940921      0.948103      0.950407      0.933441      0.954423      0.950095      0.953308      0.952014      0.944424      0.951844\n",
              "mean_per_class_error     0.052102   0.00654281  0.0590787     0.0518972     0.0495931     0.0665592     0.0455769     0.0499051     0.046692      0.0479857     0.0555759     0.048156\n",
              "mse                      0.0389693  0.00306778  0.0336931     0.0403275     0.039522      0.0427058     0.0375024     0.0406889     0.0350779     0.0410383     0.0423526     0.0367846\n",
              "pr_auc                   0.985186   0.00335343  0.989064      0.983129      0.988671      0.980534      0.980179      0.985582      0.988456      0.985204      0.983067      0.987968\n",
              "precision                0.93642    0.0264467   0.984733      0.898413      0.929825      0.955882      0.905229      0.918429      0.938776      0.944625      0.926752      0.961538\n",
              "r2                       0.834448   0.0125903   0.854044      0.826572      0.837372      0.815548      0.8368        0.829959      0.848715      0.826726      0.821603      0.847137\n",
              "recall                   0.935759   0.0266079   0.889655      0.959322      0.952096      0.890411      0.965157      0.955975      0.941979      0.938511      0.935691      0.928793\n",
              "rmse                     0.197266   0.00784811  0.183557      0.200817      0.198801      0.206654      0.193655      0.201715      0.187291      0.202579      0.205797      0.191793\n",
              "specificity              0.960037   0.0176535   0.992188      0.936884      0.948718      0.976471      0.943689      0.944215      0.964637      0.965517      0.953157      0.974895\n",
              "\n",
              "Scoring History: \n",
              "    timestamp            duration    number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
              "--  -------------------  ----------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ----------------  -------------------  -----------------  ---------------------------------\n",
              "    2023-06-21 22:17:46  32.569 sec  0                  nan              nan                 nan             nan                nan              nan                              nan                nan                   nan               nan                  nan                nan\n",
              "    2023-06-21 22:17:47  32.892 sec  5                  0.265484         1.74132             0.93921         0.900597           2.44774          0.0869925                        0.236113           0.453952              0.973293          0.960785             2.49947            0.0731954\n",
              "    2023-06-21 22:17:47  33.220 sec  10                 0.231593         0.776505            0.967315        0.9485             2.55409          0.0722026                        0.219402           0.232562              0.982869          0.975322             2.52251            0.0605755\n",
              "    2023-06-21 22:17:47  33.525 sec  15                 0.22043          0.503559            0.975977        0.962402           2.58324          0.0636784                        0.21426            0.18124               0.985791          0.979494             2.52748            0.0595659\n",
              "    2023-06-21 22:17:48  33.787 sec  20                 0.214226         0.343853            0.981147        0.971306           2.60394          0.0604814                        0.210407           0.162538              0.987066          0.982266             2.53325            0.0545179\n",
              "    2023-06-21 22:17:48  34.064 sec  25                 0.209957         0.289651            0.983349        0.975262           2.61099          0.0612296                        0.211431           0.16102               0.987087          0.982128             2.53325            0.0600707\n",
              "    2023-06-21 22:17:48  34.344 sec  30                 0.207501         0.236249            0.985155        0.978592           2.61896          0.0594837                        0.210673           0.160472              0.987287          0.982417             2.53325            0.0575467\n",
              "    2023-06-21 22:17:48  34.643 sec  35                 0.205495         0.199322            0.986598        0.980714           2.62307          0.0567402                        0.21047            0.160701              0.987226          0.982411             2.53325            0.0570419\n",
              "    2023-06-21 22:17:49  34.983 sec  40                 0.204698         0.187424            0.987067        0.981444           2.62443          0.055992                         0.210416           0.16116               0.987178          0.982428             2.53325            0.0565371\n",
              "    2023-06-21 22:17:49  35.276 sec  44                 0.20431          0.183734            0.987212        0.981584           2.62438          0.055992                         0.210265           0.161011              0.987231          0.982657             2.53325            0.0580515\n",
              "\n",
              "Variable Importances: \n",
              "variable                 relative_importance    scaled_importance     percentage\n",
              "-----------------------  ---------------------  --------------------  ---------------------\n",
              "concave points_mean      11857.65625            1.0                   0.1765809050503654\n",
              "perimeter_worst          9856.330078125         0.831220763219966     0.1467777146660371\n",
              "radius_worst             9738.794921875         0.8213085888600455    0.1450274139465453\n",
              "concave points_worst     6207.02490234375       0.5234613629775067    0.09243328123346596\n",
              "area_se                  5506.34619140625       0.4643705362437244    0.08199896956864036\n",
              "perimeter_mean           4992.412109375         0.42102857462873405   0.07434560676000718\n",
              "radius_se                2336.15771484375       0.1970168189724466    0.03478940820429862\n",
              "area_worst               2132.290283203125      0.1798239245806375    0.03175347135215762\n",
              "concavity_mean           1775.343994140625      0.1497213240719999    0.026437926909972802\n",
              "compactness_worst        1584.4405517578125     0.13362173083384943   0.02359504616503745\n",
              "---                      ---                    ---                   ---\n",
              "smoothness_mean          366.64947509765625     0.030920906068402535  0.005460041578535855\n",
              "symmetry_mean            338.6394348144531      0.02855871579296736   0.0050429238817983404\n",
              "fractal_dimension_mean   331.54730224609375     0.02796061002747434   0.004937309824411741\n",
              "fractal_dimension_worst  319.9285888671875      0.02698076096338073   0.0047642871898613375\n",
              "concavity_se             319.1920166015625      0.02691864310044934   0.004753318361405119\n",
              "smoothness_se            315.3716125488281      0.026596454299206738  0.004696425971284607\n",
              "texture_se               302.1045227050781      0.02547759155230007   0.00449885617480869\n",
              "fractal_dimension_se     301.01763916015625     0.025385930643769188  0.004482670608622568\n",
              "symmetry_se              288.40093994140625     0.02432191774334884   0.004294786247681079\n",
              "concave points_se        252.89234924316406     0.021327346982517228  0.003766002232496072\n",
              "[30 rows x 4 columns]\n",
              "\n",
              "\n",
              "[tips]\n",
              "Use `model.explain()` to inspect the model.\n",
              "--\n",
              "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
            ],
            "text/html": [
              "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
              "=============\n",
              "H2ORandomForestEstimator : Distributed Random Forest\n",
              "Model Key: XRT_1_AutoML_1_20230621_221208\n",
              "</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-2.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-2 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-2 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-2 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-2 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-2 .h2o-table th,\n",
              "#h2o-table-2 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Model Summary: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>number_of_trees</th>\n",
              "<th>number_of_internal_trees</th>\n",
              "<th>model_size_in_bytes</th>\n",
              "<th>min_depth</th>\n",
              "<th>max_depth</th>\n",
              "<th>mean_depth</th>\n",
              "<th>min_leaves</th>\n",
              "<th>max_leaves</th>\n",
              "<th>mean_leaves</th></tr></thead>\n",
              "    <tbody><tr><td></td>\n",
              "<td>44.0</td>\n",
              "<td>44.0</td>\n",
              "<td>197575.0</td>\n",
              "<td>16.0</td>\n",
              "<td>20.0</td>\n",
              "<td>18.681818</td>\n",
              "<td>322.0</td>\n",
              "<td>387.0</td>\n",
              "<td>352.68182</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: drf\n",
              "** Reported on train data. **\n",
              "\n",
              "MSE: 0.041742776868105666\n",
              "RMSE: 0.20431049133146753\n",
              "LogLoss: 0.18373419051793238\n",
              "Mean Per-Class Error: 0.0575781811330931\n",
              "AUC: 0.9872121269052022\n",
              "AUCPR: 0.9815838197399517\n",
              "Gini: 0.9744242538104044</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-3.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-3 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-3 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-3 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-3 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-3 .h2o-table th,\n",
              "#h2o-table-3 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-3 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-3\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4615384615384616</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>B</th>\n",
              "<th>M</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>B</td>\n",
              "<td>4714.0</td>\n",
              "<td>253.0</td>\n",
              "<td>0.0509</td>\n",
              "<td> (253.0/4967.0)</td></tr>\n",
              "<tr><td>M</td>\n",
              "<td>196.0</td>\n",
              "<td>2856.0</td>\n",
              "<td>0.0642</td>\n",
              "<td> (196.0/3052.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>4910.0</td>\n",
              "<td>3109.0</td>\n",
              "<td>0.056</td>\n",
              "<td> (449.0/8019.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-4.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-4 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-4 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-4 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-4 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-4 .h2o-table th,\n",
              "#h2o-table-4 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-4 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-4\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.4615385</td>\n",
              "<td>0.9271222</td>\n",
              "<td>108.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.24</td>\n",
              "<td>0.9481500</td>\n",
              "<td>159.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.6521739</td>\n",
              "<td>0.9438849</td>\n",
              "<td>64.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.4615385</td>\n",
              "<td>0.9440080</td>\n",
              "<td>108.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9988284</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>274.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9995973</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.4615385</td>\n",
              "<td>0.8817689</td>\n",
              "<td>108.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.4285714</td>\n",
              "<td>0.9420173</td>\n",
              "<td>113.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.3846154</td>\n",
              "<td>0.9435805</td>\n",
              "<td>124.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>1.0</td>\n",
              "<td>4965.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>1.0</td>\n",
              "<td>1347.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0</td>\n",
              "<td>4967.0</td>\n",
              "<td>274.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0</td>\n",
              "<td>3052.0</td>\n",
              "<td>274.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9995973</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>1.0</td>\n",
              "<td>0.4413499</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>274.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>274.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-5.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-5 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-5 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-5 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-5 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-5 .h2o-table th,\n",
              "#h2o-table-5 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-5 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-5\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 38.06 %, avg score: 37.96 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.2128694</td>\n",
              "<td>1.0</td>\n",
              "<td>2.6243790</td>\n",
              "<td>2.6243790</td>\n",
              "<td>0.9988284</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9988284</td>\n",
              "<td>1.0</td>\n",
              "<td>0.5586501</td>\n",
              "<td>0.5586501</td>\n",
              "<td>162.4378955</td>\n",
              "<td>162.4378955</td>\n",
              "<td>0.5582474</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.3001621</td>\n",
              "<td>0.8</td>\n",
              "<td>2.5223591</td>\n",
              "<td>2.5947097</td>\n",
              "<td>0.96</td>\n",
              "<td>0.8949948</td>\n",
              "<td>0.9875364</td>\n",
              "<td>0.9694626</td>\n",
              "<td>0.2201835</td>\n",
              "<td>0.7788336</td>\n",
              "<td>152.2359109</td>\n",
              "<td>159.4709702</td>\n",
              "<td>0.7727937</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.4009228</td>\n",
              "<td>0.4</td>\n",
              "<td>1.6941897</td>\n",
              "<td>2.3683893</td>\n",
              "<td>0.6448020</td>\n",
              "<td>0.6038941</td>\n",
              "<td>0.9013997</td>\n",
              "<td>0.8775872</td>\n",
              "<td>0.1707077</td>\n",
              "<td>0.9495413</td>\n",
              "<td>69.4189738</td>\n",
              "<td>136.8389288</td>\n",
              "<td>0.8857201</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.5013094</td>\n",
              "<td>0.1052632</td>\n",
              "<td>0.4079903</td>\n",
              "<td>1.9758218</td>\n",
              "<td>0.1552795</td>\n",
              "<td>0.2304212</td>\n",
              "<td>0.7519900</td>\n",
              "<td>0.7479930</td>\n",
              "<td>0.0409567</td>\n",
              "<td>0.9904980</td>\n",
              "<td>-59.2009720</td>\n",
              "<td>97.5821825</td>\n",
              "<td>0.7897733</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0190538</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0072518</td>\n",
              "<td>0.0092673</td>\n",
              "<td>0.3805961</td>\n",
              "<td>0.3795974</td>\n",
              "<td>0.0095020</td>\n",
              "<td>1.0</td>\n",
              "<td>-98.0946170</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: drf\n",
              "** Reported on validation data. **\n",
              "\n",
              "MSE: 0.044211270195100294\n",
              "RMSE: 0.21026476213360215\n",
              "LogLoss: 0.1610109017476356\n",
              "Mean Per-Class Error: 0.06374504329055117\n",
              "AUC: 0.987230940532285\n",
              "AUCPR: 0.9826571285713736\n",
              "Gini: 0.97446188106457</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-6.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-6 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-6 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-6 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-6 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-6 .h2o-table th,\n",
              "#h2o-table-6 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-6 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-6\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5020661150867289</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>B</th>\n",
              "<th>M</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>B</td>\n",
              "<td>1155.0</td>\n",
              "<td>44.0</td>\n",
              "<td>0.0367</td>\n",
              "<td> (44.0/1199.0)</td></tr>\n",
              "<tr><td>M</td>\n",
              "<td>71.0</td>\n",
              "<td>711.0</td>\n",
              "<td>0.0908</td>\n",
              "<td> (71.0/782.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>1226.0</td>\n",
              "<td>755.0</td>\n",
              "<td>0.0581</td>\n",
              "<td> (115.0/1981.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-7.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-7 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-7 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-7 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-7 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-7 .h2o-table th,\n",
              "#h2o-table-7 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-7 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-7\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.5020661</td>\n",
              "<td>0.9251789</td>\n",
              "<td>28.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.2613636</td>\n",
              "<td>0.9455765</td>\n",
              "<td>55.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.5926573</td>\n",
              "<td>0.9466556</td>\n",
              "<td>20.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.5229151</td>\n",
              "<td>0.9424533</td>\n",
              "<td>26.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>97.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.5229151</td>\n",
              "<td>0.8793173</td>\n",
              "<td>26.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.4320060</td>\n",
              "<td>0.9360614</td>\n",
              "<td>38.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.4338843</td>\n",
              "<td>0.9390343</td>\n",
              "<td>35.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>1.0</td>\n",
              "<td>1199.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>1.0</td>\n",
              "<td>433.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0</td>\n",
              "<td>1199.0</td>\n",
              "<td>97.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0</td>\n",
              "<td>782.0</td>\n",
              "<td>97.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>1.0</td>\n",
              "<td>0.5537084</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>97.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>97.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-8.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-8 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-8 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-8 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-8 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-8 .h2o-table th,\n",
              "#h2o-table-8 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-8 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-8\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 39.48 %, avg score: 38.88 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.1761736</td>\n",
              "<td>1.0</td>\n",
              "<td>2.5332481</td>\n",
              "<td>2.5332481</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.4462916</td>\n",
              "<td>0.4462916</td>\n",
              "<td>153.3248082</td>\n",
              "<td>153.3248082</td>\n",
              "<td>0.4462916</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.2125189</td>\n",
              "<td>0.9772727</td>\n",
              "<td>2.5332481</td>\n",
              "<td>2.5332481</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9772727</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9961132</td>\n",
              "<td>0.0920716</td>\n",
              "<td>0.5383632</td>\n",
              "<td>153.3248082</td>\n",
              "<td>153.3248082</td>\n",
              "<td>0.5383632</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.3033821</td>\n",
              "<td>0.7954545</td>\n",
              "<td>2.4769537</td>\n",
              "<td>2.5163879</td>\n",
              "<td>0.9777778</td>\n",
              "<td>0.8948232</td>\n",
              "<td>0.9933444</td>\n",
              "<td>0.9657767</td>\n",
              "<td>0.2250639</td>\n",
              "<td>0.7634271</td>\n",
              "<td>147.6953680</td>\n",
              "<td>151.6387862</td>\n",
              "<td>0.7600910</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.4023221</td>\n",
              "<td>0.4545455</td>\n",
              "<td>1.7060650</td>\n",
              "<td>2.3171115</td>\n",
              "<td>0.6734694</td>\n",
              "<td>0.6156977</td>\n",
              "<td>0.9146801</td>\n",
              "<td>0.8796845</td>\n",
              "<td>0.1687980</td>\n",
              "<td>0.9322251</td>\n",
              "<td>70.6065035</td>\n",
              "<td>131.7111483</td>\n",
              "<td>0.8755111</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.5078243</td>\n",
              "<td>0.1363636</td>\n",
              "<td>0.5333154</td>\n",
              "<td>1.9465216</td>\n",
              "<td>0.2105263</td>\n",
              "<td>0.2706075</td>\n",
              "<td>0.7683897</td>\n",
              "<td>0.7531467</td>\n",
              "<td>0.0562660</td>\n",
              "<td>0.9884910</td>\n",
              "<td>-46.6684614</td>\n",
              "<td>94.6521637</td>\n",
              "<td>0.7941624</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.6335184</td>\n",
              "<td>0.0227273</td>\n",
              "<td>0.0813895</td>\n",
              "<td>1.5764675</td>\n",
              "<td>0.0321285</td>\n",
              "<td>0.0501141</td>\n",
              "<td>0.6223108</td>\n",
              "<td>0.6136605</td>\n",
              "<td>0.0102302</td>\n",
              "<td>0.9987212</td>\n",
              "<td>-91.8610503</td>\n",
              "<td>57.6467531</td>\n",
              "<td>0.6033918</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0034893</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0013774</td>\n",
              "<td>0.0000433</td>\n",
              "<td>0.3947501</td>\n",
              "<td>0.3887811</td>\n",
              "<td>0.0012788</td>\n",
              "<td>1.0</td>\n",
              "<td>-99.6510678</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: drf\n",
              "** Reported on cross-validation data. **\n",
              "\n",
              "MSE: 0.03898470525935156\n",
              "RMSE: 0.19744544881903853\n",
              "LogLoss: 0.14274403270840974\n",
              "Mean Per-Class Error: 0.056429446140068354\n",
              "AUC: 0.9901730187256865\n",
              "AUCPR: 0.9851653844865583\n",
              "Gini: 0.980346037451373</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-9.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-9 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-9 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-9 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-9 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-9 .h2o-table th,\n",
              "#h2o-table-9 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-9 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-9\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5333333333333333</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>B</th>\n",
              "<th>M</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>B</td>\n",
              "<td>4784.0</td>\n",
              "<td>183.0</td>\n",
              "<td>0.0368</td>\n",
              "<td> (183.0/4967.0)</td></tr>\n",
              "<tr><td>M</td>\n",
              "<td>232.0</td>\n",
              "<td>2820.0</td>\n",
              "<td>0.076</td>\n",
              "<td> (232.0/3052.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>5016.0</td>\n",
              "<td>3003.0</td>\n",
              "<td>0.0518</td>\n",
              "<td> (415.0/8019.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-10.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-10 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-10 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-10 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-10 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-10 .h2o-table th,\n",
              "#h2o-table-10 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-10 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-10\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.5333333</td>\n",
              "<td>0.9314616</td>\n",
              "<td>80.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.28</td>\n",
              "<td>0.9535476</td>\n",
              "<td>132.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.64</td>\n",
              "<td>0.9492908</td>\n",
              "<td>59.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.5333333</td>\n",
              "<td>0.9482479</td>\n",
              "<td>80.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>0.9333333</td>\n",
              "<td>0.9994837</td>\n",
              "<td>9.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>202.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9997987</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.5333333</td>\n",
              "<td>0.8899705</td>\n",
              "<td>80.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.4400000</td>\n",
              "<td>0.9452386</td>\n",
              "<td>96.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.4004651</td>\n",
              "<td>0.9472162</td>\n",
              "<td>104.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>1.0</td>\n",
              "<td>4966.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>1.0</td>\n",
              "<td>1656.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0</td>\n",
              "<td>4967.0</td>\n",
              "<td>202.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0</td>\n",
              "<td>3052.0</td>\n",
              "<td>202.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9997987</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>1.0</td>\n",
              "<td>0.5425950</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>202.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>202.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-11.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-11 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-11 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-11 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-11 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-11 .h2o-table th,\n",
              "#h2o-table-11 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-11 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-11\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 38.06 %, avg score: 38.03 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.1742112</td>\n",
              "<td>1.0</td>\n",
              "<td>2.6255766</td>\n",
              "<td>2.6255766</td>\n",
              "<td>0.9992842</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9992842</td>\n",
              "<td>1.0</td>\n",
              "<td>0.4574050</td>\n",
              "<td>0.4574050</td>\n",
              "<td>162.5576619</td>\n",
              "<td>162.5576619</td>\n",
              "<td>0.4572037</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.2026437</td>\n",
              "<td>0.9714286</td>\n",
              "<td>2.6274574</td>\n",
              "<td>2.6258405</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9785965</td>\n",
              "<td>0.9993846</td>\n",
              "<td>0.9969969</td>\n",
              "<td>0.0747051</td>\n",
              "<td>0.5321101</td>\n",
              "<td>162.7457405</td>\n",
              "<td>162.5840508</td>\n",
              "<td>0.5319088</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.3007856</td>\n",
              "<td>0.78</td>\n",
              "<td>2.5473316</td>\n",
              "<td>2.6002242</td>\n",
              "<td>0.9695044</td>\n",
              "<td>0.8954536</td>\n",
              "<td>0.9896352</td>\n",
              "<td>0.9638648</td>\n",
              "<td>0.25</td>\n",
              "<td>0.7821101</td>\n",
              "<td>154.7331639</td>\n",
              "<td>160.0224223</td>\n",
              "<td>0.7770769</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.4042898</td>\n",
              "<td>0.4</td>\n",
              "<td>1.6904365</td>\n",
              "<td>2.3673051</td>\n",
              "<td>0.6433735</td>\n",
              "<td>0.5992807</td>\n",
              "<td>0.9009870</td>\n",
              "<td>0.8705259</td>\n",
              "<td>0.1749672</td>\n",
              "<td>0.9570773</td>\n",
              "<td>69.0436451</td>\n",
              "<td>136.7305083</td>\n",
              "<td>0.8924508</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.5114104</td>\n",
              "<td>0.1</td>\n",
              "<td>0.3548138</td>\n",
              "<td>1.9457664</td>\n",
              "<td>0.1350407</td>\n",
              "<td>0.2177843</td>\n",
              "<td>0.7405511</td>\n",
              "<td>0.7338019</td>\n",
              "<td>0.0380079</td>\n",
              "<td>0.9950852</td>\n",
              "<td>-64.5186194</td>\n",
              "<td>94.5766432</td>\n",
              "<td>0.7808714</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.6337449</td>\n",
              "<td>0.02</td>\n",
              "<td>0.0348185</td>\n",
              "<td>1.5768881</td>\n",
              "<td>0.0132518</td>\n",
              "<td>0.0407945</td>\n",
              "<td>0.6001574</td>\n",
              "<td>0.6000278</td>\n",
              "<td>0.0042595</td>\n",
              "<td>0.9993447</td>\n",
              "<td>-96.5181502</td>\n",
              "<td>57.6888053</td>\n",
              "<td>0.5902446</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0017892</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0006810</td>\n",
              "<td>0.0000068</td>\n",
              "<td>0.3805961</td>\n",
              "<td>0.3802670</td>\n",
              "<td>0.0006553</td>\n",
              "<td>1.0</td>\n",
              "<td>-99.8210788</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-12.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-12 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-12 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-12 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-12 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-12 .h2o-table th,\n",
              "#h2o-table-12 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-12 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-12\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Cross-Validation Metrics Summary: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>mean</th>\n",
              "<th>sd</th>\n",
              "<th>cv_1_valid</th>\n",
              "<th>cv_2_valid</th>\n",
              "<th>cv_3_valid</th>\n",
              "<th>cv_4_valid</th>\n",
              "<th>cv_5_valid</th>\n",
              "<th>cv_6_valid</th>\n",
              "<th>cv_7_valid</th>\n",
              "<th>cv_8_valid</th>\n",
              "<th>cv_9_valid</th>\n",
              "<th>cv_10_valid</th></tr></thead>\n",
              "    <tbody><tr><td>accuracy</td>\n",
              "<td>0.9509920</td>\n",
              "<td>0.0045478</td>\n",
              "<td>0.9551122</td>\n",
              "<td>0.9451371</td>\n",
              "<td>0.9501247</td>\n",
              "<td>0.9451371</td>\n",
              "<td>0.9513715</td>\n",
              "<td>0.9488778</td>\n",
              "<td>0.9563591</td>\n",
              "<td>0.9551122</td>\n",
              "<td>0.946384</td>\n",
              "<td>0.9563046</td></tr>\n",
              "<tr><td>auc</td>\n",
              "<td>0.9902219</td>\n",
              "<td>0.0018713</td>\n",
              "<td>0.9934402</td>\n",
              "<td>0.9896333</td>\n",
              "<td>0.9902503</td>\n",
              "<td>0.9872817</td>\n",
              "<td>0.9899868</td>\n",
              "<td>0.9900105</td>\n",
              "<td>0.9927952</td>\n",
              "<td>0.9903306</td>\n",
              "<td>0.9879175</td>\n",
              "<td>0.9905728</td></tr>\n",
              "<tr><td>err</td>\n",
              "<td>0.0490079</td>\n",
              "<td>0.0045478</td>\n",
              "<td>0.0448878</td>\n",
              "<td>0.0548628</td>\n",
              "<td>0.0498753</td>\n",
              "<td>0.0548628</td>\n",
              "<td>0.0486284</td>\n",
              "<td>0.0511222</td>\n",
              "<td>0.0436409</td>\n",
              "<td>0.0448878</td>\n",
              "<td>0.0536160</td>\n",
              "<td>0.0436954</td></tr>\n",
              "<tr><td>err_count</td>\n",
              "<td>39.3</td>\n",
              "<td>3.653005</td>\n",
              "<td>36.0</td>\n",
              "<td>44.0</td>\n",
              "<td>40.0</td>\n",
              "<td>44.0</td>\n",
              "<td>39.0</td>\n",
              "<td>41.0</td>\n",
              "<td>35.0</td>\n",
              "<td>36.0</td>\n",
              "<td>43.0</td>\n",
              "<td>35.0</td></tr>\n",
              "<tr><td>f0point5</td>\n",
              "<td>0.9358772</td>\n",
              "<td>0.0165531</td>\n",
              "<td>0.9641256</td>\n",
              "<td>0.9099678</td>\n",
              "<td>0.9341950</td>\n",
              "<td>0.942029</td>\n",
              "<td>0.9166115</td>\n",
              "<td>0.9257004</td>\n",
              "<td>0.9394146</td>\n",
              "<td>0.9433962</td>\n",
              "<td>0.9285259</td>\n",
              "<td>0.9548058</td></tr>\n",
              "<tr><td>f1</td>\n",
              "<td>0.9354539</td>\n",
              "<td>0.0069928</td>\n",
              "<td>0.9347826</td>\n",
              "<td>0.9278688</td>\n",
              "<td>0.9408284</td>\n",
              "<td>0.9219858</td>\n",
              "<td>0.9342327</td>\n",
              "<td>0.9368259</td>\n",
              "<td>0.9403748</td>\n",
              "<td>0.9415584</td>\n",
              "<td>0.9312</td>\n",
              "<td>0.9448819</td></tr>\n",
              "<tr><td>f2</td>\n",
              "<td>0.9354879</td>\n",
              "<td>0.0171474</td>\n",
              "<td>0.907173</td>\n",
              "<td>0.9464883</td>\n",
              "<td>0.9475566</td>\n",
              "<td>0.9027778</td>\n",
              "<td>0.9525447</td>\n",
              "<td>0.9482221</td>\n",
              "<td>0.941337</td>\n",
              "<td>0.9397278</td>\n",
              "<td>0.9338896</td>\n",
              "<td>0.9351621</td></tr>\n",
              "<tr><td>lift_top_group</td>\n",
              "<td>2.6318035</td>\n",
              "<td>0.1341717</td>\n",
              "<td>2.7655172</td>\n",
              "<td>2.7186441</td>\n",
              "<td>2.4011977</td>\n",
              "<td>2.7465754</td>\n",
              "<td>2.7727628</td>\n",
              "<td>2.5220125</td>\n",
              "<td>2.7372015</td>\n",
              "<td>2.5954692</td>\n",
              "<td>2.578778</td>\n",
              "<td>2.4798763</td></tr>\n",
              "<tr><td>logloss</td>\n",
              "<td>0.1429408</td>\n",
              "<td>0.0197233</td>\n",
              "<td>0.1152349</td>\n",
              "<td>0.1316957</td>\n",
              "<td>0.1731677</td>\n",
              "<td>0.1402760</td>\n",
              "<td>0.1681999</td>\n",
              "<td>0.1360007</td>\n",
              "<td>0.1188141</td>\n",
              "<td>0.140949</td>\n",
              "<td>0.1418141</td>\n",
              "<td>0.1632562</td></tr>\n",
              "<tr><td>max_per_class_error</td>\n",
              "<td>0.0701453</td>\n",
              "<td>0.0216841</td>\n",
              "<td>0.1103448</td>\n",
              "<td>0.0631164</td>\n",
              "<td>0.0512821</td>\n",
              "<td>0.1095890</td>\n",
              "<td>0.0563107</td>\n",
              "<td>0.0557851</td>\n",
              "<td>0.0580205</td>\n",
              "<td>0.0614887</td>\n",
              "<td>0.0643087</td>\n",
              "<td>0.0712074</td></tr>\n",
              "<tr><td>mcc</td>\n",
              "<td>0.8966104</td>\n",
              "<td>0.0096192</td>\n",
              "<td>0.9033948</td>\n",
              "<td>0.8849177</td>\n",
              "<td>0.8979232</td>\n",
              "<td>0.8810771</td>\n",
              "<td>0.896878</td>\n",
              "<td>0.8944289</td>\n",
              "<td>0.9059632</td>\n",
              "<td>0.9051344</td>\n",
              "<td>0.8873068</td>\n",
              "<td>0.9090797</td></tr>\n",
              "<tr><td>mean_per_class_accuracy</td>\n",
              "<td>0.9478980</td>\n",
              "<td>0.0065428</td>\n",
              "<td>0.9409213</td>\n",
              "<td>0.9481028</td>\n",
              "<td>0.9504069</td>\n",
              "<td>0.9334407</td>\n",
              "<td>0.9544231</td>\n",
              "<td>0.9500949</td>\n",
              "<td>0.9533080</td>\n",
              "<td>0.9520143</td>\n",
              "<td>0.9444241</td>\n",
              "<td>0.951844</td></tr>\n",
              "<tr><td>mean_per_class_error</td>\n",
              "<td>0.0521020</td>\n",
              "<td>0.0065428</td>\n",
              "<td>0.0590787</td>\n",
              "<td>0.0518972</td>\n",
              "<td>0.0495931</td>\n",
              "<td>0.0665592</td>\n",
              "<td>0.0455769</td>\n",
              "<td>0.0499051</td>\n",
              "<td>0.0466920</td>\n",
              "<td>0.0479857</td>\n",
              "<td>0.0555759</td>\n",
              "<td>0.0481560</td></tr>\n",
              "<tr><td>mse</td>\n",
              "<td>0.0389693</td>\n",
              "<td>0.0030678</td>\n",
              "<td>0.0336931</td>\n",
              "<td>0.0403275</td>\n",
              "<td>0.0395220</td>\n",
              "<td>0.0427058</td>\n",
              "<td>0.0375024</td>\n",
              "<td>0.0406889</td>\n",
              "<td>0.0350779</td>\n",
              "<td>0.0410383</td>\n",
              "<td>0.0423526</td>\n",
              "<td>0.0367846</td></tr>\n",
              "<tr><td>pr_auc</td>\n",
              "<td>0.9851856</td>\n",
              "<td>0.0033534</td>\n",
              "<td>0.9890643</td>\n",
              "<td>0.9831293</td>\n",
              "<td>0.988671</td>\n",
              "<td>0.9805338</td>\n",
              "<td>0.9801792</td>\n",
              "<td>0.9855819</td>\n",
              "<td>0.9884563</td>\n",
              "<td>0.9852043</td>\n",
              "<td>0.9830673</td>\n",
              "<td>0.9879683</td></tr>\n",
              "<tr><td>precision</td>\n",
              "<td>0.9364201</td>\n",
              "<td>0.0264467</td>\n",
              "<td>0.9847328</td>\n",
              "<td>0.8984127</td>\n",
              "<td>0.9298246</td>\n",
              "<td>0.9558824</td>\n",
              "<td>0.9052287</td>\n",
              "<td>0.918429</td>\n",
              "<td>0.9387755</td>\n",
              "<td>0.9446254</td>\n",
              "<td>0.9267516</td>\n",
              "<td>0.9615384</td></tr>\n",
              "<tr><td>r2</td>\n",
              "<td>0.8344477</td>\n",
              "<td>0.0125903</td>\n",
              "<td>0.8540440</td>\n",
              "<td>0.8265718</td>\n",
              "<td>0.837372</td>\n",
              "<td>0.8155482</td>\n",
              "<td>0.8368003</td>\n",
              "<td>0.8299595</td>\n",
              "<td>0.8487146</td>\n",
              "<td>0.8267264</td>\n",
              "<td>0.8216033</td>\n",
              "<td>0.8471374</td></tr>\n",
              "<tr><td>recall</td>\n",
              "<td>0.935759</td>\n",
              "<td>0.0266079</td>\n",
              "<td>0.8896552</td>\n",
              "<td>0.9593220</td>\n",
              "<td>0.9520958</td>\n",
              "<td>0.8904110</td>\n",
              "<td>0.9651568</td>\n",
              "<td>0.9559748</td>\n",
              "<td>0.9419795</td>\n",
              "<td>0.9385113</td>\n",
              "<td>0.9356913</td>\n",
              "<td>0.9287926</td></tr>\n",
              "<tr><td>rmse</td>\n",
              "<td>0.1972660</td>\n",
              "<td>0.0078481</td>\n",
              "<td>0.1835569</td>\n",
              "<td>0.200817</td>\n",
              "<td>0.1988014</td>\n",
              "<td>0.2066539</td>\n",
              "<td>0.1936555</td>\n",
              "<td>0.2017150</td>\n",
              "<td>0.1872910</td>\n",
              "<td>0.2025790</td>\n",
              "<td>0.2057975</td>\n",
              "<td>0.1917932</td></tr>\n",
              "<tr><td>specificity</td>\n",
              "<td>0.960037</td>\n",
              "<td>0.0176535</td>\n",
              "<td>0.9921875</td>\n",
              "<td>0.9368836</td>\n",
              "<td>0.9487180</td>\n",
              "<td>0.9764706</td>\n",
              "<td>0.9436893</td>\n",
              "<td>0.9442149</td>\n",
              "<td>0.9646366</td>\n",
              "<td>0.9655172</td>\n",
              "<td>0.9531568</td>\n",
              "<td>0.9748954</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-13.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-13 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-13 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-13 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-13 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-13 .h2o-table th,\n",
              "#h2o-table-13 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-13 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-13\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Scoring History: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>timestamp</th>\n",
              "<th>duration</th>\n",
              "<th>number_of_trees</th>\n",
              "<th>training_rmse</th>\n",
              "<th>training_logloss</th>\n",
              "<th>training_auc</th>\n",
              "<th>training_pr_auc</th>\n",
              "<th>training_lift</th>\n",
              "<th>training_classification_error</th>\n",
              "<th>validation_rmse</th>\n",
              "<th>validation_logloss</th>\n",
              "<th>validation_auc</th>\n",
              "<th>validation_pr_auc</th>\n",
              "<th>validation_lift</th>\n",
              "<th>validation_classification_error</th></tr></thead>\n",
              "    <tbody><tr><td></td>\n",
              "<td>2023-06-21 22:17:46</td>\n",
              "<td>32.569 sec</td>\n",
              "<td>0.0</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 22:17:47</td>\n",
              "<td>32.892 sec</td>\n",
              "<td>5.0</td>\n",
              "<td>0.2654843</td>\n",
              "<td>1.7413155</td>\n",
              "<td>0.9392099</td>\n",
              "<td>0.9005971</td>\n",
              "<td>2.4477362</td>\n",
              "<td>0.0869925</td>\n",
              "<td>0.2361131</td>\n",
              "<td>0.4539518</td>\n",
              "<td>0.9732930</td>\n",
              "<td>0.9607852</td>\n",
              "<td>2.4994714</td>\n",
              "<td>0.0731954</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 22:17:47</td>\n",
              "<td>33.220 sec</td>\n",
              "<td>10.0</td>\n",
              "<td>0.2315927</td>\n",
              "<td>0.7765049</td>\n",
              "<td>0.9673155</td>\n",
              "<td>0.9485001</td>\n",
              "<td>2.5540904</td>\n",
              "<td>0.0722026</td>\n",
              "<td>0.2194020</td>\n",
              "<td>0.2325617</td>\n",
              "<td>0.9828688</td>\n",
              "<td>0.9753224</td>\n",
              "<td>2.5225140</td>\n",
              "<td>0.0605755</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 22:17:47</td>\n",
              "<td>33.525 sec</td>\n",
              "<td>15.0</td>\n",
              "<td>0.2204299</td>\n",
              "<td>0.5035587</td>\n",
              "<td>0.9759766</td>\n",
              "<td>0.9624020</td>\n",
              "<td>2.5832365</td>\n",
              "<td>0.0636784</td>\n",
              "<td>0.2142603</td>\n",
              "<td>0.1812396</td>\n",
              "<td>0.9857911</td>\n",
              "<td>0.9794942</td>\n",
              "<td>2.5274776</td>\n",
              "<td>0.0595659</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 22:17:48</td>\n",
              "<td>33.787 sec</td>\n",
              "<td>20.0</td>\n",
              "<td>0.2142265</td>\n",
              "<td>0.3438534</td>\n",
              "<td>0.9811466</td>\n",
              "<td>0.9713057</td>\n",
              "<td>2.6039396</td>\n",
              "<td>0.0604814</td>\n",
              "<td>0.2104068</td>\n",
              "<td>0.1625383</td>\n",
              "<td>0.9870656</td>\n",
              "<td>0.9822662</td>\n",
              "<td>2.5332481</td>\n",
              "<td>0.0545179</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 22:17:48</td>\n",
              "<td>34.064 sec</td>\n",
              "<td>25.0</td>\n",
              "<td>0.2099573</td>\n",
              "<td>0.2896510</td>\n",
              "<td>0.9833486</td>\n",
              "<td>0.9752624</td>\n",
              "<td>2.6109929</td>\n",
              "<td>0.0612296</td>\n",
              "<td>0.2114308</td>\n",
              "<td>0.1610202</td>\n",
              "<td>0.9870875</td>\n",
              "<td>0.9821275</td>\n",
              "<td>2.5332481</td>\n",
              "<td>0.0600707</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 22:17:48</td>\n",
              "<td>34.344 sec</td>\n",
              "<td>30.0</td>\n",
              "<td>0.2075009</td>\n",
              "<td>0.2362486</td>\n",
              "<td>0.9851545</td>\n",
              "<td>0.9785918</td>\n",
              "<td>2.6189589</td>\n",
              "<td>0.0594837</td>\n",
              "<td>0.2106734</td>\n",
              "<td>0.1604717</td>\n",
              "<td>0.9872869</td>\n",
              "<td>0.9824172</td>\n",
              "<td>2.5332481</td>\n",
              "<td>0.0575467</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 22:17:48</td>\n",
              "<td>34.643 sec</td>\n",
              "<td>35.0</td>\n",
              "<td>0.2054949</td>\n",
              "<td>0.1993216</td>\n",
              "<td>0.9865976</td>\n",
              "<td>0.9807144</td>\n",
              "<td>2.6230686</td>\n",
              "<td>0.0567402</td>\n",
              "<td>0.2104699</td>\n",
              "<td>0.1607007</td>\n",
              "<td>0.9872256</td>\n",
              "<td>0.9824110</td>\n",
              "<td>2.5332481</td>\n",
              "<td>0.0570419</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 22:17:49</td>\n",
              "<td>34.983 sec</td>\n",
              "<td>40.0</td>\n",
              "<td>0.2046981</td>\n",
              "<td>0.1874237</td>\n",
              "<td>0.9870665</td>\n",
              "<td>0.9814442</td>\n",
              "<td>2.6244339</td>\n",
              "<td>0.0559920</td>\n",
              "<td>0.2104163</td>\n",
              "<td>0.1611603</td>\n",
              "<td>0.9871781</td>\n",
              "<td>0.9824279</td>\n",
              "<td>2.5332481</td>\n",
              "<td>0.0565371</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 22:17:49</td>\n",
              "<td>35.276 sec</td>\n",
              "<td>44.0</td>\n",
              "<td>0.2043105</td>\n",
              "<td>0.1837342</td>\n",
              "<td>0.9872121</td>\n",
              "<td>0.9815838</td>\n",
              "<td>2.6243790</td>\n",
              "<td>0.0559920</td>\n",
              "<td>0.2102648</td>\n",
              "<td>0.1610109</td>\n",
              "<td>0.9872309</td>\n",
              "<td>0.9826571</td>\n",
              "<td>2.5332481</td>\n",
              "<td>0.0580515</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-14.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-14 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-14 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-14 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-14 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-14 .h2o-table th,\n",
              "#h2o-table-14 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-14 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-14\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Variable Importances: </caption>\n",
              "    <thead><tr><th>variable</th>\n",
              "<th>relative_importance</th>\n",
              "<th>scaled_importance</th>\n",
              "<th>percentage</th></tr></thead>\n",
              "    <tbody><tr><td>concave points_mean</td>\n",
              "<td>11857.6562500</td>\n",
              "<td>1.0</td>\n",
              "<td>0.1765809</td></tr>\n",
              "<tr><td>perimeter_worst</td>\n",
              "<td>9856.3300781</td>\n",
              "<td>0.8312208</td>\n",
              "<td>0.1467777</td></tr>\n",
              "<tr><td>radius_worst</td>\n",
              "<td>9738.7949219</td>\n",
              "<td>0.8213086</td>\n",
              "<td>0.1450274</td></tr>\n",
              "<tr><td>concave points_worst</td>\n",
              "<td>6207.0249023</td>\n",
              "<td>0.5234614</td>\n",
              "<td>0.0924333</td></tr>\n",
              "<tr><td>area_se</td>\n",
              "<td>5506.3461914</td>\n",
              "<td>0.4643705</td>\n",
              "<td>0.0819990</td></tr>\n",
              "<tr><td>perimeter_mean</td>\n",
              "<td>4992.4121094</td>\n",
              "<td>0.4210286</td>\n",
              "<td>0.0743456</td></tr>\n",
              "<tr><td>radius_se</td>\n",
              "<td>2336.1577148</td>\n",
              "<td>0.1970168</td>\n",
              "<td>0.0347894</td></tr>\n",
              "<tr><td>area_worst</td>\n",
              "<td>2132.2902832</td>\n",
              "<td>0.1798239</td>\n",
              "<td>0.0317535</td></tr>\n",
              "<tr><td>concavity_mean</td>\n",
              "<td>1775.3439941</td>\n",
              "<td>0.1497213</td>\n",
              "<td>0.0264379</td></tr>\n",
              "<tr><td>compactness_worst</td>\n",
              "<td>1584.4405518</td>\n",
              "<td>0.1336217</td>\n",
              "<td>0.0235950</td></tr>\n",
              "<tr><td>---</td>\n",
              "<td>---</td>\n",
              "<td>---</td>\n",
              "<td>---</td></tr>\n",
              "<tr><td>smoothness_mean</td>\n",
              "<td>366.6494751</td>\n",
              "<td>0.0309209</td>\n",
              "<td>0.0054600</td></tr>\n",
              "<tr><td>symmetry_mean</td>\n",
              "<td>338.6394348</td>\n",
              "<td>0.0285587</td>\n",
              "<td>0.0050429</td></tr>\n",
              "<tr><td>fractal_dimension_mean</td>\n",
              "<td>331.5473022</td>\n",
              "<td>0.0279606</td>\n",
              "<td>0.0049373</td></tr>\n",
              "<tr><td>fractal_dimension_worst</td>\n",
              "<td>319.9285889</td>\n",
              "<td>0.0269808</td>\n",
              "<td>0.0047643</td></tr>\n",
              "<tr><td>concavity_se</td>\n",
              "<td>319.1920166</td>\n",
              "<td>0.0269186</td>\n",
              "<td>0.0047533</td></tr>\n",
              "<tr><td>smoothness_se</td>\n",
              "<td>315.3716125</td>\n",
              "<td>0.0265965</td>\n",
              "<td>0.0046964</td></tr>\n",
              "<tr><td>texture_se</td>\n",
              "<td>302.1045227</td>\n",
              "<td>0.0254776</td>\n",
              "<td>0.0044989</td></tr>\n",
              "<tr><td>fractal_dimension_se</td>\n",
              "<td>301.0176392</td>\n",
              "<td>0.0253859</td>\n",
              "<td>0.0044827</td></tr>\n",
              "<tr><td>symmetry_se</td>\n",
              "<td>288.4009399</td>\n",
              "<td>0.0243219</td>\n",
              "<td>0.0042948</td></tr>\n",
              "<tr><td>concave points_se</td>\n",
              "<td>252.8923492</td>\n",
              "<td>0.0213273</td>\n",
              "<td>0.0037660</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "<pre style='font-size: smaller; margin-bottom: 1em;'>[30 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
              "\n",
              "[tips]\n",
              "Use `model.explain()` to inspect the model.\n",
              "--\n",
              "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lb = aml.leaderboard\n",
        "lb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "gmCXw_D_4y1D",
        "outputId": "76c12b3e-b895-466e-a0c3-d54024a4f332"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model_id                              accuracy       auc    logloss     aucpr    mean_per_class_error      rmse        mse\n",
              "----------------------------------  ----------  --------  ---------  --------  ----------------------  --------  ---------\n",
              "XRT_1_AutoML_1_20230621_221208        0.948248  0.990173   0.142744  0.985165               0.0564294  0.197445  0.0389847\n",
              "XGBoost_1_AutoML_1_20230621_221208    0.949121  0.99135    0.119628  0.986632               0.0519982  0.191492  0.0366691\n",
              "XGBoost_3_AutoML_1_20230621_221208    0.949121  0.991217   0.122126  0.986492               0.0509619  0.193006  0.0372514\n",
              "DRF_1_AutoML_1_20230621_221208        0.94937   0.990019   0.143017  0.985409               0.0531233  0.197396  0.038965\n",
              "XGBoost_2_AutoML_1_20230621_221208    0.951366  0.991466   0.122189  0.986864               0.0498191  0.191878  0.0368172\n",
              "GLM_1_AutoML_1_20230621_221208        0.952363  0.991618   0.113402  0.987462               0.0499494  0.186467  0.0347701\n",
              "GBM_4_AutoML_1_20230621_221208        0.952363  0.991298   0.118826  0.986904               0.0485085  0.188759  0.03563\n",
              "GBM_1_AutoML_1_20230621_221208        0.952488  0.99202    0.111742  0.987773               0.0481808  0.184708  0.0341169\n",
              "GBM_3_AutoML_1_20230621_221208        0.952613  0.991659   0.116224  0.987435               0.0485598  0.186946  0.0349489\n",
              "GBM_2_AutoML_1_20230621_221208        0.952737  0.99222    0.113268  0.988108               0.0513528  0.186396  0.0347436\n",
              "[12 rows x 8 columns]\n"
            ],
            "text/html": [
              "<table class='dataframe'>\n",
              "<thead>\n",
              "<tr><th>model_id                          </th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">      mse</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>XRT_1_AutoML_1_20230621_221208    </td><td style=\"text-align: right;\">  0.948248</td><td style=\"text-align: right;\">0.990173</td><td style=\"text-align: right;\"> 0.142744</td><td style=\"text-align: right;\">0.985165</td><td style=\"text-align: right;\">             0.0564294</td><td style=\"text-align: right;\">0.197445</td><td style=\"text-align: right;\">0.0389847</td></tr>\n",
              "<tr><td>XGBoost_1_AutoML_1_20230621_221208</td><td style=\"text-align: right;\">  0.949121</td><td style=\"text-align: right;\">0.99135 </td><td style=\"text-align: right;\"> 0.119628</td><td style=\"text-align: right;\">0.986632</td><td style=\"text-align: right;\">             0.0519982</td><td style=\"text-align: right;\">0.191492</td><td style=\"text-align: right;\">0.0366691</td></tr>\n",
              "<tr><td>XGBoost_3_AutoML_1_20230621_221208</td><td style=\"text-align: right;\">  0.949121</td><td style=\"text-align: right;\">0.991217</td><td style=\"text-align: right;\"> 0.122126</td><td style=\"text-align: right;\">0.986492</td><td style=\"text-align: right;\">             0.0509619</td><td style=\"text-align: right;\">0.193006</td><td style=\"text-align: right;\">0.0372514</td></tr>\n",
              "<tr><td>DRF_1_AutoML_1_20230621_221208    </td><td style=\"text-align: right;\">  0.94937 </td><td style=\"text-align: right;\">0.990019</td><td style=\"text-align: right;\"> 0.143017</td><td style=\"text-align: right;\">0.985409</td><td style=\"text-align: right;\">             0.0531233</td><td style=\"text-align: right;\">0.197396</td><td style=\"text-align: right;\">0.038965 </td></tr>\n",
              "<tr><td>XGBoost_2_AutoML_1_20230621_221208</td><td style=\"text-align: right;\">  0.951366</td><td style=\"text-align: right;\">0.991466</td><td style=\"text-align: right;\"> 0.122189</td><td style=\"text-align: right;\">0.986864</td><td style=\"text-align: right;\">             0.0498191</td><td style=\"text-align: right;\">0.191878</td><td style=\"text-align: right;\">0.0368172</td></tr>\n",
              "<tr><td>GLM_1_AutoML_1_20230621_221208    </td><td style=\"text-align: right;\">  0.952363</td><td style=\"text-align: right;\">0.991618</td><td style=\"text-align: right;\"> 0.113402</td><td style=\"text-align: right;\">0.987462</td><td style=\"text-align: right;\">             0.0499494</td><td style=\"text-align: right;\">0.186467</td><td style=\"text-align: right;\">0.0347701</td></tr>\n",
              "<tr><td>GBM_4_AutoML_1_20230621_221208    </td><td style=\"text-align: right;\">  0.952363</td><td style=\"text-align: right;\">0.991298</td><td style=\"text-align: right;\"> 0.118826</td><td style=\"text-align: right;\">0.986904</td><td style=\"text-align: right;\">             0.0485085</td><td style=\"text-align: right;\">0.188759</td><td style=\"text-align: right;\">0.03563  </td></tr>\n",
              "<tr><td>GBM_1_AutoML_1_20230621_221208    </td><td style=\"text-align: right;\">  0.952488</td><td style=\"text-align: right;\">0.99202 </td><td style=\"text-align: right;\"> 0.111742</td><td style=\"text-align: right;\">0.987773</td><td style=\"text-align: right;\">             0.0481808</td><td style=\"text-align: right;\">0.184708</td><td style=\"text-align: right;\">0.0341169</td></tr>\n",
              "<tr><td>GBM_3_AutoML_1_20230621_221208    </td><td style=\"text-align: right;\">  0.952613</td><td style=\"text-align: right;\">0.991659</td><td style=\"text-align: right;\"> 0.116224</td><td style=\"text-align: right;\">0.987435</td><td style=\"text-align: right;\">             0.0485598</td><td style=\"text-align: right;\">0.186946</td><td style=\"text-align: right;\">0.0349489</td></tr>\n",
              "<tr><td>GBM_2_AutoML_1_20230621_221208    </td><td style=\"text-align: right;\">  0.952737</td><td style=\"text-align: right;\">0.99222 </td><td style=\"text-align: right;\"> 0.113268</td><td style=\"text-align: right;\">0.988108</td><td style=\"text-align: right;\">             0.0513528</td><td style=\"text-align: right;\">0.186396</td><td style=\"text-align: right;\">0.0347436</td></tr>\n",
              "</tbody>\n",
              "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[12 rows x 8 columns]</pre>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = aml.get_best_model()\n",
        "best_model"
      ],
      "metadata": {
        "id": "vlH8zwtisQU1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4973bd80-d415-4278-b36d-73cfae4611db"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model Details\n",
              "=============\n",
              "H2ORandomForestEstimator : Distributed Random Forest\n",
              "Model Key: XRT_1_AutoML_1_20230621_221208\n",
              "\n",
              "\n",
              "Model Summary: \n",
              "    number_of_trees    number_of_internal_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n",
              "--  -----------------  --------------------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n",
              "    44                 44                          197575                 16           20           18.6818       322           387           352.682\n",
              "\n",
              "ModelMetricsBinomial: drf\n",
              "** Reported on train data. **\n",
              "\n",
              "MSE: 0.041742776868105666\n",
              "RMSE: 0.20431049133146753\n",
              "LogLoss: 0.18373419051793238\n",
              "Mean Per-Class Error: 0.0575781811330931\n",
              "AUC: 0.9872121269052022\n",
              "AUCPR: 0.9815838197399517\n",
              "Gini: 0.9744242538104044\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4615384615384616\n",
              "       B     M     Error    Rate\n",
              "-----  ----  ----  -------  --------------\n",
              "B      4714  253   0.0509   (253.0/4967.0)\n",
              "M      196   2856  0.0642   (196.0/3052.0)\n",
              "Total  4910  3109  0.056    (449.0/8019.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.461538     0.927122  108\n",
              "max f2                       0.24         0.94815   159\n",
              "max f0point5                 0.652174     0.943885  64\n",
              "max accuracy                 0.461538     0.944008  108\n",
              "max precision                1            0.998828  0\n",
              "max recall                   0            1         274\n",
              "max specificity              1            0.999597  0\n",
              "max absolute_mcc             0.461538     0.881769  108\n",
              "max min_per_class_accuracy   0.428571     0.942017  113\n",
              "max mean_per_class_accuracy  0.384615     0.94358   124\n",
              "max tns                      1            4965      0\n",
              "max fns                      1            1347      0\n",
              "max fps                      0            4967      274\n",
              "max tps                      0            3052      274\n",
              "max tnr                      1            0.999597  0\n",
              "max fnr                      1            0.44135   0\n",
              "max fpr                      0            1         274\n",
              "max tpr                      0            1         274\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 38.06 %, avg score: 37.96 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.212869                    1                  2.62438    2.62438            0.998828         1           0.998828                    1                   0.55865         0.55865                    162.438   162.438            0.558247\n",
              "2        0.300162                    0.8                2.52236    2.59471            0.96             0.894995    0.987536                    0.969463            0.220183        0.778834                   152.236   159.471            0.772794\n",
              "3        0.400923                    0.4                1.69419    2.36839            0.644802         0.603894    0.9014                      0.877587            0.170708        0.949541                   69.419    136.839            0.88572\n",
              "4        0.501309                    0.105263           0.40799    1.97582            0.15528          0.230421    0.75199                     0.747993            0.0409567       0.990498                   -59.201   97.5822            0.789773\n",
              "5        1                           0                  0.0190538  1                  0.00725181       0.00926727  0.380596                    0.379597            0.00950197      1                          -98.0946  0                  0\n",
              "\n",
              "ModelMetricsBinomial: drf\n",
              "** Reported on validation data. **\n",
              "\n",
              "MSE: 0.044211270195100294\n",
              "RMSE: 0.21026476213360215\n",
              "LogLoss: 0.1610109017476356\n",
              "Mean Per-Class Error: 0.06374504329055117\n",
              "AUC: 0.987230940532285\n",
              "AUCPR: 0.9826571285713736\n",
              "Gini: 0.97446188106457\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5020661150867289\n",
              "       B     M    Error    Rate\n",
              "-----  ----  ---  -------  --------------\n",
              "B      1155  44   0.0367   (44.0/1199.0)\n",
              "M      71    711  0.0908   (71.0/782.0)\n",
              "Total  1226  755  0.0581   (115.0/1981.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.502066     0.925179  28\n",
              "max f2                       0.261364     0.945577  55\n",
              "max f0point5                 0.592657     0.946656  20\n",
              "max accuracy                 0.522915     0.942453  26\n",
              "max precision                1            1         0\n",
              "max recall                   0            1         97\n",
              "max specificity              1            1         0\n",
              "max absolute_mcc             0.522915     0.879317  26\n",
              "max min_per_class_accuracy   0.432006     0.936061  38\n",
              "max mean_per_class_accuracy  0.433884     0.939034  35\n",
              "max tns                      1            1199      0\n",
              "max fns                      1            433       0\n",
              "max fps                      0            1199      97\n",
              "max tps                      0            782       97\n",
              "max tnr                      1            1         0\n",
              "max fnr                      1            0.553708  0\n",
              "max fpr                      0            1         97\n",
              "max tpr                      0            1         97\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 39.48 %, avg score: 38.88 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.176174                    1                  2.53325     2.53325            1                1            1                           1                   0.446292        0.446292                   153.325   153.325            0.446292\n",
              "2        0.212519                    0.977273           2.53325     2.53325            1                0.977273     1                           0.996113            0.0920716       0.538363                   153.325   153.325            0.538363\n",
              "3        0.303382                    0.795455           2.47695     2.51639            0.977778         0.894823     0.993344                    0.965777            0.225064        0.763427                   147.695   151.639            0.760091\n",
              "4        0.402322                    0.454545           1.70607     2.31711            0.673469         0.615698     0.91468                     0.879685            0.168798        0.932225                   70.6065   131.711            0.875511\n",
              "5        0.507824                    0.136364           0.533315    1.94652            0.210526         0.270607     0.76839                     0.753147            0.056266        0.988491                   -46.6685  94.6522            0.794162\n",
              "6        0.633518                    0.0227273          0.0813895   1.57647            0.0321285        0.0501141    0.622311                    0.613661            0.0102302       0.998721                   -91.8611  57.6468            0.603392\n",
              "7        1                           0                  0.00348932  1                  0.00137741       4.33006e-05  0.39475                     0.388781            0.00127877      1                          -99.6511  0                  0\n",
              "\n",
              "ModelMetricsBinomial: drf\n",
              "** Reported on cross-validation data. **\n",
              "\n",
              "MSE: 0.03898470525935156\n",
              "RMSE: 0.19744544881903853\n",
              "LogLoss: 0.14274403270840974\n",
              "Mean Per-Class Error: 0.056429446140068354\n",
              "AUC: 0.9901730187256865\n",
              "AUCPR: 0.9851653844865583\n",
              "Gini: 0.980346037451373\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5333333333333333\n",
              "       B     M     Error    Rate\n",
              "-----  ----  ----  -------  --------------\n",
              "B      4784  183   0.0368   (183.0/4967.0)\n",
              "M      232   2820  0.076    (232.0/3052.0)\n",
              "Total  5016  3003  0.0518   (415.0/8019.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.533333     0.931462  80\n",
              "max f2                       0.28         0.953548  132\n",
              "max f0point5                 0.64         0.949291  59\n",
              "max accuracy                 0.533333     0.948248  80\n",
              "max precision                0.933333     0.999484  9\n",
              "max recall                   0            1         202\n",
              "max specificity              1            0.999799  0\n",
              "max absolute_mcc             0.533333     0.889971  80\n",
              "max min_per_class_accuracy   0.44         0.945239  96\n",
              "max mean_per_class_accuracy  0.400465     0.947216  104\n",
              "max tns                      1            4966      0\n",
              "max fns                      1            1656      0\n",
              "max fps                      0            4967      202\n",
              "max tps                      0            3052      202\n",
              "max tnr                      1            0.999799  0\n",
              "max fnr                      1            0.542595  0\n",
              "max fpr                      0            1         202\n",
              "max tpr                      0            1         202\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 38.06 %, avg score: 38.03 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.174211                    1                  2.62558     2.62558            0.999284         1            0.999284                    1                   0.457405        0.457405                   162.558   162.558            0.457204\n",
              "2        0.202644                    0.971429           2.62746     2.62584            1                0.978596     0.999385                    0.996997            0.0747051       0.53211                    162.746   162.584            0.531909\n",
              "3        0.300786                    0.78               2.54733     2.60022            0.969504         0.895454     0.989635                    0.963865            0.25            0.78211                    154.733   160.022            0.777077\n",
              "4        0.40429                     0.4                1.69044     2.36731            0.643373         0.599281     0.900987                    0.870526            0.174967        0.957077                   69.0436   136.731            0.892451\n",
              "5        0.51141                     0.1                0.354814    1.94577            0.135041         0.217784     0.740551                    0.733802            0.0380079       0.995085                   -64.5186  94.5766            0.780871\n",
              "6        0.633745                    0.02               0.0348185   1.57689            0.0132518        0.0407945    0.600157                    0.600028            0.0042595       0.999345                   -96.5182  57.6888            0.590245\n",
              "7        1                           0                  0.00178921  1                  0.000680967      6.80967e-06  0.380596                    0.380267            0.000655308     1                          -99.8211  0                  0\n",
              "\n",
              "Cross-Validation Metrics Summary: \n",
              "                         mean       sd          cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid    cv_6_valid    cv_7_valid    cv_8_valid    cv_9_valid    cv_10_valid\n",
              "-----------------------  ---------  ----------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  -------------\n",
              "accuracy                 0.950992   0.00454777  0.955112      0.945137      0.950125      0.945137      0.951372      0.948878      0.956359      0.955112      0.946384      0.956305\n",
              "auc                      0.990222   0.0018713   0.99344       0.989633      0.99025       0.987282      0.989987      0.990011      0.992795      0.990331      0.987918      0.990573\n",
              "err                      0.0490079  0.00454777  0.0448878     0.0548628     0.0498753     0.0548628     0.0486284     0.0511222     0.0436409     0.0448878     0.053616      0.0436954\n",
              "err_count                39.3       3.653       36            44            40            44            39            41            35            36            43            35\n",
              "f0point5                 0.935877   0.0165531   0.964126      0.909968      0.934195      0.942029      0.916612      0.9257        0.939415      0.943396      0.928526      0.954806\n",
              "f1                       0.935454   0.00699281  0.934783      0.927869      0.940828      0.921986      0.934233      0.936826      0.940375      0.941558      0.9312        0.944882\n",
              "f2                       0.935488   0.0171474   0.907173      0.946488      0.947557      0.902778      0.952545      0.948222      0.941337      0.939728      0.93389       0.935162\n",
              "lift_top_group           2.6318     0.134172    2.76552       2.71864       2.4012        2.74658       2.77276       2.52201       2.7372        2.59547       2.57878       2.47988\n",
              "logloss                  0.142941   0.0197233   0.115235      0.131696      0.173168      0.140276      0.1682        0.136001      0.118814      0.140949      0.141814      0.163256\n",
              "max_per_class_error      0.0701453  0.0216841   0.110345      0.0631164     0.0512821     0.109589      0.0563107     0.0557851     0.0580205     0.0614887     0.0643087     0.0712074\n",
              "mcc                      0.89661    0.0096192   0.903395      0.884918      0.897923      0.881077      0.896878      0.894429      0.905963      0.905134      0.887307      0.90908\n",
              "mean_per_class_accuracy  0.947898   0.00654281  0.940921      0.948103      0.950407      0.933441      0.954423      0.950095      0.953308      0.952014      0.944424      0.951844\n",
              "mean_per_class_error     0.052102   0.00654281  0.0590787     0.0518972     0.0495931     0.0665592     0.0455769     0.0499051     0.046692      0.0479857     0.0555759     0.048156\n",
              "mse                      0.0389693  0.00306778  0.0336931     0.0403275     0.039522      0.0427058     0.0375024     0.0406889     0.0350779     0.0410383     0.0423526     0.0367846\n",
              "pr_auc                   0.985186   0.00335343  0.989064      0.983129      0.988671      0.980534      0.980179      0.985582      0.988456      0.985204      0.983067      0.987968\n",
              "precision                0.93642    0.0264467   0.984733      0.898413      0.929825      0.955882      0.905229      0.918429      0.938776      0.944625      0.926752      0.961538\n",
              "r2                       0.834448   0.0125903   0.854044      0.826572      0.837372      0.815548      0.8368        0.829959      0.848715      0.826726      0.821603      0.847137\n",
              "recall                   0.935759   0.0266079   0.889655      0.959322      0.952096      0.890411      0.965157      0.955975      0.941979      0.938511      0.935691      0.928793\n",
              "rmse                     0.197266   0.00784811  0.183557      0.200817      0.198801      0.206654      0.193655      0.201715      0.187291      0.202579      0.205797      0.191793\n",
              "specificity              0.960037   0.0176535   0.992188      0.936884      0.948718      0.976471      0.943689      0.944215      0.964637      0.965517      0.953157      0.974895\n",
              "\n",
              "Scoring History: \n",
              "    timestamp            duration    number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
              "--  -------------------  ----------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ----------------  -------------------  -----------------  ---------------------------------\n",
              "    2023-06-21 22:17:46  32.569 sec  0                  nan              nan                 nan             nan                nan              nan                              nan                nan                   nan               nan                  nan                nan\n",
              "    2023-06-21 22:17:47  32.892 sec  5                  0.265484         1.74132             0.93921         0.900597           2.44774          0.0869925                        0.236113           0.453952              0.973293          0.960785             2.49947            0.0731954\n",
              "    2023-06-21 22:17:47  33.220 sec  10                 0.231593         0.776505            0.967315        0.9485             2.55409          0.0722026                        0.219402           0.232562              0.982869          0.975322             2.52251            0.0605755\n",
              "    2023-06-21 22:17:47  33.525 sec  15                 0.22043          0.503559            0.975977        0.962402           2.58324          0.0636784                        0.21426            0.18124               0.985791          0.979494             2.52748            0.0595659\n",
              "    2023-06-21 22:17:48  33.787 sec  20                 0.214226         0.343853            0.981147        0.971306           2.60394          0.0604814                        0.210407           0.162538              0.987066          0.982266             2.53325            0.0545179\n",
              "    2023-06-21 22:17:48  34.064 sec  25                 0.209957         0.289651            0.983349        0.975262           2.61099          0.0612296                        0.211431           0.16102               0.987087          0.982128             2.53325            0.0600707\n",
              "    2023-06-21 22:17:48  34.344 sec  30                 0.207501         0.236249            0.985155        0.978592           2.61896          0.0594837                        0.210673           0.160472              0.987287          0.982417             2.53325            0.0575467\n",
              "    2023-06-21 22:17:48  34.643 sec  35                 0.205495         0.199322            0.986598        0.980714           2.62307          0.0567402                        0.21047            0.160701              0.987226          0.982411             2.53325            0.0570419\n",
              "    2023-06-21 22:17:49  34.983 sec  40                 0.204698         0.187424            0.987067        0.981444           2.62443          0.055992                         0.210416           0.16116               0.987178          0.982428             2.53325            0.0565371\n",
              "    2023-06-21 22:17:49  35.276 sec  44                 0.20431          0.183734            0.987212        0.981584           2.62438          0.055992                         0.210265           0.161011              0.987231          0.982657             2.53325            0.0580515\n",
              "\n",
              "Variable Importances: \n",
              "variable                 relative_importance    scaled_importance     percentage\n",
              "-----------------------  ---------------------  --------------------  ---------------------\n",
              "concave points_mean      11857.65625            1.0                   0.1765809050503654\n",
              "perimeter_worst          9856.330078125         0.831220763219966     0.1467777146660371\n",
              "radius_worst             9738.794921875         0.8213085888600455    0.1450274139465453\n",
              "concave points_worst     6207.02490234375       0.5234613629775067    0.09243328123346596\n",
              "area_se                  5506.34619140625       0.4643705362437244    0.08199896956864036\n",
              "perimeter_mean           4992.412109375         0.42102857462873405   0.07434560676000718\n",
              "radius_se                2336.15771484375       0.1970168189724466    0.03478940820429862\n",
              "area_worst               2132.290283203125      0.1798239245806375    0.03175347135215762\n",
              "concavity_mean           1775.343994140625      0.1497213240719999    0.026437926909972802\n",
              "compactness_worst        1584.4405517578125     0.13362173083384943   0.02359504616503745\n",
              "---                      ---                    ---                   ---\n",
              "smoothness_mean          366.64947509765625     0.030920906068402535  0.005460041578535855\n",
              "symmetry_mean            338.6394348144531      0.02855871579296736   0.0050429238817983404\n",
              "fractal_dimension_mean   331.54730224609375     0.02796061002747434   0.004937309824411741\n",
              "fractal_dimension_worst  319.9285888671875      0.02698076096338073   0.0047642871898613375\n",
              "concavity_se             319.1920166015625      0.02691864310044934   0.004753318361405119\n",
              "smoothness_se            315.3716125488281      0.026596454299206738  0.004696425971284607\n",
              "texture_se               302.1045227050781      0.02547759155230007   0.00449885617480869\n",
              "fractal_dimension_se     301.01763916015625     0.025385930643769188  0.004482670608622568\n",
              "symmetry_se              288.40093994140625     0.02432191774334884   0.004294786247681079\n",
              "concave points_se        252.89234924316406     0.021327346982517228  0.003766002232496072\n",
              "[30 rows x 4 columns]\n",
              "\n",
              "\n",
              "[tips]\n",
              "Use `model.explain()` to inspect the model.\n",
              "--\n",
              "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
            ],
            "text/html": [
              "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
              "=============\n",
              "H2ORandomForestEstimator : Distributed Random Forest\n",
              "Model Key: XRT_1_AutoML_1_20230621_221208\n",
              "</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-15.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-15 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-15 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-15 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-15 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-15 .h2o-table th,\n",
              "#h2o-table-15 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-15 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-15\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Model Summary: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>number_of_trees</th>\n",
              "<th>number_of_internal_trees</th>\n",
              "<th>model_size_in_bytes</th>\n",
              "<th>min_depth</th>\n",
              "<th>max_depth</th>\n",
              "<th>mean_depth</th>\n",
              "<th>min_leaves</th>\n",
              "<th>max_leaves</th>\n",
              "<th>mean_leaves</th></tr></thead>\n",
              "    <tbody><tr><td></td>\n",
              "<td>44.0</td>\n",
              "<td>44.0</td>\n",
              "<td>197575.0</td>\n",
              "<td>16.0</td>\n",
              "<td>20.0</td>\n",
              "<td>18.681818</td>\n",
              "<td>322.0</td>\n",
              "<td>387.0</td>\n",
              "<td>352.68182</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: drf\n",
              "** Reported on train data. **\n",
              "\n",
              "MSE: 0.041742776868105666\n",
              "RMSE: 0.20431049133146753\n",
              "LogLoss: 0.18373419051793238\n",
              "Mean Per-Class Error: 0.0575781811330931\n",
              "AUC: 0.9872121269052022\n",
              "AUCPR: 0.9815838197399517\n",
              "Gini: 0.9744242538104044</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-16.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-16 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-16 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-16 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-16 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-16 .h2o-table th,\n",
              "#h2o-table-16 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-16 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-16\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4615384615384616</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>B</th>\n",
              "<th>M</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>B</td>\n",
              "<td>4714.0</td>\n",
              "<td>253.0</td>\n",
              "<td>0.0509</td>\n",
              "<td> (253.0/4967.0)</td></tr>\n",
              "<tr><td>M</td>\n",
              "<td>196.0</td>\n",
              "<td>2856.0</td>\n",
              "<td>0.0642</td>\n",
              "<td> (196.0/3052.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>4910.0</td>\n",
              "<td>3109.0</td>\n",
              "<td>0.056</td>\n",
              "<td> (449.0/8019.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-17.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-17 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-17 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-17 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-17 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-17 .h2o-table th,\n",
              "#h2o-table-17 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-17 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-17\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.4615385</td>\n",
              "<td>0.9271222</td>\n",
              "<td>108.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.24</td>\n",
              "<td>0.9481500</td>\n",
              "<td>159.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.6521739</td>\n",
              "<td>0.9438849</td>\n",
              "<td>64.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.4615385</td>\n",
              "<td>0.9440080</td>\n",
              "<td>108.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9988284</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>274.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9995973</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.4615385</td>\n",
              "<td>0.8817689</td>\n",
              "<td>108.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.4285714</td>\n",
              "<td>0.9420173</td>\n",
              "<td>113.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.3846154</td>\n",
              "<td>0.9435805</td>\n",
              "<td>124.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>1.0</td>\n",
              "<td>4965.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>1.0</td>\n",
              "<td>1347.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0</td>\n",
              "<td>4967.0</td>\n",
              "<td>274.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0</td>\n",
              "<td>3052.0</td>\n",
              "<td>274.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9995973</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>1.0</td>\n",
              "<td>0.4413499</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>274.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>274.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-18.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-18 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-18 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-18 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-18 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-18 .h2o-table th,\n",
              "#h2o-table-18 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-18 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-18\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 38.06 %, avg score: 37.96 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.2128694</td>\n",
              "<td>1.0</td>\n",
              "<td>2.6243790</td>\n",
              "<td>2.6243790</td>\n",
              "<td>0.9988284</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9988284</td>\n",
              "<td>1.0</td>\n",
              "<td>0.5586501</td>\n",
              "<td>0.5586501</td>\n",
              "<td>162.4378955</td>\n",
              "<td>162.4378955</td>\n",
              "<td>0.5582474</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.3001621</td>\n",
              "<td>0.8</td>\n",
              "<td>2.5223591</td>\n",
              "<td>2.5947097</td>\n",
              "<td>0.96</td>\n",
              "<td>0.8949948</td>\n",
              "<td>0.9875364</td>\n",
              "<td>0.9694626</td>\n",
              "<td>0.2201835</td>\n",
              "<td>0.7788336</td>\n",
              "<td>152.2359109</td>\n",
              "<td>159.4709702</td>\n",
              "<td>0.7727937</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.4009228</td>\n",
              "<td>0.4</td>\n",
              "<td>1.6941897</td>\n",
              "<td>2.3683893</td>\n",
              "<td>0.6448020</td>\n",
              "<td>0.6038941</td>\n",
              "<td>0.9013997</td>\n",
              "<td>0.8775872</td>\n",
              "<td>0.1707077</td>\n",
              "<td>0.9495413</td>\n",
              "<td>69.4189738</td>\n",
              "<td>136.8389288</td>\n",
              "<td>0.8857201</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.5013094</td>\n",
              "<td>0.1052632</td>\n",
              "<td>0.4079903</td>\n",
              "<td>1.9758218</td>\n",
              "<td>0.1552795</td>\n",
              "<td>0.2304212</td>\n",
              "<td>0.7519900</td>\n",
              "<td>0.7479930</td>\n",
              "<td>0.0409567</td>\n",
              "<td>0.9904980</td>\n",
              "<td>-59.2009720</td>\n",
              "<td>97.5821825</td>\n",
              "<td>0.7897733</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0190538</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0072518</td>\n",
              "<td>0.0092673</td>\n",
              "<td>0.3805961</td>\n",
              "<td>0.3795974</td>\n",
              "<td>0.0095020</td>\n",
              "<td>1.0</td>\n",
              "<td>-98.0946170</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: drf\n",
              "** Reported on validation data. **\n",
              "\n",
              "MSE: 0.044211270195100294\n",
              "RMSE: 0.21026476213360215\n",
              "LogLoss: 0.1610109017476356\n",
              "Mean Per-Class Error: 0.06374504329055117\n",
              "AUC: 0.987230940532285\n",
              "AUCPR: 0.9826571285713736\n",
              "Gini: 0.97446188106457</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-19.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-19 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-19 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-19 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-19 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-19 .h2o-table th,\n",
              "#h2o-table-19 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-19 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-19\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5020661150867289</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>B</th>\n",
              "<th>M</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>B</td>\n",
              "<td>1155.0</td>\n",
              "<td>44.0</td>\n",
              "<td>0.0367</td>\n",
              "<td> (44.0/1199.0)</td></tr>\n",
              "<tr><td>M</td>\n",
              "<td>71.0</td>\n",
              "<td>711.0</td>\n",
              "<td>0.0908</td>\n",
              "<td> (71.0/782.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>1226.0</td>\n",
              "<td>755.0</td>\n",
              "<td>0.0581</td>\n",
              "<td> (115.0/1981.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-20.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-20 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-20 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-20 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-20 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-20 .h2o-table th,\n",
              "#h2o-table-20 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-20 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-20\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.5020661</td>\n",
              "<td>0.9251789</td>\n",
              "<td>28.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.2613636</td>\n",
              "<td>0.9455765</td>\n",
              "<td>55.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.5926573</td>\n",
              "<td>0.9466556</td>\n",
              "<td>20.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.5229151</td>\n",
              "<td>0.9424533</td>\n",
              "<td>26.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>97.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.5229151</td>\n",
              "<td>0.8793173</td>\n",
              "<td>26.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.4320060</td>\n",
              "<td>0.9360614</td>\n",
              "<td>38.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.4338843</td>\n",
              "<td>0.9390343</td>\n",
              "<td>35.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>1.0</td>\n",
              "<td>1199.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>1.0</td>\n",
              "<td>433.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0</td>\n",
              "<td>1199.0</td>\n",
              "<td>97.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0</td>\n",
              "<td>782.0</td>\n",
              "<td>97.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>1.0</td>\n",
              "<td>0.5537084</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>97.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>97.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-21.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-21 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-21 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-21 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-21 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-21 .h2o-table th,\n",
              "#h2o-table-21 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-21 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-21\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 39.48 %, avg score: 38.88 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.1761736</td>\n",
              "<td>1.0</td>\n",
              "<td>2.5332481</td>\n",
              "<td>2.5332481</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.4462916</td>\n",
              "<td>0.4462916</td>\n",
              "<td>153.3248082</td>\n",
              "<td>153.3248082</td>\n",
              "<td>0.4462916</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.2125189</td>\n",
              "<td>0.9772727</td>\n",
              "<td>2.5332481</td>\n",
              "<td>2.5332481</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9772727</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9961132</td>\n",
              "<td>0.0920716</td>\n",
              "<td>0.5383632</td>\n",
              "<td>153.3248082</td>\n",
              "<td>153.3248082</td>\n",
              "<td>0.5383632</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.3033821</td>\n",
              "<td>0.7954545</td>\n",
              "<td>2.4769537</td>\n",
              "<td>2.5163879</td>\n",
              "<td>0.9777778</td>\n",
              "<td>0.8948232</td>\n",
              "<td>0.9933444</td>\n",
              "<td>0.9657767</td>\n",
              "<td>0.2250639</td>\n",
              "<td>0.7634271</td>\n",
              "<td>147.6953680</td>\n",
              "<td>151.6387862</td>\n",
              "<td>0.7600910</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.4023221</td>\n",
              "<td>0.4545455</td>\n",
              "<td>1.7060650</td>\n",
              "<td>2.3171115</td>\n",
              "<td>0.6734694</td>\n",
              "<td>0.6156977</td>\n",
              "<td>0.9146801</td>\n",
              "<td>0.8796845</td>\n",
              "<td>0.1687980</td>\n",
              "<td>0.9322251</td>\n",
              "<td>70.6065035</td>\n",
              "<td>131.7111483</td>\n",
              "<td>0.8755111</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.5078243</td>\n",
              "<td>0.1363636</td>\n",
              "<td>0.5333154</td>\n",
              "<td>1.9465216</td>\n",
              "<td>0.2105263</td>\n",
              "<td>0.2706075</td>\n",
              "<td>0.7683897</td>\n",
              "<td>0.7531467</td>\n",
              "<td>0.0562660</td>\n",
              "<td>0.9884910</td>\n",
              "<td>-46.6684614</td>\n",
              "<td>94.6521637</td>\n",
              "<td>0.7941624</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.6335184</td>\n",
              "<td>0.0227273</td>\n",
              "<td>0.0813895</td>\n",
              "<td>1.5764675</td>\n",
              "<td>0.0321285</td>\n",
              "<td>0.0501141</td>\n",
              "<td>0.6223108</td>\n",
              "<td>0.6136605</td>\n",
              "<td>0.0102302</td>\n",
              "<td>0.9987212</td>\n",
              "<td>-91.8610503</td>\n",
              "<td>57.6467531</td>\n",
              "<td>0.6033918</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0034893</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0013774</td>\n",
              "<td>0.0000433</td>\n",
              "<td>0.3947501</td>\n",
              "<td>0.3887811</td>\n",
              "<td>0.0012788</td>\n",
              "<td>1.0</td>\n",
              "<td>-99.6510678</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: drf\n",
              "** Reported on cross-validation data. **\n",
              "\n",
              "MSE: 0.03898470525935156\n",
              "RMSE: 0.19744544881903853\n",
              "LogLoss: 0.14274403270840974\n",
              "Mean Per-Class Error: 0.056429446140068354\n",
              "AUC: 0.9901730187256865\n",
              "AUCPR: 0.9851653844865583\n",
              "Gini: 0.980346037451373</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-22.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-22 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-22 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-22 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-22 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-22 .h2o-table th,\n",
              "#h2o-table-22 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-22 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-22\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5333333333333333</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>B</th>\n",
              "<th>M</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>B</td>\n",
              "<td>4784.0</td>\n",
              "<td>183.0</td>\n",
              "<td>0.0368</td>\n",
              "<td> (183.0/4967.0)</td></tr>\n",
              "<tr><td>M</td>\n",
              "<td>232.0</td>\n",
              "<td>2820.0</td>\n",
              "<td>0.076</td>\n",
              "<td> (232.0/3052.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>5016.0</td>\n",
              "<td>3003.0</td>\n",
              "<td>0.0518</td>\n",
              "<td> (415.0/8019.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-23.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-23 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-23 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-23 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-23 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-23 .h2o-table th,\n",
              "#h2o-table-23 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-23 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-23\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.5333333</td>\n",
              "<td>0.9314616</td>\n",
              "<td>80.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.28</td>\n",
              "<td>0.9535476</td>\n",
              "<td>132.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.64</td>\n",
              "<td>0.9492908</td>\n",
              "<td>59.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.5333333</td>\n",
              "<td>0.9482479</td>\n",
              "<td>80.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>0.9333333</td>\n",
              "<td>0.9994837</td>\n",
              "<td>9.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>202.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9997987</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.5333333</td>\n",
              "<td>0.8899705</td>\n",
              "<td>80.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.4400000</td>\n",
              "<td>0.9452386</td>\n",
              "<td>96.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.4004651</td>\n",
              "<td>0.9472162</td>\n",
              "<td>104.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>1.0</td>\n",
              "<td>4966.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>1.0</td>\n",
              "<td>1656.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0</td>\n",
              "<td>4967.0</td>\n",
              "<td>202.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0</td>\n",
              "<td>3052.0</td>\n",
              "<td>202.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9997987</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>1.0</td>\n",
              "<td>0.5425950</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>202.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>202.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-24.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-24 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-24 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-24 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-24 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-24 .h2o-table th,\n",
              "#h2o-table-24 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-24 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-24\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 38.06 %, avg score: 38.03 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.1742112</td>\n",
              "<td>1.0</td>\n",
              "<td>2.6255766</td>\n",
              "<td>2.6255766</td>\n",
              "<td>0.9992842</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9992842</td>\n",
              "<td>1.0</td>\n",
              "<td>0.4574050</td>\n",
              "<td>0.4574050</td>\n",
              "<td>162.5576619</td>\n",
              "<td>162.5576619</td>\n",
              "<td>0.4572037</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.2026437</td>\n",
              "<td>0.9714286</td>\n",
              "<td>2.6274574</td>\n",
              "<td>2.6258405</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9785965</td>\n",
              "<td>0.9993846</td>\n",
              "<td>0.9969969</td>\n",
              "<td>0.0747051</td>\n",
              "<td>0.5321101</td>\n",
              "<td>162.7457405</td>\n",
              "<td>162.5840508</td>\n",
              "<td>0.5319088</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.3007856</td>\n",
              "<td>0.78</td>\n",
              "<td>2.5473316</td>\n",
              "<td>2.6002242</td>\n",
              "<td>0.9695044</td>\n",
              "<td>0.8954536</td>\n",
              "<td>0.9896352</td>\n",
              "<td>0.9638648</td>\n",
              "<td>0.25</td>\n",
              "<td>0.7821101</td>\n",
              "<td>154.7331639</td>\n",
              "<td>160.0224223</td>\n",
              "<td>0.7770769</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.4042898</td>\n",
              "<td>0.4</td>\n",
              "<td>1.6904365</td>\n",
              "<td>2.3673051</td>\n",
              "<td>0.6433735</td>\n",
              "<td>0.5992807</td>\n",
              "<td>0.9009870</td>\n",
              "<td>0.8705259</td>\n",
              "<td>0.1749672</td>\n",
              "<td>0.9570773</td>\n",
              "<td>69.0436451</td>\n",
              "<td>136.7305083</td>\n",
              "<td>0.8924508</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.5114104</td>\n",
              "<td>0.1</td>\n",
              "<td>0.3548138</td>\n",
              "<td>1.9457664</td>\n",
              "<td>0.1350407</td>\n",
              "<td>0.2177843</td>\n",
              "<td>0.7405511</td>\n",
              "<td>0.7338019</td>\n",
              "<td>0.0380079</td>\n",
              "<td>0.9950852</td>\n",
              "<td>-64.5186194</td>\n",
              "<td>94.5766432</td>\n",
              "<td>0.7808714</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.6337449</td>\n",
              "<td>0.02</td>\n",
              "<td>0.0348185</td>\n",
              "<td>1.5768881</td>\n",
              "<td>0.0132518</td>\n",
              "<td>0.0407945</td>\n",
              "<td>0.6001574</td>\n",
              "<td>0.6000278</td>\n",
              "<td>0.0042595</td>\n",
              "<td>0.9993447</td>\n",
              "<td>-96.5181502</td>\n",
              "<td>57.6888053</td>\n",
              "<td>0.5902446</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0017892</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0006810</td>\n",
              "<td>0.0000068</td>\n",
              "<td>0.3805961</td>\n",
              "<td>0.3802670</td>\n",
              "<td>0.0006553</td>\n",
              "<td>1.0</td>\n",
              "<td>-99.8210788</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-25.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-25 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-25 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-25 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-25 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-25 .h2o-table th,\n",
              "#h2o-table-25 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-25 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-25\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Cross-Validation Metrics Summary: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>mean</th>\n",
              "<th>sd</th>\n",
              "<th>cv_1_valid</th>\n",
              "<th>cv_2_valid</th>\n",
              "<th>cv_3_valid</th>\n",
              "<th>cv_4_valid</th>\n",
              "<th>cv_5_valid</th>\n",
              "<th>cv_6_valid</th>\n",
              "<th>cv_7_valid</th>\n",
              "<th>cv_8_valid</th>\n",
              "<th>cv_9_valid</th>\n",
              "<th>cv_10_valid</th></tr></thead>\n",
              "    <tbody><tr><td>accuracy</td>\n",
              "<td>0.9509920</td>\n",
              "<td>0.0045478</td>\n",
              "<td>0.9551122</td>\n",
              "<td>0.9451371</td>\n",
              "<td>0.9501247</td>\n",
              "<td>0.9451371</td>\n",
              "<td>0.9513715</td>\n",
              "<td>0.9488778</td>\n",
              "<td>0.9563591</td>\n",
              "<td>0.9551122</td>\n",
              "<td>0.946384</td>\n",
              "<td>0.9563046</td></tr>\n",
              "<tr><td>auc</td>\n",
              "<td>0.9902219</td>\n",
              "<td>0.0018713</td>\n",
              "<td>0.9934402</td>\n",
              "<td>0.9896333</td>\n",
              "<td>0.9902503</td>\n",
              "<td>0.9872817</td>\n",
              "<td>0.9899868</td>\n",
              "<td>0.9900105</td>\n",
              "<td>0.9927952</td>\n",
              "<td>0.9903306</td>\n",
              "<td>0.9879175</td>\n",
              "<td>0.9905728</td></tr>\n",
              "<tr><td>err</td>\n",
              "<td>0.0490079</td>\n",
              "<td>0.0045478</td>\n",
              "<td>0.0448878</td>\n",
              "<td>0.0548628</td>\n",
              "<td>0.0498753</td>\n",
              "<td>0.0548628</td>\n",
              "<td>0.0486284</td>\n",
              "<td>0.0511222</td>\n",
              "<td>0.0436409</td>\n",
              "<td>0.0448878</td>\n",
              "<td>0.0536160</td>\n",
              "<td>0.0436954</td></tr>\n",
              "<tr><td>err_count</td>\n",
              "<td>39.3</td>\n",
              "<td>3.653005</td>\n",
              "<td>36.0</td>\n",
              "<td>44.0</td>\n",
              "<td>40.0</td>\n",
              "<td>44.0</td>\n",
              "<td>39.0</td>\n",
              "<td>41.0</td>\n",
              "<td>35.0</td>\n",
              "<td>36.0</td>\n",
              "<td>43.0</td>\n",
              "<td>35.0</td></tr>\n",
              "<tr><td>f0point5</td>\n",
              "<td>0.9358772</td>\n",
              "<td>0.0165531</td>\n",
              "<td>0.9641256</td>\n",
              "<td>0.9099678</td>\n",
              "<td>0.9341950</td>\n",
              "<td>0.942029</td>\n",
              "<td>0.9166115</td>\n",
              "<td>0.9257004</td>\n",
              "<td>0.9394146</td>\n",
              "<td>0.9433962</td>\n",
              "<td>0.9285259</td>\n",
              "<td>0.9548058</td></tr>\n",
              "<tr><td>f1</td>\n",
              "<td>0.9354539</td>\n",
              "<td>0.0069928</td>\n",
              "<td>0.9347826</td>\n",
              "<td>0.9278688</td>\n",
              "<td>0.9408284</td>\n",
              "<td>0.9219858</td>\n",
              "<td>0.9342327</td>\n",
              "<td>0.9368259</td>\n",
              "<td>0.9403748</td>\n",
              "<td>0.9415584</td>\n",
              "<td>0.9312</td>\n",
              "<td>0.9448819</td></tr>\n",
              "<tr><td>f2</td>\n",
              "<td>0.9354879</td>\n",
              "<td>0.0171474</td>\n",
              "<td>0.907173</td>\n",
              "<td>0.9464883</td>\n",
              "<td>0.9475566</td>\n",
              "<td>0.9027778</td>\n",
              "<td>0.9525447</td>\n",
              "<td>0.9482221</td>\n",
              "<td>0.941337</td>\n",
              "<td>0.9397278</td>\n",
              "<td>0.9338896</td>\n",
              "<td>0.9351621</td></tr>\n",
              "<tr><td>lift_top_group</td>\n",
              "<td>2.6318035</td>\n",
              "<td>0.1341717</td>\n",
              "<td>2.7655172</td>\n",
              "<td>2.7186441</td>\n",
              "<td>2.4011977</td>\n",
              "<td>2.7465754</td>\n",
              "<td>2.7727628</td>\n",
              "<td>2.5220125</td>\n",
              "<td>2.7372015</td>\n",
              "<td>2.5954692</td>\n",
              "<td>2.578778</td>\n",
              "<td>2.4798763</td></tr>\n",
              "<tr><td>logloss</td>\n",
              "<td>0.1429408</td>\n",
              "<td>0.0197233</td>\n",
              "<td>0.1152349</td>\n",
              "<td>0.1316957</td>\n",
              "<td>0.1731677</td>\n",
              "<td>0.1402760</td>\n",
              "<td>0.1681999</td>\n",
              "<td>0.1360007</td>\n",
              "<td>0.1188141</td>\n",
              "<td>0.140949</td>\n",
              "<td>0.1418141</td>\n",
              "<td>0.1632562</td></tr>\n",
              "<tr><td>max_per_class_error</td>\n",
              "<td>0.0701453</td>\n",
              "<td>0.0216841</td>\n",
              "<td>0.1103448</td>\n",
              "<td>0.0631164</td>\n",
              "<td>0.0512821</td>\n",
              "<td>0.1095890</td>\n",
              "<td>0.0563107</td>\n",
              "<td>0.0557851</td>\n",
              "<td>0.0580205</td>\n",
              "<td>0.0614887</td>\n",
              "<td>0.0643087</td>\n",
              "<td>0.0712074</td></tr>\n",
              "<tr><td>mcc</td>\n",
              "<td>0.8966104</td>\n",
              "<td>0.0096192</td>\n",
              "<td>0.9033948</td>\n",
              "<td>0.8849177</td>\n",
              "<td>0.8979232</td>\n",
              "<td>0.8810771</td>\n",
              "<td>0.896878</td>\n",
              "<td>0.8944289</td>\n",
              "<td>0.9059632</td>\n",
              "<td>0.9051344</td>\n",
              "<td>0.8873068</td>\n",
              "<td>0.9090797</td></tr>\n",
              "<tr><td>mean_per_class_accuracy</td>\n",
              "<td>0.9478980</td>\n",
              "<td>0.0065428</td>\n",
              "<td>0.9409213</td>\n",
              "<td>0.9481028</td>\n",
              "<td>0.9504069</td>\n",
              "<td>0.9334407</td>\n",
              "<td>0.9544231</td>\n",
              "<td>0.9500949</td>\n",
              "<td>0.9533080</td>\n",
              "<td>0.9520143</td>\n",
              "<td>0.9444241</td>\n",
              "<td>0.951844</td></tr>\n",
              "<tr><td>mean_per_class_error</td>\n",
              "<td>0.0521020</td>\n",
              "<td>0.0065428</td>\n",
              "<td>0.0590787</td>\n",
              "<td>0.0518972</td>\n",
              "<td>0.0495931</td>\n",
              "<td>0.0665592</td>\n",
              "<td>0.0455769</td>\n",
              "<td>0.0499051</td>\n",
              "<td>0.0466920</td>\n",
              "<td>0.0479857</td>\n",
              "<td>0.0555759</td>\n",
              "<td>0.0481560</td></tr>\n",
              "<tr><td>mse</td>\n",
              "<td>0.0389693</td>\n",
              "<td>0.0030678</td>\n",
              "<td>0.0336931</td>\n",
              "<td>0.0403275</td>\n",
              "<td>0.0395220</td>\n",
              "<td>0.0427058</td>\n",
              "<td>0.0375024</td>\n",
              "<td>0.0406889</td>\n",
              "<td>0.0350779</td>\n",
              "<td>0.0410383</td>\n",
              "<td>0.0423526</td>\n",
              "<td>0.0367846</td></tr>\n",
              "<tr><td>pr_auc</td>\n",
              "<td>0.9851856</td>\n",
              "<td>0.0033534</td>\n",
              "<td>0.9890643</td>\n",
              "<td>0.9831293</td>\n",
              "<td>0.988671</td>\n",
              "<td>0.9805338</td>\n",
              "<td>0.9801792</td>\n",
              "<td>0.9855819</td>\n",
              "<td>0.9884563</td>\n",
              "<td>0.9852043</td>\n",
              "<td>0.9830673</td>\n",
              "<td>0.9879683</td></tr>\n",
              "<tr><td>precision</td>\n",
              "<td>0.9364201</td>\n",
              "<td>0.0264467</td>\n",
              "<td>0.9847328</td>\n",
              "<td>0.8984127</td>\n",
              "<td>0.9298246</td>\n",
              "<td>0.9558824</td>\n",
              "<td>0.9052287</td>\n",
              "<td>0.918429</td>\n",
              "<td>0.9387755</td>\n",
              "<td>0.9446254</td>\n",
              "<td>0.9267516</td>\n",
              "<td>0.9615384</td></tr>\n",
              "<tr><td>r2</td>\n",
              "<td>0.8344477</td>\n",
              "<td>0.0125903</td>\n",
              "<td>0.8540440</td>\n",
              "<td>0.8265718</td>\n",
              "<td>0.837372</td>\n",
              "<td>0.8155482</td>\n",
              "<td>0.8368003</td>\n",
              "<td>0.8299595</td>\n",
              "<td>0.8487146</td>\n",
              "<td>0.8267264</td>\n",
              "<td>0.8216033</td>\n",
              "<td>0.8471374</td></tr>\n",
              "<tr><td>recall</td>\n",
              "<td>0.935759</td>\n",
              "<td>0.0266079</td>\n",
              "<td>0.8896552</td>\n",
              "<td>0.9593220</td>\n",
              "<td>0.9520958</td>\n",
              "<td>0.8904110</td>\n",
              "<td>0.9651568</td>\n",
              "<td>0.9559748</td>\n",
              "<td>0.9419795</td>\n",
              "<td>0.9385113</td>\n",
              "<td>0.9356913</td>\n",
              "<td>0.9287926</td></tr>\n",
              "<tr><td>rmse</td>\n",
              "<td>0.1972660</td>\n",
              "<td>0.0078481</td>\n",
              "<td>0.1835569</td>\n",
              "<td>0.200817</td>\n",
              "<td>0.1988014</td>\n",
              "<td>0.2066539</td>\n",
              "<td>0.1936555</td>\n",
              "<td>0.2017150</td>\n",
              "<td>0.1872910</td>\n",
              "<td>0.2025790</td>\n",
              "<td>0.2057975</td>\n",
              "<td>0.1917932</td></tr>\n",
              "<tr><td>specificity</td>\n",
              "<td>0.960037</td>\n",
              "<td>0.0176535</td>\n",
              "<td>0.9921875</td>\n",
              "<td>0.9368836</td>\n",
              "<td>0.9487180</td>\n",
              "<td>0.9764706</td>\n",
              "<td>0.9436893</td>\n",
              "<td>0.9442149</td>\n",
              "<td>0.9646366</td>\n",
              "<td>0.9655172</td>\n",
              "<td>0.9531568</td>\n",
              "<td>0.9748954</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-26.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-26 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-26 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-26 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-26 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-26 .h2o-table th,\n",
              "#h2o-table-26 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-26 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-26\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Scoring History: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>timestamp</th>\n",
              "<th>duration</th>\n",
              "<th>number_of_trees</th>\n",
              "<th>training_rmse</th>\n",
              "<th>training_logloss</th>\n",
              "<th>training_auc</th>\n",
              "<th>training_pr_auc</th>\n",
              "<th>training_lift</th>\n",
              "<th>training_classification_error</th>\n",
              "<th>validation_rmse</th>\n",
              "<th>validation_logloss</th>\n",
              "<th>validation_auc</th>\n",
              "<th>validation_pr_auc</th>\n",
              "<th>validation_lift</th>\n",
              "<th>validation_classification_error</th></tr></thead>\n",
              "    <tbody><tr><td></td>\n",
              "<td>2023-06-21 22:17:46</td>\n",
              "<td>32.569 sec</td>\n",
              "<td>0.0</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 22:17:47</td>\n",
              "<td>32.892 sec</td>\n",
              "<td>5.0</td>\n",
              "<td>0.2654843</td>\n",
              "<td>1.7413155</td>\n",
              "<td>0.9392099</td>\n",
              "<td>0.9005971</td>\n",
              "<td>2.4477362</td>\n",
              "<td>0.0869925</td>\n",
              "<td>0.2361131</td>\n",
              "<td>0.4539518</td>\n",
              "<td>0.9732930</td>\n",
              "<td>0.9607852</td>\n",
              "<td>2.4994714</td>\n",
              "<td>0.0731954</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 22:17:47</td>\n",
              "<td>33.220 sec</td>\n",
              "<td>10.0</td>\n",
              "<td>0.2315927</td>\n",
              "<td>0.7765049</td>\n",
              "<td>0.9673155</td>\n",
              "<td>0.9485001</td>\n",
              "<td>2.5540904</td>\n",
              "<td>0.0722026</td>\n",
              "<td>0.2194020</td>\n",
              "<td>0.2325617</td>\n",
              "<td>0.9828688</td>\n",
              "<td>0.9753224</td>\n",
              "<td>2.5225140</td>\n",
              "<td>0.0605755</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 22:17:47</td>\n",
              "<td>33.525 sec</td>\n",
              "<td>15.0</td>\n",
              "<td>0.2204299</td>\n",
              "<td>0.5035587</td>\n",
              "<td>0.9759766</td>\n",
              "<td>0.9624020</td>\n",
              "<td>2.5832365</td>\n",
              "<td>0.0636784</td>\n",
              "<td>0.2142603</td>\n",
              "<td>0.1812396</td>\n",
              "<td>0.9857911</td>\n",
              "<td>0.9794942</td>\n",
              "<td>2.5274776</td>\n",
              "<td>0.0595659</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 22:17:48</td>\n",
              "<td>33.787 sec</td>\n",
              "<td>20.0</td>\n",
              "<td>0.2142265</td>\n",
              "<td>0.3438534</td>\n",
              "<td>0.9811466</td>\n",
              "<td>0.9713057</td>\n",
              "<td>2.6039396</td>\n",
              "<td>0.0604814</td>\n",
              "<td>0.2104068</td>\n",
              "<td>0.1625383</td>\n",
              "<td>0.9870656</td>\n",
              "<td>0.9822662</td>\n",
              "<td>2.5332481</td>\n",
              "<td>0.0545179</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 22:17:48</td>\n",
              "<td>34.064 sec</td>\n",
              "<td>25.0</td>\n",
              "<td>0.2099573</td>\n",
              "<td>0.2896510</td>\n",
              "<td>0.9833486</td>\n",
              "<td>0.9752624</td>\n",
              "<td>2.6109929</td>\n",
              "<td>0.0612296</td>\n",
              "<td>0.2114308</td>\n",
              "<td>0.1610202</td>\n",
              "<td>0.9870875</td>\n",
              "<td>0.9821275</td>\n",
              "<td>2.5332481</td>\n",
              "<td>0.0600707</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 22:17:48</td>\n",
              "<td>34.344 sec</td>\n",
              "<td>30.0</td>\n",
              "<td>0.2075009</td>\n",
              "<td>0.2362486</td>\n",
              "<td>0.9851545</td>\n",
              "<td>0.9785918</td>\n",
              "<td>2.6189589</td>\n",
              "<td>0.0594837</td>\n",
              "<td>0.2106734</td>\n",
              "<td>0.1604717</td>\n",
              "<td>0.9872869</td>\n",
              "<td>0.9824172</td>\n",
              "<td>2.5332481</td>\n",
              "<td>0.0575467</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 22:17:48</td>\n",
              "<td>34.643 sec</td>\n",
              "<td>35.0</td>\n",
              "<td>0.2054949</td>\n",
              "<td>0.1993216</td>\n",
              "<td>0.9865976</td>\n",
              "<td>0.9807144</td>\n",
              "<td>2.6230686</td>\n",
              "<td>0.0567402</td>\n",
              "<td>0.2104699</td>\n",
              "<td>0.1607007</td>\n",
              "<td>0.9872256</td>\n",
              "<td>0.9824110</td>\n",
              "<td>2.5332481</td>\n",
              "<td>0.0570419</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 22:17:49</td>\n",
              "<td>34.983 sec</td>\n",
              "<td>40.0</td>\n",
              "<td>0.2046981</td>\n",
              "<td>0.1874237</td>\n",
              "<td>0.9870665</td>\n",
              "<td>0.9814442</td>\n",
              "<td>2.6244339</td>\n",
              "<td>0.0559920</td>\n",
              "<td>0.2104163</td>\n",
              "<td>0.1611603</td>\n",
              "<td>0.9871781</td>\n",
              "<td>0.9824279</td>\n",
              "<td>2.5332481</td>\n",
              "<td>0.0565371</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 22:17:49</td>\n",
              "<td>35.276 sec</td>\n",
              "<td>44.0</td>\n",
              "<td>0.2043105</td>\n",
              "<td>0.1837342</td>\n",
              "<td>0.9872121</td>\n",
              "<td>0.9815838</td>\n",
              "<td>2.6243790</td>\n",
              "<td>0.0559920</td>\n",
              "<td>0.2102648</td>\n",
              "<td>0.1610109</td>\n",
              "<td>0.9872309</td>\n",
              "<td>0.9826571</td>\n",
              "<td>2.5332481</td>\n",
              "<td>0.0580515</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-27.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-27 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-27 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-27 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-27 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-27 .h2o-table th,\n",
              "#h2o-table-27 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-27 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-27\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Variable Importances: </caption>\n",
              "    <thead><tr><th>variable</th>\n",
              "<th>relative_importance</th>\n",
              "<th>scaled_importance</th>\n",
              "<th>percentage</th></tr></thead>\n",
              "    <tbody><tr><td>concave points_mean</td>\n",
              "<td>11857.6562500</td>\n",
              "<td>1.0</td>\n",
              "<td>0.1765809</td></tr>\n",
              "<tr><td>perimeter_worst</td>\n",
              "<td>9856.3300781</td>\n",
              "<td>0.8312208</td>\n",
              "<td>0.1467777</td></tr>\n",
              "<tr><td>radius_worst</td>\n",
              "<td>9738.7949219</td>\n",
              "<td>0.8213086</td>\n",
              "<td>0.1450274</td></tr>\n",
              "<tr><td>concave points_worst</td>\n",
              "<td>6207.0249023</td>\n",
              "<td>0.5234614</td>\n",
              "<td>0.0924333</td></tr>\n",
              "<tr><td>area_se</td>\n",
              "<td>5506.3461914</td>\n",
              "<td>0.4643705</td>\n",
              "<td>0.0819990</td></tr>\n",
              "<tr><td>perimeter_mean</td>\n",
              "<td>4992.4121094</td>\n",
              "<td>0.4210286</td>\n",
              "<td>0.0743456</td></tr>\n",
              "<tr><td>radius_se</td>\n",
              "<td>2336.1577148</td>\n",
              "<td>0.1970168</td>\n",
              "<td>0.0347894</td></tr>\n",
              "<tr><td>area_worst</td>\n",
              "<td>2132.2902832</td>\n",
              "<td>0.1798239</td>\n",
              "<td>0.0317535</td></tr>\n",
              "<tr><td>concavity_mean</td>\n",
              "<td>1775.3439941</td>\n",
              "<td>0.1497213</td>\n",
              "<td>0.0264379</td></tr>\n",
              "<tr><td>compactness_worst</td>\n",
              "<td>1584.4405518</td>\n",
              "<td>0.1336217</td>\n",
              "<td>0.0235950</td></tr>\n",
              "<tr><td>---</td>\n",
              "<td>---</td>\n",
              "<td>---</td>\n",
              "<td>---</td></tr>\n",
              "<tr><td>smoothness_mean</td>\n",
              "<td>366.6494751</td>\n",
              "<td>0.0309209</td>\n",
              "<td>0.0054600</td></tr>\n",
              "<tr><td>symmetry_mean</td>\n",
              "<td>338.6394348</td>\n",
              "<td>0.0285587</td>\n",
              "<td>0.0050429</td></tr>\n",
              "<tr><td>fractal_dimension_mean</td>\n",
              "<td>331.5473022</td>\n",
              "<td>0.0279606</td>\n",
              "<td>0.0049373</td></tr>\n",
              "<tr><td>fractal_dimension_worst</td>\n",
              "<td>319.9285889</td>\n",
              "<td>0.0269808</td>\n",
              "<td>0.0047643</td></tr>\n",
              "<tr><td>concavity_se</td>\n",
              "<td>319.1920166</td>\n",
              "<td>0.0269186</td>\n",
              "<td>0.0047533</td></tr>\n",
              "<tr><td>smoothness_se</td>\n",
              "<td>315.3716125</td>\n",
              "<td>0.0265965</td>\n",
              "<td>0.0046964</td></tr>\n",
              "<tr><td>texture_se</td>\n",
              "<td>302.1045227</td>\n",
              "<td>0.0254776</td>\n",
              "<td>0.0044989</td></tr>\n",
              "<tr><td>fractal_dimension_se</td>\n",
              "<td>301.0176392</td>\n",
              "<td>0.0253859</td>\n",
              "<td>0.0044827</td></tr>\n",
              "<tr><td>symmetry_se</td>\n",
              "<td>288.4009399</td>\n",
              "<td>0.0243219</td>\n",
              "<td>0.0042948</td></tr>\n",
              "<tr><td>concave points_se</td>\n",
              "<td>252.8923492</td>\n",
              "<td>0.0213273</td>\n",
              "<td>0.0037660</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "<pre style='font-size: smaller; margin-bottom: 1em;'>[30 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
              "\n",
              "[tips]\n",
              "Use `model.explain()` to inspect the model.\n",
              "--\n",
              "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.model_performance(train).accuracy()"
      ],
      "metadata": {
        "id": "G_PyYFNMs97_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33796f94-3c93-47b5-c46f-1c72017ea753"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.5681818181140856, 0.999750592343185]]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = aml.get_best_model()\n",
        "HATr  = best_model.model_performance(train)\n",
        "HATe  = best_model.model_performance(valid)"
      ],
      "metadata": {
        "id": "jKquKjVVJBL9"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uzfosknt7ILF"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SFOLD DATA AUTOML\n",
        "\n",
        "shdf = h2o.H2OFrame(newdata)\n",
        "shdf[\"y_test\"] = shdf[\"y_test\"].asfactor()\n",
        "shy = \"y_test\"\n",
        "shx = shdf.columns\n",
        "shx.remove(shy)\n",
        "strain, svalid = shdf.split_frame(ratios=[.8], seed=123)\n",
        "saml = H2OAutoML(max_models = 10, seed = 123, verbosity=\"info\", nfolds=10, sort_metric='accuracy')\n",
        "saml.train(x = shx, y = shy, training_frame = strain, validation_frame = svalid)\n",
        "sbest_model = saml.get_best_model()\n",
        "sHATr  = sbest_model.model_performance(strain)\n",
        "sHATe  = sbest_model.model_performance(svalid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMDqylVK7svS",
        "outputId": "1c533aac-b79c-4372-dc57-cb781ac42389"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
            "AutoML progress: |\n",
            "22:18:26.257: Project: AutoML_2_20230621_221826\n",
            "22:18:26.258: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n",
            "22:18:26.258: Setting stopping tolerance adaptively based on the training frame: 0.011167086836213468\n",
            "22:18:26.258: Build control seed: 123\n",
            "22:18:26.258: training frame: Frame key: AutoML_2_20230621_221826_training_py_14_sid_8e4e    cols: 7    rows: 8019  chunks: 1    size: 8063  checksum: -2050260287136184480\n",
            "22:18:26.258: validation frame: Frame key: py_15_sid_8e4e    cols: 7    rows: 1981  chunks: 1    size: 2778  checksum: -2050254522517019840\n",
            "22:18:26.258: leaderboard frame: NULL\n",
            "22:18:26.258: blending frame: NULL\n",
            "22:18:26.258: response column: y_test\n",
            "22:18:26.258: fold column: null\n",
            "22:18:26.258: weights column: null\n",
            "22:18:26.258: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (7g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (7g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (6g, 60w)]}, {StackedEnsemble : [monotonic (9g, 10w), best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
            "22:18:26.260: AutoML job created: 2023.06.21 22:18:26.257\n",
            "22:18:26.261: AutoML build started: 2023.06.21 22:18:26.261\n",
            "22:18:26.262: AutoML: starting XGBoost_1_AutoML_2_20230621_221826 model training\n",
            "\n",
            "██\n",
            "22:18:34.980: New leader: XGBoost_1_AutoML_2_20230621_221826, accuracy: 0.9524878413767303\n",
            "22:18:34.981: AutoML: starting GLM_1_AutoML_2_20230621_221826 model training\n",
            "\n",
            "█\n",
            "22:18:43.164: AutoML: starting GBM_1_AutoML_2_20230621_221826 model training\n",
            "\n",
            "█\n",
            "22:18:50.707: New leader: GBM_1_AutoML_2_20230621_221826, accuracy: 0.9524878413767303\n",
            "22:18:50.712: AutoML: starting XGBoost_2_AutoML_2_20230621_221826 model training\n",
            "\n",
            "█\n",
            "22:18:56.359: AutoML: starting DRF_1_AutoML_2_20230621_221826 model training\n",
            "\n",
            "█\n",
            "22:19:02.132: AutoML: starting GBM_2_AutoML_2_20230621_221826 model training\n",
            "\n",
            "██\n",
            "22:19:09.641: AutoML: starting GBM_3_AutoML_2_20230621_221826 model training\n",
            "\n",
            "█\n",
            "22:19:16.369: AutoML: starting GBM_4_AutoML_2_20230621_221826 model training\n",
            "\n",
            "█\n",
            "22:19:23.25: AutoML: starting XGBoost_3_AutoML_2_20230621_221826 model training\n",
            "\n",
            "█\n",
            "22:19:27.892: AutoML: starting XRT_1_AutoML_2_20230621_221826 model training\n",
            "\n",
            "█\n",
            "22:19:33.188: No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'monotonic'.\n",
            "22:19:33.190: AutoML: starting StackedEnsemble_BestOfFamily_1_AutoML_2_20230621_221826 model training\n",
            "\n",
            "█████\n",
            "22:19:44.578: AutoML: starting StackedEnsemble_AllModels_1_AutoML_2_20230621_221826 model training\n",
            "\n",
            "██████████████████████████████████████████████| (done) 100%\n",
            "\n",
            "22:19:59.138: New leader: GLM_1_AutoML_2_20230621_221826, accuracy: 0.9524878413767303\n",
            "22:19:59.138: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GLM : [def_1 (1g, 10w)]}, {GBM : [def_5 (1g, 10w)]}, {XGBoost : [def_1 (2g, 10w)]}, {DRF : [def_1 (2g, 10w)]}, {GBM : [def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w)]}, {XGBoost : [def_3 (3g, 10w)]}, {DRF : [XRT (3g, 10w)]}, {StackedEnsemble : [best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
            "22:19:59.139: AutoML build stopped: 2023.06.21 22:19:59.138\n",
            "22:19:59.139: AutoML build done: built 10 models\n",
            "22:19:59.139: AutoML duration:  1 min 32.877 sec\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = pd.DataFrame(\n",
        "    {\n",
        "    \"SVM\":[STr,STe],\n",
        "    \"KNN\":[KTr,KTe],\n",
        "    \"RF\" :[RTr,RTe],\n",
        "    \"LR\" :[LTr,LTe],\n",
        "    \"ANN\":[ATr,ATe],\n",
        "    \"XGB\":[XTr,XTe],\n",
        "    \"DNN\":[DTr,DTe],\n",
        "    \"H_OD\":[HATr.accuracy()[0][1],HATe.accuracy()[0][1]],\n",
        "    \"H_SOD\":[sHATr.accuracy()[0][1],sHATe.accuracy()[0][1]]\n",
        "    })\n",
        "acc.index = [\"train\", \"test\"]\n",
        "acc = acc.T\n",
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "F1gz4fq-6P6o",
        "outputId": "4fad91c4-6e9e-4372-a146-1c7502bed35e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          train      test\n",
              "SVM    0.950500  0.950000\n",
              "KNN    0.954875  0.944500\n",
              "RF     0.943875  0.950500\n",
              "LR     0.950000  0.950000\n",
              "ANN    0.958250  0.949000\n",
              "XGB    0.988250  0.945500\n",
              "DNN    0.954375  0.950500\n",
              "H_OD   0.999751  0.942453\n",
              "H_SOD  0.953485  0.944472"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e523b70e-c7cc-40bf-b507-dc9667510f3a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>0.950500</td>\n",
              "      <td>0.950000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>0.954875</td>\n",
              "      <td>0.944500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>0.943875</td>\n",
              "      <td>0.950500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LR</th>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.950000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ANN</th>\n",
              "      <td>0.958250</td>\n",
              "      <td>0.949000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGB</th>\n",
              "      <td>0.988250</td>\n",
              "      <td>0.945500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DNN</th>\n",
              "      <td>0.954375</td>\n",
              "      <td>0.950500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H_OD</th>\n",
              "      <td>0.999751</td>\n",
              "      <td>0.942453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H_SOD</th>\n",
              "      <td>0.953485</td>\n",
              "      <td>0.944472</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e523b70e-c7cc-40bf-b507-dc9667510f3a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e523b70e-c7cc-40bf-b507-dc9667510f3a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e523b70e-c7cc-40bf-b507-dc9667510f3a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.bar(acc.index, acc['train'], color ='black',width = 0.4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "nJrcI3Gn8we2",
        "outputId": "9808637e-068c-4470-c19e-4b0d7e8c8250"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 9 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc['avg'] = (acc['train']+acc['test'])/2\n",
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "qkRt32FBFDUc",
        "outputId": "0ec2e61a-e049-4662-9ba5-99d2785b4c07"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          train      test       avg\n",
              "SVM    0.950500  0.950000  0.950250\n",
              "KNN    0.954875  0.944500  0.949688\n",
              "RF     0.943875  0.950500  0.947188\n",
              "LR     0.950000  0.950000  0.950000\n",
              "ANN    0.958250  0.949000  0.953625\n",
              "XGB    0.988250  0.945500  0.966875\n",
              "DNN    0.954375  0.950500  0.952438\n",
              "H_OD   0.999751  0.942453  0.971102\n",
              "H_SOD  0.953485  0.944472  0.948979"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-548107b0-1562-4925-8219-83bd39591d97\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "      <th>avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>0.950500</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.950250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>0.954875</td>\n",
              "      <td>0.944500</td>\n",
              "      <td>0.949688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>0.943875</td>\n",
              "      <td>0.950500</td>\n",
              "      <td>0.947188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LR</th>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.950000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ANN</th>\n",
              "      <td>0.958250</td>\n",
              "      <td>0.949000</td>\n",
              "      <td>0.953625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGB</th>\n",
              "      <td>0.988250</td>\n",
              "      <td>0.945500</td>\n",
              "      <td>0.966875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DNN</th>\n",
              "      <td>0.954375</td>\n",
              "      <td>0.950500</td>\n",
              "      <td>0.952438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H_OD</th>\n",
              "      <td>0.999751</td>\n",
              "      <td>0.942453</td>\n",
              "      <td>0.971102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H_SOD</th>\n",
              "      <td>0.953485</td>\n",
              "      <td>0.944472</td>\n",
              "      <td>0.948979</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-548107b0-1562-4925-8219-83bd39591d97')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-548107b0-1562-4925-8219-83bd39591d97 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-548107b0-1562-4925-8219-83bd39591d97');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(acc.index, acc['avg'], color ='black',width = 0.4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "ikadXQW1FMDY",
        "outputId": "481f09f4-3f19-401c-d2db-1d8fbca44118"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 9 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}