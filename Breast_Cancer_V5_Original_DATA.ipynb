{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashiqurrahmankhan21st/BreastCancer/blob/main/Breast_Cancer_V5_Original_DATA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUMYU_d6_J-X"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "#import keras_metrics\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from sklearn.inspection import PartialDependenceDisplay\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#original data\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/ashiqurrahmankhan21st/BreastCancer/main/data.csv\")\n",
        "del df['id']\n",
        "df"
      ],
      "metadata": {
        "id": "Ntdqq4T_aGXN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "outputId": "cc63e5a6-cce2-4f81-854c-03e1bf3aa1cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0           M        17.99         10.38          122.80     1001.0   \n",
              "1           M        20.57         17.77          132.90     1326.0   \n",
              "2           M        19.69         21.25          130.00     1203.0   \n",
              "3           M        11.42         20.38           77.58      386.1   \n",
              "4           M        20.29         14.34          135.10     1297.0   \n",
              "..        ...          ...           ...             ...        ...   \n",
              "564         M        21.56         22.39          142.00     1479.0   \n",
              "565         M        20.13         28.25          131.20     1261.0   \n",
              "566         M        16.60         28.08          108.30      858.1   \n",
              "567         M        20.60         29.33          140.10     1265.0   \n",
              "568         B         7.76         24.54           47.92      181.0   \n",
              "\n",
              "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0            0.11840           0.27760         0.30010              0.14710   \n",
              "1            0.08474           0.07864         0.08690              0.07017   \n",
              "2            0.10960           0.15990         0.19740              0.12790   \n",
              "3            0.14250           0.28390         0.24140              0.10520   \n",
              "4            0.10030           0.13280         0.19800              0.10430   \n",
              "..               ...               ...             ...                  ...   \n",
              "564          0.11100           0.11590         0.24390              0.13890   \n",
              "565          0.09780           0.10340         0.14400              0.09791   \n",
              "566          0.08455           0.10230         0.09251              0.05302   \n",
              "567          0.11780           0.27700         0.35140              0.15200   \n",
              "568          0.05263           0.04362         0.00000              0.00000   \n",
              "\n",
              "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
              "0           0.2419  ...        25.380          17.33           184.60   \n",
              "1           0.1812  ...        24.990          23.41           158.80   \n",
              "2           0.2069  ...        23.570          25.53           152.50   \n",
              "3           0.2597  ...        14.910          26.50            98.87   \n",
              "4           0.1809  ...        22.540          16.67           152.20   \n",
              "..             ...  ...           ...            ...              ...   \n",
              "564         0.1726  ...        25.450          26.40           166.10   \n",
              "565         0.1752  ...        23.690          38.25           155.00   \n",
              "566         0.1590  ...        18.980          34.12           126.70   \n",
              "567         0.2397  ...        25.740          39.42           184.60   \n",
              "568         0.1587  ...         9.456          30.37            59.16   \n",
              "\n",
              "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
              "0        2019.0           0.16220            0.66560           0.7119   \n",
              "1        1956.0           0.12380            0.18660           0.2416   \n",
              "2        1709.0           0.14440            0.42450           0.4504   \n",
              "3         567.7           0.20980            0.86630           0.6869   \n",
              "4        1575.0           0.13740            0.20500           0.4000   \n",
              "..          ...               ...                ...              ...   \n",
              "564      2027.0           0.14100            0.21130           0.4107   \n",
              "565      1731.0           0.11660            0.19220           0.3215   \n",
              "566      1124.0           0.11390            0.30940           0.3403   \n",
              "567      1821.0           0.16500            0.86810           0.9387   \n",
              "568       268.6           0.08996            0.06444           0.0000   \n",
              "\n",
              "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
              "0                  0.2654          0.4601                  0.11890  \n",
              "1                  0.1860          0.2750                  0.08902  \n",
              "2                  0.2430          0.3613                  0.08758  \n",
              "3                  0.2575          0.6638                  0.17300  \n",
              "4                  0.1625          0.2364                  0.07678  \n",
              "..                    ...             ...                      ...  \n",
              "564                0.2216          0.2060                  0.07115  \n",
              "565                0.1628          0.2572                  0.06637  \n",
              "566                0.1418          0.2218                  0.07820  \n",
              "567                0.2650          0.4087                  0.12400  \n",
              "568                0.0000          0.2871                  0.07039  \n",
              "\n",
              "[569 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bf23eed4-e12f-4aca-bfdf-940d466f4b0a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>...</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>...</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>...</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>...</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>...</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>M</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>...</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>M</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>...</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>M</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>...</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>M</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>...</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>B</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>...</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows Ã— 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf23eed4-e12f-4aca-bfdf-940d466f4b0a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bf23eed4-e12f-4aca-bfdf-940d466f4b0a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bf23eed4-e12f-4aca-bfdf-940d466f4b0a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(df['diagnosis']).copy()\n",
        "X = df.drop(columns=['diagnosis']).copy()\n",
        "X = StandardScaler().fit_transform(X).copy()"
      ],
      "metadata": {
        "id": "4cimS259ti6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['diagnosis'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bv9sG-P8M1Fe",
        "outputId": "9bbe79ee-218c-4de8-8be4-77c8cbe412e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "B    357\n",
              "M    212\n",
              "Name: diagnosis, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(df['diagnosis']).copy()\n",
        "X = df.drop(columns=['diagnosis']).copy()\n",
        "X = StandardScaler().fit_transform(X).copy()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "#X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=123)\n",
        "y_test_indi_ML = y_test.copy()\n",
        "print(\"Original data : \",df.shape)\n",
        "print(\"tarin         : \",X_train.shape)\n",
        "print(\"test          : \",X_test.shape[0])\n",
        "#print(\"validation    : \",X_val.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpyVwv13CTut",
        "outputId": "daf07047-f7f6-410b-8270-4d50351e2a8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original data :  (569, 31)\n",
            "tarin         :  (455, 30)\n",
            "test          :  114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM\n",
        "st = time.time()\n",
        "svm = SVC(C=0.1, gamma='auto', kernel = 'rbf',probability=True)\n",
        "svm.fit(X_train, y_train)\n",
        "send = time.time() - st\n",
        "STr = svm.score(X_train, y_train)\n",
        "STe = svm.score(X_test, y_test)\n",
        "y_pred_svm = svm.predict(X_test)"
      ],
      "metadata": {
        "id": "wnRYFOkyEEZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ANN\n",
        "st = time.time()\n",
        "tf.random.set_seed(123)\n",
        "ANNmodel = Sequential()\n",
        "ANNmodel.add(Dense(30, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "ANNmodel.add(Dense(15, activation='relu'))\n",
        "ANNmodel.add(Dense(1, activation='sigmoid'))\n",
        "ANNmodel.compile(loss='BinaryCrossentropy', optimizer='adam', metrics=['accuracy']) #tf.keras.metrics.Precision(), tf.keras.metrics.Recall()\n",
        "ANNmodel.fit(X_train,y_train, batch_size = 128, epochs = 20, validation_split = 0.1)\n",
        "aend = time.time() - st\n",
        "ATr = ANNmodel.evaluate(X_train,y_train,verbose=0)[1]\n",
        "ATe = ANNmodel.evaluate(X_test,y_test,verbose=0)[1]\n",
        "y_pred_ANN = (ANNmodel.predict(X_test) > 0.5).astype(\"int32\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZX7DbN-OIyu",
        "outputId": "25de9dc0-e310-493d-a34f-5eab79eb6e93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "4/4 [==============================] - 1s 95ms/step - loss: 0.8241 - accuracy: 0.3105 - val_loss: 0.7713 - val_accuracy: 0.4348\n",
            "Epoch 2/20\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7296 - accuracy: 0.4645 - val_loss: 0.7049 - val_accuracy: 0.5217\n",
            "Epoch 3/20\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6510 - accuracy: 0.5868 - val_loss: 0.6463 - val_accuracy: 0.6957\n",
            "Epoch 4/20\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5810 - accuracy: 0.7237 - val_loss: 0.5953 - val_accuracy: 0.7391\n",
            "Epoch 5/20\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5197 - accuracy: 0.8289 - val_loss: 0.5487 - val_accuracy: 0.7826\n",
            "Epoch 6/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4628 - accuracy: 0.8655 - val_loss: 0.5081 - val_accuracy: 0.8043\n",
            "Epoch 7/20\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4119 - accuracy: 0.8924 - val_loss: 0.4744 - val_accuracy: 0.8261\n",
            "Epoch 8/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3665 - accuracy: 0.9071 - val_loss: 0.4452 - val_accuracy: 0.8261\n",
            "Epoch 9/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3264 - accuracy: 0.9242 - val_loss: 0.4195 - val_accuracy: 0.8478\n",
            "Epoch 10/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.2914 - accuracy: 0.9315 - val_loss: 0.3981 - val_accuracy: 0.8478\n",
            "Epoch 11/20\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2618 - accuracy: 0.9364 - val_loss: 0.3787 - val_accuracy: 0.8478\n",
            "Epoch 12/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.2365 - accuracy: 0.9389 - val_loss: 0.3615 - val_accuracy: 0.8478\n",
            "Epoch 13/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.2152 - accuracy: 0.9462 - val_loss: 0.3464 - val_accuracy: 0.8696\n",
            "Epoch 14/20\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1977 - accuracy: 0.9487 - val_loss: 0.3333 - val_accuracy: 0.8696\n",
            "Epoch 15/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1827 - accuracy: 0.9462 - val_loss: 0.3217 - val_accuracy: 0.8696\n",
            "Epoch 16/20\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.1699 - accuracy: 0.9487 - val_loss: 0.3109 - val_accuracy: 0.8696\n",
            "Epoch 17/20\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1589 - accuracy: 0.9511 - val_loss: 0.3009 - val_accuracy: 0.8696\n",
            "Epoch 18/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.1496 - accuracy: 0.9511 - val_loss: 0.2919 - val_accuracy: 0.8913\n",
            "Epoch 19/20\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1412 - accuracy: 0.9560 - val_loss: 0.2841 - val_accuracy: 0.9130\n",
            "Epoch 20/20\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.1341 - accuracy: 0.9584 - val_loss: 0.2765 - val_accuracy: 0.9130\n",
            "4/4 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ATr,ATe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8_62aKT4GzA",
        "outputId": "4bbf4bda-c023-437e-e7a8-612a0db9404d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9604395627975464, 0.9736841917037964)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XGBoost\n",
        "st = time.time()\n",
        "xgb = XGBClassifier(objective='binary:logistic',max_depth= 6,alpha= 10,learning_rate= 0.03,n_estimators=250)\n",
        "xgb.fit(X_train, y_train)\n",
        "xend = time.time() - st\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "XTr = accuracy_score(y_train, xgb.predict(X_train))\n",
        "XTe = accuracy_score(y_test, xgb.predict(X_test))\n",
        "XTr,XTe"
      ],
      "metadata": {
        "id": "PCP82YZ9RjgJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "297c9f60-26ab-40e8-bcbd-393fdc8fbacb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9934065934065934, 0.9824561403508771)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#KNN\n",
        "# Define the range of n_neighbors values to test\n",
        "n_neighbors_values = [1,3, 5, 7, 9, 11]\n",
        "\n",
        "best_accuracy = 0.0\n",
        "best_n_neighbors = None\n",
        "\n",
        "for n_neighbors in n_neighbors_values:\n",
        "    print(\"Number of Neighbors:\", n_neighbors)\n",
        "\n",
        "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    y_pred_knn = knn.predict(X_test)\n",
        "\n",
        "    train_accuracy = accuracy_score(y_train, knn.predict(X_train))\n",
        "    test_accuracy = accuracy_score(y_test, knn.predict(X_test))\n",
        "\n",
        "    print('KNN model train accuracy score: {0:0.4f}'.format(train_accuracy))\n",
        "    print('KNN model test accuracy score: {0:0.4f}'.format(test_accuracy))\n",
        "    print()\n",
        "\n",
        "    # Check if the current test accuracy is better than the previous best\n",
        "    if test_accuracy > best_accuracy:\n",
        "        best_accuracy = test_accuracy\n",
        "        best_n_neighbors = n_neighbors\n",
        "print(\"best neighbours: \", best_n_neighbors)\n",
        "\n",
        "st = time.time()\n",
        "knn = KNeighborsClassifier(n_neighbors=best_n_neighbors)\n",
        "knn.fit(X_train, y_train)\n",
        "kend = time.time() - st\n",
        "KTr = accuracy_score(y_train, knn.predict(X_train))\n",
        "KTe = accuracy_score(y_test, knn.predict(X_test))\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "KTr,KTe\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Y_6b33A1imy",
        "outputId": "137be8e4-f0ed-440e-bb27-1a1571807e87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Neighbors: 1\n",
            "KNN model train accuracy score: 1.0000\n",
            "KNN model test accuracy score: 0.9737\n",
            "\n",
            "Number of Neighbors: 3\n",
            "KNN model train accuracy score: 0.9802\n",
            "KNN model test accuracy score: 0.9912\n",
            "\n",
            "Number of Neighbors: 5\n",
            "KNN model train accuracy score: 0.9692\n",
            "KNN model test accuracy score: 0.9825\n",
            "\n",
            "Number of Neighbors: 7\n",
            "KNN model train accuracy score: 0.9692\n",
            "KNN model test accuracy score: 0.9737\n",
            "\n",
            "Number of Neighbors: 9\n",
            "KNN model train accuracy score: 0.9692\n",
            "KNN model test accuracy score: 0.9825\n",
            "\n",
            "Number of Neighbors: 11\n",
            "KNN model train accuracy score: 0.9714\n",
            "KNN model test accuracy score: 0.9825\n",
            "\n",
            "best neighbours:  3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9802197802197802, 0.9912280701754386)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RF\n",
        "st = time.time()\n",
        "rf = RandomForestClassifier(n_estimators= 500,max_features = 'sqrt', max_samples = 100, random_state=123)\n",
        "rf.fit(X_train, y_train)\n",
        "rend = time.time() - st\n",
        "RTr = accuracy_score(y_train, rf.predict(X_train))\n",
        "RTe = accuracy_score(y_test, rf.predict(X_test))\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "RTr,RTe"
      ],
      "metadata": {
        "id": "k_kyk_E92bSX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2198aa7d-fb4b-4018-c7fb-1cf1dad0b261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9758241758241758, 0.9912280701754386)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LR\n",
        "st = time.time()\n",
        "lr = LogisticRegression(C= 0.1 , penalty='l1', solver='liblinear', max_iter = 1000, random_state=123)\n",
        "lr.fit(X_train, y_train)\n",
        "lend = time.time() - st\n",
        "LTr = accuracy_score(y_train, lr.predict(X_train))\n",
        "LTe = accuracy_score(y_test, lr.predict(X_test))\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "LTr,LTe"
      ],
      "metadata": {
        "id": "OWkZmwL23Fm_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9dc1250-3f02-45d7-abd4-abd2d0958f51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9802197802197802, 0.9736842105263158)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E9_l6r5f0w5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CVal(ML):\n",
        "\n",
        "  df = pd.read_csv(\"https://raw.githubusercontent.com/ashiqurrahmankhan21st/BreastCancer/main/data.csv\")\n",
        "  del df['id']\n",
        "\n",
        "  s = 0\n",
        "  e = round(df.shape[0]*.2)\n",
        "\n",
        "  y_pred = []\n",
        "  y_original = []\n",
        "\n",
        "  for i in range(5):\n",
        "\n",
        "    test_set  = df.iloc[s:e,:]\n",
        "    train_set = df.drop(test_set.index)\n",
        "\n",
        "    X_train = StandardScaler().fit_transform(train_set.drop(columns=['diagnosis'])).copy()\n",
        "    y_train = encoder.fit_transform(train_set['diagnosis']).copy()\n",
        "    X_test = StandardScaler().fit_transform(test_set.drop(columns=['diagnosis'])).copy()\n",
        "    y_test = encoder.fit_transform(test_set['diagnosis']).copy()\n",
        "\n",
        "    #svm = SVC(C=0.1, gamma='auto', kernel = 'rbf')\n",
        "\n",
        "    ML.fit(X_train, y_train)\n",
        "    y_pred_ML = ML.predict(X_test)\n",
        "\n",
        "\n",
        "    y_pred.append(y_pred_ML)\n",
        "    y_original.append(y_test)\n",
        "\n",
        "    s = e\n",
        "    e = e + round(df.shape[0]*.2)\n",
        "    if e-s < round(df.shape[0]*.2):\n",
        "      e = df.shape[0]+1\n",
        "\n",
        "  y_pred_final = []\n",
        "  y_original_final = []\n",
        "\n",
        "  try:\n",
        "    for i in range(5):\n",
        "      for j in range(round(df.shape[0]*.2)):\n",
        "        y_pred_final.append(y_pred[i][j])\n",
        "        y_original_final.append(y_original[i][j])\n",
        "  except:\n",
        "    pass\n",
        "  return y_pred_final"
      ],
      "metadata": {
        "id": "XqaJZ1Mb0xAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CValANN():\n",
        "\n",
        "  df = pd.read_csv(\"https://raw.githubusercontent.com/ashiqurrahmankhan21st/BreastCancer/main/data.csv\")\n",
        "  del df['id']\n",
        "\n",
        "  s = 0\n",
        "  e = round(df.shape[0]*.2)\n",
        "\n",
        "  y_pred = []\n",
        "  y_original = []\n",
        "\n",
        "  for i in range(5):\n",
        "\n",
        "    test_set  = df.iloc[s:e,:]\n",
        "    train_set = df.drop(test_set.index)\n",
        "\n",
        "    X_train = StandardScaler().fit_transform(train_set.drop(columns=['diagnosis'])).copy()\n",
        "    y_train = encoder.fit_transform(train_set['diagnosis']).copy()\n",
        "    X_test = StandardScaler().fit_transform(test_set.drop(columns=['diagnosis'])).copy()\n",
        "    y_test = encoder.fit_transform(test_set['diagnosis']).copy()\n",
        "\n",
        "    #svm = SVC(C=0.1, gamma='auto', kernel = 'rbf')\n",
        "    tf.random.set_seed(123)\n",
        "    ANNmodel = Sequential()\n",
        "    ANNmodel.add(Dense(30, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "    ANNmodel.add(Dense(15, activation='relu'))\n",
        "    ANNmodel.add(Dense(1, activation='sigmoid'))\n",
        "    ANNmodel.compile(loss='BinaryCrossentropy', optimizer='adam', metrics=['accuracy']) #tf.keras.metrics.Precision(), tf.keras.metrics.Recall()\n",
        "    ANNmodel.fit(X_train,y_train, batch_size = 128, epochs = 20, validation_split = 0.1)\n",
        "    y_pred_ANN = (ANNmodel.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "\n",
        "    y_pred.append(y_pred_ANN)\n",
        "    y_original.append(y_test)\n",
        "\n",
        "    s = e\n",
        "    e = e + round(df.shape[0]*.2)\n",
        "    if e-s < round(df.shape[0]*.2):\n",
        "      e = df.shape[0]\n",
        "\n",
        "  y_pred_fina = []\n",
        "  y_original_final = []\n",
        "\n",
        "  try:\n",
        "    for i in range(5):\n",
        "      for j in range(round(df.shape[0]*.2)):\n",
        "        y_pred_fina.append(y_pred[i][j])\n",
        "        y_original_final.append(y_original[i][j])\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  y_pred_final = []\n",
        "\n",
        "  for i in range(len(y_pred_fina)):\n",
        "    y_pred_final.append(y_pred_fina[i][0])\n",
        "\n",
        "  return y_pred_final"
      ],
      "metadata": {
        "id": "jRa_a7EY0y6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newdata = pd.DataFrame({\n",
        "    \"SVM\": CVal(SVC(C=0.1, gamma='auto', kernel = 'rbf'))\n",
        "})\n",
        "newdata[\"KNN\"] = CVal(KNeighborsClassifier(n_neighbors=3))\n",
        "newdata[\"RF\"]  = CVal(RandomForestClassifier(n_estimators= 500,max_features = 'sqrt', max_samples = 100, random_state=123))\n",
        "newdata['LR']  = CVal(LogisticRegression(C= 0.1 , penalty='l1', solver='liblinear', max_iter = 1000, random_state=123))\n",
        "newdata[\"ANN\"] = CValANN()\n",
        "newdata[\"XGB\"] = CVal(XGBClassifier(objective='binary:logistic',max_depth= 7,alpha= 10,learning_rate= 1,n_estimators=100))\n",
        "newdata['y_test'] = encoder.fit_transform(df['diagnosis']).copy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CGgdO1V0zA9",
        "outputId": "e599545d-e93f-4e45-af4d-83d7a301c10d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "4/4 [==============================] - 1s 80ms/step - loss: 0.8885 - accuracy: 0.5648 - val_loss: 0.7935 - val_accuracy: 0.5000\n",
            "Epoch 2/20\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.7871 - accuracy: 0.6039 - val_loss: 0.7170 - val_accuracy: 0.6304\n",
            "Epoch 3/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.7077 - accuracy: 0.6406 - val_loss: 0.6495 - val_accuracy: 0.7174\n",
            "Epoch 4/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.6394 - accuracy: 0.6724 - val_loss: 0.5945 - val_accuracy: 0.7391\n",
            "Epoch 5/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5829 - accuracy: 0.6895 - val_loss: 0.5459 - val_accuracy: 0.8043\n",
            "Epoch 6/20\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5328 - accuracy: 0.7164 - val_loss: 0.4986 - val_accuracy: 0.8043\n",
            "Epoch 7/20\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4879 - accuracy: 0.7433 - val_loss: 0.4544 - val_accuracy: 0.8478\n",
            "Epoch 8/20\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.4485 - accuracy: 0.7726 - val_loss: 0.4127 - val_accuracy: 0.8913\n",
            "Epoch 9/20\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4119 - accuracy: 0.8117 - val_loss: 0.3744 - val_accuracy: 0.9130\n",
            "Epoch 10/20\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3787 - accuracy: 0.8582 - val_loss: 0.3385 - val_accuracy: 0.9783\n",
            "Epoch 11/20\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3486 - accuracy: 0.8900 - val_loss: 0.3069 - val_accuracy: 0.9783\n",
            "Epoch 12/20\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.3213 - accuracy: 0.9120 - val_loss: 0.2793 - val_accuracy: 0.9783\n",
            "Epoch 13/20\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.2961 - accuracy: 0.9291 - val_loss: 0.2560 - val_accuracy: 0.9783\n",
            "Epoch 14/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.2730 - accuracy: 0.9438 - val_loss: 0.2355 - val_accuracy: 0.9783\n",
            "Epoch 15/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.2518 - accuracy: 0.9462 - val_loss: 0.2175 - val_accuracy: 0.9783\n",
            "Epoch 16/20\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.2326 - accuracy: 0.9511 - val_loss: 0.2024 - val_accuracy: 0.9783\n",
            "Epoch 17/20\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.2157 - accuracy: 0.9535 - val_loss: 0.1894 - val_accuracy: 0.9783\n",
            "Epoch 18/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.2000 - accuracy: 0.9658 - val_loss: 0.1773 - val_accuracy: 0.9783\n",
            "Epoch 19/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.1861 - accuracy: 0.9682 - val_loss: 0.1673 - val_accuracy: 0.9783\n",
            "Epoch 20/20\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.1736 - accuracy: 0.9658 - val_loss: 0.1589 - val_accuracy: 0.9783\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 1/20\n",
            "4/4 [==============================] - 1s 74ms/step - loss: 0.7981 - accuracy: 0.5623 - val_loss: 0.6154 - val_accuracy: 0.7391\n",
            "Epoch 2/20\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.6832 - accuracy: 0.6161 - val_loss: 0.5274 - val_accuracy: 0.7609\n",
            "Epoch 3/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.5890 - accuracy: 0.6968 - val_loss: 0.4517 - val_accuracy: 0.8261\n",
            "Epoch 4/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5031 - accuracy: 0.7800 - val_loss: 0.3878 - val_accuracy: 0.8913\n",
            "Epoch 5/20\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4331 - accuracy: 0.8606 - val_loss: 0.3356 - val_accuracy: 0.9130\n",
            "Epoch 6/20\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3754 - accuracy: 0.8949 - val_loss: 0.2945 - val_accuracy: 0.9348\n",
            "Epoch 7/20\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.3285 - accuracy: 0.9169 - val_loss: 0.2599 - val_accuracy: 0.9565\n",
            "Epoch 8/20\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.2900 - accuracy: 0.9218 - val_loss: 0.2314 - val_accuracy: 0.9565\n",
            "Epoch 9/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2595 - accuracy: 0.9291 - val_loss: 0.2068 - val_accuracy: 0.9565\n",
            "Epoch 10/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.2337 - accuracy: 0.9364 - val_loss: 0.1866 - val_accuracy: 0.9565\n",
            "Epoch 11/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2118 - accuracy: 0.9413 - val_loss: 0.1699 - val_accuracy: 0.9565\n",
            "Epoch 12/20\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1946 - accuracy: 0.9487 - val_loss: 0.1563 - val_accuracy: 0.9565\n",
            "Epoch 13/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1792 - accuracy: 0.9535 - val_loss: 0.1455 - val_accuracy: 0.9565\n",
            "Epoch 14/20\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.1662 - accuracy: 0.9535 - val_loss: 0.1364 - val_accuracy: 0.9783\n",
            "Epoch 15/20\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.1550 - accuracy: 0.9560 - val_loss: 0.1294 - val_accuracy: 0.9783\n",
            "Epoch 16/20\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1451 - accuracy: 0.9535 - val_loss: 0.1236 - val_accuracy: 0.9783\n",
            "Epoch 17/20\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.1365 - accuracy: 0.9535 - val_loss: 0.1186 - val_accuracy: 0.9783\n",
            "Epoch 18/20\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1291 - accuracy: 0.9584 - val_loss: 0.1141 - val_accuracy: 0.9783\n",
            "Epoch 19/20\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1227 - accuracy: 0.9609 - val_loss: 0.1106 - val_accuracy: 0.9783\n",
            "Epoch 20/20\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.1166 - accuracy: 0.9633 - val_loss: 0.1078 - val_accuracy: 0.9783\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 1/20\n",
            "4/4 [==============================] - 1s 83ms/step - loss: 0.6233 - accuracy: 0.7017 - val_loss: 0.5510 - val_accuracy: 0.8696\n",
            "Epoch 2/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5572 - accuracy: 0.8435 - val_loss: 0.4753 - val_accuracy: 0.9130\n",
            "Epoch 3/20\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4968 - accuracy: 0.9144 - val_loss: 0.4127 - val_accuracy: 0.9130\n",
            "Epoch 4/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4416 - accuracy: 0.9364 - val_loss: 0.3593 - val_accuracy: 0.9348\n",
            "Epoch 5/20\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.3935 - accuracy: 0.9438 - val_loss: 0.3144 - val_accuracy: 0.9348\n",
            "Epoch 6/20\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.3515 - accuracy: 0.9438 - val_loss: 0.2773 - val_accuracy: 0.9348\n",
            "Epoch 7/20\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.3163 - accuracy: 0.9462 - val_loss: 0.2466 - val_accuracy: 0.9348\n",
            "Epoch 8/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2859 - accuracy: 0.9438 - val_loss: 0.2214 - val_accuracy: 0.9348\n",
            "Epoch 9/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.2611 - accuracy: 0.9462 - val_loss: 0.2008 - val_accuracy: 0.9348\n",
            "Epoch 10/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2390 - accuracy: 0.9462 - val_loss: 0.1845 - val_accuracy: 0.9565\n",
            "Epoch 11/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2207 - accuracy: 0.9438 - val_loss: 0.1714 - val_accuracy: 0.9783\n",
            "Epoch 12/20\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.2053 - accuracy: 0.9438 - val_loss: 0.1605 - val_accuracy: 0.9783\n",
            "Epoch 13/20\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1916 - accuracy: 0.9438 - val_loss: 0.1509 - val_accuracy: 0.9783\n",
            "Epoch 14/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.1797 - accuracy: 0.9462 - val_loss: 0.1427 - val_accuracy: 0.9783\n",
            "Epoch 15/20\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1688 - accuracy: 0.9511 - val_loss: 0.1365 - val_accuracy: 0.9783\n",
            "Epoch 16/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1590 - accuracy: 0.9535 - val_loss: 0.1314 - val_accuracy: 0.9783\n",
            "Epoch 17/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1502 - accuracy: 0.9535 - val_loss: 0.1269 - val_accuracy: 0.9783\n",
            "Epoch 18/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.1421 - accuracy: 0.9560 - val_loss: 0.1232 - val_accuracy: 0.9783\n",
            "Epoch 19/20\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1346 - accuracy: 0.9560 - val_loss: 0.1204 - val_accuracy: 0.9783\n",
            "Epoch 20/20\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.1278 - accuracy: 0.9584 - val_loss: 0.1185 - val_accuracy: 0.9783\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 1/20\n",
            "4/4 [==============================] - 1s 80ms/step - loss: 0.8773 - accuracy: 0.5746 - val_loss: 0.6085 - val_accuracy: 0.8043\n",
            "Epoch 2/20\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.7732 - accuracy: 0.5746 - val_loss: 0.5375 - val_accuracy: 0.8043\n",
            "Epoch 3/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6944 - accuracy: 0.5746 - val_loss: 0.4800 - val_accuracy: 0.8043\n",
            "Epoch 4/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.6285 - accuracy: 0.5746 - val_loss: 0.4320 - val_accuracy: 0.8043\n",
            "Epoch 5/20\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5747 - accuracy: 0.5770 - val_loss: 0.3922 - val_accuracy: 0.8043\n",
            "Epoch 6/20\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.5304 - accuracy: 0.5770 - val_loss: 0.3586 - val_accuracy: 0.8043\n",
            "Epoch 7/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4933 - accuracy: 0.5917 - val_loss: 0.3300 - val_accuracy: 0.8261\n",
            "Epoch 8/20\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4627 - accuracy: 0.6308 - val_loss: 0.3069 - val_accuracy: 0.8478\n",
            "Epoch 9/20\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4377 - accuracy: 0.6822 - val_loss: 0.2885 - val_accuracy: 0.8696\n",
            "Epoch 10/20\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4154 - accuracy: 0.7457 - val_loss: 0.2737 - val_accuracy: 0.9130\n",
            "Epoch 11/20\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3973 - accuracy: 0.7775 - val_loss: 0.2604 - val_accuracy: 0.9348\n",
            "Epoch 12/20\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3818 - accuracy: 0.8191 - val_loss: 0.2489 - val_accuracy: 0.9565\n",
            "Epoch 13/20\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.3683 - accuracy: 0.8631 - val_loss: 0.2390 - val_accuracy: 0.9565\n",
            "Epoch 14/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3559 - accuracy: 0.8802 - val_loss: 0.2304 - val_accuracy: 0.9565\n",
            "Epoch 15/20\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.3445 - accuracy: 0.8998 - val_loss: 0.2235 - val_accuracy: 0.9348\n",
            "Epoch 16/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3331 - accuracy: 0.9193 - val_loss: 0.2176 - val_accuracy: 0.9348\n",
            "Epoch 17/20\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.3221 - accuracy: 0.9364 - val_loss: 0.2115 - val_accuracy: 0.9348\n",
            "Epoch 18/20\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.3104 - accuracy: 0.9462 - val_loss: 0.2057 - val_accuracy: 0.9565\n",
            "Epoch 19/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2982 - accuracy: 0.9487 - val_loss: 0.1990 - val_accuracy: 0.9565\n",
            "Epoch 20/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2856 - accuracy: 0.9584 - val_loss: 0.1920 - val_accuracy: 0.9565\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 1/20\n",
            "4/4 [==============================] - 1s 77ms/step - loss: 0.8319 - accuracy: 0.3098 - val_loss: 0.7150 - val_accuracy: 0.4348\n",
            "Epoch 2/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.7185 - accuracy: 0.4732 - val_loss: 0.6386 - val_accuracy: 0.6522\n",
            "Epoch 3/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6246 - accuracy: 0.7024 - val_loss: 0.5730 - val_accuracy: 0.8261\n",
            "Epoch 4/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5477 - accuracy: 0.8293 - val_loss: 0.5143 - val_accuracy: 0.8913\n",
            "Epoch 5/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4848 - accuracy: 0.8805 - val_loss: 0.4613 - val_accuracy: 0.8913\n",
            "Epoch 6/20\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4324 - accuracy: 0.8951 - val_loss: 0.4139 - val_accuracy: 0.9130\n",
            "Epoch 7/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3882 - accuracy: 0.9073 - val_loss: 0.3724 - val_accuracy: 0.9565\n",
            "Epoch 8/20\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3509 - accuracy: 0.9146 - val_loss: 0.3365 - val_accuracy: 0.9565\n",
            "Epoch 9/20\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.3193 - accuracy: 0.9268 - val_loss: 0.3051 - val_accuracy: 0.9565\n",
            "Epoch 10/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.2922 - accuracy: 0.9366 - val_loss: 0.2780 - val_accuracy: 0.9565\n",
            "Epoch 11/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.2684 - accuracy: 0.9415 - val_loss: 0.2549 - val_accuracy: 0.9565\n",
            "Epoch 12/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.2481 - accuracy: 0.9439 - val_loss: 0.2349 - val_accuracy: 0.9565\n",
            "Epoch 13/20\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.2303 - accuracy: 0.9439 - val_loss: 0.2178 - val_accuracy: 0.9565\n",
            "Epoch 14/20\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2144 - accuracy: 0.9488 - val_loss: 0.2029 - val_accuracy: 0.9348\n",
            "Epoch 15/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2003 - accuracy: 0.9488 - val_loss: 0.1898 - val_accuracy: 0.9348\n",
            "Epoch 16/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1878 - accuracy: 0.9512 - val_loss: 0.1782 - val_accuracy: 0.9348\n",
            "Epoch 17/20\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.1762 - accuracy: 0.9537 - val_loss: 0.1680 - val_accuracy: 0.9348\n",
            "Epoch 18/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1657 - accuracy: 0.9561 - val_loss: 0.1588 - val_accuracy: 0.9348\n",
            "Epoch 19/20\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.1564 - accuracy: 0.9634 - val_loss: 0.1504 - val_accuracy: 0.9348\n",
            "Epoch 20/20\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1477 - accuracy: 0.9659 - val_loss: 0.1430 - val_accuracy: 0.9348\n",
            "4/4 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newdata.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "05ryfvyLzFVK",
        "outputId": "cd280f57-d0d4-4903-8bd3-e04f88e2af66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   SVM  KNN  RF  LR  ANN  XGB  y_test\n",
              "0    1    1   1   1    1    0       1\n",
              "1    1    1   1   1    1    1       1\n",
              "2    1    1   1   1    1    1       1\n",
              "3    1    1   1   1    1    1       1\n",
              "4    1    1   1   1    1    0       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd052f83-da08-438c-9551-ae8a71d9929b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SVM</th>\n",
              "      <th>KNN</th>\n",
              "      <th>RF</th>\n",
              "      <th>LR</th>\n",
              "      <th>ANN</th>\n",
              "      <th>XGB</th>\n",
              "      <th>y_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd052f83-da08-438c-9551-ae8a71d9929b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dd052f83-da08-438c-9551-ae8a71d9929b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dd052f83-da08-438c-9551-ae8a71d9929b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the DNN model\n",
        "DNNX = newdata.drop(columns=['y_test']).copy()\n",
        "DNNY = newdata.y_test.copy()\n",
        "DX_train, DX_test, Dy_train, Dy_test = train_test_split(\n",
        "    DNNX, DNNY, test_size=0.2, random_state=123)\n",
        "\n",
        "st = time.time()\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(30, activation='relu', input_shape=DNNX.shape[1:]),\n",
        "    tf.keras.layers.Dense(25, activation='relu'),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dense(15, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(DX_train, Dy_train, epochs=500, batch_size=64, validation_split=0.2)\n",
        "dend = time.time() - st"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4kf97a3yX15",
        "outputId": "6efdd6bd-e0aa-464e-abdc-2fa419ffdf49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "6/6 [==============================] - 2s 55ms/step - loss: 0.6927 - accuracy: 0.6346 - val_loss: 0.6916 - val_accuracy: 0.5824\n",
            "Epoch 2/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6899 - accuracy: 0.6346 - val_loss: 0.6888 - val_accuracy: 0.5824\n",
            "Epoch 3/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6862 - accuracy: 0.6346 - val_loss: 0.6854 - val_accuracy: 0.5824\n",
            "Epoch 4/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6821 - accuracy: 0.6346 - val_loss: 0.6816 - val_accuracy: 0.5824\n",
            "Epoch 5/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6771 - accuracy: 0.6346 - val_loss: 0.6774 - val_accuracy: 0.5824\n",
            "Epoch 6/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6713 - accuracy: 0.6346 - val_loss: 0.6714 - val_accuracy: 0.5824\n",
            "Epoch 7/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6635 - accuracy: 0.6346 - val_loss: 0.6639 - val_accuracy: 0.5824\n",
            "Epoch 8/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6540 - accuracy: 0.6346 - val_loss: 0.6548 - val_accuracy: 0.5824\n",
            "Epoch 9/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6429 - accuracy: 0.6346 - val_loss: 0.6442 - val_accuracy: 0.5824\n",
            "Epoch 10/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.6287 - accuracy: 0.6346 - val_loss: 0.6305 - val_accuracy: 0.5824\n",
            "Epoch 11/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6104 - accuracy: 0.6346 - val_loss: 0.6134 - val_accuracy: 0.5824\n",
            "Epoch 12/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.5884 - accuracy: 0.6346 - val_loss: 0.5918 - val_accuracy: 0.5824\n",
            "Epoch 13/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.5604 - accuracy: 0.6346 - val_loss: 0.5660 - val_accuracy: 0.5824\n",
            "Epoch 14/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.5275 - accuracy: 0.6346 - val_loss: 0.5368 - val_accuracy: 0.5824\n",
            "Epoch 15/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4878 - accuracy: 0.6346 - val_loss: 0.5072 - val_accuracy: 0.5824\n",
            "Epoch 16/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.4486 - accuracy: 0.6346 - val_loss: 0.4842 - val_accuracy: 0.5824\n",
            "Epoch 17/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4130 - accuracy: 0.6346 - val_loss: 0.4725 - val_accuracy: 0.5824\n",
            "Epoch 18/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3921 - accuracy: 0.6346 - val_loss: 0.4728 - val_accuracy: 0.5824\n",
            "Epoch 19/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3774 - accuracy: 0.6346 - val_loss: 0.4788 - val_accuracy: 0.5824\n",
            "Epoch 20/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3706 - accuracy: 0.6346 - val_loss: 0.4867 - val_accuracy: 0.5824\n",
            "Epoch 21/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3656 - accuracy: 0.6346 - val_loss: 0.4884 - val_accuracy: 0.5824\n",
            "Epoch 22/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3617 - accuracy: 0.6346 - val_loss: 0.4914 - val_accuracy: 0.5824\n",
            "Epoch 23/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3599 - accuracy: 0.6346 - val_loss: 0.4964 - val_accuracy: 0.5824\n",
            "Epoch 24/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3579 - accuracy: 0.6346 - val_loss: 0.4989 - val_accuracy: 0.5824\n",
            "Epoch 25/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3564 - accuracy: 0.6346 - val_loss: 0.4986 - val_accuracy: 0.5824\n",
            "Epoch 26/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3545 - accuracy: 0.7253 - val_loss: 0.4943 - val_accuracy: 0.9011\n",
            "Epoch 27/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3530 - accuracy: 0.9533 - val_loss: 0.4934 - val_accuracy: 0.9121\n",
            "Epoch 28/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3510 - accuracy: 0.9505 - val_loss: 0.4900 - val_accuracy: 0.9011\n",
            "Epoch 29/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3498 - accuracy: 0.9560 - val_loss: 0.4881 - val_accuracy: 0.9011\n",
            "Epoch 30/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3490 - accuracy: 0.9533 - val_loss: 0.4876 - val_accuracy: 0.9121\n",
            "Epoch 31/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3473 - accuracy: 0.9533 - val_loss: 0.4852 - val_accuracy: 0.9121\n",
            "Epoch 32/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3459 - accuracy: 0.9560 - val_loss: 0.4859 - val_accuracy: 0.9011\n",
            "Epoch 33/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3448 - accuracy: 0.9560 - val_loss: 0.4884 - val_accuracy: 0.9011\n",
            "Epoch 34/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3436 - accuracy: 0.9533 - val_loss: 0.4911 - val_accuracy: 0.9011\n",
            "Epoch 35/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3421 - accuracy: 0.9560 - val_loss: 0.4898 - val_accuracy: 0.9011\n",
            "Epoch 36/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3409 - accuracy: 0.9560 - val_loss: 0.4897 - val_accuracy: 0.9011\n",
            "Epoch 37/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3398 - accuracy: 0.9560 - val_loss: 0.4903 - val_accuracy: 0.9011\n",
            "Epoch 38/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3393 - accuracy: 0.9560 - val_loss: 0.4865 - val_accuracy: 0.9011\n",
            "Epoch 39/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3379 - accuracy: 0.9560 - val_loss: 0.4895 - val_accuracy: 0.9011\n",
            "Epoch 40/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3369 - accuracy: 0.9560 - val_loss: 0.4849 - val_accuracy: 0.9011\n",
            "Epoch 41/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3361 - accuracy: 0.9560 - val_loss: 0.4835 - val_accuracy: 0.9011\n",
            "Epoch 42/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3349 - accuracy: 0.9560 - val_loss: 0.4882 - val_accuracy: 0.9011\n",
            "Epoch 43/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3337 - accuracy: 0.9560 - val_loss: 0.4837 - val_accuracy: 0.9011\n",
            "Epoch 44/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3336 - accuracy: 0.9560 - val_loss: 0.4800 - val_accuracy: 0.8901\n",
            "Epoch 45/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3315 - accuracy: 0.9560 - val_loss: 0.4819 - val_accuracy: 0.9011\n",
            "Epoch 46/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3307 - accuracy: 0.9560 - val_loss: 0.4835 - val_accuracy: 0.9011\n",
            "Epoch 47/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3296 - accuracy: 0.9560 - val_loss: 0.4837 - val_accuracy: 0.9011\n",
            "Epoch 48/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3286 - accuracy: 0.9560 - val_loss: 0.4821 - val_accuracy: 0.9011\n",
            "Epoch 49/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3276 - accuracy: 0.9560 - val_loss: 0.4803 - val_accuracy: 0.8901\n",
            "Epoch 50/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3272 - accuracy: 0.9560 - val_loss: 0.4812 - val_accuracy: 0.9011\n",
            "Epoch 51/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3259 - accuracy: 0.9560 - val_loss: 0.4791 - val_accuracy: 0.9011\n",
            "Epoch 52/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3250 - accuracy: 0.9560 - val_loss: 0.4816 - val_accuracy: 0.9011\n",
            "Epoch 53/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3236 - accuracy: 0.9560 - val_loss: 0.4767 - val_accuracy: 0.9011\n",
            "Epoch 54/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3260 - accuracy: 0.9560 - val_loss: 0.4704 - val_accuracy: 0.8901\n",
            "Epoch 55/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3240 - accuracy: 0.9560 - val_loss: 0.4783 - val_accuracy: 0.9011\n",
            "Epoch 56/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3213 - accuracy: 0.9560 - val_loss: 0.4786 - val_accuracy: 0.9011\n",
            "Epoch 57/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3199 - accuracy: 0.9560 - val_loss: 0.4755 - val_accuracy: 0.9011\n",
            "Epoch 58/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3193 - accuracy: 0.9560 - val_loss: 0.4743 - val_accuracy: 0.9011\n",
            "Epoch 59/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3187 - accuracy: 0.9560 - val_loss: 0.4737 - val_accuracy: 0.9011\n",
            "Epoch 60/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3178 - accuracy: 0.9560 - val_loss: 0.4760 - val_accuracy: 0.9011\n",
            "Epoch 61/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3167 - accuracy: 0.9560 - val_loss: 0.4741 - val_accuracy: 0.8901\n",
            "Epoch 62/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3158 - accuracy: 0.9560 - val_loss: 0.4751 - val_accuracy: 0.8901\n",
            "Epoch 63/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3151 - accuracy: 0.9560 - val_loss: 0.4759 - val_accuracy: 0.8901\n",
            "Epoch 64/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3142 - accuracy: 0.9560 - val_loss: 0.4779 - val_accuracy: 0.9011\n",
            "Epoch 65/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3135 - accuracy: 0.9560 - val_loss: 0.4737 - val_accuracy: 0.8901\n",
            "Epoch 66/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3126 - accuracy: 0.9560 - val_loss: 0.4749 - val_accuracy: 0.8901\n",
            "Epoch 67/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3117 - accuracy: 0.9560 - val_loss: 0.4719 - val_accuracy: 0.8901\n",
            "Epoch 68/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3109 - accuracy: 0.9560 - val_loss: 0.4720 - val_accuracy: 0.8901\n",
            "Epoch 69/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3103 - accuracy: 0.9560 - val_loss: 0.4703 - val_accuracy: 0.9011\n",
            "Epoch 70/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3093 - accuracy: 0.9560 - val_loss: 0.4709 - val_accuracy: 0.9011\n",
            "Epoch 71/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3085 - accuracy: 0.9560 - val_loss: 0.4695 - val_accuracy: 0.9011\n",
            "Epoch 72/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3076 - accuracy: 0.9560 - val_loss: 0.4673 - val_accuracy: 0.9011\n",
            "Epoch 73/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3070 - accuracy: 0.9560 - val_loss: 0.4667 - val_accuracy: 0.8901\n",
            "Epoch 74/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3067 - accuracy: 0.9560 - val_loss: 0.4695 - val_accuracy: 0.9011\n",
            "Epoch 75/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3058 - accuracy: 0.9560 - val_loss: 0.4680 - val_accuracy: 0.9011\n",
            "Epoch 76/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3046 - accuracy: 0.9560 - val_loss: 0.4678 - val_accuracy: 0.9011\n",
            "Epoch 77/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3059 - accuracy: 0.9560 - val_loss: 0.4715 - val_accuracy: 0.9011\n",
            "Epoch 78/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3042 - accuracy: 0.9533 - val_loss: 0.4630 - val_accuracy: 0.9011\n",
            "Epoch 79/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3025 - accuracy: 0.9560 - val_loss: 0.4623 - val_accuracy: 0.9011\n",
            "Epoch 80/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3031 - accuracy: 0.9560 - val_loss: 0.4585 - val_accuracy: 0.9011\n",
            "Epoch 81/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3027 - accuracy: 0.9560 - val_loss: 0.4667 - val_accuracy: 0.9011\n",
            "Epoch 82/500\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.3001 - accuracy: 0.9560 - val_loss: 0.4640 - val_accuracy: 0.9011\n",
            "Epoch 83/500\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.3000 - accuracy: 0.9560 - val_loss: 0.4603 - val_accuracy: 0.8901\n",
            "Epoch 84/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2992 - accuracy: 0.9560 - val_loss: 0.4638 - val_accuracy: 0.8901\n",
            "Epoch 85/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.2980 - accuracy: 0.9560 - val_loss: 0.4654 - val_accuracy: 0.8901\n",
            "Epoch 86/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.2974 - accuracy: 0.9560 - val_loss: 0.4617 - val_accuracy: 0.8901\n",
            "Epoch 87/500\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.2968 - accuracy: 0.9560 - val_loss: 0.4646 - val_accuracy: 0.8901\n",
            "Epoch 88/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2958 - accuracy: 0.9560 - val_loss: 0.4638 - val_accuracy: 0.8901\n",
            "Epoch 89/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2962 - accuracy: 0.9560 - val_loss: 0.4589 - val_accuracy: 0.8901\n",
            "Epoch 90/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2945 - accuracy: 0.9560 - val_loss: 0.4610 - val_accuracy: 0.8901\n",
            "Epoch 91/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2934 - accuracy: 0.9560 - val_loss: 0.4653 - val_accuracy: 0.8901\n",
            "Epoch 92/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2931 - accuracy: 0.9560 - val_loss: 0.4651 - val_accuracy: 0.8901\n",
            "Epoch 93/500\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.2925 - accuracy: 0.9560 - val_loss: 0.4628 - val_accuracy: 0.8901\n",
            "Epoch 94/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2917 - accuracy: 0.9560 - val_loss: 0.4626 - val_accuracy: 0.8901\n",
            "Epoch 95/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.2915 - accuracy: 0.9560 - val_loss: 0.4645 - val_accuracy: 0.8901\n",
            "Epoch 96/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.2905 - accuracy: 0.9560 - val_loss: 0.4591 - val_accuracy: 0.8901\n",
            "Epoch 97/500\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.2904 - accuracy: 0.9560 - val_loss: 0.4546 - val_accuracy: 0.8901\n",
            "Epoch 98/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.2898 - accuracy: 0.9560 - val_loss: 0.4603 - val_accuracy: 0.8901\n",
            "Epoch 99/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.2891 - accuracy: 0.9560 - val_loss: 0.4565 - val_accuracy: 0.8901\n",
            "Epoch 100/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2877 - accuracy: 0.9560 - val_loss: 0.4568 - val_accuracy: 0.8901\n",
            "Epoch 101/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2879 - accuracy: 0.9560 - val_loss: 0.4606 - val_accuracy: 0.8901\n",
            "Epoch 102/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2876 - accuracy: 0.9560 - val_loss: 0.4538 - val_accuracy: 0.8901\n",
            "Epoch 103/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2865 - accuracy: 0.9560 - val_loss: 0.4579 - val_accuracy: 0.8901\n",
            "Epoch 104/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2859 - accuracy: 0.9560 - val_loss: 0.4546 - val_accuracy: 0.8901\n",
            "Epoch 105/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2846 - accuracy: 0.9560 - val_loss: 0.4554 - val_accuracy: 0.8901\n",
            "Epoch 106/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2838 - accuracy: 0.9560 - val_loss: 0.4550 - val_accuracy: 0.8901\n",
            "Epoch 107/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2832 - accuracy: 0.9560 - val_loss: 0.4564 - val_accuracy: 0.8901\n",
            "Epoch 108/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2830 - accuracy: 0.9560 - val_loss: 0.4568 - val_accuracy: 0.8901\n",
            "Epoch 109/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2824 - accuracy: 0.9560 - val_loss: 0.4570 - val_accuracy: 0.8901\n",
            "Epoch 110/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2815 - accuracy: 0.9560 - val_loss: 0.4524 - val_accuracy: 0.8901\n",
            "Epoch 111/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2807 - accuracy: 0.9560 - val_loss: 0.4526 - val_accuracy: 0.8901\n",
            "Epoch 112/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2803 - accuracy: 0.9560 - val_loss: 0.4545 - val_accuracy: 0.8901\n",
            "Epoch 113/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2799 - accuracy: 0.9560 - val_loss: 0.4517 - val_accuracy: 0.8901\n",
            "Epoch 114/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2795 - accuracy: 0.9560 - val_loss: 0.4512 - val_accuracy: 0.8901\n",
            "Epoch 115/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2782 - accuracy: 0.9560 - val_loss: 0.4549 - val_accuracy: 0.8901\n",
            "Epoch 116/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2777 - accuracy: 0.9560 - val_loss: 0.4547 - val_accuracy: 0.8901\n",
            "Epoch 117/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2770 - accuracy: 0.9560 - val_loss: 0.4518 - val_accuracy: 0.8901\n",
            "Epoch 118/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2773 - accuracy: 0.9560 - val_loss: 0.4478 - val_accuracy: 0.8901\n",
            "Epoch 119/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2762 - accuracy: 0.9560 - val_loss: 0.4513 - val_accuracy: 0.8901\n",
            "Epoch 120/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2753 - accuracy: 0.9560 - val_loss: 0.4527 - val_accuracy: 0.8901\n",
            "Epoch 121/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2750 - accuracy: 0.9560 - val_loss: 0.4541 - val_accuracy: 0.8901\n",
            "Epoch 122/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2744 - accuracy: 0.9560 - val_loss: 0.4536 - val_accuracy: 0.8901\n",
            "Epoch 123/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2747 - accuracy: 0.9560 - val_loss: 0.4461 - val_accuracy: 0.8901\n",
            "Epoch 124/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2733 - accuracy: 0.9560 - val_loss: 0.4469 - val_accuracy: 0.8901\n",
            "Epoch 125/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2728 - accuracy: 0.9560 - val_loss: 0.4481 - val_accuracy: 0.8901\n",
            "Epoch 126/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2720 - accuracy: 0.9560 - val_loss: 0.4539 - val_accuracy: 0.9011\n",
            "Epoch 127/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2718 - accuracy: 0.9560 - val_loss: 0.4474 - val_accuracy: 0.9011\n",
            "Epoch 128/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2710 - accuracy: 0.9533 - val_loss: 0.4430 - val_accuracy: 0.9011\n",
            "Epoch 129/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2724 - accuracy: 0.9560 - val_loss: 0.4416 - val_accuracy: 0.9121\n",
            "Epoch 130/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2707 - accuracy: 0.9560 - val_loss: 0.4377 - val_accuracy: 0.9011\n",
            "Epoch 131/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2704 - accuracy: 0.9560 - val_loss: 0.4368 - val_accuracy: 0.9011\n",
            "Epoch 132/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2696 - accuracy: 0.9560 - val_loss: 0.4376 - val_accuracy: 0.9011\n",
            "Epoch 133/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2685 - accuracy: 0.9560 - val_loss: 0.4475 - val_accuracy: 0.9011\n",
            "Epoch 134/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2678 - accuracy: 0.9560 - val_loss: 0.4478 - val_accuracy: 0.9011\n",
            "Epoch 135/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2677 - accuracy: 0.9560 - val_loss: 0.4428 - val_accuracy: 0.9011\n",
            "Epoch 136/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2665 - accuracy: 0.9560 - val_loss: 0.4411 - val_accuracy: 0.9011\n",
            "Epoch 137/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2659 - accuracy: 0.9560 - val_loss: 0.4385 - val_accuracy: 0.9011\n",
            "Epoch 138/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2659 - accuracy: 0.9560 - val_loss: 0.4398 - val_accuracy: 0.9011\n",
            "Epoch 139/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2655 - accuracy: 0.9560 - val_loss: 0.4385 - val_accuracy: 0.8901\n",
            "Epoch 140/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2646 - accuracy: 0.9560 - val_loss: 0.4366 - val_accuracy: 0.9011\n",
            "Epoch 141/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2643 - accuracy: 0.9560 - val_loss: 0.4395 - val_accuracy: 0.9011\n",
            "Epoch 142/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2636 - accuracy: 0.9560 - val_loss: 0.4423 - val_accuracy: 0.9011\n",
            "Epoch 143/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2631 - accuracy: 0.9560 - val_loss: 0.4427 - val_accuracy: 0.8901\n",
            "Epoch 144/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2637 - accuracy: 0.9560 - val_loss: 0.4337 - val_accuracy: 0.9011\n",
            "Epoch 145/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2626 - accuracy: 0.9560 - val_loss: 0.4354 - val_accuracy: 0.9011\n",
            "Epoch 146/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2622 - accuracy: 0.9560 - val_loss: 0.4433 - val_accuracy: 0.8901\n",
            "Epoch 147/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2614 - accuracy: 0.9560 - val_loss: 0.4409 - val_accuracy: 0.8901\n",
            "Epoch 148/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2605 - accuracy: 0.9560 - val_loss: 0.4418 - val_accuracy: 0.8901\n",
            "Epoch 149/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2600 - accuracy: 0.9560 - val_loss: 0.4373 - val_accuracy: 0.9011\n",
            "Epoch 150/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2600 - accuracy: 0.9560 - val_loss: 0.4359 - val_accuracy: 0.9011\n",
            "Epoch 151/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2592 - accuracy: 0.9560 - val_loss: 0.4345 - val_accuracy: 0.9011\n",
            "Epoch 152/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2589 - accuracy: 0.9560 - val_loss: 0.4364 - val_accuracy: 0.8901\n",
            "Epoch 153/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2582 - accuracy: 0.9560 - val_loss: 0.4373 - val_accuracy: 0.8901\n",
            "Epoch 154/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2583 - accuracy: 0.9560 - val_loss: 0.4363 - val_accuracy: 0.8901\n",
            "Epoch 155/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2575 - accuracy: 0.9560 - val_loss: 0.4355 - val_accuracy: 0.8901\n",
            "Epoch 156/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2563 - accuracy: 0.9560 - val_loss: 0.4381 - val_accuracy: 0.8901\n",
            "Epoch 157/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2560 - accuracy: 0.9560 - val_loss: 0.4399 - val_accuracy: 0.8901\n",
            "Epoch 158/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2556 - accuracy: 0.9560 - val_loss: 0.4401 - val_accuracy: 0.8901\n",
            "Epoch 159/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2553 - accuracy: 0.9560 - val_loss: 0.4378 - val_accuracy: 0.8901\n",
            "Epoch 160/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2560 - accuracy: 0.9560 - val_loss: 0.4335 - val_accuracy: 0.9011\n",
            "Epoch 161/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2569 - accuracy: 0.9533 - val_loss: 0.4274 - val_accuracy: 0.9011\n",
            "Epoch 162/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2544 - accuracy: 0.9560 - val_loss: 0.4311 - val_accuracy: 0.9011\n",
            "Epoch 163/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2534 - accuracy: 0.9560 - val_loss: 0.4302 - val_accuracy: 0.9011\n",
            "Epoch 164/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2532 - accuracy: 0.9560 - val_loss: 0.4325 - val_accuracy: 0.9011\n",
            "Epoch 165/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2526 - accuracy: 0.9560 - val_loss: 0.4298 - val_accuracy: 0.9011\n",
            "Epoch 166/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2521 - accuracy: 0.9560 - val_loss: 0.4293 - val_accuracy: 0.9011\n",
            "Epoch 167/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2518 - accuracy: 0.9560 - val_loss: 0.4282 - val_accuracy: 0.9011\n",
            "Epoch 168/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2519 - accuracy: 0.9560 - val_loss: 0.4266 - val_accuracy: 0.9011\n",
            "Epoch 169/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2516 - accuracy: 0.9560 - val_loss: 0.4267 - val_accuracy: 0.9011\n",
            "Epoch 170/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2512 - accuracy: 0.9560 - val_loss: 0.4354 - val_accuracy: 0.8901\n",
            "Epoch 171/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2507 - accuracy: 0.9560 - val_loss: 0.4367 - val_accuracy: 0.8901\n",
            "Epoch 172/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2499 - accuracy: 0.9560 - val_loss: 0.4301 - val_accuracy: 0.9011\n",
            "Epoch 173/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2492 - accuracy: 0.9560 - val_loss: 0.4303 - val_accuracy: 0.9011\n",
            "Epoch 174/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2498 - accuracy: 0.9560 - val_loss: 0.4239 - val_accuracy: 0.9011\n",
            "Epoch 175/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2498 - accuracy: 0.9560 - val_loss: 0.4330 - val_accuracy: 0.8901\n",
            "Epoch 176/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2479 - accuracy: 0.9560 - val_loss: 0.4302 - val_accuracy: 0.8901\n",
            "Epoch 177/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2473 - accuracy: 0.9560 - val_loss: 0.4274 - val_accuracy: 0.8901\n",
            "Epoch 178/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2472 - accuracy: 0.9560 - val_loss: 0.4265 - val_accuracy: 0.8901\n",
            "Epoch 179/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2471 - accuracy: 0.9560 - val_loss: 0.4258 - val_accuracy: 0.8901\n",
            "Epoch 180/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2486 - accuracy: 0.9560 - val_loss: 0.4361 - val_accuracy: 0.8901\n",
            "Epoch 181/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2463 - accuracy: 0.9560 - val_loss: 0.4284 - val_accuracy: 0.8901\n",
            "Epoch 182/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2460 - accuracy: 0.9560 - val_loss: 0.4241 - val_accuracy: 0.8901\n",
            "Epoch 183/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2453 - accuracy: 0.9560 - val_loss: 0.4269 - val_accuracy: 0.8901\n",
            "Epoch 184/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2446 - accuracy: 0.9560 - val_loss: 0.4287 - val_accuracy: 0.8901\n",
            "Epoch 185/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2442 - accuracy: 0.9560 - val_loss: 0.4277 - val_accuracy: 0.8901\n",
            "Epoch 186/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2437 - accuracy: 0.9560 - val_loss: 0.4290 - val_accuracy: 0.8901\n",
            "Epoch 187/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2434 - accuracy: 0.9560 - val_loss: 0.4275 - val_accuracy: 0.8901\n",
            "Epoch 188/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2429 - accuracy: 0.9560 - val_loss: 0.4257 - val_accuracy: 0.8901\n",
            "Epoch 189/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2425 - accuracy: 0.9560 - val_loss: 0.4231 - val_accuracy: 0.8901\n",
            "Epoch 190/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2424 - accuracy: 0.9560 - val_loss: 0.4219 - val_accuracy: 0.8901\n",
            "Epoch 191/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2417 - accuracy: 0.9560 - val_loss: 0.4239 - val_accuracy: 0.8901\n",
            "Epoch 192/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2428 - accuracy: 0.9560 - val_loss: 0.4306 - val_accuracy: 0.9011\n",
            "Epoch 193/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.2411 - accuracy: 0.9560 - val_loss: 0.4283 - val_accuracy: 0.9011\n",
            "Epoch 194/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2417 - accuracy: 0.9560 - val_loss: 0.4195 - val_accuracy: 0.8901\n",
            "Epoch 195/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2399 - accuracy: 0.9560 - val_loss: 0.4226 - val_accuracy: 0.9011\n",
            "Epoch 196/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2403 - accuracy: 0.9533 - val_loss: 0.4241 - val_accuracy: 0.9011\n",
            "Epoch 197/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2415 - accuracy: 0.9560 - val_loss: 0.4282 - val_accuracy: 0.9011\n",
            "Epoch 198/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2397 - accuracy: 0.9560 - val_loss: 0.4195 - val_accuracy: 0.9011\n",
            "Epoch 199/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2387 - accuracy: 0.9560 - val_loss: 0.4144 - val_accuracy: 0.9011\n",
            "Epoch 200/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2390 - accuracy: 0.9560 - val_loss: 0.4172 - val_accuracy: 0.9011\n",
            "Epoch 201/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2379 - accuracy: 0.9533 - val_loss: 0.4196 - val_accuracy: 0.9011\n",
            "Epoch 202/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2372 - accuracy: 0.9560 - val_loss: 0.4178 - val_accuracy: 0.9121\n",
            "Epoch 203/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2372 - accuracy: 0.9560 - val_loss: 0.4178 - val_accuracy: 0.9121\n",
            "Epoch 204/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2370 - accuracy: 0.9560 - val_loss: 0.4199 - val_accuracy: 0.9011\n",
            "Epoch 205/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2363 - accuracy: 0.9560 - val_loss: 0.4193 - val_accuracy: 0.9011\n",
            "Epoch 206/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2360 - accuracy: 0.9560 - val_loss: 0.4197 - val_accuracy: 0.8901\n",
            "Epoch 207/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2357 - accuracy: 0.9533 - val_loss: 0.4168 - val_accuracy: 0.8901\n",
            "Epoch 208/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2354 - accuracy: 0.9560 - val_loss: 0.4160 - val_accuracy: 0.9011\n",
            "Epoch 209/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2354 - accuracy: 0.9560 - val_loss: 0.4182 - val_accuracy: 0.9011\n",
            "Epoch 210/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2346 - accuracy: 0.9560 - val_loss: 0.4185 - val_accuracy: 0.8901\n",
            "Epoch 211/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2343 - accuracy: 0.9560 - val_loss: 0.4175 - val_accuracy: 0.9011\n",
            "Epoch 212/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2337 - accuracy: 0.9560 - val_loss: 0.4173 - val_accuracy: 0.9011\n",
            "Epoch 213/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2338 - accuracy: 0.9560 - val_loss: 0.4189 - val_accuracy: 0.9011\n",
            "Epoch 214/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2333 - accuracy: 0.9560 - val_loss: 0.4166 - val_accuracy: 0.9011\n",
            "Epoch 215/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2329 - accuracy: 0.9533 - val_loss: 0.4170 - val_accuracy: 0.8901\n",
            "Epoch 216/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2322 - accuracy: 0.9560 - val_loss: 0.4168 - val_accuracy: 0.8901\n",
            "Epoch 217/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2325 - accuracy: 0.9560 - val_loss: 0.4163 - val_accuracy: 0.8901\n",
            "Epoch 218/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2314 - accuracy: 0.9560 - val_loss: 0.4176 - val_accuracy: 0.9011\n",
            "Epoch 219/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2322 - accuracy: 0.9560 - val_loss: 0.4170 - val_accuracy: 0.9121\n",
            "Epoch 220/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2310 - accuracy: 0.9560 - val_loss: 0.4114 - val_accuracy: 0.9011\n",
            "Epoch 221/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2317 - accuracy: 0.9560 - val_loss: 0.4097 - val_accuracy: 0.9011\n",
            "Epoch 222/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2315 - accuracy: 0.9560 - val_loss: 0.4083 - val_accuracy: 0.9011\n",
            "Epoch 223/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2312 - accuracy: 0.9560 - val_loss: 0.4134 - val_accuracy: 0.9011\n",
            "Epoch 224/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2300 - accuracy: 0.9560 - val_loss: 0.4117 - val_accuracy: 0.9011\n",
            "Epoch 225/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2297 - accuracy: 0.9560 - val_loss: 0.4114 - val_accuracy: 0.9011\n",
            "Epoch 226/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2293 - accuracy: 0.9560 - val_loss: 0.4138 - val_accuracy: 0.9011\n",
            "Epoch 227/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2292 - accuracy: 0.9560 - val_loss: 0.4157 - val_accuracy: 0.9011\n",
            "Epoch 228/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2291 - accuracy: 0.9560 - val_loss: 0.4118 - val_accuracy: 0.9011\n",
            "Epoch 229/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2287 - accuracy: 0.9560 - val_loss: 0.4139 - val_accuracy: 0.9011\n",
            "Epoch 230/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2282 - accuracy: 0.9560 - val_loss: 0.4133 - val_accuracy: 0.9011\n",
            "Epoch 231/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2278 - accuracy: 0.9560 - val_loss: 0.4138 - val_accuracy: 0.9011\n",
            "Epoch 232/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2276 - accuracy: 0.9560 - val_loss: 0.4123 - val_accuracy: 0.9011\n",
            "Epoch 233/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2290 - accuracy: 0.9560 - val_loss: 0.4074 - val_accuracy: 0.9011\n",
            "Epoch 234/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2278 - accuracy: 0.9560 - val_loss: 0.4143 - val_accuracy: 0.9011\n",
            "Epoch 235/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2269 - accuracy: 0.9560 - val_loss: 0.4116 - val_accuracy: 0.9011\n",
            "Epoch 236/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.2269 - accuracy: 0.9533 - val_loss: 0.4103 - val_accuracy: 0.9011\n",
            "Epoch 237/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.2253 - accuracy: 0.9560 - val_loss: 0.4062 - val_accuracy: 0.9011\n",
            "Epoch 238/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2260 - accuracy: 0.9560 - val_loss: 0.4045 - val_accuracy: 0.9011\n",
            "Epoch 239/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2250 - accuracy: 0.9560 - val_loss: 0.4072 - val_accuracy: 0.9011\n",
            "Epoch 240/500\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.2246 - accuracy: 0.9588 - val_loss: 0.4100 - val_accuracy: 0.9011\n",
            "Epoch 241/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2242 - accuracy: 0.9560 - val_loss: 0.4097 - val_accuracy: 0.9011\n",
            "Epoch 242/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.2241 - accuracy: 0.9560 - val_loss: 0.4056 - val_accuracy: 0.9011\n",
            "Epoch 243/500\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.2237 - accuracy: 0.9560 - val_loss: 0.4058 - val_accuracy: 0.9011\n",
            "Epoch 244/500\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.2237 - accuracy: 0.9560 - val_loss: 0.4102 - val_accuracy: 0.9011\n",
            "Epoch 245/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2231 - accuracy: 0.9560 - val_loss: 0.4101 - val_accuracy: 0.9011\n",
            "Epoch 246/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.2233 - accuracy: 0.9560 - val_loss: 0.4099 - val_accuracy: 0.9011\n",
            "Epoch 247/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.2238 - accuracy: 0.9533 - val_loss: 0.4073 - val_accuracy: 0.9011\n",
            "Epoch 248/500\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.2229 - accuracy: 0.9560 - val_loss: 0.4060 - val_accuracy: 0.9011\n",
            "Epoch 249/500\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.2227 - accuracy: 0.9560 - val_loss: 0.4073 - val_accuracy: 0.9011\n",
            "Epoch 250/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.2228 - accuracy: 0.9560 - val_loss: 0.4043 - val_accuracy: 0.9011\n",
            "Epoch 251/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.2211 - accuracy: 0.9588 - val_loss: 0.4079 - val_accuracy: 0.9011\n",
            "Epoch 252/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2219 - accuracy: 0.9560 - val_loss: 0.4080 - val_accuracy: 0.9121\n",
            "Epoch 253/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2223 - accuracy: 0.9560 - val_loss: 0.4047 - val_accuracy: 0.9011\n",
            "Epoch 254/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2209 - accuracy: 0.9533 - val_loss: 0.4044 - val_accuracy: 0.9011\n",
            "Epoch 255/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.2213 - accuracy: 0.9533 - val_loss: 0.4078 - val_accuracy: 0.9011\n",
            "Epoch 256/500\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.2202 - accuracy: 0.9533 - val_loss: 0.4076 - val_accuracy: 0.9011\n",
            "Epoch 257/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2198 - accuracy: 0.9560 - val_loss: 0.4062 - val_accuracy: 0.9011\n",
            "Epoch 258/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2195 - accuracy: 0.9533 - val_loss: 0.4042 - val_accuracy: 0.9011\n",
            "Epoch 259/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2191 - accuracy: 0.9560 - val_loss: 0.4069 - val_accuracy: 0.9011\n",
            "Epoch 260/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2189 - accuracy: 0.9560 - val_loss: 0.4056 - val_accuracy: 0.9011\n",
            "Epoch 261/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2187 - accuracy: 0.9560 - val_loss: 0.4046 - val_accuracy: 0.9011\n",
            "Epoch 262/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2182 - accuracy: 0.9560 - val_loss: 0.4034 - val_accuracy: 0.9011\n",
            "Epoch 263/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2179 - accuracy: 0.9560 - val_loss: 0.4037 - val_accuracy: 0.9011\n",
            "Epoch 264/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2177 - accuracy: 0.9560 - val_loss: 0.4024 - val_accuracy: 0.9011\n",
            "Epoch 265/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2189 - accuracy: 0.9533 - val_loss: 0.4051 - val_accuracy: 0.9011\n",
            "Epoch 266/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2172 - accuracy: 0.9560 - val_loss: 0.4023 - val_accuracy: 0.9011\n",
            "Epoch 267/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2168 - accuracy: 0.9533 - val_loss: 0.4024 - val_accuracy: 0.9011\n",
            "Epoch 268/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2172 - accuracy: 0.9533 - val_loss: 0.4062 - val_accuracy: 0.9011\n",
            "Epoch 269/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2166 - accuracy: 0.9560 - val_loss: 0.4068 - val_accuracy: 0.9011\n",
            "Epoch 270/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2166 - accuracy: 0.9560 - val_loss: 0.4008 - val_accuracy: 0.9011\n",
            "Epoch 271/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2159 - accuracy: 0.9560 - val_loss: 0.4038 - val_accuracy: 0.9011\n",
            "Epoch 272/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2156 - accuracy: 0.9533 - val_loss: 0.4041 - val_accuracy: 0.9011\n",
            "Epoch 273/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2156 - accuracy: 0.9560 - val_loss: 0.4076 - val_accuracy: 0.9011\n",
            "Epoch 274/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2153 - accuracy: 0.9533 - val_loss: 0.4053 - val_accuracy: 0.9011\n",
            "Epoch 275/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2149 - accuracy: 0.9533 - val_loss: 0.4056 - val_accuracy: 0.9011\n",
            "Epoch 276/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2144 - accuracy: 0.9560 - val_loss: 0.4051 - val_accuracy: 0.9011\n",
            "Epoch 277/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2144 - accuracy: 0.9560 - val_loss: 0.4017 - val_accuracy: 0.9011\n",
            "Epoch 278/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2142 - accuracy: 0.9560 - val_loss: 0.4025 - val_accuracy: 0.9011\n",
            "Epoch 279/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2144 - accuracy: 0.9560 - val_loss: 0.4046 - val_accuracy: 0.9011\n",
            "Epoch 280/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2145 - accuracy: 0.9533 - val_loss: 0.4014 - val_accuracy: 0.9011\n",
            "Epoch 281/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2135 - accuracy: 0.9560 - val_loss: 0.4012 - val_accuracy: 0.9011\n",
            "Epoch 282/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2128 - accuracy: 0.9560 - val_loss: 0.4030 - val_accuracy: 0.9121\n",
            "Epoch 283/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2131 - accuracy: 0.9560 - val_loss: 0.4011 - val_accuracy: 0.9011\n",
            "Epoch 284/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2127 - accuracy: 0.9560 - val_loss: 0.4016 - val_accuracy: 0.9011\n",
            "Epoch 285/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2125 - accuracy: 0.9560 - val_loss: 0.4028 - val_accuracy: 0.9011\n",
            "Epoch 286/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2131 - accuracy: 0.9560 - val_loss: 0.4073 - val_accuracy: 0.9011\n",
            "Epoch 287/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2119 - accuracy: 0.9560 - val_loss: 0.4069 - val_accuracy: 0.9011\n",
            "Epoch 288/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2121 - accuracy: 0.9560 - val_loss: 0.4040 - val_accuracy: 0.9011\n",
            "Epoch 289/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2116 - accuracy: 0.9560 - val_loss: 0.4038 - val_accuracy: 0.9011\n",
            "Epoch 290/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2111 - accuracy: 0.9560 - val_loss: 0.4016 - val_accuracy: 0.9011\n",
            "Epoch 291/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2119 - accuracy: 0.9533 - val_loss: 0.3951 - val_accuracy: 0.9011\n",
            "Epoch 292/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2120 - accuracy: 0.9560 - val_loss: 0.4001 - val_accuracy: 0.9011\n",
            "Epoch 293/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2110 - accuracy: 0.9560 - val_loss: 0.4013 - val_accuracy: 0.9011\n",
            "Epoch 294/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2108 - accuracy: 0.9560 - val_loss: 0.3984 - val_accuracy: 0.9011\n",
            "Epoch 295/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.2111 - accuracy: 0.9533 - val_loss: 0.4038 - val_accuracy: 0.9011\n",
            "Epoch 296/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2101 - accuracy: 0.9533 - val_loss: 0.3995 - val_accuracy: 0.9011\n",
            "Epoch 297/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2109 - accuracy: 0.9533 - val_loss: 0.4024 - val_accuracy: 0.9011\n",
            "Epoch 298/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2094 - accuracy: 0.9560 - val_loss: 0.3985 - val_accuracy: 0.9011\n",
            "Epoch 299/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2094 - accuracy: 0.9560 - val_loss: 0.3976 - val_accuracy: 0.9011\n",
            "Epoch 300/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2090 - accuracy: 0.9560 - val_loss: 0.3987 - val_accuracy: 0.9011\n",
            "Epoch 301/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2088 - accuracy: 0.9560 - val_loss: 0.4029 - val_accuracy: 0.9011\n",
            "Epoch 302/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2087 - accuracy: 0.9533 - val_loss: 0.4012 - val_accuracy: 0.9011\n",
            "Epoch 303/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2080 - accuracy: 0.9533 - val_loss: 0.3983 - val_accuracy: 0.9011\n",
            "Epoch 304/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2085 - accuracy: 0.9560 - val_loss: 0.3977 - val_accuracy: 0.9121\n",
            "Epoch 305/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2087 - accuracy: 0.9560 - val_loss: 0.4005 - val_accuracy: 0.9121\n",
            "Epoch 306/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2076 - accuracy: 0.9533 - val_loss: 0.3952 - val_accuracy: 0.9011\n",
            "Epoch 307/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2076 - accuracy: 0.9560 - val_loss: 0.3944 - val_accuracy: 0.9011\n",
            "Epoch 308/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2080 - accuracy: 0.9560 - val_loss: 0.3995 - val_accuracy: 0.9011\n",
            "Epoch 309/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2076 - accuracy: 0.9560 - val_loss: 0.3958 - val_accuracy: 0.9121\n",
            "Epoch 310/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2073 - accuracy: 0.9560 - val_loss: 0.3946 - val_accuracy: 0.9121\n",
            "Epoch 311/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2068 - accuracy: 0.9560 - val_loss: 0.3907 - val_accuracy: 0.9011\n",
            "Epoch 312/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2073 - accuracy: 0.9560 - val_loss: 0.3921 - val_accuracy: 0.9011\n",
            "Epoch 313/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2062 - accuracy: 0.9560 - val_loss: 0.3979 - val_accuracy: 0.9011\n",
            "Epoch 314/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2067 - accuracy: 0.9560 - val_loss: 0.4040 - val_accuracy: 0.9011\n",
            "Epoch 315/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2062 - accuracy: 0.9560 - val_loss: 0.3966 - val_accuracy: 0.9011\n",
            "Epoch 316/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2059 - accuracy: 0.9533 - val_loss: 0.3929 - val_accuracy: 0.9011\n",
            "Epoch 317/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2065 - accuracy: 0.9533 - val_loss: 0.3935 - val_accuracy: 0.9011\n",
            "Epoch 318/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2057 - accuracy: 0.9560 - val_loss: 0.3925 - val_accuracy: 0.9011\n",
            "Epoch 319/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2049 - accuracy: 0.9560 - val_loss: 0.3948 - val_accuracy: 0.9011\n",
            "Epoch 320/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2059 - accuracy: 0.9560 - val_loss: 0.4000 - val_accuracy: 0.9011\n",
            "Epoch 321/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2045 - accuracy: 0.9560 - val_loss: 0.3947 - val_accuracy: 0.9011\n",
            "Epoch 322/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2045 - accuracy: 0.9533 - val_loss: 0.3959 - val_accuracy: 0.9011\n",
            "Epoch 323/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2039 - accuracy: 0.9560 - val_loss: 0.3931 - val_accuracy: 0.9011\n",
            "Epoch 324/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2041 - accuracy: 0.9560 - val_loss: 0.3962 - val_accuracy: 0.9011\n",
            "Epoch 325/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2039 - accuracy: 0.9560 - val_loss: 0.3928 - val_accuracy: 0.9011\n",
            "Epoch 326/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2035 - accuracy: 0.9560 - val_loss: 0.3962 - val_accuracy: 0.9011\n",
            "Epoch 327/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2033 - accuracy: 0.9533 - val_loss: 0.3943 - val_accuracy: 0.9011\n",
            "Epoch 328/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2033 - accuracy: 0.9560 - val_loss: 0.3947 - val_accuracy: 0.9011\n",
            "Epoch 329/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2032 - accuracy: 0.9560 - val_loss: 0.3921 - val_accuracy: 0.9011\n",
            "Epoch 330/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2033 - accuracy: 0.9533 - val_loss: 0.3923 - val_accuracy: 0.9011\n",
            "Epoch 331/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2042 - accuracy: 0.9533 - val_loss: 0.3983 - val_accuracy: 0.9011\n",
            "Epoch 332/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2023 - accuracy: 0.9560 - val_loss: 0.3965 - val_accuracy: 0.9011\n",
            "Epoch 333/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2031 - accuracy: 0.9560 - val_loss: 0.3913 - val_accuracy: 0.9011\n",
            "Epoch 334/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2020 - accuracy: 0.9560 - val_loss: 0.3923 - val_accuracy: 0.9011\n",
            "Epoch 335/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.2023 - accuracy: 0.9560 - val_loss: 0.3938 - val_accuracy: 0.9121\n",
            "Epoch 336/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2014 - accuracy: 0.9560 - val_loss: 0.3949 - val_accuracy: 0.9011\n",
            "Epoch 337/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2013 - accuracy: 0.9560 - val_loss: 0.3979 - val_accuracy: 0.9011\n",
            "Epoch 338/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2014 - accuracy: 0.9560 - val_loss: 0.3982 - val_accuracy: 0.9011\n",
            "Epoch 339/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2010 - accuracy: 0.9560 - val_loss: 0.3986 - val_accuracy: 0.9011\n",
            "Epoch 340/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2007 - accuracy: 0.9588 - val_loss: 0.3988 - val_accuracy: 0.9011\n",
            "Epoch 341/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2018 - accuracy: 0.9560 - val_loss: 0.3954 - val_accuracy: 0.9121\n",
            "Epoch 342/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2004 - accuracy: 0.9560 - val_loss: 0.3918 - val_accuracy: 0.9011\n",
            "Epoch 343/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2008 - accuracy: 0.9533 - val_loss: 0.3927 - val_accuracy: 0.9011\n",
            "Epoch 344/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1999 - accuracy: 0.9560 - val_loss: 0.3937 - val_accuracy: 0.9011\n",
            "Epoch 345/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2003 - accuracy: 0.9533 - val_loss: 0.3935 - val_accuracy: 0.9011\n",
            "Epoch 346/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1994 - accuracy: 0.9560 - val_loss: 0.3925 - val_accuracy: 0.9011\n",
            "Epoch 347/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1997 - accuracy: 0.9560 - val_loss: 0.3915 - val_accuracy: 0.9011\n",
            "Epoch 348/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1992 - accuracy: 0.9533 - val_loss: 0.3936 - val_accuracy: 0.9011\n",
            "Epoch 349/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1998 - accuracy: 0.9560 - val_loss: 0.3989 - val_accuracy: 0.9011\n",
            "Epoch 350/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1999 - accuracy: 0.9560 - val_loss: 0.3923 - val_accuracy: 0.9011\n",
            "Epoch 351/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1991 - accuracy: 0.9560 - val_loss: 0.3948 - val_accuracy: 0.9011\n",
            "Epoch 352/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1992 - accuracy: 0.9560 - val_loss: 0.3966 - val_accuracy: 0.9011\n",
            "Epoch 353/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1992 - accuracy: 0.9533 - val_loss: 0.3944 - val_accuracy: 0.9011\n",
            "Epoch 354/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1987 - accuracy: 0.9560 - val_loss: 0.3966 - val_accuracy: 0.9121\n",
            "Epoch 355/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1986 - accuracy: 0.9560 - val_loss: 0.3929 - val_accuracy: 0.9011\n",
            "Epoch 356/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1985 - accuracy: 0.9533 - val_loss: 0.3920 - val_accuracy: 0.9011\n",
            "Epoch 357/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1979 - accuracy: 0.9533 - val_loss: 0.3955 - val_accuracy: 0.9011\n",
            "Epoch 358/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1976 - accuracy: 0.9560 - val_loss: 0.3945 - val_accuracy: 0.9011\n",
            "Epoch 359/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1975 - accuracy: 0.9560 - val_loss: 0.3963 - val_accuracy: 0.9011\n",
            "Epoch 360/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1973 - accuracy: 0.9560 - val_loss: 0.3935 - val_accuracy: 0.9011\n",
            "Epoch 361/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1978 - accuracy: 0.9560 - val_loss: 0.3948 - val_accuracy: 0.9121\n",
            "Epoch 362/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1969 - accuracy: 0.9533 - val_loss: 0.3901 - val_accuracy: 0.9011\n",
            "Epoch 363/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1975 - accuracy: 0.9560 - val_loss: 0.3917 - val_accuracy: 0.9011\n",
            "Epoch 364/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1977 - accuracy: 0.9560 - val_loss: 0.3954 - val_accuracy: 0.9011\n",
            "Epoch 365/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1969 - accuracy: 0.9533 - val_loss: 0.3952 - val_accuracy: 0.9011\n",
            "Epoch 366/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1972 - accuracy: 0.9533 - val_loss: 0.3902 - val_accuracy: 0.9011\n",
            "Epoch 367/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1971 - accuracy: 0.9560 - val_loss: 0.3876 - val_accuracy: 0.9011\n",
            "Epoch 368/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1964 - accuracy: 0.9560 - val_loss: 0.3893 - val_accuracy: 0.9011\n",
            "Epoch 369/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1962 - accuracy: 0.9533 - val_loss: 0.3943 - val_accuracy: 0.9121\n",
            "Epoch 370/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1968 - accuracy: 0.9560 - val_loss: 0.3961 - val_accuracy: 0.9011\n",
            "Epoch 371/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1959 - accuracy: 0.9560 - val_loss: 0.3917 - val_accuracy: 0.9011\n",
            "Epoch 372/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1960 - accuracy: 0.9533 - val_loss: 0.3889 - val_accuracy: 0.9011\n",
            "Epoch 373/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1949 - accuracy: 0.9560 - val_loss: 0.3919 - val_accuracy: 0.9011\n",
            "Epoch 374/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1953 - accuracy: 0.9560 - val_loss: 0.3921 - val_accuracy: 0.9121\n",
            "Epoch 375/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1950 - accuracy: 0.9560 - val_loss: 0.3925 - val_accuracy: 0.9121\n",
            "Epoch 376/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1946 - accuracy: 0.9560 - val_loss: 0.3880 - val_accuracy: 0.9011\n",
            "Epoch 377/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1946 - accuracy: 0.9533 - val_loss: 0.3880 - val_accuracy: 0.9011\n",
            "Epoch 378/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1945 - accuracy: 0.9560 - val_loss: 0.3885 - val_accuracy: 0.9011\n",
            "Epoch 379/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1946 - accuracy: 0.9533 - val_loss: 0.3930 - val_accuracy: 0.9011\n",
            "Epoch 380/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1948 - accuracy: 0.9560 - val_loss: 0.3955 - val_accuracy: 0.9121\n",
            "Epoch 381/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1945 - accuracy: 0.9560 - val_loss: 0.3909 - val_accuracy: 0.9011\n",
            "Epoch 382/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1937 - accuracy: 0.9560 - val_loss: 0.3923 - val_accuracy: 0.9011\n",
            "Epoch 383/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1949 - accuracy: 0.9560 - val_loss: 0.3879 - val_accuracy: 0.9011\n",
            "Epoch 384/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1942 - accuracy: 0.9533 - val_loss: 0.3934 - val_accuracy: 0.9011\n",
            "Epoch 385/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1942 - accuracy: 0.9533 - val_loss: 0.3908 - val_accuracy: 0.9011\n",
            "Epoch 386/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1930 - accuracy: 0.9560 - val_loss: 0.3939 - val_accuracy: 0.9011\n",
            "Epoch 387/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1932 - accuracy: 0.9560 - val_loss: 0.3927 - val_accuracy: 0.9011\n",
            "Epoch 388/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1932 - accuracy: 0.9560 - val_loss: 0.3951 - val_accuracy: 0.9011\n",
            "Epoch 389/500\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.1932 - accuracy: 0.9560 - val_loss: 0.3949 - val_accuracy: 0.9011\n",
            "Epoch 390/500\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.1930 - accuracy: 0.9533 - val_loss: 0.3929 - val_accuracy: 0.9011\n",
            "Epoch 391/500\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.1931 - accuracy: 0.9533 - val_loss: 0.3931 - val_accuracy: 0.9011\n",
            "Epoch 392/500\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.1920 - accuracy: 0.9560 - val_loss: 0.3899 - val_accuracy: 0.9011\n",
            "Epoch 393/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.1922 - accuracy: 0.9560 - val_loss: 0.3876 - val_accuracy: 0.9011\n",
            "Epoch 394/500\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.1924 - accuracy: 0.9560 - val_loss: 0.3858 - val_accuracy: 0.9011\n",
            "Epoch 395/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1927 - accuracy: 0.9533 - val_loss: 0.3898 - val_accuracy: 0.9011\n",
            "Epoch 396/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1931 - accuracy: 0.9560 - val_loss: 0.3948 - val_accuracy: 0.9011\n",
            "Epoch 397/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.1914 - accuracy: 0.9560 - val_loss: 0.3900 - val_accuracy: 0.9011\n",
            "Epoch 398/500\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.1917 - accuracy: 0.9560 - val_loss: 0.3879 - val_accuracy: 0.9011\n",
            "Epoch 399/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1921 - accuracy: 0.9560 - val_loss: 0.3881 - val_accuracy: 0.9011\n",
            "Epoch 400/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1914 - accuracy: 0.9560 - val_loss: 0.3920 - val_accuracy: 0.9011\n",
            "Epoch 401/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.1914 - accuracy: 0.9560 - val_loss: 0.3905 - val_accuracy: 0.9011\n",
            "Epoch 402/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1923 - accuracy: 0.9560 - val_loss: 0.3922 - val_accuracy: 0.9121\n",
            "Epoch 403/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1910 - accuracy: 0.9560 - val_loss: 0.3890 - val_accuracy: 0.9011\n",
            "Epoch 404/500\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.1908 - accuracy: 0.9560 - val_loss: 0.3873 - val_accuracy: 0.9011\n",
            "Epoch 405/500\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.1910 - accuracy: 0.9560 - val_loss: 0.3859 - val_accuracy: 0.9011\n",
            "Epoch 406/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1904 - accuracy: 0.9560 - val_loss: 0.3879 - val_accuracy: 0.9011\n",
            "Epoch 407/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.1905 - accuracy: 0.9560 - val_loss: 0.3911 - val_accuracy: 0.9011\n",
            "Epoch 408/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1906 - accuracy: 0.9533 - val_loss: 0.3888 - val_accuracy: 0.9011\n",
            "Epoch 409/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1902 - accuracy: 0.9533 - val_loss: 0.3893 - val_accuracy: 0.9011\n",
            "Epoch 410/500\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.1901 - accuracy: 0.9560 - val_loss: 0.3875 - val_accuracy: 0.9011\n",
            "Epoch 411/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1902 - accuracy: 0.9560 - val_loss: 0.3891 - val_accuracy: 0.9011\n",
            "Epoch 412/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1906 - accuracy: 0.9533 - val_loss: 0.3860 - val_accuracy: 0.9011\n",
            "Epoch 413/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1899 - accuracy: 0.9560 - val_loss: 0.3869 - val_accuracy: 0.9011\n",
            "Epoch 414/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1901 - accuracy: 0.9560 - val_loss: 0.3871 - val_accuracy: 0.9011\n",
            "Epoch 415/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1898 - accuracy: 0.9560 - val_loss: 0.3839 - val_accuracy: 0.9011\n",
            "Epoch 416/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1892 - accuracy: 0.9560 - val_loss: 0.3866 - val_accuracy: 0.9011\n",
            "Epoch 417/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1893 - accuracy: 0.9560 - val_loss: 0.3914 - val_accuracy: 0.9011\n",
            "Epoch 418/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1895 - accuracy: 0.9560 - val_loss: 0.3910 - val_accuracy: 0.9011\n",
            "Epoch 419/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1908 - accuracy: 0.9533 - val_loss: 0.3846 - val_accuracy: 0.9011\n",
            "Epoch 420/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1884 - accuracy: 0.9560 - val_loss: 0.3858 - val_accuracy: 0.9011\n",
            "Epoch 421/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1887 - accuracy: 0.9560 - val_loss: 0.3902 - val_accuracy: 0.9011\n",
            "Epoch 422/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1890 - accuracy: 0.9560 - val_loss: 0.3898 - val_accuracy: 0.9011\n",
            "Epoch 423/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1893 - accuracy: 0.9560 - val_loss: 0.3856 - val_accuracy: 0.9011\n",
            "Epoch 424/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1885 - accuracy: 0.9533 - val_loss: 0.3900 - val_accuracy: 0.9011\n",
            "Epoch 425/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1882 - accuracy: 0.9560 - val_loss: 0.3893 - val_accuracy: 0.9011\n",
            "Epoch 426/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1892 - accuracy: 0.9560 - val_loss: 0.3871 - val_accuracy: 0.9011\n",
            "Epoch 427/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1882 - accuracy: 0.9560 - val_loss: 0.3908 - val_accuracy: 0.9011\n",
            "Epoch 428/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1879 - accuracy: 0.9560 - val_loss: 0.3889 - val_accuracy: 0.9011\n",
            "Epoch 429/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1878 - accuracy: 0.9560 - val_loss: 0.3872 - val_accuracy: 0.9011\n",
            "Epoch 430/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1872 - accuracy: 0.9560 - val_loss: 0.3889 - val_accuracy: 0.9011\n",
            "Epoch 431/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1882 - accuracy: 0.9560 - val_loss: 0.3930 - val_accuracy: 0.9011\n",
            "Epoch 432/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1873 - accuracy: 0.9560 - val_loss: 0.3884 - val_accuracy: 0.9011\n",
            "Epoch 433/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1894 - accuracy: 0.9560 - val_loss: 0.3857 - val_accuracy: 0.9011\n",
            "Epoch 434/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1880 - accuracy: 0.9533 - val_loss: 0.3903 - val_accuracy: 0.9011\n",
            "Epoch 435/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1884 - accuracy: 0.9560 - val_loss: 0.3954 - val_accuracy: 0.9011\n",
            "Epoch 436/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1870 - accuracy: 0.9560 - val_loss: 0.3881 - val_accuracy: 0.9011\n",
            "Epoch 437/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1869 - accuracy: 0.9560 - val_loss: 0.3845 - val_accuracy: 0.9011\n",
            "Epoch 438/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1869 - accuracy: 0.9560 - val_loss: 0.3862 - val_accuracy: 0.9011\n",
            "Epoch 439/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1868 - accuracy: 0.9560 - val_loss: 0.3906 - val_accuracy: 0.9011\n",
            "Epoch 440/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1864 - accuracy: 0.9560 - val_loss: 0.3904 - val_accuracy: 0.9011\n",
            "Epoch 441/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1873 - accuracy: 0.9533 - val_loss: 0.3858 - val_accuracy: 0.9011\n",
            "Epoch 442/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1863 - accuracy: 0.9533 - val_loss: 0.3876 - val_accuracy: 0.9011\n",
            "Epoch 443/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1860 - accuracy: 0.9560 - val_loss: 0.3871 - val_accuracy: 0.9011\n",
            "Epoch 444/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1864 - accuracy: 0.9560 - val_loss: 0.3888 - val_accuracy: 0.9011\n",
            "Epoch 445/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1866 - accuracy: 0.9533 - val_loss: 0.3896 - val_accuracy: 0.9011\n",
            "Epoch 446/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1857 - accuracy: 0.9560 - val_loss: 0.3860 - val_accuracy: 0.9011\n",
            "Epoch 447/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1856 - accuracy: 0.9560 - val_loss: 0.3840 - val_accuracy: 0.9011\n",
            "Epoch 448/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1857 - accuracy: 0.9560 - val_loss: 0.3848 - val_accuracy: 0.9011\n",
            "Epoch 449/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1852 - accuracy: 0.9560 - val_loss: 0.3845 - val_accuracy: 0.9011\n",
            "Epoch 450/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1854 - accuracy: 0.9560 - val_loss: 0.3845 - val_accuracy: 0.9011\n",
            "Epoch 451/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1858 - accuracy: 0.9560 - val_loss: 0.3836 - val_accuracy: 0.9011\n",
            "Epoch 452/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1856 - accuracy: 0.9560 - val_loss: 0.3902 - val_accuracy: 0.9011\n",
            "Epoch 453/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1854 - accuracy: 0.9560 - val_loss: 0.3904 - val_accuracy: 0.9011\n",
            "Epoch 454/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1849 - accuracy: 0.9560 - val_loss: 0.3859 - val_accuracy: 0.9011\n",
            "Epoch 455/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1844 - accuracy: 0.9560 - val_loss: 0.3827 - val_accuracy: 0.9011\n",
            "Epoch 456/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1851 - accuracy: 0.9560 - val_loss: 0.3839 - val_accuracy: 0.9011\n",
            "Epoch 457/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1851 - accuracy: 0.9533 - val_loss: 0.3792 - val_accuracy: 0.9011\n",
            "Epoch 458/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1847 - accuracy: 0.9533 - val_loss: 0.3817 - val_accuracy: 0.9011\n",
            "Epoch 459/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1857 - accuracy: 0.9560 - val_loss: 0.3875 - val_accuracy: 0.9011\n",
            "Epoch 460/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1850 - accuracy: 0.9560 - val_loss: 0.3866 - val_accuracy: 0.9011\n",
            "Epoch 461/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1842 - accuracy: 0.9560 - val_loss: 0.3849 - val_accuracy: 0.9011\n",
            "Epoch 462/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1848 - accuracy: 0.9560 - val_loss: 0.3822 - val_accuracy: 0.9011\n",
            "Epoch 463/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1846 - accuracy: 0.9560 - val_loss: 0.3823 - val_accuracy: 0.9011\n",
            "Epoch 464/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1864 - accuracy: 0.9560 - val_loss: 0.3866 - val_accuracy: 0.9011\n",
            "Epoch 465/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1857 - accuracy: 0.9533 - val_loss: 0.3837 - val_accuracy: 0.9011\n",
            "Epoch 466/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1842 - accuracy: 0.9560 - val_loss: 0.3846 - val_accuracy: 0.9011\n",
            "Epoch 467/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1836 - accuracy: 0.9560 - val_loss: 0.3839 - val_accuracy: 0.9011\n",
            "Epoch 468/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1835 - accuracy: 0.9533 - val_loss: 0.3840 - val_accuracy: 0.9011\n",
            "Epoch 469/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1845 - accuracy: 0.9560 - val_loss: 0.3842 - val_accuracy: 0.9011\n",
            "Epoch 470/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1833 - accuracy: 0.9560 - val_loss: 0.3871 - val_accuracy: 0.9011\n",
            "Epoch 471/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1831 - accuracy: 0.9560 - val_loss: 0.3898 - val_accuracy: 0.9011\n",
            "Epoch 472/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1839 - accuracy: 0.9533 - val_loss: 0.3905 - val_accuracy: 0.9011\n",
            "Epoch 473/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1837 - accuracy: 0.9560 - val_loss: 0.3913 - val_accuracy: 0.9011\n",
            "Epoch 474/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1843 - accuracy: 0.9560 - val_loss: 0.3813 - val_accuracy: 0.9011\n",
            "Epoch 475/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1832 - accuracy: 0.9533 - val_loss: 0.3808 - val_accuracy: 0.9011\n",
            "Epoch 476/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1826 - accuracy: 0.9560 - val_loss: 0.3832 - val_accuracy: 0.9011\n",
            "Epoch 477/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1831 - accuracy: 0.9560 - val_loss: 0.3874 - val_accuracy: 0.9011\n",
            "Epoch 478/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1826 - accuracy: 0.9560 - val_loss: 0.3875 - val_accuracy: 0.9011\n",
            "Epoch 479/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1834 - accuracy: 0.9560 - val_loss: 0.3872 - val_accuracy: 0.9011\n",
            "Epoch 480/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1830 - accuracy: 0.9560 - val_loss: 0.3853 - val_accuracy: 0.9011\n",
            "Epoch 481/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1817 - accuracy: 0.9560 - val_loss: 0.3860 - val_accuracy: 0.9011\n",
            "Epoch 482/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1825 - accuracy: 0.9560 - val_loss: 0.3886 - val_accuracy: 0.9121\n",
            "Epoch 483/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1828 - accuracy: 0.9560 - val_loss: 0.3856 - val_accuracy: 0.9011\n",
            "Epoch 484/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1824 - accuracy: 0.9560 - val_loss: 0.3834 - val_accuracy: 0.9011\n",
            "Epoch 485/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1822 - accuracy: 0.9533 - val_loss: 0.3836 - val_accuracy: 0.9011\n",
            "Epoch 486/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1822 - accuracy: 0.9560 - val_loss: 0.3864 - val_accuracy: 0.9011\n",
            "Epoch 487/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1833 - accuracy: 0.9560 - val_loss: 0.3821 - val_accuracy: 0.9011\n",
            "Epoch 488/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1820 - accuracy: 0.9560 - val_loss: 0.3836 - val_accuracy: 0.9011\n",
            "Epoch 489/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1819 - accuracy: 0.9560 - val_loss: 0.3879 - val_accuracy: 0.9011\n",
            "Epoch 490/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1823 - accuracy: 0.9560 - val_loss: 0.3849 - val_accuracy: 0.9011\n",
            "Epoch 491/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1820 - accuracy: 0.9560 - val_loss: 0.3864 - val_accuracy: 0.9011\n",
            "Epoch 492/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1820 - accuracy: 0.9560 - val_loss: 0.3834 - val_accuracy: 0.9011\n",
            "Epoch 493/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1816 - accuracy: 0.9560 - val_loss: 0.3856 - val_accuracy: 0.9011\n",
            "Epoch 494/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1815 - accuracy: 0.9560 - val_loss: 0.3852 - val_accuracy: 0.9011\n",
            "Epoch 495/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1811 - accuracy: 0.9560 - val_loss: 0.3857 - val_accuracy: 0.9011\n",
            "Epoch 496/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1810 - accuracy: 0.9560 - val_loss: 0.3843 - val_accuracy: 0.9011\n",
            "Epoch 497/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1810 - accuracy: 0.9560 - val_loss: 0.3837 - val_accuracy: 0.9011\n",
            "Epoch 498/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1807 - accuracy: 0.9560 - val_loss: 0.3838 - val_accuracy: 0.9011\n",
            "Epoch 499/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1806 - accuracy: 0.9560 - val_loss: 0.3833 - val_accuracy: 0.9011\n",
            "Epoch 500/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1811 - accuracy: 0.9560 - val_loss: 0.3830 - val_accuracy: 0.9011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#y_pred_DNN = (model.predict(DNNX) > 0.5).astype(\"int32\")\n",
        "DTr = model.evaluate(DX_train, Dy_train,verbose=0)[1]\n",
        "DTe = model.evaluate(DX_test, Dy_test,verbose=0)[1]\n",
        "DTr,DTe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhG0YCbhASH9",
        "outputId": "f1c6118b-b72b-4a5f-abed-bb48acbfb621"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9450549483299255, 0.9122806787490845)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_DNN = (model.predict(DX_test) > 0.5).astype(\"int32\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKbxrS57kOBE",
        "outputId": "e6a5d93f-4858-468f-d18a-15ff94dc06d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = pd.DataFrame(\n",
        "    {\n",
        "    \"SVM\":[STr,STe],\n",
        "    \"KNN\":[KTr,KTe],\n",
        "    \"RF\" :[RTr,RTe],\n",
        "    \"LR\" :[LTr,LTe],\n",
        "    \"ANN\":[ATr,ATe],\n",
        "    \"XGB\":[XTr,XTe],\n",
        "    \"DNN\":[DTr,DTe]})\n",
        "acc.index = [\"train\", \"test\"]\n",
        "acc = acc.T\n",
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "v_YjlCdOO1JY",
        "outputId": "08429317-d461-4863-bf2e-65328d62af75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        train      test\n",
              "SVM  0.951648  0.956140\n",
              "KNN  0.980220  0.991228\n",
              "RF   0.975824  0.991228\n",
              "LR   0.980220  0.973684\n",
              "ANN  0.953846  0.964912\n",
              "XGB  0.993407  0.982456\n",
              "DNN  0.945055  0.912281"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a0e9a84-2edf-4557-9b3e-07e8dfa9974c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>0.951648</td>\n",
              "      <td>0.956140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>0.980220</td>\n",
              "      <td>0.991228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>0.975824</td>\n",
              "      <td>0.991228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LR</th>\n",
              "      <td>0.980220</td>\n",
              "      <td>0.973684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ANN</th>\n",
              "      <td>0.953846</td>\n",
              "      <td>0.964912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGB</th>\n",
              "      <td>0.993407</td>\n",
              "      <td>0.982456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DNN</th>\n",
              "      <td>0.945055</td>\n",
              "      <td>0.912281</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a0e9a84-2edf-4557-9b3e-07e8dfa9974c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1a0e9a84-2edf-4557-9b3e-07e8dfa9974c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1a0e9a84-2edf-4557-9b3e-07e8dfa9974c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **AutoML Individual and AutoML DNN**"
      ],
      "metadata": {
        "id": "nJaAMLDKKfKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#H2O AutoML"
      ],
      "metadata": {
        "id": "EhNt_UkjDKcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h2o\n",
        "import h2o\n",
        "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
        "h2o.init()\n",
        "from h2o.model.segment_models import H2OFrame\n",
        "from h2o.automl import H2OAutoML\n",
        "print(\"All Library Loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 873
        },
        "id": "iwMF9ROeDOzF",
        "outputId": "d682ffac-8691-4a03-e408-9b4ac2ee4c9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting h2o\n",
            "  Downloading h2o-3.40.0.4.tar.gz (177.6 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m177.6/177.6 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from h2o) (2.27.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from h2o) (0.8.10)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from h2o) (0.18.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (3.4)\n",
            "Building wheels for collected packages: h2o\n",
            "  Building wheel for h2o (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for h2o: filename=h2o-3.40.0.4-py2.py3-none-any.whl size=177697886 sha256=5d58ada7f6193bad9637bf26c499b7876ab0bb082a383d2de4812f58bc7357de\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/f2/b0/5bb4d702a0467e82d77c45088db3eef25114c26b0eec8e7f6a\n",
            "Successfully built h2o\n",
            "Installing collected packages: h2o\n",
            "Successfully installed h2o-3.40.0.4\n",
            "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
            "Attempting to start a local H2O server...\n",
            "  Java Version: openjdk version \"11.0.19\" 2023-04-18; OpenJDK Runtime Environment (build 11.0.19+7-post-Ubuntu-0ubuntu120.04.1); OpenJDK 64-Bit Server VM (build 11.0.19+7-post-Ubuntu-0ubuntu120.04.1, mixed mode, sharing)\n",
            "  Starting server from /usr/local/lib/python3.10/dist-packages/h2o/backend/bin/h2o.jar\n",
            "  Ice root: /tmp/tmppsn3ogls\n",
            "  JVM stdout: /tmp/tmppsn3ogls/h2o_unknownUser_started_from_python.out\n",
            "  JVM stderr: /tmp/tmppsn3ogls/h2o_unknownUser_started_from_python.err\n",
            "  Server is running at http://127.0.0.1:54321\n",
            "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "--------------------------  -----------------------------------------------------------------------------------------\n",
              "H2O_cluster_uptime:         03 secs\n",
              "H2O_cluster_timezone:       Etc/UTC\n",
              "H2O_data_parsing_timezone:  UTC\n",
              "H2O_cluster_version:        3.40.0.4\n",
              "H2O_cluster_version_age:    2 months and 6 days\n",
              "H2O_cluster_name:           H2O_from_python_unknownUser_2po1sl\n",
              "H2O_cluster_total_nodes:    1\n",
              "H2O_cluster_free_memory:    3.170 Gb\n",
              "H2O_cluster_total_cores:    2\n",
              "H2O_cluster_allowed_cores:  2\n",
              "H2O_cluster_status:         locked, healthy\n",
              "H2O_connection_url:         http://127.0.0.1:54321\n",
              "H2O_connection_proxy:       {\"http\": null, \"https\": null, \"colab_language_server\": \"/usr/colab/bin/language_service\"}\n",
              "H2O_internal_security:      False\n",
              "Python_version:             3.10.12 final\n",
              "--------------------------  -----------------------------------------------------------------------------------------"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "#h2o-table-1.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-1 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-1 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-1 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-1 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-1 .h2o-table th,\n",
              "#h2o-table-1 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption></caption>\n",
              "    <thead></thead>\n",
              "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
              "<td>03 secs</td></tr>\n",
              "<tr><td>H2O_cluster_timezone:</td>\n",
              "<td>Etc/UTC</td></tr>\n",
              "<tr><td>H2O_data_parsing_timezone:</td>\n",
              "<td>UTC</td></tr>\n",
              "<tr><td>H2O_cluster_version:</td>\n",
              "<td>3.40.0.4</td></tr>\n",
              "<tr><td>H2O_cluster_version_age:</td>\n",
              "<td>2 months and 6 days</td></tr>\n",
              "<tr><td>H2O_cluster_name:</td>\n",
              "<td>H2O_from_python_unknownUser_2po1sl</td></tr>\n",
              "<tr><td>H2O_cluster_total_nodes:</td>\n",
              "<td>1</td></tr>\n",
              "<tr><td>H2O_cluster_free_memory:</td>\n",
              "<td>3.170 Gb</td></tr>\n",
              "<tr><td>H2O_cluster_total_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_allowed_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_status:</td>\n",
              "<td>locked, healthy</td></tr>\n",
              "<tr><td>H2O_connection_url:</td>\n",
              "<td>http://127.0.0.1:54321</td></tr>\n",
              "<tr><td>H2O_connection_proxy:</td>\n",
              "<td>{\"http\": null, \"https\": null, \"colab_language_server\": \"/usr/colab/bin/language_service\"}</td></tr>\n",
              "<tr><td>H2O_internal_security:</td>\n",
              "<td>False</td></tr>\n",
              "<tr><td>Python_version:</td>\n",
              "<td>3.10.12 final</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Library Loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kWdoOLbsF2qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X-QiglXeF_XE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8P1HTOHbugE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "asKywHvIu83f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z5wVvB0pvWHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train, valid = hdf.split_frame(ratios=[.8], seed=123)\n",
        "#hdf = h2o.H2OFrame(df)\n",
        "#hdf[\"diagnosis\"] = hdf[\"diagnosis\"].asfactor()\n",
        "hy = \"diagnosis\"\n",
        "hx = list(df.columns)\n",
        "hx.remove(hy)\n",
        "hdf  = df.copy()\n",
        "hdf.iloc[:,1:] = StandardScaler().fit_transform(hdf.iloc[:,1:])\n",
        "hdf.iloc[:,0] = LabelEncoder().fit_transform(hdf.iloc[:,0])\n",
        "hdf.iloc[:,0] = hdf.iloc[:,0].astype('category')\n",
        "train1, valid1 = train_test_split(hdf, test_size=0.2,random_state=123)\n",
        "train = h2o.H2OFrame(train1)\n",
        "valid = h2o.H2OFrame(valid1)\n",
        "train[\"diagnosis\"] = train[\"diagnosis\"].asfactor()\n",
        "valid[\"diagnosis\"] = valid[\"diagnosis\"].asfactor()"
      ],
      "metadata": {
        "id": "NVoFNbYCGxGh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b87384e7-034c-450f-b5da-06a06ac16464"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-460708a37676>:9: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  hdf.iloc[:,0] = LabelEncoder().fit_transform(hdf.iloc[:,0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n",
            "Parse progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "st = time.time()\n",
        "aml = H2OAutoML(max_models = 10, seed = 123, verbosity=\"info\",\n",
        "                nfolds=10, sort_metric='accuracy')\n",
        "aml.train(x = hx, y = hy, training_frame = train,\n",
        "          validation_frame = valid)\n",
        "autoend = time.time() - st"
      ],
      "metadata": {
        "id": "7JNO6XnVHH5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e1cacb6-5c61-44f4-b73c-1e3329f3b4a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoML progress: |\n",
            "11:31:34.194: Project: AutoML_1_20230705_113134\n",
            "11:31:34.199: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n",
            "11:31:34.204: Setting stopping tolerance adaptively based on the training frame: 0.04688072309384954\n",
            "11:31:34.204: Build control seed: 123\n",
            "11:31:34.205: training frame: Frame key: AutoML_1_20230705_113134_training_py_1_sid_9fa1    cols: 31    rows: 455  chunks: 1    size: 111919  checksum: -6999049652048799504\n",
            "11:31:34.210: validation frame: Frame key: py_2_sid_9fa1    cols: 31    rows: 114  chunks: 1    size: 30037  checksum: 1244986154056216624\n",
            "11:31:34.210: leaderboard frame: NULL\n",
            "11:31:34.210: blending frame: NULL\n",
            "11:31:34.211: response column: diagnosis\n",
            "11:31:34.211: fold column: null\n",
            "11:31:34.211: weights column: null\n",
            "11:31:34.246: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (7g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (7g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (6g, 60w)]}, {StackedEnsemble : [monotonic (9g, 10w), best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
            "11:31:34.287: AutoML job created: 2023.07.05 11:31:34.99\n",
            "11:31:34.288: AutoML build started: 2023.07.05 11:31:34.288\n",
            "11:31:34.356: AutoML: starting XGBoost_1_AutoML_1_20230705_113134 model training\n",
            "\n",
            "â–ˆ\n",
            "11:31:40.889: New leader: XGBoost_1_AutoML_1_20230705_113134, accuracy: 0.9428571428571428\n",
            "11:31:40.913: AutoML: starting GLM_1_AutoML_1_20230705_113134 model training\n",
            "\n",
            "â–ˆâ–ˆ\n",
            "11:31:48.226: AutoML: starting GBM_1_AutoML_1_20230705_113134 model training\n",
            "\n",
            "â–ˆâ–ˆ\n",
            "11:32:05.287: AutoML: starting XGBoost_2_AutoML_1_20230705_113134 model training\n",
            "\n",
            "â–ˆ\n",
            "11:32:10.204: AutoML: starting DRF_1_AutoML_1_20230705_113134 model training\n",
            "\n",
            "\n",
            "11:32:13.939: AutoML: starting GBM_2_AutoML_1_20230705_113134 model training\n",
            "\n",
            "â–ˆâ–ˆâ–ˆ\n",
            "11:32:27.233: AutoML: starting GBM_3_AutoML_1_20230705_113134 model training\n",
            "\n",
            "â–ˆ\n",
            "11:32:39.624: AutoML: starting GBM_4_AutoML_1_20230705_113134 model training\n",
            "\n",
            "â–ˆ\n",
            "11:32:51.667: AutoML: starting XGBoost_3_AutoML_1_20230705_113134 model training\n",
            "\n",
            "â–ˆ\n",
            "11:32:55.940: AutoML: starting XRT_1_AutoML_1_20230705_113134 model training\n",
            "\n",
            "â–ˆ\n",
            "11:33:01.753: No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'monotonic'.\n",
            "11:33:01.766: AutoML: starting StackedEnsemble_BestOfFamily_1_AutoML_1_20230705_113134 model training\n",
            "\n",
            "â–ˆâ–ˆ\n",
            "11:33:05.417: AutoML: starting StackedEnsemble_AllModels_1_AutoML_1_20230705_113134 model training\n",
            "\n",
            "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n",
            "\n",
            "11:33:09.64: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GLM : [def_1 (1g, 10w)]}, {GBM : [def_5 (1g, 10w)]}, {XGBoost : [def_1 (2g, 10w)]}, {DRF : [def_1 (2g, 10w)]}, {GBM : [def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w)]}, {XGBoost : [def_3 (3g, 10w)]}, {DRF : [XRT (3g, 10w)]}, {StackedEnsemble : [best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
            "11:33:09.64: AutoML build stopped: 2023.07.05 11:33:09.64\n",
            "11:33:09.64: AutoML build done: built 10 models\n",
            "11:33:09.64: AutoML duration:  1 min 34.776 sec\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lbo606kFH4Zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lb = aml.leaderboard\n",
        "lb.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "gmCXw_D_4y1D",
        "outputId": "495ba004-2d38-423b-f78b-f6a35f4ccc4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model_id                              accuracy       auc    logloss     aucpr    mean_per_class_error      rmse        mse\n",
              "----------------------------------  ----------  --------  ---------  --------  ----------------------  --------  ---------\n",
              "XGBoost_1_AutoML_1_20230705_113134    0.942857  0.984114  0.166379   0.979636               0.0539185  0.210251  0.0442054\n",
              "XRT_1_AutoML_1_20230705_113134        0.96044   0.991619  0.116734   0.98782                0.0421609  0.184096  0.0338912\n",
              "DRF_1_AutoML_1_20230705_113134        0.96044   0.987058  0.249487   0.985869               0.0421609  0.18258   0.0333355\n",
              "XGBoost_2_AutoML_1_20230705_113134    0.962637  0.990394  0.11331    0.987678               0.0392369  0.174879  0.0305826\n",
              "GBM_4_AutoML_1_20230705_113134        0.967033  0.993246  0.0998609  0.990397               0.0333889  0.170342  0.0290164\n",
              "GBM_2_AutoML_1_20230705_113134        0.967033  0.994255  0.0933299  0.991681               0.0380426  0.162663  0.0264594\n",
              "XGBoost_3_AutoML_1_20230705_113134    0.969231  0.992999  0.0965668  0.990609               0.0316284  0.161568  0.0261043\n",
              "GBM_1_AutoML_1_20230705_113134        0.971429  0.994461  0.0911605  0.992401               0.0287044  0.158892  0.0252468\n",
              "GBM_3_AutoML_1_20230705_113134        0.971429  0.994461  0.0902413  0.991937               0.027541   0.157908  0.0249349\n",
              "GLM_1_AutoML_1_20230705_113134        0.978022  0.996479  0.0739483  0.994833               0.0269129  0.1449    0.0209961\n",
              "[10 rows x 8 columns]\n"
            ],
            "text/html": [
              "<table class='dataframe'>\n",
              "<thead>\n",
              "<tr><th>model_id                          </th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">      mse</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>XGBoost_1_AutoML_1_20230705_113134</td><td style=\"text-align: right;\">  0.942857</td><td style=\"text-align: right;\">0.984114</td><td style=\"text-align: right;\">0.166379 </td><td style=\"text-align: right;\">0.979636</td><td style=\"text-align: right;\">             0.0539185</td><td style=\"text-align: right;\">0.210251</td><td style=\"text-align: right;\">0.0442054</td></tr>\n",
              "<tr><td>XRT_1_AutoML_1_20230705_113134    </td><td style=\"text-align: right;\">  0.96044 </td><td style=\"text-align: right;\">0.991619</td><td style=\"text-align: right;\">0.116734 </td><td style=\"text-align: right;\">0.98782 </td><td style=\"text-align: right;\">             0.0421609</td><td style=\"text-align: right;\">0.184096</td><td style=\"text-align: right;\">0.0338912</td></tr>\n",
              "<tr><td>DRF_1_AutoML_1_20230705_113134    </td><td style=\"text-align: right;\">  0.96044 </td><td style=\"text-align: right;\">0.987058</td><td style=\"text-align: right;\">0.249487 </td><td style=\"text-align: right;\">0.985869</td><td style=\"text-align: right;\">             0.0421609</td><td style=\"text-align: right;\">0.18258 </td><td style=\"text-align: right;\">0.0333355</td></tr>\n",
              "<tr><td>XGBoost_2_AutoML_1_20230705_113134</td><td style=\"text-align: right;\">  0.962637</td><td style=\"text-align: right;\">0.990394</td><td style=\"text-align: right;\">0.11331  </td><td style=\"text-align: right;\">0.987678</td><td style=\"text-align: right;\">             0.0392369</td><td style=\"text-align: right;\">0.174879</td><td style=\"text-align: right;\">0.0305826</td></tr>\n",
              "<tr><td>GBM_4_AutoML_1_20230705_113134    </td><td style=\"text-align: right;\">  0.967033</td><td style=\"text-align: right;\">0.993246</td><td style=\"text-align: right;\">0.0998609</td><td style=\"text-align: right;\">0.990397</td><td style=\"text-align: right;\">             0.0333889</td><td style=\"text-align: right;\">0.170342</td><td style=\"text-align: right;\">0.0290164</td></tr>\n",
              "<tr><td>GBM_2_AutoML_1_20230705_113134    </td><td style=\"text-align: right;\">  0.967033</td><td style=\"text-align: right;\">0.994255</td><td style=\"text-align: right;\">0.0933299</td><td style=\"text-align: right;\">0.991681</td><td style=\"text-align: right;\">             0.0380426</td><td style=\"text-align: right;\">0.162663</td><td style=\"text-align: right;\">0.0264594</td></tr>\n",
              "<tr><td>XGBoost_3_AutoML_1_20230705_113134</td><td style=\"text-align: right;\">  0.969231</td><td style=\"text-align: right;\">0.992999</td><td style=\"text-align: right;\">0.0965668</td><td style=\"text-align: right;\">0.990609</td><td style=\"text-align: right;\">             0.0316284</td><td style=\"text-align: right;\">0.161568</td><td style=\"text-align: right;\">0.0261043</td></tr>\n",
              "<tr><td>GBM_1_AutoML_1_20230705_113134    </td><td style=\"text-align: right;\">  0.971429</td><td style=\"text-align: right;\">0.994461</td><td style=\"text-align: right;\">0.0911605</td><td style=\"text-align: right;\">0.992401</td><td style=\"text-align: right;\">             0.0287044</td><td style=\"text-align: right;\">0.158892</td><td style=\"text-align: right;\">0.0252468</td></tr>\n",
              "<tr><td>GBM_3_AutoML_1_20230705_113134    </td><td style=\"text-align: right;\">  0.971429</td><td style=\"text-align: right;\">0.994461</td><td style=\"text-align: right;\">0.0902413</td><td style=\"text-align: right;\">0.991937</td><td style=\"text-align: right;\">             0.027541 </td><td style=\"text-align: right;\">0.157908</td><td style=\"text-align: right;\">0.0249349</td></tr>\n",
              "<tr><td>GLM_1_AutoML_1_20230705_113134    </td><td style=\"text-align: right;\">  0.978022</td><td style=\"text-align: right;\">0.996479</td><td style=\"text-align: right;\">0.0739483</td><td style=\"text-align: right;\">0.994833</td><td style=\"text-align: right;\">             0.0269129</td><td style=\"text-align: right;\">0.1449  </td><td style=\"text-align: right;\">0.0209961</td></tr>\n",
              "</tbody>\n",
              "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[10 rows x 8 columns]</pre>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = aml.get_best_model()\n",
        "best_model"
      ],
      "metadata": {
        "id": "vlH8zwtisQU1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "486a356f-001f-43df-afaa-65944f2af741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model Details\n",
              "=============\n",
              "H2OXGBoostEstimator : XGBoost\n",
              "Model Key: XGBoost_1_AutoML_1_20230705_113134\n",
              "\n",
              "\n",
              "Model Summary: \n",
              "    number_of_trees\n",
              "--  -----------------\n",
              "    36\n",
              "\n",
              "ModelMetricsBinomial: xgboost\n",
              "** Reported on train data. **\n",
              "\n",
              "MSE: 0.029074514855628383\n",
              "RMSE: 0.17051250644931704\n",
              "LogLoss: 0.12394929039565182\n",
              "Mean Per-Class Error: 0.029270653158718393\n",
              "AUC: 0.9940799769376494\n",
              "AUCPR: 0.992056368504806\n",
              "Gini: 0.9881599538752988\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4925362765789032\n",
              "       0    1    Error    Rate\n",
              "-----  ---  ---  -------  ------------\n",
              "0      279  5    0.0176   (5.0/284.0)\n",
              "1      7    164  0.0409   (7.0/171.0)\n",
              "Total  286  169  0.0264   (12.0/455.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.492536     0.964706  38\n",
              "max f2                       0.317989     0.971098  49\n",
              "max f0point5                 0.514766     0.971395  37\n",
              "max accuracy                 0.514766     0.973626  37\n",
              "max precision                0.968002     1         0\n",
              "max recall                   0.0588847    1         100\n",
              "max specificity              0.968002     1         0\n",
              "max absolute_mcc             0.492536     0.943696  38\n",
              "max min_per_class_accuracy   0.402806     0.964912  42\n",
              "max mean_per_class_accuracy  0.492536     0.970729  38\n",
              "max tns                      0.968002     284       0\n",
              "max fns                      0.968002     110       0\n",
              "max fps                      0.0148769    284       134\n",
              "max tps                      0.0588847    171       100\n",
              "max tnr                      0.968002     1         0\n",
              "max fnr                      0.968002     0.643275  0\n",
              "max fpr                      0.0148769    1         134\n",
              "max tpr                      0.0588847    1         100\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 37.58 %, avg score: 37.29 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.134066                    0.968002           2.66082    2.66082            1                0.968002   1                           0.968002            0.356725        0.356725                   166.082   166.082            0.356725\n",
              "2        0.162637                    0.957612           2.66082    2.66082            1                0.957612   1                           0.966177            0.0760234       0.432749                   166.082   166.082            0.432749\n",
              "3        0.2                         0.950501           2.66082    2.66082            1                0.953488   1                           0.963806            0.0994152       0.532164                   166.082   166.082            0.532164\n",
              "4        0.301099                    0.807568           2.66082    2.66082            1                0.897179   1                           0.941435            0.269006        0.80117                    166.082   166.082            0.80117\n",
              "5        0.4                         0.314704           1.83301    2.45614            0.688889         0.582323   0.923077                    0.852644            0.181287        0.982456                   83.3008   145.614            0.93316\n",
              "6        0.501099                    0.076693           0.0578439  1.97227            0.0217391        0.161579   0.741228                    0.713218            0.00584795      0.988304                   -94.2156  97.2274            0.780558\n",
              "7        0.624176                    0.0503081          0.0950292  1.60211            0.0357143        0.058398   0.602113                    0.584099            0.0116959       1                          -90.4971  60.2113            0.602113\n",
              "8        0.698901                    0.0279195          0          1.43082            0                0.0365022  0.537736                    0.525551            0               1                          -100      43.0818            0.482394\n",
              "9        0.804396                    0.0177071          0          1.24317            0                0.0225316  0.467213                    0.459581            0               1                          -100      24.3169            0.31338\n",
              "10       0.931868                    0.0175245          0          1.07311            0                0.0175245  0.403302                    0.399111            0               1                          -100      7.31132            0.109155\n",
              "11       1                           0.0148769          0          1                  0                0.0148769  0.375824                    0.372932            0               1                          -100      0                  0\n",
              "\n",
              "ModelMetricsBinomial: xgboost\n",
              "** Reported on validation data. **\n",
              "\n",
              "MSE: 0.03762067586537018\n",
              "RMSE: 0.19396050078655236\n",
              "LogLoss: 0.1512542647982658\n",
              "Mean Per-Class Error: 0.03274306715669896\n",
              "AUC: 0.976445038422987\n",
              "AUCPR: 0.9791961628675718\n",
              "Gini: 0.952890076845974\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.25368359684944153\n",
              "       0    1    Error    Rate\n",
              "-----  ---  ---  -------  -----------\n",
              "0      70   3    0.0411   (3.0/73.0)\n",
              "1      1    40   0.0244   (1.0/41.0)\n",
              "Total  71   43   0.0351   (4.0/114.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.253684     0.952381  20\n",
              "max f2                       0.253684     0.966184  20\n",
              "max f0point5                 0.705651     0.972973  15\n",
              "max accuracy                 0.253684     0.964912  20\n",
              "max precision                0.968002     1         0\n",
              "max recall                   0.0175245    1         46\n",
              "max specificity              0.968002     1         0\n",
              "max absolute_mcc             0.253684     0.925285  20\n",
              "max min_per_class_accuracy   0.253684     0.958904  20\n",
              "max mean_per_class_accuracy  0.253684     0.967257  20\n",
              "max tns                      0.968002     73        0\n",
              "max fns                      0.968002     27        0\n",
              "max fps                      0.0148769    73        47\n",
              "max tps                      0.0175245    41        46\n",
              "max tnr                      0.968002     1         0\n",
              "max fnr                      0.968002     0.658537  0\n",
              "max fpr                      0.0148769    1         47\n",
              "max tpr                      0.0175245    1         46\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 35.96 %, avg score: 34.85 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.122807                    0.968002           2.78049    2.78049            1                0.968002   1                           0.968002            0.341463        0.341463                   178.049   178.049            0.341463\n",
              "2        0.157895                    0.954363           2.78049    2.78049            1                0.955175   1                           0.965152            0.097561        0.439024                   178.049   178.049            0.439024\n",
              "3        0.210526                    0.932284           2.78049    2.78049            1                0.935408   1                           0.957716            0.146341        0.585366                   178.049   178.049            0.585366\n",
              "4        0.298246                    0.717271           2.78049    2.78049            1                0.870593   1                           0.932091            0.243902        0.829268                   178.049   178.049            0.829268\n",
              "5        0.403509                    0.169029           1.39024    2.41782            0.5              0.45112    0.869565                    0.806621            0.146341        0.97561                    39.0244   141.782            0.893418\n",
              "6        0.508772                    0.0588847          0          1.91758            0                0.093715   0.689655                    0.659123            0               0.97561                    -100      91.7578            0.729034\n",
              "7        0.596491                    0.0359404          0          1.63558            0                0.0470055  0.588235                    0.569106            0               0.97561                    -100      63.5581            0.592048\n",
              "8        0.701754                    0.023509           0          1.39024            0                0.0319946  0.5                         0.488539            0               0.97561                    -100      39.0244            0.427665\n",
              "9        0.973684                    0.0175245          0.0896932  1.02703            0.0322581        0.0192596  0.369369                    0.357479            0.0243902       1                          -91.0307  2.7027             0.0410959\n",
              "10       1                           0.0148769          0          1                  0                0.0148769  0.359649                    0.348463            0               1                          -100      0                  0\n",
              "\n",
              "ModelMetricsBinomial: xgboost\n",
              "** Reported on cross-validation data. **\n",
              "\n",
              "MSE: 0.044205368519838424\n",
              "RMSE: 0.21025072775103162\n",
              "LogLoss: 0.16637884924436225\n",
              "Mean Per-Class Error: 0.05391854048266205\n",
              "AUC: 0.9841137468083354\n",
              "AUCPR: 0.9796363289807396\n",
              "Gini: 0.9682274936166708\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.35231223702430725\n",
              "       0    1    Error    Rate\n",
              "-----  ---  ---  -------  ------------\n",
              "0      265  19   0.0669   (19.0/284.0)\n",
              "1      7    164  0.0409   (7.0/171.0)\n",
              "Total  272  183  0.0571   (26.0/455.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.352312     0.926554  103\n",
              "max f2                       0.352312     0.94579   103\n",
              "max f0point5                 0.648854     0.953307  71\n",
              "max accuracy                 0.624354     0.942857  74\n",
              "max precision                0.968105     1         0\n",
              "max recall                   0.0317377    1         212\n",
              "max specificity              0.968105     1         0\n",
              "max absolute_mcc             0.352312     0.881234  103\n",
              "max min_per_class_accuracy   0.393351     0.940141  98\n",
              "max mean_per_class_accuracy  0.352312     0.946081  103\n",
              "max tns                      0.968105     284       0\n",
              "max fns                      0.968105     168       0\n",
              "max fps                      0.0161675    284       239\n",
              "max tps                      0.0317377    171       212\n",
              "max tnr                      0.968105     1         0\n",
              "max fnr                      0.968105     0.982456  0\n",
              "max fpr                      0.0161675    1         239\n",
              "max tpr                      0.0317377    1         212\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 37.58 %, avg score: 37.58 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.0153846                   0.964642           2.66082    2.66082            1                0.966126   1                           0.966126            0.0409357       0.0409357                  166.082   166.082            0.0409357\n",
              "2        0.032967                    0.964165           2.66082    2.66082            1                0.964165   1                           0.96508             0.0467836       0.0877193                  166.082   166.082            0.0877193\n",
              "3        0.0461538                   0.96322            2.66082    2.66082            1                0.96322    1                           0.964549            0.0350877       0.122807                   166.082   166.082            0.122807\n",
              "4        0.0659341                   0.961647           2.66082    2.66082            1                0.961647   1                           0.963678            0.0526316       0.175439                   166.082   166.082            0.175439\n",
              "5        0.101099                    0.959238           2.66082    2.66082            1                0.960176   1                           0.96246             0.0935673       0.269006                   166.082   166.082            0.269006\n",
              "6        0.151648                    0.95194            2.66082    2.66082            1                0.954832   1                           0.959917            0.134503        0.403509                   166.082   166.082            0.403509\n",
              "7        0.2                         0.934824           2.66082    2.66082            1                0.944351   1                           0.956154            0.128655        0.532164                   166.082   166.082            0.532164\n",
              "8        0.301099                    0.781079           2.54513    2.62197            0.956522         0.887324   0.985401                    0.933043            0.25731         0.789474                   154.513   162.197            0.782431\n",
              "9        0.4                         0.354154           1.65562    2.38304            0.622222         0.566931   0.895604                    0.842521            0.163743        0.953216                   65.5621   138.304            0.886315\n",
              "10       0.501099                    0.0901423          0.289219   1.9606             0.108696         0.19796    0.736842                    0.712478            0.0292398       0.982456                   -71.0781  96.0603            0.771189\n",
              "11       0.6                         0.0496738          0.0591293  1.64717            0.0222222        0.0669556  0.619048                    0.606073            0.00584795      0.988304                   -94.0871  64.7173            0.622107\n",
              "12       0.698901                    0.0362709          0.0591293  1.42245            0.0222222        0.0437602  0.534591                    0.526501            0.00584795      0.994152                   -94.0871  42.245             0.473025\n",
              "13       0.8                         0.0304273          0.0578439  1.25               0.0217391        0.0321457  0.46978                     0.464027            0.00584795      1                          -94.2156  25                 0.320423\n",
              "14       0.907692                    0.0233827          0          1.10169            0                0.0257063  0.414044                    0.412023            0               1                          -100      10.1695            0.147887\n",
              "15       1                           0.0161675          0          1                  0                0.0195924  0.375824                    0.375799            0               1                          -100      0                  0\n",
              "\n",
              "Cross-Validation Metrics Summary: \n",
              "                         mean       sd         cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid    cv_6_valid    cv_7_valid    cv_8_valid    cv_9_valid    cv_10_valid\n",
              "-----------------------  ---------  ---------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  -------------\n",
              "accuracy                 0.96715    0.0235589  0.934783      0.978261      0.978261      0.956522      0.934783      0.955556      1             0.955556      1             0.977778\n",
              "auc                      0.983879   0.0178793  0.960938      0.995833      0.997972      0.984615      0.975446      0.980159      1             0.948276      1             0.995556\n",
              "err                      0.0328502  0.0235589  0.0652174     0.0217391     0.0217391     0.0434783     0.0652174     0.0444444     0             0.0444444     0             0.0222222\n",
              "err_count                1.5        1.08012    3             1             1             2             3             2             0             2             0             1\n",
              "f0point5                 0.958851   0.0287485  0.948276      0.986842      0.955056      0.95          0.909091      0.952381      1             0.9375        1             0.949367\n",
              "f1                       0.951568   0.0406347  0.88          0.967742      0.971429      0.95          0.888889      0.952381      1             0.9375        1             0.967742\n",
              "f2                       0.945492   0.0586199  0.820896      0.949367      0.988372      0.95          0.869565      0.952381      1             0.9375        1             0.986842\n",
              "lift_top_group           2.7497     0.495565   3.28571       2.875         2.70588       2.3           3.28571       2.14286       1.875         2.8125        3.21429       3\n",
              "logloss                  0.166222   0.0649039  0.212998      0.147144      0.106434      0.204719      0.231138      0.199252      0.0746679     0.255789      0.0740798     0.156001\n",
              "max_per_class_error      0.0647578  0.0660564  0.214286      0.0625        0.0344828     0.05          0.142857      0.0476191     0             0.0625        0             0.0333333\n",
              "mcc                      0.927621   0.0547608  0.847566      0.952501      0.954923      0.911539      0.843984      0.910714      1             0.903017      1             0.951972\n",
              "mean_per_class_accuracy  0.960328   0.035232   0.892857      0.96875       0.982759      0.955769      0.912946      0.955357      1             0.951509      1             0.983333\n",
              "mean_per_class_error     0.0396719  0.035232   0.107143      0.03125       0.0172414     0.0442308     0.0870536     0.0446429     0             0.0484914     0             0.0166667\n",
              "mse                      0.0441377  0.0226749  0.0620417     0.0377012     0.0215032     0.0596129     0.0706184     0.0543299     0.0114468     0.0693428     0.0124989     0.0422811\n",
              "pr_auc                   0.977882   0.023669   0.938531      0.992855      0.996638      0.980331      0.952928      0.982007      1             0.944435      1             0.991098\n",
              "precision                0.96449    0.0315774  1             1             0.944444      0.95          0.923077      0.952381      1             0.9375        1             0.9375\n",
              "r2                       0.805685   0.102998   0.706964      0.833801      0.907706      0.757421      0.666454      0.78171       0.954008      0.697372      0.941681      0.809735\n",
              "recall                   0.942024   0.0709415  0.785714      0.9375        1             0.95          0.857143      0.952381      1             0.9375        1             1\n",
              "rmse                     0.202062   0.0606329  0.249082      0.194168      0.14664       0.244158      0.265741      0.233088      0.10699       0.26333       0.111799      0.205624\n",
              "specificity              0.978632   0.0186053  1             1             0.965517      0.961538      0.96875       0.958333      1             0.965517      1             0.966667\n",
              "\n",
              "Scoring History: \n",
              "    timestamp            duration    number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
              "--  -------------------  ----------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ----------------  -------------------  -----------------  ---------------------------------\n",
              "    2023-07-05 11:31:40  5.663 sec   0                  0.5              0.693147            0.5             0.375824           1                0.624176                         0.5                0.693147              0.5               0.359649             1                  0.640351\n",
              "    2023-07-05 11:31:40  5.698 sec   5                  0.225101         0.220985            0.991465        0.987958           2.66082          0.0307692                        0.225428           0.222521              0.976779          0.978796             2.78049            0.0438596\n",
              "    2023-07-05 11:31:40  5.735 sec   10                 0.182175         0.144104            0.993503        0.991125           2.66082          0.0307692                        0.194942           0.160143              0.97728           0.979975             2.78049            0.0350877\n",
              "    2023-07-05 11:31:40  5.777 sec   15                 0.172352         0.130611            0.994533        0.992725           2.66082          0.0241758                        0.191048           0.152637              0.977113          0.980463             2.78049            0.0350877\n",
              "    2023-07-05 11:31:40  5.841 sec   20                 0.170296         0.1239              0.99408         0.992056           2.66082          0.0263736                        0.193492           0.150659              0.976445          0.979196             2.78049            0.0350877\n",
              "    2023-07-05 11:31:40  5.900 sec   25                 0.170296         0.1239              0.99408         0.992056           2.66082          0.0263736                        0.193495           0.150663              0.976445          0.979196             2.78049            0.0350877\n",
              "    2023-07-05 11:31:40  5.968 sec   30                 0.170295         0.123902            0.99408         0.992056           2.66082          0.0263736                        0.193487           0.150653              0.976445          0.979196             2.78049            0.0350877\n",
              "    2023-07-05 11:31:40  6.062 sec   35                 0.17029          0.123951            0.99408         0.992056           2.66082          0.0263736                        0.193367           0.150506              0.976445          0.979196             2.78049            0.0350877\n",
              "    2023-07-05 11:31:40  6.123 sec   36                 0.170513         0.123949            0.99408         0.992056           2.66082          0.0263736                        0.193961           0.151254              0.976445          0.979196             2.78049            0.0350877\n",
              "\n",
              "Variable Importances: \n",
              "variable              relative_importance    scaled_importance    percentage\n",
              "--------------------  ---------------------  -------------------  ------------\n",
              "concave points_worst  204.282                1                    0.341069\n",
              "area_worst            111.787                0.547218             0.186639\n",
              "concave points_mean   80.5573                0.394343             0.134498\n",
              "radius_worst          72.7003                0.355881             0.12138\n",
              "perimeter_worst       63.8343                0.312481             0.106577\n",
              "texture_worst         22.0758                0.108065             0.0368576\n",
              "concavity_worst       20.4532                0.100122             0.0341486\n",
              "texture_mean          10.5059                0.0514284            0.0175406\n",
              "radius_mean           8.47355                0.0414796            0.0141474\n",
              "concavity_mean        3.36487                0.0164716            0.00561796\n",
              "compactness_se        0.913376               0.00447114           0.00152497\n",
              "\n",
              "[tips]\n",
              "Use `model.explain()` to inspect the model.\n",
              "--\n",
              "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
            ],
            "text/html": [
              "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
              "=============\n",
              "H2OXGBoostEstimator : XGBoost\n",
              "Model Key: XGBoost_1_AutoML_1_20230705_113134\n",
              "</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-2.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-2 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-2 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-2 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-2 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-2 .h2o-table th,\n",
              "#h2o-table-2 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Model Summary: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>number_of_trees</th></tr></thead>\n",
              "    <tbody><tr><td></td>\n",
              "<td>36.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: xgboost\n",
              "** Reported on train data. **\n",
              "\n",
              "MSE: 0.029074514855628383\n",
              "RMSE: 0.17051250644931704\n",
              "LogLoss: 0.12394929039565182\n",
              "Mean Per-Class Error: 0.029270653158718393\n",
              "AUC: 0.9940799769376494\n",
              "AUCPR: 0.992056368504806\n",
              "Gini: 0.9881599538752988</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-3.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-3 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-3 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-3 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-3 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-3 .h2o-table th,\n",
              "#h2o-table-3 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-3 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-3\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4925362765789032</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>0</th>\n",
              "<th>1</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>0</td>\n",
              "<td>279.0</td>\n",
              "<td>5.0</td>\n",
              "<td>0.0176</td>\n",
              "<td> (5.0/284.0)</td></tr>\n",
              "<tr><td>1</td>\n",
              "<td>7.0</td>\n",
              "<td>164.0</td>\n",
              "<td>0.0409</td>\n",
              "<td> (7.0/171.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>286.0</td>\n",
              "<td>169.0</td>\n",
              "<td>0.0264</td>\n",
              "<td> (12.0/455.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-4.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-4 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-4 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-4 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-4 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-4 .h2o-table th,\n",
              "#h2o-table-4 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-4 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-4\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.4925363</td>\n",
              "<td>0.9647059</td>\n",
              "<td>38.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.3179893</td>\n",
              "<td>0.9710983</td>\n",
              "<td>49.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.5147656</td>\n",
              "<td>0.9713945</td>\n",
              "<td>37.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.5147656</td>\n",
              "<td>0.9736264</td>\n",
              "<td>37.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>0.9680020</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0588847</td>\n",
              "<td>1.0</td>\n",
              "<td>100.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>0.9680020</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.4925363</td>\n",
              "<td>0.9436960</td>\n",
              "<td>38.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.4028056</td>\n",
              "<td>0.9649123</td>\n",
              "<td>42.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.4925363</td>\n",
              "<td>0.9707293</td>\n",
              "<td>38.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>0.9680020</td>\n",
              "<td>284.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>0.9680020</td>\n",
              "<td>110.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0148769</td>\n",
              "<td>284.0</td>\n",
              "<td>134.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0588847</td>\n",
              "<td>171.0</td>\n",
              "<td>100.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>0.9680020</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>0.9680020</td>\n",
              "<td>0.6432749</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0148769</td>\n",
              "<td>1.0</td>\n",
              "<td>134.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0588847</td>\n",
              "<td>1.0</td>\n",
              "<td>100.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-5.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-5 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-5 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-5 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-5 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-5 .h2o-table th,\n",
              "#h2o-table-5 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-5 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-5\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 37.58 %, avg score: 37.29 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.1340659</td>\n",
              "<td>0.9680020</td>\n",
              "<td>2.6608187</td>\n",
              "<td>2.6608187</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9680020</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9680020</td>\n",
              "<td>0.3567251</td>\n",
              "<td>0.3567251</td>\n",
              "<td>166.0818713</td>\n",
              "<td>166.0818713</td>\n",
              "<td>0.3567251</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.1626374</td>\n",
              "<td>0.9576122</td>\n",
              "<td>2.6608187</td>\n",
              "<td>2.6608187</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9576122</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9661767</td>\n",
              "<td>0.0760234</td>\n",
              "<td>0.4327485</td>\n",
              "<td>166.0818713</td>\n",
              "<td>166.0818713</td>\n",
              "<td>0.4327485</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.2</td>\n",
              "<td>0.9505008</td>\n",
              "<td>2.6608187</td>\n",
              "<td>2.6608187</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9534877</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9638063</td>\n",
              "<td>0.0994152</td>\n",
              "<td>0.5321637</td>\n",
              "<td>166.0818713</td>\n",
              "<td>166.0818713</td>\n",
              "<td>0.5321637</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.3010989</td>\n",
              "<td>0.8075677</td>\n",
              "<td>2.6608187</td>\n",
              "<td>2.6608187</td>\n",
              "<td>1.0</td>\n",
              "<td>0.8971791</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9414351</td>\n",
              "<td>0.2690058</td>\n",
              "<td>0.8011696</td>\n",
              "<td>166.0818713</td>\n",
              "<td>166.0818713</td>\n",
              "<td>0.8011696</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.4</td>\n",
              "<td>0.3147044</td>\n",
              "<td>1.8330084</td>\n",
              "<td>2.4561404</td>\n",
              "<td>0.6888889</td>\n",
              "<td>0.5823229</td>\n",
              "<td>0.9230769</td>\n",
              "<td>0.8526436</td>\n",
              "<td>0.1812865</td>\n",
              "<td>0.9824561</td>\n",
              "<td>83.3008447</td>\n",
              "<td>145.6140351</td>\n",
              "<td>0.9331604</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.5010989</td>\n",
              "<td>0.0766930</td>\n",
              "<td>0.0578439</td>\n",
              "<td>1.9722735</td>\n",
              "<td>0.0217391</td>\n",
              "<td>0.1615786</td>\n",
              "<td>0.7412281</td>\n",
              "<td>0.7132182</td>\n",
              "<td>0.0058480</td>\n",
              "<td>0.9883041</td>\n",
              "<td>-94.2156115</td>\n",
              "<td>97.2273520</td>\n",
              "<td>0.7805576</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>0.6241758</td>\n",
              "<td>0.0503081</td>\n",
              "<td>0.0950292</td>\n",
              "<td>1.6021127</td>\n",
              "<td>0.0357143</td>\n",
              "<td>0.0583980</td>\n",
              "<td>0.6021127</td>\n",
              "<td>0.5840988</td>\n",
              "<td>0.0116959</td>\n",
              "<td>1.0</td>\n",
              "<td>-90.4970760</td>\n",
              "<td>60.2112676</td>\n",
              "<td>0.6021127</td></tr>\n",
              "<tr><td>8</td>\n",
              "<td>0.6989011</td>\n",
              "<td>0.0279195</td>\n",
              "<td>0.0</td>\n",
              "<td>1.4308176</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0365022</td>\n",
              "<td>0.5377358</td>\n",
              "<td>0.5255507</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>43.0817610</td>\n",
              "<td>0.4823944</td></tr>\n",
              "<tr><td>9</td>\n",
              "<td>0.8043956</td>\n",
              "<td>0.0177071</td>\n",
              "<td>0.0</td>\n",
              "<td>1.2431694</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0225316</td>\n",
              "<td>0.4672131</td>\n",
              "<td>0.4595810</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>24.3169399</td>\n",
              "<td>0.3133803</td></tr>\n",
              "<tr><td>10</td>\n",
              "<td>0.9318681</td>\n",
              "<td>0.0175245</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0731132</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0175245</td>\n",
              "<td>0.4033019</td>\n",
              "<td>0.3991110</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>7.3113208</td>\n",
              "<td>0.1091549</td></tr>\n",
              "<tr><td>11</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0148769</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0148769</td>\n",
              "<td>0.3758242</td>\n",
              "<td>0.3729324</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: xgboost\n",
              "** Reported on validation data. **\n",
              "\n",
              "MSE: 0.03762067586537018\n",
              "RMSE: 0.19396050078655236\n",
              "LogLoss: 0.1512542647982658\n",
              "Mean Per-Class Error: 0.03274306715669896\n",
              "AUC: 0.976445038422987\n",
              "AUCPR: 0.9791961628675718\n",
              "Gini: 0.952890076845974</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-6.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-6 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-6 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-6 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-6 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-6 .h2o-table th,\n",
              "#h2o-table-6 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-6 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-6\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.25368359684944153</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>0</th>\n",
              "<th>1</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>0</td>\n",
              "<td>70.0</td>\n",
              "<td>3.0</td>\n",
              "<td>0.0411</td>\n",
              "<td> (3.0/73.0)</td></tr>\n",
              "<tr><td>1</td>\n",
              "<td>1.0</td>\n",
              "<td>40.0</td>\n",
              "<td>0.0244</td>\n",
              "<td> (1.0/41.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>71.0</td>\n",
              "<td>43.0</td>\n",
              "<td>0.0351</td>\n",
              "<td> (4.0/114.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-7.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-7 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-7 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-7 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-7 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-7 .h2o-table th,\n",
              "#h2o-table-7 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-7 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-7\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.2536836</td>\n",
              "<td>0.9523810</td>\n",
              "<td>20.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.2536836</td>\n",
              "<td>0.9661836</td>\n",
              "<td>20.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.7056506</td>\n",
              "<td>0.9729730</td>\n",
              "<td>15.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.2536836</td>\n",
              "<td>0.9649123</td>\n",
              "<td>20.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>0.9680020</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0175245</td>\n",
              "<td>1.0</td>\n",
              "<td>46.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>0.9680020</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.2536836</td>\n",
              "<td>0.9252854</td>\n",
              "<td>20.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.2536836</td>\n",
              "<td>0.9589041</td>\n",
              "<td>20.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.2536836</td>\n",
              "<td>0.9672569</td>\n",
              "<td>20.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>0.9680020</td>\n",
              "<td>73.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>0.9680020</td>\n",
              "<td>27.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0148769</td>\n",
              "<td>73.0</td>\n",
              "<td>47.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0175245</td>\n",
              "<td>41.0</td>\n",
              "<td>46.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>0.9680020</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>0.9680020</td>\n",
              "<td>0.6585366</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0148769</td>\n",
              "<td>1.0</td>\n",
              "<td>47.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0175245</td>\n",
              "<td>1.0</td>\n",
              "<td>46.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-8.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-8 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-8 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-8 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-8 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-8 .h2o-table th,\n",
              "#h2o-table-8 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-8 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-8\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 35.96 %, avg score: 34.85 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.1228070</td>\n",
              "<td>0.9680020</td>\n",
              "<td>2.7804878</td>\n",
              "<td>2.7804878</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9680020</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9680020</td>\n",
              "<td>0.3414634</td>\n",
              "<td>0.3414634</td>\n",
              "<td>178.0487805</td>\n",
              "<td>178.0487805</td>\n",
              "<td>0.3414634</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.1578947</td>\n",
              "<td>0.9543629</td>\n",
              "<td>2.7804878</td>\n",
              "<td>2.7804878</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9551752</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9651516</td>\n",
              "<td>0.0975610</td>\n",
              "<td>0.4390244</td>\n",
              "<td>178.0487805</td>\n",
              "<td>178.0487805</td>\n",
              "<td>0.4390244</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.2105263</td>\n",
              "<td>0.9322835</td>\n",
              "<td>2.7804878</td>\n",
              "<td>2.7804878</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9354083</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9577157</td>\n",
              "<td>0.1463415</td>\n",
              "<td>0.5853659</td>\n",
              "<td>178.0487805</td>\n",
              "<td>178.0487805</td>\n",
              "<td>0.5853659</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.2982456</td>\n",
              "<td>0.7172713</td>\n",
              "<td>2.7804878</td>\n",
              "<td>2.7804878</td>\n",
              "<td>1.0</td>\n",
              "<td>0.8705932</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9320915</td>\n",
              "<td>0.2439024</td>\n",
              "<td>0.8292683</td>\n",
              "<td>178.0487805</td>\n",
              "<td>178.0487805</td>\n",
              "<td>0.8292683</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.4035088</td>\n",
              "<td>0.1690287</td>\n",
              "<td>1.3902439</td>\n",
              "<td>2.4178155</td>\n",
              "<td>0.5</td>\n",
              "<td>0.4511201</td>\n",
              "<td>0.8695652</td>\n",
              "<td>0.8066207</td>\n",
              "<td>0.1463415</td>\n",
              "<td>0.9756098</td>\n",
              "<td>39.0243902</td>\n",
              "<td>141.7815483</td>\n",
              "<td>0.8934180</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.5087719</td>\n",
              "<td>0.0588847</td>\n",
              "<td>0.0</td>\n",
              "<td>1.9175778</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0937150</td>\n",
              "<td>0.6896552</td>\n",
              "<td>0.6591230</td>\n",
              "<td>0.0</td>\n",
              "<td>0.9756098</td>\n",
              "<td>-100.0</td>\n",
              "<td>91.7577796</td>\n",
              "<td>0.7290344</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>0.5964912</td>\n",
              "<td>0.0359404</td>\n",
              "<td>0.0</td>\n",
              "<td>1.6355811</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0470055</td>\n",
              "<td>0.5882353</td>\n",
              "<td>0.5691057</td>\n",
              "<td>0.0</td>\n",
              "<td>0.9756098</td>\n",
              "<td>-100.0</td>\n",
              "<td>63.5581062</td>\n",
              "<td>0.5920481</td></tr>\n",
              "<tr><td>8</td>\n",
              "<td>0.7017544</td>\n",
              "<td>0.0235090</td>\n",
              "<td>0.0</td>\n",
              "<td>1.3902439</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0319946</td>\n",
              "<td>0.5</td>\n",
              "<td>0.4885390</td>\n",
              "<td>0.0</td>\n",
              "<td>0.9756098</td>\n",
              "<td>-100.0</td>\n",
              "<td>39.0243902</td>\n",
              "<td>0.4276646</td></tr>\n",
              "<tr><td>9</td>\n",
              "<td>0.9736842</td>\n",
              "<td>0.0175245</td>\n",
              "<td>0.0896932</td>\n",
              "<td>1.0270270</td>\n",
              "<td>0.0322581</td>\n",
              "<td>0.0192596</td>\n",
              "<td>0.3693694</td>\n",
              "<td>0.3574790</td>\n",
              "<td>0.0243902</td>\n",
              "<td>1.0</td>\n",
              "<td>-91.0306845</td>\n",
              "<td>2.7027027</td>\n",
              "<td>0.0410959</td></tr>\n",
              "<tr><td>10</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0148769</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0148769</td>\n",
              "<td>0.3596491</td>\n",
              "<td>0.3484632</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: xgboost\n",
              "** Reported on cross-validation data. **\n",
              "\n",
              "MSE: 0.044205368519838424\n",
              "RMSE: 0.21025072775103162\n",
              "LogLoss: 0.16637884924436225\n",
              "Mean Per-Class Error: 0.05391854048266205\n",
              "AUC: 0.9841137468083354\n",
              "AUCPR: 0.9796363289807396\n",
              "Gini: 0.9682274936166708</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-9.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-9 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-9 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-9 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-9 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-9 .h2o-table th,\n",
              "#h2o-table-9 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-9 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-9\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.35231223702430725</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>0</th>\n",
              "<th>1</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>0</td>\n",
              "<td>265.0</td>\n",
              "<td>19.0</td>\n",
              "<td>0.0669</td>\n",
              "<td> (19.0/284.0)</td></tr>\n",
              "<tr><td>1</td>\n",
              "<td>7.0</td>\n",
              "<td>164.0</td>\n",
              "<td>0.0409</td>\n",
              "<td> (7.0/171.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>272.0</td>\n",
              "<td>183.0</td>\n",
              "<td>0.0571</td>\n",
              "<td> (26.0/455.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-10.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-10 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-10 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-10 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-10 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-10 .h2o-table th,\n",
              "#h2o-table-10 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-10 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-10\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.3523122</td>\n",
              "<td>0.9265537</td>\n",
              "<td>103.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.3523122</td>\n",
              "<td>0.9457901</td>\n",
              "<td>103.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.6488545</td>\n",
              "<td>0.9533074</td>\n",
              "<td>71.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.6243538</td>\n",
              "<td>0.9428571</td>\n",
              "<td>74.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>0.9681047</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0317377</td>\n",
              "<td>1.0</td>\n",
              "<td>212.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>0.9681047</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.3523122</td>\n",
              "<td>0.8812343</td>\n",
              "<td>103.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.3933513</td>\n",
              "<td>0.9401408</td>\n",
              "<td>98.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.3523122</td>\n",
              "<td>0.9460815</td>\n",
              "<td>103.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>0.9681047</td>\n",
              "<td>284.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>0.9681047</td>\n",
              "<td>168.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0161675</td>\n",
              "<td>284.0</td>\n",
              "<td>239.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0317377</td>\n",
              "<td>171.0</td>\n",
              "<td>212.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>0.9681047</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>0.9681047</td>\n",
              "<td>0.9824561</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0161675</td>\n",
              "<td>1.0</td>\n",
              "<td>239.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0317377</td>\n",
              "<td>1.0</td>\n",
              "<td>212.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-11.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-11 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-11 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-11 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-11 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-11 .h2o-table th,\n",
              "#h2o-table-11 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-11 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-11\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 37.58 %, avg score: 37.58 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.0153846</td>\n",
              "<td>0.9646416</td>\n",
              "<td>2.6608187</td>\n",
              "<td>2.6608187</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9661258</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9661258</td>\n",
              "<td>0.0409357</td>\n",
              "<td>0.0409357</td>\n",
              "<td>166.0818713</td>\n",
              "<td>166.0818713</td>\n",
              "<td>0.0409357</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.0329670</td>\n",
              "<td>0.9641652</td>\n",
              "<td>2.6608187</td>\n",
              "<td>2.6608187</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9641652</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9650801</td>\n",
              "<td>0.0467836</td>\n",
              "<td>0.0877193</td>\n",
              "<td>166.0818713</td>\n",
              "<td>166.0818713</td>\n",
              "<td>0.0877193</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.0461538</td>\n",
              "<td>0.9632205</td>\n",
              "<td>2.6608187</td>\n",
              "<td>2.6608187</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9632205</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9645488</td>\n",
              "<td>0.0350877</td>\n",
              "<td>0.1228070</td>\n",
              "<td>166.0818713</td>\n",
              "<td>166.0818713</td>\n",
              "<td>0.1228070</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.0659341</td>\n",
              "<td>0.9616467</td>\n",
              "<td>2.6608187</td>\n",
              "<td>2.6608187</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9616467</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9636782</td>\n",
              "<td>0.0526316</td>\n",
              "<td>0.1754386</td>\n",
              "<td>166.0818713</td>\n",
              "<td>166.0818713</td>\n",
              "<td>0.1754386</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.1010989</td>\n",
              "<td>0.9592377</td>\n",
              "<td>2.6608187</td>\n",
              "<td>2.6608187</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9601760</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9624600</td>\n",
              "<td>0.0935673</td>\n",
              "<td>0.2690058</td>\n",
              "<td>166.0818713</td>\n",
              "<td>166.0818713</td>\n",
              "<td>0.2690058</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.1516484</td>\n",
              "<td>0.9519403</td>\n",
              "<td>2.6608187</td>\n",
              "<td>2.6608187</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9548322</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9599174</td>\n",
              "<td>0.1345029</td>\n",
              "<td>0.4035088</td>\n",
              "<td>166.0818713</td>\n",
              "<td>166.0818713</td>\n",
              "<td>0.4035088</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>0.2</td>\n",
              "<td>0.9348235</td>\n",
              "<td>2.6608187</td>\n",
              "<td>2.6608187</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9443512</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9561542</td>\n",
              "<td>0.1286550</td>\n",
              "<td>0.5321637</td>\n",
              "<td>166.0818713</td>\n",
              "<td>166.0818713</td>\n",
              "<td>0.5321637</td></tr>\n",
              "<tr><td>8</td>\n",
              "<td>0.3010989</td>\n",
              "<td>0.7810790</td>\n",
              "<td>2.5451309</td>\n",
              "<td>2.6219746</td>\n",
              "<td>0.9565217</td>\n",
              "<td>0.8873240</td>\n",
              "<td>0.9854015</td>\n",
              "<td>0.9330433</td>\n",
              "<td>0.2573099</td>\n",
              "<td>0.7894737</td>\n",
              "<td>154.5130943</td>\n",
              "<td>162.1974645</td>\n",
              "<td>0.7824314</td></tr>\n",
              "<tr><td>9</td>\n",
              "<td>0.4</td>\n",
              "<td>0.3541536</td>\n",
              "<td>1.6556205</td>\n",
              "<td>2.3830409</td>\n",
              "<td>0.6222222</td>\n",
              "<td>0.5669310</td>\n",
              "<td>0.8956044</td>\n",
              "<td>0.8425210</td>\n",
              "<td>0.1637427</td>\n",
              "<td>0.9532164</td>\n",
              "<td>65.5620533</td>\n",
              "<td>138.3040936</td>\n",
              "<td>0.8863150</td></tr>\n",
              "<tr><td>10</td>\n",
              "<td>0.5010989</td>\n",
              "<td>0.0901423</td>\n",
              "<td>0.2892194</td>\n",
              "<td>1.9606033</td>\n",
              "<td>0.1086957</td>\n",
              "<td>0.1979604</td>\n",
              "<td>0.7368421</td>\n",
              "<td>0.7124781</td>\n",
              "<td>0.0292398</td>\n",
              "<td>0.9824561</td>\n",
              "<td>-71.0780575</td>\n",
              "<td>96.0603263</td>\n",
              "<td>0.7711885</td></tr>\n",
              "<tr><td>11</td>\n",
              "<td>0.6</td>\n",
              "<td>0.0496738</td>\n",
              "<td>0.0591293</td>\n",
              "<td>1.6471735</td>\n",
              "<td>0.0222222</td>\n",
              "<td>0.0669556</td>\n",
              "<td>0.6190476</td>\n",
              "<td>0.6060733</td>\n",
              "<td>0.0058480</td>\n",
              "<td>0.9883041</td>\n",
              "<td>-94.0870695</td>\n",
              "<td>64.7173489</td>\n",
              "<td>0.6221069</td></tr>\n",
              "<tr><td>12</td>\n",
              "<td>0.6989011</td>\n",
              "<td>0.0362709</td>\n",
              "<td>0.0591293</td>\n",
              "<td>1.4224503</td>\n",
              "<td>0.0222222</td>\n",
              "<td>0.0437602</td>\n",
              "<td>0.5345912</td>\n",
              "<td>0.5265007</td>\n",
              "<td>0.0058480</td>\n",
              "<td>0.9941520</td>\n",
              "<td>-94.0870695</td>\n",
              "<td>42.2450256</td>\n",
              "<td>0.4730253</td></tr>\n",
              "<tr><td>13</td>\n",
              "<td>0.8</td>\n",
              "<td>0.0304273</td>\n",
              "<td>0.0578439</td>\n",
              "<td>1.25</td>\n",
              "<td>0.0217391</td>\n",
              "<td>0.0321457</td>\n",
              "<td>0.4697802</td>\n",
              "<td>0.4640272</td>\n",
              "<td>0.0058480</td>\n",
              "<td>1.0</td>\n",
              "<td>-94.2156115</td>\n",
              "<td>25.0</td>\n",
              "<td>0.3204225</td></tr>\n",
              "<tr><td>14</td>\n",
              "<td>0.9076923</td>\n",
              "<td>0.0233827</td>\n",
              "<td>0.0</td>\n",
              "<td>1.1016949</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0257063</td>\n",
              "<td>0.4140436</td>\n",
              "<td>0.4120231</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>10.1694915</td>\n",
              "<td>0.1478873</td></tr>\n",
              "<tr><td>15</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0161675</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0195924</td>\n",
              "<td>0.3758242</td>\n",
              "<td>0.3757987</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-12.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-12 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-12 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-12 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-12 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-12 .h2o-table th,\n",
              "#h2o-table-12 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-12 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-12\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Cross-Validation Metrics Summary: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>mean</th>\n",
              "<th>sd</th>\n",
              "<th>cv_1_valid</th>\n",
              "<th>cv_2_valid</th>\n",
              "<th>cv_3_valid</th>\n",
              "<th>cv_4_valid</th>\n",
              "<th>cv_5_valid</th>\n",
              "<th>cv_6_valid</th>\n",
              "<th>cv_7_valid</th>\n",
              "<th>cv_8_valid</th>\n",
              "<th>cv_9_valid</th>\n",
              "<th>cv_10_valid</th></tr></thead>\n",
              "    <tbody><tr><td>accuracy</td>\n",
              "<td>0.9671497</td>\n",
              "<td>0.0235589</td>\n",
              "<td>0.9347826</td>\n",
              "<td>0.9782609</td>\n",
              "<td>0.9782609</td>\n",
              "<td>0.9565217</td>\n",
              "<td>0.9347826</td>\n",
              "<td>0.9555556</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9555556</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9777778</td></tr>\n",
              "<tr><td>auc</td>\n",
              "<td>0.9838794</td>\n",
              "<td>0.0178793</td>\n",
              "<td>0.9609375</td>\n",
              "<td>0.9958333</td>\n",
              "<td>0.9979716</td>\n",
              "<td>0.9846154</td>\n",
              "<td>0.9754464</td>\n",
              "<td>0.9801587</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9482759</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9955556</td></tr>\n",
              "<tr><td>err</td>\n",
              "<td>0.0328502</td>\n",
              "<td>0.0235589</td>\n",
              "<td>0.0652174</td>\n",
              "<td>0.0217391</td>\n",
              "<td>0.0217391</td>\n",
              "<td>0.0434783</td>\n",
              "<td>0.0652174</td>\n",
              "<td>0.0444444</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0444444</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0222222</td></tr>\n",
              "<tr><td>err_count</td>\n",
              "<td>1.5</td>\n",
              "<td>1.0801234</td>\n",
              "<td>3.0</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>2.0</td>\n",
              "<td>3.0</td>\n",
              "<td>2.0</td>\n",
              "<td>0.0</td>\n",
              "<td>2.0</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td></tr>\n",
              "<tr><td>f0point5</td>\n",
              "<td>0.9588513</td>\n",
              "<td>0.0287485</td>\n",
              "<td>0.9482759</td>\n",
              "<td>0.9868421</td>\n",
              "<td>0.9550562</td>\n",
              "<td>0.95</td>\n",
              "<td>0.9090909</td>\n",
              "<td>0.9523810</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9375</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9493671</td></tr>\n",
              "<tr><td>f1</td>\n",
              "<td>0.9515683</td>\n",
              "<td>0.0406347</td>\n",
              "<td>0.88</td>\n",
              "<td>0.9677419</td>\n",
              "<td>0.9714286</td>\n",
              "<td>0.95</td>\n",
              "<td>0.8888889</td>\n",
              "<td>0.9523810</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9375</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9677419</td></tr>\n",
              "<tr><td>f2</td>\n",
              "<td>0.9454923</td>\n",
              "<td>0.0586199</td>\n",
              "<td>0.8208955</td>\n",
              "<td>0.9493671</td>\n",
              "<td>0.9883721</td>\n",
              "<td>0.95</td>\n",
              "<td>0.8695652</td>\n",
              "<td>0.9523810</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9375</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9868421</td></tr>\n",
              "<tr><td>lift_top_group</td>\n",
              "<td>2.7496953</td>\n",
              "<td>0.4955653</td>\n",
              "<td>3.2857144</td>\n",
              "<td>2.875</td>\n",
              "<td>2.7058823</td>\n",
              "<td>2.3</td>\n",
              "<td>3.2857144</td>\n",
              "<td>2.142857</td>\n",
              "<td>1.875</td>\n",
              "<td>2.8125</td>\n",
              "<td>3.2142856</td>\n",
              "<td>3.0</td></tr>\n",
              "<tr><td>logloss</td>\n",
              "<td>0.1662221</td>\n",
              "<td>0.0649039</td>\n",
              "<td>0.2129980</td>\n",
              "<td>0.1471438</td>\n",
              "<td>0.1064336</td>\n",
              "<td>0.2047186</td>\n",
              "<td>0.2311378</td>\n",
              "<td>0.199252</td>\n",
              "<td>0.0746679</td>\n",
              "<td>0.2557887</td>\n",
              "<td>0.0740798</td>\n",
              "<td>0.1560008</td></tr>\n",
              "<tr><td>max_per_class_error</td>\n",
              "<td>0.0647578</td>\n",
              "<td>0.0660564</td>\n",
              "<td>0.2142857</td>\n",
              "<td>0.0625</td>\n",
              "<td>0.0344828</td>\n",
              "<td>0.05</td>\n",
              "<td>0.1428571</td>\n",
              "<td>0.0476191</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0625</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0333333</td></tr>\n",
              "<tr><td>mcc</td>\n",
              "<td>0.9276215</td>\n",
              "<td>0.0547608</td>\n",
              "<td>0.8475655</td>\n",
              "<td>0.9525009</td>\n",
              "<td>0.9549227</td>\n",
              "<td>0.9115385</td>\n",
              "<td>0.8439837</td>\n",
              "<td>0.9107143</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9030172</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9519716</td></tr>\n",
              "<tr><td>mean_per_class_accuracy</td>\n",
              "<td>0.9603280</td>\n",
              "<td>0.0352320</td>\n",
              "<td>0.8928571</td>\n",
              "<td>0.96875</td>\n",
              "<td>0.9827586</td>\n",
              "<td>0.9557692</td>\n",
              "<td>0.9129464</td>\n",
              "<td>0.9553571</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9515086</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9833333</td></tr>\n",
              "<tr><td>mean_per_class_error</td>\n",
              "<td>0.0396719</td>\n",
              "<td>0.0352320</td>\n",
              "<td>0.1071429</td>\n",
              "<td>0.03125</td>\n",
              "<td>0.0172414</td>\n",
              "<td>0.0442308</td>\n",
              "<td>0.0870536</td>\n",
              "<td>0.0446429</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0484914</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0166667</td></tr>\n",
              "<tr><td>mse</td>\n",
              "<td>0.0441377</td>\n",
              "<td>0.0226749</td>\n",
              "<td>0.0620417</td>\n",
              "<td>0.0377012</td>\n",
              "<td>0.0215032</td>\n",
              "<td>0.0596129</td>\n",
              "<td>0.0706184</td>\n",
              "<td>0.0543299</td>\n",
              "<td>0.0114468</td>\n",
              "<td>0.0693428</td>\n",
              "<td>0.0124989</td>\n",
              "<td>0.0422811</td></tr>\n",
              "<tr><td>pr_auc</td>\n",
              "<td>0.9778822</td>\n",
              "<td>0.0236690</td>\n",
              "<td>0.9385305</td>\n",
              "<td>0.9928552</td>\n",
              "<td>0.9966378</td>\n",
              "<td>0.9803309</td>\n",
              "<td>0.9529279</td>\n",
              "<td>0.9820066</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9444352</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9910979</td></tr>\n",
              "<tr><td>precision</td>\n",
              "<td>0.9644902</td>\n",
              "<td>0.0315774</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9444444</td>\n",
              "<td>0.95</td>\n",
              "<td>0.9230769</td>\n",
              "<td>0.9523810</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9375</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9375</td></tr>\n",
              "<tr><td>r2</td>\n",
              "<td>0.8056853</td>\n",
              "<td>0.1029978</td>\n",
              "<td>0.7069637</td>\n",
              "<td>0.8338005</td>\n",
              "<td>0.9077061</td>\n",
              "<td>0.7574214</td>\n",
              "<td>0.6664543</td>\n",
              "<td>0.7817103</td>\n",
              "<td>0.9540083</td>\n",
              "<td>0.6973723</td>\n",
              "<td>0.9416813</td>\n",
              "<td>0.8097349</td></tr>\n",
              "<tr><td>recall</td>\n",
              "<td>0.9420238</td>\n",
              "<td>0.0709415</td>\n",
              "<td>0.7857143</td>\n",
              "<td>0.9375</td>\n",
              "<td>1.0</td>\n",
              "<td>0.95</td>\n",
              "<td>0.8571429</td>\n",
              "<td>0.9523810</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9375</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td></tr>\n",
              "<tr><td>rmse</td>\n",
              "<td>0.2020618</td>\n",
              "<td>0.0606329</td>\n",
              "<td>0.2490817</td>\n",
              "<td>0.1941680</td>\n",
              "<td>0.1466398</td>\n",
              "<td>0.2441575</td>\n",
              "<td>0.2657412</td>\n",
              "<td>0.2330877</td>\n",
              "<td>0.1069898</td>\n",
              "<td>0.2633303</td>\n",
              "<td>0.1117986</td>\n",
              "<td>0.2056237</td></tr>\n",
              "<tr><td>specificity</td>\n",
              "<td>0.9786323</td>\n",
              "<td>0.0186053</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9655172</td>\n",
              "<td>0.9615384</td>\n",
              "<td>0.96875</td>\n",
              "<td>0.9583333</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9655172</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9666666</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-13.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-13 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-13 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-13 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-13 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-13 .h2o-table th,\n",
              "#h2o-table-13 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-13 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-13\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Scoring History: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>timestamp</th>\n",
              "<th>duration</th>\n",
              "<th>number_of_trees</th>\n",
              "<th>training_rmse</th>\n",
              "<th>training_logloss</th>\n",
              "<th>training_auc</th>\n",
              "<th>training_pr_auc</th>\n",
              "<th>training_lift</th>\n",
              "<th>training_classification_error</th>\n",
              "<th>validation_rmse</th>\n",
              "<th>validation_logloss</th>\n",
              "<th>validation_auc</th>\n",
              "<th>validation_pr_auc</th>\n",
              "<th>validation_lift</th>\n",
              "<th>validation_classification_error</th></tr></thead>\n",
              "    <tbody><tr><td></td>\n",
              "<td>2023-07-05 11:31:40</td>\n",
              "<td> 5.663 sec</td>\n",
              "<td>0.0</td>\n",
              "<td>0.5</td>\n",
              "<td>0.6931472</td>\n",
              "<td>0.5</td>\n",
              "<td>0.3758242</td>\n",
              "<td>1.0</td>\n",
              "<td>0.6241758</td>\n",
              "<td>0.5</td>\n",
              "<td>0.6931472</td>\n",
              "<td>0.5</td>\n",
              "<td>0.3596491</td>\n",
              "<td>1.0</td>\n",
              "<td>0.6403509</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-07-05 11:31:40</td>\n",
              "<td> 5.698 sec</td>\n",
              "<td>5.0</td>\n",
              "<td>0.2251009</td>\n",
              "<td>0.2209849</td>\n",
              "<td>0.9914649</td>\n",
              "<td>0.9879580</td>\n",
              "<td>2.6608187</td>\n",
              "<td>0.0307692</td>\n",
              "<td>0.2254283</td>\n",
              "<td>0.2225214</td>\n",
              "<td>0.9767792</td>\n",
              "<td>0.9787964</td>\n",
              "<td>2.7804878</td>\n",
              "<td>0.0438596</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-07-05 11:31:40</td>\n",
              "<td> 5.735 sec</td>\n",
              "<td>10.0</td>\n",
              "<td>0.1821748</td>\n",
              "<td>0.1441039</td>\n",
              "<td>0.9935034</td>\n",
              "<td>0.9911247</td>\n",
              "<td>2.6608187</td>\n",
              "<td>0.0307692</td>\n",
              "<td>0.1949417</td>\n",
              "<td>0.1601430</td>\n",
              "<td>0.9772803</td>\n",
              "<td>0.9799751</td>\n",
              "<td>2.7804878</td>\n",
              "<td>0.0350877</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-07-05 11:31:40</td>\n",
              "<td> 5.777 sec</td>\n",
              "<td>15.0</td>\n",
              "<td>0.1723523</td>\n",
              "<td>0.1306105</td>\n",
              "<td>0.9945330</td>\n",
              "<td>0.9927252</td>\n",
              "<td>2.6608187</td>\n",
              "<td>0.0241758</td>\n",
              "<td>0.1910482</td>\n",
              "<td>0.1526369</td>\n",
              "<td>0.9771133</td>\n",
              "<td>0.9804633</td>\n",
              "<td>2.7804878</td>\n",
              "<td>0.0350877</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-07-05 11:31:40</td>\n",
              "<td> 5.841 sec</td>\n",
              "<td>20.0</td>\n",
              "<td>0.1702960</td>\n",
              "<td>0.1239005</td>\n",
              "<td>0.9940800</td>\n",
              "<td>0.9920564</td>\n",
              "<td>2.6608187</td>\n",
              "<td>0.0263736</td>\n",
              "<td>0.1934925</td>\n",
              "<td>0.1506594</td>\n",
              "<td>0.9764450</td>\n",
              "<td>0.9791962</td>\n",
              "<td>2.7804878</td>\n",
              "<td>0.0350877</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-07-05 11:31:40</td>\n",
              "<td> 5.900 sec</td>\n",
              "<td>25.0</td>\n",
              "<td>0.1702965</td>\n",
              "<td>0.1238999</td>\n",
              "<td>0.9940800</td>\n",
              "<td>0.9920564</td>\n",
              "<td>2.6608187</td>\n",
              "<td>0.0263736</td>\n",
              "<td>0.1934951</td>\n",
              "<td>0.1506626</td>\n",
              "<td>0.9764450</td>\n",
              "<td>0.9791962</td>\n",
              "<td>2.7804878</td>\n",
              "<td>0.0350877</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-07-05 11:31:40</td>\n",
              "<td> 5.968 sec</td>\n",
              "<td>30.0</td>\n",
              "<td>0.1702950</td>\n",
              "<td>0.1239018</td>\n",
              "<td>0.9940800</td>\n",
              "<td>0.9920564</td>\n",
              "<td>2.6608187</td>\n",
              "<td>0.0263736</td>\n",
              "<td>0.1934870</td>\n",
              "<td>0.1506526</td>\n",
              "<td>0.9764450</td>\n",
              "<td>0.9791962</td>\n",
              "<td>2.7804878</td>\n",
              "<td>0.0350877</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-07-05 11:31:40</td>\n",
              "<td> 6.062 sec</td>\n",
              "<td>35.0</td>\n",
              "<td>0.1702896</td>\n",
              "<td>0.1239514</td>\n",
              "<td>0.9940800</td>\n",
              "<td>0.9920564</td>\n",
              "<td>2.6608187</td>\n",
              "<td>0.0263736</td>\n",
              "<td>0.1933670</td>\n",
              "<td>0.1505057</td>\n",
              "<td>0.9764450</td>\n",
              "<td>0.9791962</td>\n",
              "<td>2.7804878</td>\n",
              "<td>0.0350877</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-07-05 11:31:40</td>\n",
              "<td> 6.123 sec</td>\n",
              "<td>36.0</td>\n",
              "<td>0.1705125</td>\n",
              "<td>0.1239493</td>\n",
              "<td>0.9940800</td>\n",
              "<td>0.9920564</td>\n",
              "<td>2.6608187</td>\n",
              "<td>0.0263736</td>\n",
              "<td>0.1939605</td>\n",
              "<td>0.1512543</td>\n",
              "<td>0.9764450</td>\n",
              "<td>0.9791962</td>\n",
              "<td>2.7804878</td>\n",
              "<td>0.0350877</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-14.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-14 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-14 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-14 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-14 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-14 .h2o-table th,\n",
              "#h2o-table-14 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-14 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-14\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Variable Importances: </caption>\n",
              "    <thead><tr><th>variable</th>\n",
              "<th>relative_importance</th>\n",
              "<th>scaled_importance</th>\n",
              "<th>percentage</th></tr></thead>\n",
              "    <tbody><tr><td>concave points_worst</td>\n",
              "<td>204.2824097</td>\n",
              "<td>1.0</td>\n",
              "<td>0.3410687</td></tr>\n",
              "<tr><td>area_worst</td>\n",
              "<td>111.7869415</td>\n",
              "<td>0.5472177</td>\n",
              "<td>0.1866388</td></tr>\n",
              "<tr><td>concave points_mean</td>\n",
              "<td>80.5573425</td>\n",
              "<td>0.3943430</td>\n",
              "<td>0.1344981</td></tr>\n",
              "<tr><td>radius_worst</td>\n",
              "<td>72.7002869</td>\n",
              "<td>0.3558813</td>\n",
              "<td>0.1213800</td></tr>\n",
              "<tr><td>perimeter_worst</td>\n",
              "<td>63.8343277</td>\n",
              "<td>0.3124808</td>\n",
              "<td>0.1065774</td></tr>\n",
              "<tr><td>texture_worst</td>\n",
              "<td>22.0757656</td>\n",
              "<td>0.1080649</td>\n",
              "<td>0.0368576</td></tr>\n",
              "<tr><td>concavity_worst</td>\n",
              "<td>20.4532471</td>\n",
              "<td>0.1001224</td>\n",
              "<td>0.0341486</td></tr>\n",
              "<tr><td>texture_mean</td>\n",
              "<td>10.5059090</td>\n",
              "<td>0.0514284</td>\n",
              "<td>0.0175406</td></tr>\n",
              "<tr><td>radius_mean</td>\n",
              "<td>8.4735489</td>\n",
              "<td>0.0414796</td>\n",
              "<td>0.0141474</td></tr>\n",
              "<tr><td>concavity_mean</td>\n",
              "<td>3.3648682</td>\n",
              "<td>0.0164716</td>\n",
              "<td>0.0056180</td></tr>\n",
              "<tr><td>compactness_se</td>\n",
              "<td>0.9133759</td>\n",
              "<td>0.0044711</td>\n",
              "<td>0.0015250</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
              "\n",
              "[tips]\n",
              "Use `model.explain()` to inspect the model.\n",
              "--\n",
              "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.model_performance(train).accuracy()"
      ],
      "metadata": {
        "id": "G_PyYFNMs97_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f88663a-11c1-46d8-fbb2-dd62539a78bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.5147656202316284, 0.9736263736263736]]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = aml.get_best_model()\n",
        "HATr  = best_model.model_performance(train)\n",
        "HATe  = best_model.model_performance(valid)"
      ],
      "metadata": {
        "id": "jKquKjVVJBL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_h2o = pd.DataFrame(h2o.as_list(best_model.predict(valid)))['predict']\n",
        "y_test_h2o = np.array(valid1['diagnosis']).copy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-caBWGPlp8P",
        "outputId": "f6c58479-d3e5-47cd-8dfd-d269f520e1a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xgboost prediction progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SFOLD DATA AUTOML\n",
        "#strain, svalid = shdf.split_frame(ratios=[.8], seed=123)\n",
        "shdf  = newdata.copy()\n",
        "#shdf['y_test'] = shdf['y_test'].replace(0,\"B\")\n",
        "#shdf['y_test'] = shdf['y_test'].replace(1,\"M\")\n",
        "shy = \"y_test\"\n",
        "shx = list(shdf.columns)\n",
        "shx.remove(shy)\n",
        "\n",
        "shdf.iloc[:,0:6] = StandardScaler().fit_transform(shdf.iloc[:,0:6])\n",
        "#shdf.iloc[:,-1] = LabelEncoder().fit_transform(shdf.iloc[:,-1])\n",
        "strain1, svalid1 = train_test_split(shdf, test_size=0.2,random_state=123)\n",
        "strain = h2o.H2OFrame(strain1)\n",
        "svalid = h2o.H2OFrame(svalid1)\n",
        "strain[\"y_test\"] = strain[\"y_test\"].asfactor()\n",
        "svalid[\"y_test\"] = svalid[\"y_test\"].asfactor()\n",
        "\n",
        "st = time.time()\n",
        "\n",
        "\n",
        "saml = H2OAutoML(include_algos = ['DeepLearning'],max_models = 10, seed = 123, verbosity=\"info\", nfolds=10, sort_metric='accuracy')\n",
        "\n",
        "\n",
        "saml.train(x = shx, y = shy, training_frame = strain, validation_frame = svalid)\n",
        "sautoend = time.time() - st\n",
        "sbest_model = saml.get_best_model()\n",
        "sHATr  = sbest_model.model_performance(strain)\n",
        "sHATe  = sbest_model.model_performance(svalid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMDqylVK7svS",
        "outputId": "f3d39614-7b81-49c5-bcc1-449ce9dd4f9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n",
            "Parse progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n",
            "AutoML progress: |\n",
            "11:33:50.133: Project: AutoML_2_20230705_113350\n",
            "11:33:50.133: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n",
            "11:33:50.134: Setting stopping tolerance adaptively based on the training frame: 0.04688072309384954\n",
            "11:33:50.134: Build control seed: 123\n",
            "11:33:50.134: training frame: Frame key: AutoML_2_20230705_113350_training_py_11_sid_9fa1    cols: 7    rows: 455  chunks: 1    size: 6691  checksum: -2264614507710689488\n",
            "11:33:50.135: validation frame: Frame key: py_12_sid_9fa1    cols: 7    rows: 114  chunks: 1    size: 2557  checksum: -5131178475415970944\n",
            "11:33:50.135: leaderboard frame: NULL\n",
            "11:33:50.135: blending frame: NULL\n",
            "11:33:50.135: response column: y_test\n",
            "11:33:50.135: fold column: null\n",
            "11:33:50.135: weights column: null\n",
            "11:33:50.135: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (7g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (7g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (6g, 60w)]}, {StackedEnsemble : [monotonic (9g, 10w), best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
            "11:33:50.137: Disabling Algo: DRF as requested by the user.\n",
            "11:33:50.137: Disabling Algo: StackedEnsemble as requested by the user.\n",
            "11:33:50.137: Disabling Algo: GBM as requested by the user.\n",
            "11:33:50.137: Disabling Algo: GLM as requested by the user.\n",
            "11:33:50.137: Disabling Algo: XGBoost as requested by the user.\n",
            "11:33:50.137: AutoML job created: 2023.07.05 11:33:50.133\n",
            "11:33:50.140: AutoML build started: 2023.07.05 11:33:50.140\n",
            "11:33:50.170: AutoML: starting DeepLearning_1_AutoML_2_20230705_113350 model training\n",
            "\n",
            "â–ˆâ–ˆ\n",
            "11:33:53.69: New leader: DeepLearning_1_AutoML_2_20230705_113350, accuracy: 0.9384615384615385\n",
            "11:33:53.83: AutoML: starting DeepLearning_grid_1_AutoML_2_20230705_113350 hyperparameter search\n",
            "\n",
            "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "11:39:24.280: New leader: DeepLearning_grid_1_AutoML_2_20230705_113350_model_2, accuracy: 0.9384615384615385\n",
            "11:42:40.119: AutoML: starting DeepLearning_grid_2_AutoML_2_20230705_113350 hyperparameter search\n",
            "\n",
            "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "11:45:46.196: New leader: DeepLearning_grid_2_AutoML_2_20230705_113350_model_1, accuracy: 0.9340659340659341\n",
            "11:51:42.686: AutoML: starting DeepLearning_grid_3_AutoML_2_20230705_113350 hyperparameter search\n",
            "\n",
            "â–ˆâ–ˆ| (done) 100%\n",
            "\n",
            "12:01:43.628: Skipping StackedEnsemble 'monotonic' due to the exclude_algos option or it is already trained.\n",
            "12:01:43.629: Skipping StackedEnsemble 'best_of_family_xglm' due to the exclude_algos option or it is already trained.\n",
            "12:01:43.632: Skipping StackedEnsemble 'all_xglm' due to the exclude_algos option or it is already trained.\n",
            "12:01:43.632: Actual modeling steps: [{DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}]\n",
            "12:01:43.632: AutoML build stopped: 2023.07.05 12:01:43.632\n",
            "12:01:43.632: AutoML build done: built 10 models\n",
            "12:01:43.632: AutoML duration: 27 min 53.492 sec\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sbest_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W-pmhLYk7zQ9",
        "outputId": "743a0f4c-9bf8-4076-def9-0aaa59374478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model Details\n",
              "=============\n",
              "H2ODeepLearningEstimator : Deep Learning\n",
              "Model Key: DeepLearning_grid_2_AutoML_2_20230705_113350_model_1\n",
              "\n",
              "\n",
              "Status of Neuron Layers: predicting y_test, 2-class classification, bernoulli distribution, CrossEntropy loss, 602 weights/biases, 11.8 KB, 3,103,100 training samples, mini-batch size 1\n",
              "    layer    units    type              dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight           weight_rms          mean_bias               bias_rms\n",
              "--  -------  -------  ----------------  ---------  ----  ----  ---------------------  --------------------  ----------  --------------------  ------------------  ----------------------  -------------------\n",
              "    1        6        Input             0.0\n",
              "    2        20       RectifierDropout  20.0       0.0   0.0   0.0019689237997226883  0.001358123030513525  0.0         -0.03810954527386154  0.5392730236053467  -0.0033748034963270806  0.3420414924621582\n",
              "    3        20       RectifierDropout  20.0       0.0   0.0   0.0016403184803675686  0.003264199011027813  0.0         -0.14952308519386862  0.3652282953262329  0.04700749861386243     0.39474940299987793\n",
              "    4        2        Softmax                      0.0   0.0   0.006132629289641045   0.003359326161444187  0.0         0.03785821977071464   1.7657928466796875  0.0005770644247454215   0.5357174873352051\n",
              "\n",
              "ModelMetricsBinomial: deeplearning\n",
              "** Reported on train data. **\n",
              "\n",
              "MSE: 0.04254059709762216\n",
              "RMSE: 0.20625372020310848\n",
              "LogLoss: 0.17887338748788162\n",
              "Mean Per-Class Error: 0.054423029404497156\n",
              "AUC: 0.9618750514784614\n",
              "AUCPR: 0.9592124168317213\n",
              "Gini: 0.9237501029569228\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.34571171077870927\n",
              "       0    1    Error    Rate\n",
              "-----  ---  ---  -------  ------------\n",
              "0      278  6    0.0211   (6.0/284.0)\n",
              "1      15   156  0.0877   (15.0/171.0)\n",
              "Total  293  162  0.0462   (21.0/455.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.345712     0.936937  14\n",
              "max f2                       0.250521     0.92723   16\n",
              "max f0point5                 0.566203     0.960809  11\n",
              "max accuracy                 0.431915     0.953846  13\n",
              "max precision                0.998808     1         0\n",
              "max recall                   0.0707055    1         18\n",
              "max specificity              0.998808     1         0\n",
              "max absolute_mcc             0.431915     0.901578  13\n",
              "max min_per_class_accuracy   0.116075     0.929825  17\n",
              "max mean_per_class_accuracy  0.345712     0.945577  14\n",
              "max tns                      0.998808     284       0\n",
              "max fns                      0.998808     170       0\n",
              "max fps                      4.2204e-05   284       32\n",
              "max tps                      0.0707055    171       18\n",
              "max tnr                      0.998808     1         0\n",
              "max fnr                      0.998808     0.994152  0\n",
              "max fpr                      4.2204e-05   1         32\n",
              "max tpr                      0.0707055    1         18\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 37.58 %, avg score: 36.38 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  --------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.0153846                   0.996771           2.66082   2.66082            1                0.997328    1                           0.997328            0.0409357       0.0409357                  166.082   166.082            0.0409357\n",
              "2        0.021978                    0.99112            2.66082   2.66082            1                0.993839    1                           0.996281            0.0175439       0.0584795                  166.082   166.082            0.0584795\n",
              "3        0.323077                    0.922213           2.62197   2.62462            0.985401         0.923224    0.986395                    0.928194            0.789474        0.847953                   162.197   162.462            0.840911\n",
              "4        0.945055                    0.0707055          0.244457  1.05814            0.0918728        0.101894    0.397674                    0.384374            0.152047        1                          -75.5543  5.81395            0.0880282\n",
              "5        1                           4.2204e-05         0         1                  0                0.00922718  0.375824                    0.363761            0               1                          -100      0                  0\n",
              "\n",
              "ModelMetricsBinomial: deeplearning\n",
              "** Reported on validation data. **\n",
              "\n",
              "MSE: 0.08192587400291837\n",
              "RMSE: 0.28622696239683354\n",
              "LogLoss: 0.30930297760308006\n",
              "Mean Per-Class Error: 0.10591379886401604\n",
              "AUC: 0.8914132976946209\n",
              "AUCPR: 0.8551767026479652\n",
              "Gini: 0.7828265953892417\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5662031596113569\n",
              "       0    1    Error    Rate\n",
              "-----  ---  ---  -------  ------------\n",
              "0      70   3    0.0411   (3.0/73.0)\n",
              "1      7    34   0.1707   (7.0/41.0)\n",
              "Total  77   37   0.0877   (10.0/114.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.566203     0.871795  6\n",
              "max f2                       0.566203     0.845771  6\n",
              "max f0point5                 0.922213     0.924855  3\n",
              "max accuracy                 0.922213     0.912281  3\n",
              "max precision                0.994013     1         0\n",
              "max recall                   0.0137673    1         10\n",
              "max specificity              0.994013     1         0\n",
              "max absolute_mcc             0.922213     0.81139   3\n",
              "max min_per_class_accuracy   0.566203     0.829268  6\n",
              "max mean_per_class_accuracy  0.566203     0.894086  6\n",
              "max tns                      0.994013     73        0\n",
              "max fns                      0.994013     40        0\n",
              "max fps                      4.2204e-05   73        12\n",
              "max tps                      0.0137673    41        10\n",
              "max tnr                      0.994013     1         0\n",
              "max fnr                      0.994013     0.97561   0\n",
              "max fpr                      4.2204e-05   1         12\n",
              "max tpr                      0.0137673    1         10\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 35.96 %, avg score: 34.29 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  --------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.0175439                   0.95754            2.78049   2.78049            1                0.978204   1                           0.978204            0.0487805       0.0487805                  178.049   178.049            0.0487805\n",
              "2        0.0263158                   0.924312           0         1.85366            0                0.92505    0.666667                    0.960486            0               0.0487805                  -100      85.3659            0.0350819\n",
              "3        0.289474                    0.922213           2.78049   2.69623            1                0.922213   0.969697                    0.925692            0.731707        0.780488                   178.049   169.623            0.766789\n",
              "4        0.298246                    0.843788           0         2.61693            0                0.894301   0.941176                    0.924769            0               0.780488                   -100      161.693            0.753091\n",
              "5        0.95614                     0.0707055          0.296585  1.02036            0.106667         0.101141   0.366972                    0.358052            0.195122        0.97561                    -70.3415  2.03625            0.0304043\n",
              "6        1                           4.2204e-05         0.556098  1                  0.2              0.0116588  0.359649                    0.34286             0.0243902       1                          -44.3902  0                  0\n",
              "\n",
              "ModelMetricsBinomial: deeplearning\n",
              "** Reported on cross-validation data. **\n",
              "\n",
              "MSE: 0.05900454322012961\n",
              "RMSE: 0.24290850792043\n",
              "LogLoss: 0.25156113091399396\n",
              "Mean Per-Class Error: 0.07492175273865415\n",
              "AUC: 0.9431574829091508\n",
              "AUCPR: 0.9315693507825556\n",
              "Gini: 0.8863149658183016\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4622007295193631\n",
              "       0    1    Error    Rate\n",
              "-----  ---  ---  -------  ------------\n",
              "0      273  11   0.0387   (11.0/284.0)\n",
              "1      19   152  0.1111   (19.0/171.0)\n",
              "Total  292  163  0.0659   (30.0/455.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.462201     0.91018   35\n",
              "max f2                       0.15445      0.907494  42\n",
              "max f0point5                 0.778866     0.933926  26\n",
              "max accuracy                 0.589493     0.934066  31\n",
              "max precision                0.999895     1         0\n",
              "max recall                   0.000766845  1         74\n",
              "max specificity              0.999895     1         0\n",
              "max absolute_mcc             0.589493     0.858871  31\n",
              "max min_per_class_accuracy   0.15445      0.906433  42\n",
              "max mean_per_class_accuracy  0.15445      0.926808  42\n",
              "max tns                      0.999895     284       0\n",
              "max fns                      0.999895     158       0\n",
              "max fps                      0.000531738  284       77\n",
              "max tps                      0.000766845  171       74\n",
              "max tnr                      0.999895     1         0\n",
              "max fnr                      0.999895     0.923977  0\n",
              "max fpr                      0.000531738  1         77\n",
              "max tpr                      0.000766845  1         74\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 37.58 %, avg score: 37.58 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.0285714                   0.999895           2.66082   2.66082            1                0.999895     1                           0.999895            0.0760234       0.0760234                  166.082   166.082            0.0760234\n",
              "2        0.0505495                   0.999871           2.66082   2.66082            1                0.999871     1                           0.999884            0.0584795       0.134503                   166.082   166.082            0.134503\n",
              "3        0.0505495                   0.99976            0         2.66082            0                0            1                           0.999884            0               0.134503                   -100      166.082            0.134503\n",
              "4        0.120879                    0.993548           2.49452   2.56406            0.9375           0.994494     0.963636                    0.996748            0.175439        0.309942                   149.452   156.406            0.302899\n",
              "5        0.151648                    0.992658           2.66082   2.58369            1                0.992963     0.971014                    0.99598             0.0818713       0.391813                   166.082   158.369            0.384771\n",
              "6        0.202198                    0.986821           2.66082   2.60297            1                0.987026     0.978261                    0.993742            0.134503        0.526316                   166.082   160.297            0.519274\n",
              "7        0.305495                    0.958751           2.43437   2.54596            0.914894         0.972296     0.956835                    0.98649             0.251462        0.777778                   143.437   154.596            0.756651\n",
              "8        0.43956                     0.0978934          1.00326   2.07544            0.377049         0.39167      0.78                        0.80507             0.134503        0.912281                   0.325951  107.544            0.757351\n",
              "9        0.501099                    0.0734633          0.285088  1.85557            0.107143         0.0963017    0.697368                    0.718028            0.0175439       0.929825                   -71.4912  85.5571            0.686867\n",
              "10       0.632967                    0.0461309          0.133041  1.49671            0.05             0.0494794    0.5625                      0.578747            0.0175439       0.947368                   -86.6959  49.6711            0.503706\n",
              "11       0.723077                    0.044585           0.064898  1.31828            0.0243902        0.045105     0.495441                    0.512245            0.00584795      0.953216                   -93.5102  31.8278            0.368709\n",
              "12       0.846154                    0.0361137          0.190058  1.15417            0.0714286        0.0394091    0.433766                    0.443469            0.0233918       0.976608                   -80.9942  15.4173            0.209003\n",
              "13       0.945055                    0.00076685         0.236517  1.05814            0.0888889        0.00493891   0.397674                    0.397576            0.0233918       1                          -76.3483  5.81395            0.0880282\n",
              "14       1                           0.00053174         0         1                  0                0.000572662  0.375824                    0.375763            0               1                          -100      0                  0\n",
              "\n",
              "Cross-Validation Metrics Summary: \n",
              "                         mean       sd         cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid    cv_6_valid    cv_7_valid    cv_8_valid    cv_9_valid    cv_10_valid\n",
              "-----------------------  ---------  ---------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  -------------\n",
              "accuracy                 0.949517   0.0399085  0.978261      0.978261      0.978261      0.913044      0.869565      0.933333      0.977778      0.911111      0.977778      0.977778\n",
              "auc                      0.936431   0.0495105  0.958705      0.99375       0.96856       0.880769      0.845982      0.931548      0.977183      0.882543      0.96083       0.964444\n",
              "err                      0.0504831  0.0399085  0.0217391     0.0217391     0.0217391     0.0869565     0.130435      0.0666667     0.0222222     0.0888889     0.0222222     0.0222222\n",
              "err_count                2.3        1.82878    1             1             1             4             6             3             1             4             1             1\n",
              "f0point5                 0.944326   0.0654617  0.984849      0.952381      0.987654      0.9           0.785714      0.967742      0.991379      0.902778      0.984849      0.985915\n",
              "f1                       0.928502   0.0621067  0.962963      0.969697      0.969697      0.9           0.785714      0.923077      0.978723      0.866667      0.962963      0.965517\n",
              "f2                       0.913783   0.0635921  0.942029      0.987654      0.952381      0.9           0.785714      0.882353      0.966387      0.833333      0.942029      0.945946\n",
              "lift_top_group           2.57008    0.576081   3.28571       2.875         2.70588       2.14667       1.64286       2.14286       1.875         2.8125        3.21429       3\n",
              "logloss                  0.251161   0.137335   0.132481      0.163612      0.219305      0.416833      0.505446      0.247789      0.0991574     0.373419      0.230402      0.12317\n",
              "max_per_class_error      0.098799   0.062206   0.0714286     0.0333333     0.0588235     0.1           0.214286      0.142857      0.0416667     0.1875        0.0714286     0.0666667\n",
              "mcc                      0.890422   0.0909229  0.948911      0.953836      0.953836      0.823077      0.691964      0.872872      0.956438      0.804458      0.948448      0.950382\n",
              "mean_per_class_accuracy  0.940343   0.0454815  0.964286      0.983333      0.970588      0.911539      0.845982      0.928571      0.979167      0.889009      0.964286      0.966667\n",
              "mean_per_class_error     0.0596573  0.0454815  0.0357143     0.0166667     0.0294118     0.0884615     0.154018      0.0714286     0.0208333     0.110991      0.0357143     0.0333333\n",
              "mse                      0.0589211  0.0310636  0.0296985     0.0488763     0.0547721     0.0844932     0.114725      0.068377      0.0216424     0.0949401     0.0430127     0.0286741\n",
              "pr_auc                   0.9192     0.0968744  0.9607        0.987865      0.973225      0.88123       0.678964      0.951826      0.987051      0.841204      0.96274       0.967197\n",
              "precision                0.955546   0.0704897  1             0.941176      1             0.9           0.785714      1             1             0.928571      1             1\n",
              "r2                       0.741773   0.140648   0.859728      0.784537      0.764913      0.656178      0.45813       0.725271      0.913044      0.58566       0.799307      0.870966\n",
              "recall                   0.904534   0.0668254  0.928571      1             0.941176      0.9           0.785714      0.857143      0.958333      0.8125        0.928571      0.933333\n",
              "rmse                     0.235029   0.0639657  0.172332      0.22108       0.234034      0.290677      0.33871       0.26149       0.147113      0.308123      0.207395      0.169334\n",
              "specificity              0.976151   0.0354631  1             0.966667      1             0.923077      0.90625       1             1             0.965517      1             1\n",
              "\n",
              "Scoring History: \n",
              "    timestamp            duration          training_speed    epochs    iterations    samples      training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
              "--  -------------------  ----------------  ----------------  --------  ------------  -----------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------\n",
              "    2023-07-05 11:45:27  0.000 sec                           0         0             0            nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan\n",
              "    2023-07-05 11:45:27  2 min 47.824 sec  108333 obs/sec    10        1             4550         0.238445         0.336856            0.757626       0.952424        0.947555           2.62111          0.0615385                        0.28517            0.471418              0.646889         0.915804          0.92296              2.78049            0.0877193\n",
              "    2023-07-05 11:45:32  2 min 52.831 sec  161854 obs/sec    1790      179           814450       0.200486         0.164282            0.828654       0.960331        0.956993           2.66082          0.0461538                        0.272182           0.279442              0.678322         0.902439          0.916254             2.78049            0.0701754\n",
              "    2023-07-05 11:45:37  2 min 57.840 sec  154283 obs/sec    3400      340           1.547e+06    0.202553         0.165133            0.825102       0.961566        0.958814           2.66082          0.0461538                        0.261059           0.25966               0.704076         0.92282           0.928659             2.78049            0.0701754\n",
              "    2023-07-05 11:45:42  3 min  2.854 sec  169236 obs/sec    5590      559           2.54345e+06  0.203405         0.167727            0.823628       0.961834        0.959              2.66082          0.0461538                        0.280656           0.301057              0.657979         0.901103          0.913498             2.78049            0.0877193\n",
              "    2023-07-05 11:45:45  3 min  5.566 sec  175019 obs/sec    6820      682           3.1031e+06   0.206254         0.178873            0.818652       0.961875        0.959212           2.66082          0.0461538                        0.286227           0.309303              0.644267         0.891413          0.855177             2.78049            0.0877193\n",
              "\n",
              "Variable Importances: \n",
              "variable    relative_importance    scaled_importance    percentage\n",
              "----------  ---------------------  -------------------  ------------\n",
              "ANN         1                      1                    0.197852\n",
              "KNN         0.958978               0.958978             0.189736\n",
              "SVM         0.909394               0.909394             0.179926\n",
              "XGB         0.810575               0.810575             0.160374\n",
              "RF          0.786816               0.786816             0.155673\n",
              "LR          0.58851                0.58851              0.116438\n",
              "\n",
              "[tips]\n",
              "Use `model.explain()` to inspect the model.\n",
              "--\n",
              "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
            ],
            "text/html": [
              "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
              "=============\n",
              "H2ODeepLearningEstimator : Deep Learning\n",
              "Model Key: DeepLearning_grid_2_AutoML_2_20230705_113350_model_1\n",
              "</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-15.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-15 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-15 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-15 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-15 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-15 .h2o-table th,\n",
              "#h2o-table-15 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-15 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-15\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Status of Neuron Layers: predicting y_test, 2-class classification, bernoulli distribution, CrossEntropy loss, 602 weights/biases, 11.8 KB, 3,103,100 training samples, mini-batch size 1</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>layer</th>\n",
              "<th>units</th>\n",
              "<th>type</th>\n",
              "<th>dropout</th>\n",
              "<th>l1</th>\n",
              "<th>l2</th>\n",
              "<th>mean_rate</th>\n",
              "<th>rate_rms</th>\n",
              "<th>momentum</th>\n",
              "<th>mean_weight</th>\n",
              "<th>weight_rms</th>\n",
              "<th>mean_bias</th>\n",
              "<th>bias_rms</th></tr></thead>\n",
              "    <tbody><tr><td></td>\n",
              "<td>1</td>\n",
              "<td>6</td>\n",
              "<td>Input</td>\n",
              "<td>0.0</td>\n",
              "<td></td>\n",
              "<td></td>\n",
              "<td></td>\n",
              "<td></td>\n",
              "<td></td>\n",
              "<td></td>\n",
              "<td></td>\n",
              "<td></td>\n",
              "<td></td></tr>\n",
              "<tr><td></td>\n",
              "<td>2</td>\n",
              "<td>20</td>\n",
              "<td>RectifierDropout</td>\n",
              "<td>20.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0019689</td>\n",
              "<td>0.0013581</td>\n",
              "<td>0.0</td>\n",
              "<td>-0.0381095</td>\n",
              "<td>0.5392730</td>\n",
              "<td>-0.0033748</td>\n",
              "<td>0.3420415</td></tr>\n",
              "<tr><td></td>\n",
              "<td>3</td>\n",
              "<td>20</td>\n",
              "<td>RectifierDropout</td>\n",
              "<td>20.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0016403</td>\n",
              "<td>0.0032642</td>\n",
              "<td>0.0</td>\n",
              "<td>-0.1495231</td>\n",
              "<td>0.3652283</td>\n",
              "<td>0.0470075</td>\n",
              "<td>0.3947494</td></tr>\n",
              "<tr><td></td>\n",
              "<td>4</td>\n",
              "<td>2</td>\n",
              "<td>Softmax</td>\n",
              "<td></td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0061326</td>\n",
              "<td>0.0033593</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0378582</td>\n",
              "<td>1.7657928</td>\n",
              "<td>0.0005771</td>\n",
              "<td>0.5357175</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
              "** Reported on train data. **\n",
              "\n",
              "MSE: 0.04254059709762216\n",
              "RMSE: 0.20625372020310848\n",
              "LogLoss: 0.17887338748788162\n",
              "Mean Per-Class Error: 0.054423029404497156\n",
              "AUC: 0.9618750514784614\n",
              "AUCPR: 0.9592124168317213\n",
              "Gini: 0.9237501029569228</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-16.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-16 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-16 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-16 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-16 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-16 .h2o-table th,\n",
              "#h2o-table-16 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-16 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-16\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.34571171077870927</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>0</th>\n",
              "<th>1</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>0</td>\n",
              "<td>278.0</td>\n",
              "<td>6.0</td>\n",
              "<td>0.0211</td>\n",
              "<td> (6.0/284.0)</td></tr>\n",
              "<tr><td>1</td>\n",
              "<td>15.0</td>\n",
              "<td>156.0</td>\n",
              "<td>0.0877</td>\n",
              "<td> (15.0/171.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>293.0</td>\n",
              "<td>162.0</td>\n",
              "<td>0.0462</td>\n",
              "<td> (21.0/455.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-17.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-17 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-17 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-17 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-17 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-17 .h2o-table th,\n",
              "#h2o-table-17 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-17 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-17\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.3457117</td>\n",
              "<td>0.9369369</td>\n",
              "<td>14.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.2505212</td>\n",
              "<td>0.9272300</td>\n",
              "<td>16.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.5662032</td>\n",
              "<td>0.9608091</td>\n",
              "<td>11.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.4319146</td>\n",
              "<td>0.9538462</td>\n",
              "<td>13.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>0.9988083</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0707055</td>\n",
              "<td>1.0</td>\n",
              "<td>18.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>0.9988083</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.4319146</td>\n",
              "<td>0.9015784</td>\n",
              "<td>13.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.1160754</td>\n",
              "<td>0.9298246</td>\n",
              "<td>17.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.3457117</td>\n",
              "<td>0.9455770</td>\n",
              "<td>14.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>0.9988083</td>\n",
              "<td>284.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>0.9988083</td>\n",
              "<td>170.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0000422</td>\n",
              "<td>284.0</td>\n",
              "<td>32.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0707055</td>\n",
              "<td>171.0</td>\n",
              "<td>18.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>0.9988083</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>0.9988083</td>\n",
              "<td>0.9941520</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0000422</td>\n",
              "<td>1.0</td>\n",
              "<td>32.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0707055</td>\n",
              "<td>1.0</td>\n",
              "<td>18.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-18.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-18 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-18 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-18 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-18 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-18 .h2o-table th,\n",
              "#h2o-table-18 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-18 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-18\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 37.58 %, avg score: 36.38 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.0153846</td>\n",
              "<td>0.9967707</td>\n",
              "<td>2.6608187</td>\n",
              "<td>2.6608187</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9973280</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9973280</td>\n",
              "<td>0.0409357</td>\n",
              "<td>0.0409357</td>\n",
              "<td>166.0818713</td>\n",
              "<td>166.0818713</td>\n",
              "<td>0.0409357</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.0219780</td>\n",
              "<td>0.9911197</td>\n",
              "<td>2.6608187</td>\n",
              "<td>2.6608187</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9938388</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9962813</td>\n",
              "<td>0.0175439</td>\n",
              "<td>0.0584795</td>\n",
              "<td>166.0818713</td>\n",
              "<td>166.0818713</td>\n",
              "<td>0.0584795</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.3230769</td>\n",
              "<td>0.9222128</td>\n",
              "<td>2.6219746</td>\n",
              "<td>2.6246171</td>\n",
              "<td>0.9854015</td>\n",
              "<td>0.9232241</td>\n",
              "<td>0.9863946</td>\n",
              "<td>0.9281940</td>\n",
              "<td>0.7894737</td>\n",
              "<td>0.8479532</td>\n",
              "<td>162.1974645</td>\n",
              "<td>162.4617098</td>\n",
              "<td>0.8409110</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.9450549</td>\n",
              "<td>0.0707055</td>\n",
              "<td>0.2444568</td>\n",
              "<td>1.0581395</td>\n",
              "<td>0.0918728</td>\n",
              "<td>0.1018945</td>\n",
              "<td>0.3976744</td>\n",
              "<td>0.3843736</td>\n",
              "<td>0.1520468</td>\n",
              "<td>1.0</td>\n",
              "<td>-75.5543157</td>\n",
              "<td>5.8139535</td>\n",
              "<td>0.0880282</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0000422</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0092272</td>\n",
              "<td>0.3758242</td>\n",
              "<td>0.3637612</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
              "** Reported on validation data. **\n",
              "\n",
              "MSE: 0.08192587400291837\n",
              "RMSE: 0.28622696239683354\n",
              "LogLoss: 0.30930297760308006\n",
              "Mean Per-Class Error: 0.10591379886401604\n",
              "AUC: 0.8914132976946209\n",
              "AUCPR: 0.8551767026479652\n",
              "Gini: 0.7828265953892417</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-19.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-19 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-19 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-19 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-19 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-19 .h2o-table th,\n",
              "#h2o-table-19 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-19 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-19\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5662031596113569</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>0</th>\n",
              "<th>1</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>0</td>\n",
              "<td>70.0</td>\n",
              "<td>3.0</td>\n",
              "<td>0.0411</td>\n",
              "<td> (3.0/73.0)</td></tr>\n",
              "<tr><td>1</td>\n",
              "<td>7.0</td>\n",
              "<td>34.0</td>\n",
              "<td>0.1707</td>\n",
              "<td> (7.0/41.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>77.0</td>\n",
              "<td>37.0</td>\n",
              "<td>0.0877</td>\n",
              "<td> (10.0/114.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-20.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-20 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-20 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-20 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-20 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-20 .h2o-table th,\n",
              "#h2o-table-20 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-20 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-20\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.5662032</td>\n",
              "<td>0.8717949</td>\n",
              "<td>6.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.5662032</td>\n",
              "<td>0.8457711</td>\n",
              "<td>6.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.9222128</td>\n",
              "<td>0.9248555</td>\n",
              "<td>3.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.9222128</td>\n",
              "<td>0.9122807</td>\n",
              "<td>3.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>0.9940127</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0137673</td>\n",
              "<td>1.0</td>\n",
              "<td>10.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>0.9940127</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.9222128</td>\n",
              "<td>0.8113904</td>\n",
              "<td>3.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.5662032</td>\n",
              "<td>0.8292683</td>\n",
              "<td>6.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.5662032</td>\n",
              "<td>0.8940862</td>\n",
              "<td>6.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>0.9940127</td>\n",
              "<td>73.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>0.9940127</td>\n",
              "<td>40.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0000422</td>\n",
              "<td>73.0</td>\n",
              "<td>12.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0137673</td>\n",
              "<td>41.0</td>\n",
              "<td>10.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>0.9940127</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>0.9940127</td>\n",
              "<td>0.9756098</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0000422</td>\n",
              "<td>1.0</td>\n",
              "<td>12.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0137673</td>\n",
              "<td>1.0</td>\n",
              "<td>10.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-21.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-21 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-21 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-21 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-21 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-21 .h2o-table th,\n",
              "#h2o-table-21 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-21 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-21\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 35.96 %, avg score: 34.29 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.0175439</td>\n",
              "<td>0.9575399</td>\n",
              "<td>2.7804878</td>\n",
              "<td>2.7804878</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9782037</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9782037</td>\n",
              "<td>0.0487805</td>\n",
              "<td>0.0487805</td>\n",
              "<td>178.0487805</td>\n",
              "<td>178.0487805</td>\n",
              "<td>0.0487805</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.0263158</td>\n",
              "<td>0.9243123</td>\n",
              "<td>0.0</td>\n",
              "<td>1.8536585</td>\n",
              "<td>0.0</td>\n",
              "<td>0.9250500</td>\n",
              "<td>0.6666667</td>\n",
              "<td>0.9604858</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0487805</td>\n",
              "<td>-100.0</td>\n",
              "<td>85.3658537</td>\n",
              "<td>0.0350819</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.2894737</td>\n",
              "<td>0.9222128</td>\n",
              "<td>2.7804878</td>\n",
              "<td>2.6962306</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9222128</td>\n",
              "<td>0.9696970</td>\n",
              "<td>0.9256921</td>\n",
              "<td>0.7317073</td>\n",
              "<td>0.7804878</td>\n",
              "<td>178.0487805</td>\n",
              "<td>169.6230599</td>\n",
              "<td>0.7667892</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.2982456</td>\n",
              "<td>0.8437880</td>\n",
              "<td>0.0</td>\n",
              "<td>2.6169297</td>\n",
              "<td>0.0</td>\n",
              "<td>0.8943009</td>\n",
              "<td>0.9411765</td>\n",
              "<td>0.9247689</td>\n",
              "<td>0.0</td>\n",
              "<td>0.7804878</td>\n",
              "<td>-100.0</td>\n",
              "<td>161.6929699</td>\n",
              "<td>0.7530905</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.9561404</td>\n",
              "<td>0.0707055</td>\n",
              "<td>0.2965854</td>\n",
              "<td>1.0203625</td>\n",
              "<td>0.1066667</td>\n",
              "<td>0.1011409</td>\n",
              "<td>0.3669725</td>\n",
              "<td>0.3580524</td>\n",
              "<td>0.1951220</td>\n",
              "<td>0.9756098</td>\n",
              "<td>-70.3414634</td>\n",
              "<td>2.0362497</td>\n",
              "<td>0.0304043</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0000422</td>\n",
              "<td>0.5560976</td>\n",
              "<td>1.0</td>\n",
              "<td>0.2</td>\n",
              "<td>0.0116588</td>\n",
              "<td>0.3596491</td>\n",
              "<td>0.3428597</td>\n",
              "<td>0.0243902</td>\n",
              "<td>1.0</td>\n",
              "<td>-44.3902439</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
              "** Reported on cross-validation data. **\n",
              "\n",
              "MSE: 0.05900454322012961\n",
              "RMSE: 0.24290850792043\n",
              "LogLoss: 0.25156113091399396\n",
              "Mean Per-Class Error: 0.07492175273865415\n",
              "AUC: 0.9431574829091508\n",
              "AUCPR: 0.9315693507825556\n",
              "Gini: 0.8863149658183016</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-22.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-22 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-22 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-22 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-22 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-22 .h2o-table th,\n",
              "#h2o-table-22 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-22 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-22\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4622007295193631</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>0</th>\n",
              "<th>1</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>0</td>\n",
              "<td>273.0</td>\n",
              "<td>11.0</td>\n",
              "<td>0.0387</td>\n",
              "<td> (11.0/284.0)</td></tr>\n",
              "<tr><td>1</td>\n",
              "<td>19.0</td>\n",
              "<td>152.0</td>\n",
              "<td>0.1111</td>\n",
              "<td> (19.0/171.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>292.0</td>\n",
              "<td>163.0</td>\n",
              "<td>0.0659</td>\n",
              "<td> (30.0/455.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-23.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-23 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-23 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-23 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-23 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-23 .h2o-table th,\n",
              "#h2o-table-23 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-23 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-23\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.4622007</td>\n",
              "<td>0.9101796</td>\n",
              "<td>35.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.1544498</td>\n",
              "<td>0.9074941</td>\n",
              "<td>42.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.7788656</td>\n",
              "<td>0.9339263</td>\n",
              "<td>26.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.5894930</td>\n",
              "<td>0.9340659</td>\n",
              "<td>31.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>0.9998952</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0007668</td>\n",
              "<td>1.0</td>\n",
              "<td>74.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>0.9998952</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.5894930</td>\n",
              "<td>0.8588709</td>\n",
              "<td>31.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.1544498</td>\n",
              "<td>0.9064327</td>\n",
              "<td>42.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.1544498</td>\n",
              "<td>0.9268079</td>\n",
              "<td>42.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>0.9998952</td>\n",
              "<td>284.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>0.9998952</td>\n",
              "<td>158.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0005317</td>\n",
              "<td>284.0</td>\n",
              "<td>77.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0007668</td>\n",
              "<td>171.0</td>\n",
              "<td>74.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>0.9998952</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>0.9998952</td>\n",
              "<td>0.9239766</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0005317</td>\n",
              "<td>1.0</td>\n",
              "<td>77.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0007668</td>\n",
              "<td>1.0</td>\n",
              "<td>74.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-24.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-24 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-24 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-24 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-24 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-24 .h2o-table th,\n",
              "#h2o-table-24 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-24 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-24\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 37.58 %, avg score: 37.58 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.0285714</td>\n",
              "<td>0.9998952</td>\n",
              "<td>2.6608187</td>\n",
              "<td>2.6608187</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9998952</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9998952</td>\n",
              "<td>0.0760234</td>\n",
              "<td>0.0760234</td>\n",
              "<td>166.0818713</td>\n",
              "<td>166.0818713</td>\n",
              "<td>0.0760234</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.0505495</td>\n",
              "<td>0.9998706</td>\n",
              "<td>2.6608187</td>\n",
              "<td>2.6608187</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9998706</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9998845</td>\n",
              "<td>0.0584795</td>\n",
              "<td>0.1345029</td>\n",
              "<td>166.0818713</td>\n",
              "<td>166.0818713</td>\n",
              "<td>0.1345029</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.0505495</td>\n",
              "<td>0.9997596</td>\n",
              "<td>0.0</td>\n",
              "<td>2.6608187</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9998845</td>\n",
              "<td>0.0</td>\n",
              "<td>0.1345029</td>\n",
              "<td>-100.0</td>\n",
              "<td>166.0818713</td>\n",
              "<td>0.1345029</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.1208791</td>\n",
              "<td>0.9935483</td>\n",
              "<td>2.4945175</td>\n",
              "<td>2.5640617</td>\n",
              "<td>0.9375</td>\n",
              "<td>0.9944937</td>\n",
              "<td>0.9636364</td>\n",
              "<td>0.9967480</td>\n",
              "<td>0.1754386</td>\n",
              "<td>0.3099415</td>\n",
              "<td>149.4517544</td>\n",
              "<td>156.4061669</td>\n",
              "<td>0.3028993</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.1516484</td>\n",
              "<td>0.9926579</td>\n",
              "<td>2.6608187</td>\n",
              "<td>2.5836935</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9929632</td>\n",
              "<td>0.9710145</td>\n",
              "<td>0.9959801</td>\n",
              "<td>0.0818713</td>\n",
              "<td>0.3918129</td>\n",
              "<td>166.0818713</td>\n",
              "<td>158.3693533</td>\n",
              "<td>0.3847706</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.2021978</td>\n",
              "<td>0.9868208</td>\n",
              "<td>2.6608187</td>\n",
              "<td>2.6029748</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9870257</td>\n",
              "<td>0.9782609</td>\n",
              "<td>0.9937415</td>\n",
              "<td>0.1345029</td>\n",
              "<td>0.5263158</td>\n",
              "<td>166.0818713</td>\n",
              "<td>160.2974828</td>\n",
              "<td>0.5192735</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>0.3054945</td>\n",
              "<td>0.9587509</td>\n",
              "<td>2.4343661</td>\n",
              "<td>2.5459632</td>\n",
              "<td>0.9148936</td>\n",
              "<td>0.9722959</td>\n",
              "<td>0.9568345</td>\n",
              "<td>0.9864901</td>\n",
              "<td>0.2514620</td>\n",
              "<td>0.7777778</td>\n",
              "<td>143.4366057</td>\n",
              "<td>154.5963229</td>\n",
              "<td>0.7566510</td></tr>\n",
              "<tr><td>8</td>\n",
              "<td>0.4395604</td>\n",
              "<td>0.0978934</td>\n",
              "<td>1.0032595</td>\n",
              "<td>2.0754386</td>\n",
              "<td>0.3770492</td>\n",
              "<td>0.3916700</td>\n",
              "<td>0.78</td>\n",
              "<td>0.8050700</td>\n",
              "<td>0.1345029</td>\n",
              "<td>0.9122807</td>\n",
              "<td>0.3259515</td>\n",
              "<td>107.5438596</td>\n",
              "<td>0.7573511</td></tr>\n",
              "<tr><td>9</td>\n",
              "<td>0.5010989</td>\n",
              "<td>0.0734633</td>\n",
              "<td>0.2850877</td>\n",
              "<td>1.8555709</td>\n",
              "<td>0.1071429</td>\n",
              "<td>0.0963017</td>\n",
              "<td>0.6973684</td>\n",
              "<td>0.7180282</td>\n",
              "<td>0.0175439</td>\n",
              "<td>0.9298246</td>\n",
              "<td>-71.4912281</td>\n",
              "<td>85.5570945</td>\n",
              "<td>0.6868668</td></tr>\n",
              "<tr><td>10</td>\n",
              "<td>0.6329670</td>\n",
              "<td>0.0461309</td>\n",
              "<td>0.1330409</td>\n",
              "<td>1.4967105</td>\n",
              "<td>0.05</td>\n",
              "<td>0.0494794</td>\n",
              "<td>0.5625</td>\n",
              "<td>0.5787472</td>\n",
              "<td>0.0175439</td>\n",
              "<td>0.9473684</td>\n",
              "<td>-86.6959064</td>\n",
              "<td>49.6710526</td>\n",
              "<td>0.5037064</td></tr>\n",
              "<tr><td>11</td>\n",
              "<td>0.7230769</td>\n",
              "<td>0.0445850</td>\n",
              "<td>0.0648980</td>\n",
              "<td>1.3182780</td>\n",
              "<td>0.0243902</td>\n",
              "<td>0.0451050</td>\n",
              "<td>0.4954407</td>\n",
              "<td>0.5122447</td>\n",
              "<td>0.0058480</td>\n",
              "<td>0.9532164</td>\n",
              "<td>-93.5101983</td>\n",
              "<td>31.8277964</td>\n",
              "<td>0.3687093</td></tr>\n",
              "<tr><td>12</td>\n",
              "<td>0.8461538</td>\n",
              "<td>0.0361137</td>\n",
              "<td>0.1900585</td>\n",
              "<td>1.1541733</td>\n",
              "<td>0.0714286</td>\n",
              "<td>0.0394091</td>\n",
              "<td>0.4337662</td>\n",
              "<td>0.4434686</td>\n",
              "<td>0.0233918</td>\n",
              "<td>0.9766082</td>\n",
              "<td>-80.9941520</td>\n",
              "<td>15.4173312</td>\n",
              "<td>0.2090026</td></tr>\n",
              "<tr><td>13</td>\n",
              "<td>0.9450549</td>\n",
              "<td>0.0007669</td>\n",
              "<td>0.2365172</td>\n",
              "<td>1.0581395</td>\n",
              "<td>0.0888889</td>\n",
              "<td>0.0049389</td>\n",
              "<td>0.3976744</td>\n",
              "<td>0.3975760</td>\n",
              "<td>0.0233918</td>\n",
              "<td>1.0</td>\n",
              "<td>-76.3482781</td>\n",
              "<td>5.8139535</td>\n",
              "<td>0.0880282</td></tr>\n",
              "<tr><td>14</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0005317</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0005727</td>\n",
              "<td>0.3758242</td>\n",
              "<td>0.3757626</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-25.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-25 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-25 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-25 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-25 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-25 .h2o-table th,\n",
              "#h2o-table-25 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-25 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-25\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Cross-Validation Metrics Summary: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>mean</th>\n",
              "<th>sd</th>\n",
              "<th>cv_1_valid</th>\n",
              "<th>cv_2_valid</th>\n",
              "<th>cv_3_valid</th>\n",
              "<th>cv_4_valid</th>\n",
              "<th>cv_5_valid</th>\n",
              "<th>cv_6_valid</th>\n",
              "<th>cv_7_valid</th>\n",
              "<th>cv_8_valid</th>\n",
              "<th>cv_9_valid</th>\n",
              "<th>cv_10_valid</th></tr></thead>\n",
              "    <tbody><tr><td>accuracy</td>\n",
              "<td>0.9495169</td>\n",
              "<td>0.0399085</td>\n",
              "<td>0.9782609</td>\n",
              "<td>0.9782609</td>\n",
              "<td>0.9782609</td>\n",
              "<td>0.9130435</td>\n",
              "<td>0.8695652</td>\n",
              "<td>0.9333333</td>\n",
              "<td>0.9777778</td>\n",
              "<td>0.9111111</td>\n",
              "<td>0.9777778</td>\n",
              "<td>0.9777778</td></tr>\n",
              "<tr><td>auc</td>\n",
              "<td>0.9364313</td>\n",
              "<td>0.0495105</td>\n",
              "<td>0.9587054</td>\n",
              "<td>0.99375</td>\n",
              "<td>0.9685599</td>\n",
              "<td>0.8807692</td>\n",
              "<td>0.8459821</td>\n",
              "<td>0.9315476</td>\n",
              "<td>0.9771826</td>\n",
              "<td>0.8825431</td>\n",
              "<td>0.9608295</td>\n",
              "<td>0.9644445</td></tr>\n",
              "<tr><td>err</td>\n",
              "<td>0.0504831</td>\n",
              "<td>0.0399085</td>\n",
              "<td>0.0217391</td>\n",
              "<td>0.0217391</td>\n",
              "<td>0.0217391</td>\n",
              "<td>0.0869565</td>\n",
              "<td>0.1304348</td>\n",
              "<td>0.0666667</td>\n",
              "<td>0.0222222</td>\n",
              "<td>0.0888889</td>\n",
              "<td>0.0222222</td>\n",
              "<td>0.0222222</td></tr>\n",
              "<tr><td>err_count</td>\n",
              "<td>2.3</td>\n",
              "<td>1.8287822</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>4.0</td>\n",
              "<td>6.0</td>\n",
              "<td>3.0</td>\n",
              "<td>1.0</td>\n",
              "<td>4.0</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td></tr>\n",
              "<tr><td>f0point5</td>\n",
              "<td>0.9443261</td>\n",
              "<td>0.0654617</td>\n",
              "<td>0.9848485</td>\n",
              "<td>0.9523810</td>\n",
              "<td>0.9876543</td>\n",
              "<td>0.9</td>\n",
              "<td>0.7857143</td>\n",
              "<td>0.9677419</td>\n",
              "<td>0.9913793</td>\n",
              "<td>0.9027778</td>\n",
              "<td>0.9848485</td>\n",
              "<td>0.9859155</td></tr>\n",
              "<tr><td>f1</td>\n",
              "<td>0.9285018</td>\n",
              "<td>0.0621067</td>\n",
              "<td>0.962963</td>\n",
              "<td>0.969697</td>\n",
              "<td>0.969697</td>\n",
              "<td>0.9</td>\n",
              "<td>0.7857143</td>\n",
              "<td>0.9230769</td>\n",
              "<td>0.9787234</td>\n",
              "<td>0.8666667</td>\n",
              "<td>0.962963</td>\n",
              "<td>0.9655172</td></tr>\n",
              "<tr><td>f2</td>\n",
              "<td>0.9137827</td>\n",
              "<td>0.0635921</td>\n",
              "<td>0.942029</td>\n",
              "<td>0.9876543</td>\n",
              "<td>0.9523810</td>\n",
              "<td>0.9</td>\n",
              "<td>0.7857143</td>\n",
              "<td>0.8823530</td>\n",
              "<td>0.9663866</td>\n",
              "<td>0.8333333</td>\n",
              "<td>0.942029</td>\n",
              "<td>0.9459459</td></tr>\n",
              "<tr><td>lift_top_group</td>\n",
              "<td>2.5700762</td>\n",
              "<td>0.5760813</td>\n",
              "<td>3.2857144</td>\n",
              "<td>2.875</td>\n",
              "<td>2.7058823</td>\n",
              "<td>2.1466668</td>\n",
              "<td>1.6428572</td>\n",
              "<td>2.142857</td>\n",
              "<td>1.875</td>\n",
              "<td>2.8125</td>\n",
              "<td>3.2142856</td>\n",
              "<td>3.0</td></tr>\n",
              "<tr><td>logloss</td>\n",
              "<td>0.2511614</td>\n",
              "<td>0.1373353</td>\n",
              "<td>0.1324811</td>\n",
              "<td>0.163612</td>\n",
              "<td>0.2193046</td>\n",
              "<td>0.4168329</td>\n",
              "<td>0.5054463</td>\n",
              "<td>0.2477888</td>\n",
              "<td>0.0991574</td>\n",
              "<td>0.3734189</td>\n",
              "<td>0.2304017</td>\n",
              "<td>0.1231705</td></tr>\n",
              "<tr><td>max_per_class_error</td>\n",
              "<td>0.0987990</td>\n",
              "<td>0.0622060</td>\n",
              "<td>0.0714286</td>\n",
              "<td>0.0333333</td>\n",
              "<td>0.0588235</td>\n",
              "<td>0.1</td>\n",
              "<td>0.2142857</td>\n",
              "<td>0.1428571</td>\n",
              "<td>0.0416667</td>\n",
              "<td>0.1875</td>\n",
              "<td>0.0714286</td>\n",
              "<td>0.0666667</td></tr>\n",
              "<tr><td>mcc</td>\n",
              "<td>0.8904222</td>\n",
              "<td>0.0909229</td>\n",
              "<td>0.9489114</td>\n",
              "<td>0.9538364</td>\n",
              "<td>0.9538364</td>\n",
              "<td>0.8230769</td>\n",
              "<td>0.6919643</td>\n",
              "<td>0.8728716</td>\n",
              "<td>0.9564375</td>\n",
              "<td>0.8044580</td>\n",
              "<td>0.948448</td>\n",
              "<td>0.9503819</td></tr>\n",
              "<tr><td>mean_per_class_accuracy</td>\n",
              "<td>0.9403427</td>\n",
              "<td>0.0454815</td>\n",
              "<td>0.9642857</td>\n",
              "<td>0.9833333</td>\n",
              "<td>0.9705882</td>\n",
              "<td>0.9115385</td>\n",
              "<td>0.8459821</td>\n",
              "<td>0.9285714</td>\n",
              "<td>0.9791667</td>\n",
              "<td>0.8890086</td>\n",
              "<td>0.9642857</td>\n",
              "<td>0.9666666</td></tr>\n",
              "<tr><td>mean_per_class_error</td>\n",
              "<td>0.0596573</td>\n",
              "<td>0.0454815</td>\n",
              "<td>0.0357143</td>\n",
              "<td>0.0166667</td>\n",
              "<td>0.0294118</td>\n",
              "<td>0.0884615</td>\n",
              "<td>0.1540179</td>\n",
              "<td>0.0714286</td>\n",
              "<td>0.0208333</td>\n",
              "<td>0.1109914</td>\n",
              "<td>0.0357143</td>\n",
              "<td>0.0333333</td></tr>\n",
              "<tr><td>mse</td>\n",
              "<td>0.0589211</td>\n",
              "<td>0.0310636</td>\n",
              "<td>0.0296985</td>\n",
              "<td>0.0488763</td>\n",
              "<td>0.0547721</td>\n",
              "<td>0.0844932</td>\n",
              "<td>0.1147248</td>\n",
              "<td>0.0683770</td>\n",
              "<td>0.0216424</td>\n",
              "<td>0.0949401</td>\n",
              "<td>0.0430127</td>\n",
              "<td>0.0286741</td></tr>\n",
              "<tr><td>pr_auc</td>\n",
              "<td>0.9192002</td>\n",
              "<td>0.0968744</td>\n",
              "<td>0.9606998</td>\n",
              "<td>0.9878653</td>\n",
              "<td>0.9732251</td>\n",
              "<td>0.8812302</td>\n",
              "<td>0.678964</td>\n",
              "<td>0.951826</td>\n",
              "<td>0.9870508</td>\n",
              "<td>0.8412041</td>\n",
              "<td>0.96274</td>\n",
              "<td>0.9671973</td></tr>\n",
              "<tr><td>precision</td>\n",
              "<td>0.9555462</td>\n",
              "<td>0.0704897</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9411765</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9</td>\n",
              "<td>0.7857143</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9285714</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td></tr>\n",
              "<tr><td>r2</td>\n",
              "<td>0.7417735</td>\n",
              "<td>0.1406476</td>\n",
              "<td>0.8597277</td>\n",
              "<td>0.7845370</td>\n",
              "<td>0.7649133</td>\n",
              "<td>0.6561776</td>\n",
              "<td>0.4581303</td>\n",
              "<td>0.7252709</td>\n",
              "<td>0.9130441</td>\n",
              "<td>0.5856602</td>\n",
              "<td>0.7993071</td>\n",
              "<td>0.8709663</td></tr>\n",
              "<tr><td>recall</td>\n",
              "<td>0.9045343</td>\n",
              "<td>0.0668254</td>\n",
              "<td>0.9285714</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9411765</td>\n",
              "<td>0.9</td>\n",
              "<td>0.7857143</td>\n",
              "<td>0.8571429</td>\n",
              "<td>0.9583333</td>\n",
              "<td>0.8125</td>\n",
              "<td>0.9285714</td>\n",
              "<td>0.9333333</td></tr>\n",
              "<tr><td>rmse</td>\n",
              "<td>0.2350291</td>\n",
              "<td>0.0639657</td>\n",
              "<td>0.1723324</td>\n",
              "<td>0.2210799</td>\n",
              "<td>0.2340344</td>\n",
              "<td>0.2906772</td>\n",
              "<td>0.3387105</td>\n",
              "<td>0.2614900</td>\n",
              "<td>0.1471134</td>\n",
              "<td>0.3081235</td>\n",
              "<td>0.2073950</td>\n",
              "<td>0.1693344</td></tr>\n",
              "<tr><td>specificity</td>\n",
              "<td>0.9761511</td>\n",
              "<td>0.0354631</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9666666</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9230769</td>\n",
              "<td>0.90625</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9655172</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-26.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-26 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-26 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-26 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-26 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-26 .h2o-table th,\n",
              "#h2o-table-26 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-26 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-26\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Scoring History: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>timestamp</th>\n",
              "<th>duration</th>\n",
              "<th>training_speed</th>\n",
              "<th>epochs</th>\n",
              "<th>iterations</th>\n",
              "<th>samples</th>\n",
              "<th>training_rmse</th>\n",
              "<th>training_logloss</th>\n",
              "<th>training_r2</th>\n",
              "<th>training_auc</th>\n",
              "<th>training_pr_auc</th>\n",
              "<th>training_lift</th>\n",
              "<th>training_classification_error</th>\n",
              "<th>validation_rmse</th>\n",
              "<th>validation_logloss</th>\n",
              "<th>validation_r2</th>\n",
              "<th>validation_auc</th>\n",
              "<th>validation_pr_auc</th>\n",
              "<th>validation_lift</th>\n",
              "<th>validation_classification_error</th></tr></thead>\n",
              "    <tbody><tr><td></td>\n",
              "<td>2023-07-05 11:45:27</td>\n",
              "<td> 0.000 sec</td>\n",
              "<td>None</td>\n",
              "<td>0.0</td>\n",
              "<td>0</td>\n",
              "<td>0.0</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-07-05 11:45:27</td>\n",
              "<td> 2 min 47.824 sec</td>\n",
              "<td>108333 obs/sec</td>\n",
              "<td>10.0</td>\n",
              "<td>1</td>\n",
              "<td>4550.0</td>\n",
              "<td>0.2384454</td>\n",
              "<td>0.3368560</td>\n",
              "<td>0.7576259</td>\n",
              "<td>0.9524236</td>\n",
              "<td>0.9475547</td>\n",
              "<td>2.6211050</td>\n",
              "<td>0.0615385</td>\n",
              "<td>0.2851703</td>\n",
              "<td>0.4714181</td>\n",
              "<td>0.6468888</td>\n",
              "<td>0.9158035</td>\n",
              "<td>0.9229596</td>\n",
              "<td>2.7804878</td>\n",
              "<td>0.0877193</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-07-05 11:45:32</td>\n",
              "<td> 2 min 52.831 sec</td>\n",
              "<td>161854 obs/sec</td>\n",
              "<td>1790.0</td>\n",
              "<td>179</td>\n",
              "<td>814450.0</td>\n",
              "<td>0.2004857</td>\n",
              "<td>0.1642820</td>\n",
              "<td>0.8286536</td>\n",
              "<td>0.9603307</td>\n",
              "<td>0.9569927</td>\n",
              "<td>2.6608187</td>\n",
              "<td>0.0461538</td>\n",
              "<td>0.2721819</td>\n",
              "<td>0.2794423</td>\n",
              "<td>0.6783219</td>\n",
              "<td>0.9024390</td>\n",
              "<td>0.9162537</td>\n",
              "<td>2.7804878</td>\n",
              "<td>0.0701754</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-07-05 11:45:37</td>\n",
              "<td> 2 min 57.840 sec</td>\n",
              "<td>154283 obs/sec</td>\n",
              "<td>3400.0</td>\n",
              "<td>340</td>\n",
              "<td>1547000.0</td>\n",
              "<td>0.2025529</td>\n",
              "<td>0.1651325</td>\n",
              "<td>0.8251018</td>\n",
              "<td>0.9615662</td>\n",
              "<td>0.9588142</td>\n",
              "<td>2.6608187</td>\n",
              "<td>0.0461538</td>\n",
              "<td>0.2610591</td>\n",
              "<td>0.2596596</td>\n",
              "<td>0.7040757</td>\n",
              "<td>0.9228199</td>\n",
              "<td>0.9286590</td>\n",
              "<td>2.7804878</td>\n",
              "<td>0.0701754</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-07-05 11:45:42</td>\n",
              "<td> 3 min  2.854 sec</td>\n",
              "<td>169236 obs/sec</td>\n",
              "<td>5590.0</td>\n",
              "<td>559</td>\n",
              "<td>2543450.0</td>\n",
              "<td>0.2034046</td>\n",
              "<td>0.1677272</td>\n",
              "<td>0.8236279</td>\n",
              "<td>0.9618339</td>\n",
              "<td>0.9589996</td>\n",
              "<td>2.6608187</td>\n",
              "<td>0.0461538</td>\n",
              "<td>0.2806564</td>\n",
              "<td>0.3010568</td>\n",
              "<td>0.6579790</td>\n",
              "<td>0.9011026</td>\n",
              "<td>0.9134985</td>\n",
              "<td>2.7804878</td>\n",
              "<td>0.0877193</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-07-05 11:45:45</td>\n",
              "<td> 3 min  5.566 sec</td>\n",
              "<td>175019 obs/sec</td>\n",
              "<td>6820.0</td>\n",
              "<td>682</td>\n",
              "<td>3103100.0</td>\n",
              "<td>0.2062537</td>\n",
              "<td>0.1788734</td>\n",
              "<td>0.8186524</td>\n",
              "<td>0.9618751</td>\n",
              "<td>0.9592124</td>\n",
              "<td>2.6608187</td>\n",
              "<td>0.0461538</td>\n",
              "<td>0.2862270</td>\n",
              "<td>0.3093030</td>\n",
              "<td>0.6442671</td>\n",
              "<td>0.8914133</td>\n",
              "<td>0.8551767</td>\n",
              "<td>2.7804878</td>\n",
              "<td>0.0877193</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-27.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-27 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-27 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-27 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-27 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-27 .h2o-table th,\n",
              "#h2o-table-27 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-27 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-27\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Variable Importances: </caption>\n",
              "    <thead><tr><th>variable</th>\n",
              "<th>relative_importance</th>\n",
              "<th>scaled_importance</th>\n",
              "<th>percentage</th></tr></thead>\n",
              "    <tbody><tr><td>ANN</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.1978524</td></tr>\n",
              "<tr><td>KNN</td>\n",
              "<td>0.9589782</td>\n",
              "<td>0.9589782</td>\n",
              "<td>0.1897361</td></tr>\n",
              "<tr><td>SVM</td>\n",
              "<td>0.9093941</td>\n",
              "<td>0.9093941</td>\n",
              "<td>0.1799258</td></tr>\n",
              "<tr><td>XGB</td>\n",
              "<td>0.8105750</td>\n",
              "<td>0.8105750</td>\n",
              "<td>0.1603742</td></tr>\n",
              "<tr><td>RF</td>\n",
              "<td>0.7868163</td>\n",
              "<td>0.7868163</td>\n",
              "<td>0.1556735</td></tr>\n",
              "<tr><td>LR</td>\n",
              "<td>0.5885095</td>\n",
              "<td>0.5885095</td>\n",
              "<td>0.1164380</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
              "\n",
              "[tips]\n",
              "Use `model.explain()` to inspect the model.\n",
              "--\n",
              "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saml.leaderboard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "clvKV92Y0wjQ",
        "outputId": "8581476c-a32b-4054-e842-d938a0106562"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model_id                                                accuracy       auc    logloss     aucpr    mean_per_class_error      rmse        mse\n",
              "----------------------------------------------------  ----------  --------  ---------  --------  ----------------------  --------  ---------\n",
              "DeepLearning_grid_2_AutoML_2_20230705_113350_model_1    0.934066  0.943157   0.251561  0.931569               0.0749218  0.242909  0.0590045\n",
              "DeepLearning_grid_1_AutoML_2_20230705_113350_model_2    0.938462  0.943858   0.239484  0.932976               0.066747   0.234557  0.0550169\n",
              "DeepLearning_1_AutoML_2_20230705_113350                 0.938462  0.927179   0.24598   0.902936               0.0748909  0.241661  0.0584\n",
              "DeepLearning_grid_2_AutoML_2_20230705_113350_model_3    0.940659  0.942251   0.224252  0.929079               0.0673132  0.233229  0.0543956\n",
              "DeepLearning_grid_3_AutoML_2_20230705_113350_model_2    0.940659  0.948202   0.243667  0.943803               0.0673132  0.235396  0.0554112\n",
              "DeepLearning_grid_3_AutoML_2_20230705_113350_model_3    0.940659  0.944722   0.227619  0.928777               0.0661498  0.233499  0.0545217\n",
              "DeepLearning_grid_2_AutoML_2_20230705_113350_model_2    0.942857  0.952424   0.229481  0.943183               0.0643893  0.232086  0.0538638\n",
              "DeepLearning_grid_3_AutoML_2_20230705_113350_model_1    0.942857  0.955677   0.225528  0.938339               0.0632258  0.235814  0.0556081\n",
              "DeepLearning_grid_1_AutoML_2_20230705_113350_model_1    0.942857  0.943178   0.245579  0.927731               0.0643893  0.236229  0.0558044\n",
              "DeepLearning_grid_1_AutoML_2_20230705_113350_model_3    0.945055  0.953371   0.211249  0.933622               0.0614653  0.227202  0.051621\n",
              "[10 rows x 8 columns]\n"
            ],
            "text/html": [
              "<table class='dataframe'>\n",
              "<thead>\n",
              "<tr><th>model_id                                            </th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">      mse</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DeepLearning_grid_2_AutoML_2_20230705_113350_model_1</td><td style=\"text-align: right;\">  0.934066</td><td style=\"text-align: right;\">0.943157</td><td style=\"text-align: right;\"> 0.251561</td><td style=\"text-align: right;\">0.931569</td><td style=\"text-align: right;\">             0.0749218</td><td style=\"text-align: right;\">0.242909</td><td style=\"text-align: right;\">0.0590045</td></tr>\n",
              "<tr><td>DeepLearning_grid_1_AutoML_2_20230705_113350_model_2</td><td style=\"text-align: right;\">  0.938462</td><td style=\"text-align: right;\">0.943858</td><td style=\"text-align: right;\"> 0.239484</td><td style=\"text-align: right;\">0.932976</td><td style=\"text-align: right;\">             0.066747 </td><td style=\"text-align: right;\">0.234557</td><td style=\"text-align: right;\">0.0550169</td></tr>\n",
              "<tr><td>DeepLearning_1_AutoML_2_20230705_113350             </td><td style=\"text-align: right;\">  0.938462</td><td style=\"text-align: right;\">0.927179</td><td style=\"text-align: right;\"> 0.24598 </td><td style=\"text-align: right;\">0.902936</td><td style=\"text-align: right;\">             0.0748909</td><td style=\"text-align: right;\">0.241661</td><td style=\"text-align: right;\">0.0584   </td></tr>\n",
              "<tr><td>DeepLearning_grid_2_AutoML_2_20230705_113350_model_3</td><td style=\"text-align: right;\">  0.940659</td><td style=\"text-align: right;\">0.942251</td><td style=\"text-align: right;\"> 0.224252</td><td style=\"text-align: right;\">0.929079</td><td style=\"text-align: right;\">             0.0673132</td><td style=\"text-align: right;\">0.233229</td><td style=\"text-align: right;\">0.0543956</td></tr>\n",
              "<tr><td>DeepLearning_grid_3_AutoML_2_20230705_113350_model_2</td><td style=\"text-align: right;\">  0.940659</td><td style=\"text-align: right;\">0.948202</td><td style=\"text-align: right;\"> 0.243667</td><td style=\"text-align: right;\">0.943803</td><td style=\"text-align: right;\">             0.0673132</td><td style=\"text-align: right;\">0.235396</td><td style=\"text-align: right;\">0.0554112</td></tr>\n",
              "<tr><td>DeepLearning_grid_3_AutoML_2_20230705_113350_model_3</td><td style=\"text-align: right;\">  0.940659</td><td style=\"text-align: right;\">0.944722</td><td style=\"text-align: right;\"> 0.227619</td><td style=\"text-align: right;\">0.928777</td><td style=\"text-align: right;\">             0.0661498</td><td style=\"text-align: right;\">0.233499</td><td style=\"text-align: right;\">0.0545217</td></tr>\n",
              "<tr><td>DeepLearning_grid_2_AutoML_2_20230705_113350_model_2</td><td style=\"text-align: right;\">  0.942857</td><td style=\"text-align: right;\">0.952424</td><td style=\"text-align: right;\"> 0.229481</td><td style=\"text-align: right;\">0.943183</td><td style=\"text-align: right;\">             0.0643893</td><td style=\"text-align: right;\">0.232086</td><td style=\"text-align: right;\">0.0538638</td></tr>\n",
              "<tr><td>DeepLearning_grid_3_AutoML_2_20230705_113350_model_1</td><td style=\"text-align: right;\">  0.942857</td><td style=\"text-align: right;\">0.955677</td><td style=\"text-align: right;\"> 0.225528</td><td style=\"text-align: right;\">0.938339</td><td style=\"text-align: right;\">             0.0632258</td><td style=\"text-align: right;\">0.235814</td><td style=\"text-align: right;\">0.0556081</td></tr>\n",
              "<tr><td>DeepLearning_grid_1_AutoML_2_20230705_113350_model_1</td><td style=\"text-align: right;\">  0.942857</td><td style=\"text-align: right;\">0.943178</td><td style=\"text-align: right;\"> 0.245579</td><td style=\"text-align: right;\">0.927731</td><td style=\"text-align: right;\">             0.0643893</td><td style=\"text-align: right;\">0.236229</td><td style=\"text-align: right;\">0.0558044</td></tr>\n",
              "<tr><td>DeepLearning_grid_1_AutoML_2_20230705_113350_model_3</td><td style=\"text-align: right;\">  0.945055</td><td style=\"text-align: right;\">0.953371</td><td style=\"text-align: right;\"> 0.211249</td><td style=\"text-align: right;\">0.933622</td><td style=\"text-align: right;\">             0.0614653</td><td style=\"text-align: right;\">0.227202</td><td style=\"text-align: right;\">0.051621 </td></tr>\n",
              "</tbody>\n",
              "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[10 rows x 8 columns]</pre>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_sh2o = pd.DataFrame(h2o.as_list(sbest_model.predict(svalid)))['predict']\n",
        "y_test_sh2o = np.array(svalid1['y_test']).copy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivMaaDNNmYY2",
        "outputId": "e4fdda95-ba7a-4645-c167-99fe6e6e77b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deeplearning prediction progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.bar(acc.index, acc['train'], color ='black',width = 0.4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "nJrcI3Gn8we2",
        "outputId": "c267b13a-086d-40d4-ac5e-a032ace81948"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 7 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = [ANNmodel, model, knn, lr, rf, svm, xgb, best_model]\n",
        "\n",
        "label = [\"ArtificialNeuralNetwork\", 'DeepNeuralNetwork',\n",
        "         'KNearestNeighborsClassifier', 'LogisticRegression',\n",
        "         'RandomForestClassifier', 'SupportVectorClassifier',\n",
        "         'XGBoost', type(best_model).__name__, type(sbest_model).__name__ ]\n",
        "\n",
        "acc = pd.DataFrame(\n",
        "    {\n",
        "    \"ANN\":[ATr,ATe],\n",
        "    \"DNN\":[DTr,DTe],\n",
        "    \"KNN\":[KTr,KTe],\n",
        "    \"LR\" :[LTr,LTe],\n",
        "    \"RF\" :[RTr,RTe],\n",
        "    \"SVM\":[STr,STe],\n",
        "    \"XGB\":[XTr,XTe],\n",
        "    \"H_OD\":[HATr.accuracy()[0][1],HATe.accuracy()[0][1]],\n",
        "    \"H_SOD\":[sHATr.accuracy()[0][1],sHATe.accuracy()[0][1]]\n",
        "    })\n",
        "acc.index = [\"train\", \"test\"]\n",
        "acc = acc.T\n",
        "acc['Model'] = label\n",
        "\n",
        "acc = acc[['Model', 'train', 'test']]\n",
        "acc['avg'] = round((acc['train'] + acc['test'])/2, 6)\n",
        "acc[acc[\"avg\"] == acc[\"avg\"].max()]\n",
        "acc['BestModel'] = 0\n",
        "for i in range(len(acc)):\n",
        "  if acc['avg'][i] >= 90 and acc['avg'][i] < acc['avg'].max():\n",
        "    acc.iloc[i,-1] = \"good\"\n",
        "  elif acc['avg'][i] == acc['avg'].max():\n",
        "    acc.iloc[i,-1] = \"best\"\n",
        "  else:\n",
        "    acc.iloc[i,-1] = \"not good\"\n",
        "\n",
        "acc[\"Precision\"] = np.zeros(len(acc))\n",
        "acc[\"Recall\"]    = np.zeros(len(acc))\n",
        "acc[\"F1_Score\"]  = np.zeros(len(acc))\n",
        "\n"
      ],
      "metadata": {
        "id": "Ba6kRO-eI60S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_ANNn = []\n",
        "y_pred_DNNn = []\n",
        "for i in range(len(y_pred_ANN)):\n",
        "  y_pred_ANNn.append(y_pred_ANN[i][0])\n",
        "  y_pred_DNNn.append(y_pred_DNN[i][0])"
      ],
      "metadata": {
        "id": "S7pf8G6ao4oF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = [np.array(y_pred_ANNn), np.array(y_pred_DNNn), y_pred_knn,\n",
        "        y_pred_lr, y_pred_rf,\n",
        "        y_pred_svm, y_pred_xgb, y_pred_h2o, y_pred_sh2o]\n",
        "\n",
        "tes  = [y_test_indi_ML, np.array(Dy_test), y_test_indi_ML, y_test_indi_ML,\n",
        "        y_test_indi_ML, y_test_indi_ML, y_test_indi_ML,\n",
        "        y_test_h2o.copy(), y_test_sh2o.copy()]"
      ],
      "metadata": {
        "id": "D2n2VnW1jKp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(pred)):\n",
        "  p,r,f,_ = precision_recall_fscore_support(tes[i], pred[i],\n",
        "                                            average='macro')\n",
        "  acc.iloc[i,5]= p\n",
        "  acc.iloc[i,6]= r\n",
        "  acc.iloc[i,7]= f\n",
        "  p = 0\n",
        "  r = 0\n",
        "  f = 0\n",
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "2DlSQ29moN9T",
        "outputId": "2d0f8c0c-18fe-4f95-81c6-eb189f68b2b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             Model     train      test       avg BestModel  \\\n",
              "ANN        ArtificialNeuralNetwork  0.953846  0.964912  0.959379  not good   \n",
              "DNN              DeepNeuralNetwork  0.945055  0.912281  0.928668  not good   \n",
              "KNN    KNearestNeighborsClassifier  0.980220  0.991228  0.985724  not good   \n",
              "LR              LogisticRegression  0.980220  0.973684  0.976952  not good   \n",
              "RF          RandomForestClassifier  0.975824  0.991228  0.983526  not good   \n",
              "SVM        SupportVectorClassifier  0.951648  0.956140  0.953894  not good   \n",
              "XGB                        XGBoost  0.993407  0.982456  0.987931      best   \n",
              "H_OD           H2OXGBoostEstimator  0.973626  0.964912  0.969269  not good   \n",
              "H_SOD     H2ODeepLearningEstimator  0.953846  0.912281  0.933063  not good   \n",
              "\n",
              "       Precision    Recall  F1_Score  \n",
              "ANN     0.974026  0.951220  0.961026  \n",
              "DNN     0.914005  0.894086  0.902564  \n",
              "KNN     0.993243  0.987805  0.990426  \n",
              "LR      0.980263  0.963415  0.970946  \n",
              "RF      0.993243  0.987805  0.990426  \n",
              "SVM     0.967949  0.939024  0.950976  \n",
              "XGB     0.980956  0.980956  0.980956  \n",
              "H_OD    0.958074  0.967257  0.962302  \n",
              "H_SOD   0.914005  0.894086  0.902564  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5cd980c9-e2b5-4d47-9cee-19885dec4e99\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "      <th>avg</th>\n",
              "      <th>BestModel</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ANN</th>\n",
              "      <td>ArtificialNeuralNetwork</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>0.964912</td>\n",
              "      <td>0.959379</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.974026</td>\n",
              "      <td>0.951220</td>\n",
              "      <td>0.961026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DNN</th>\n",
              "      <td>DeepNeuralNetwork</td>\n",
              "      <td>0.945055</td>\n",
              "      <td>0.912281</td>\n",
              "      <td>0.928668</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.914005</td>\n",
              "      <td>0.894086</td>\n",
              "      <td>0.902564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>KNearestNeighborsClassifier</td>\n",
              "      <td>0.980220</td>\n",
              "      <td>0.991228</td>\n",
              "      <td>0.985724</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.993243</td>\n",
              "      <td>0.987805</td>\n",
              "      <td>0.990426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LR</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.980220</td>\n",
              "      <td>0.973684</td>\n",
              "      <td>0.976952</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.980263</td>\n",
              "      <td>0.963415</td>\n",
              "      <td>0.970946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.975824</td>\n",
              "      <td>0.991228</td>\n",
              "      <td>0.983526</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.993243</td>\n",
              "      <td>0.987805</td>\n",
              "      <td>0.990426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>SupportVectorClassifier</td>\n",
              "      <td>0.951648</td>\n",
              "      <td>0.956140</td>\n",
              "      <td>0.953894</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.967949</td>\n",
              "      <td>0.939024</td>\n",
              "      <td>0.950976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGB</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.993407</td>\n",
              "      <td>0.982456</td>\n",
              "      <td>0.987931</td>\n",
              "      <td>best</td>\n",
              "      <td>0.980956</td>\n",
              "      <td>0.980956</td>\n",
              "      <td>0.980956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H_OD</th>\n",
              "      <td>H2OXGBoostEstimator</td>\n",
              "      <td>0.973626</td>\n",
              "      <td>0.964912</td>\n",
              "      <td>0.969269</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.958074</td>\n",
              "      <td>0.967257</td>\n",
              "      <td>0.962302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H_SOD</th>\n",
              "      <td>H2ODeepLearningEstimator</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>0.912281</td>\n",
              "      <td>0.933063</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.914005</td>\n",
              "      <td>0.894086</td>\n",
              "      <td>0.902564</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5cd980c9-e2b5-4d47-9cee-19885dec4e99')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5cd980c9-e2b5-4d47-9cee-19885dec4e99 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5cd980c9-e2b5-4d47-9cee-19885dec4e99');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.bar(acc.index, acc['train'], color ='black',width = 0.4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "ru4oH6-YzGPw",
        "outputId": "736778b3-5489-4931-f991-6ab2c5812e55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 9 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve"
      ],
      "metadata": {
        "id": "Qma6hWrmDBvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = [ANNmodel, model, knn, lr, rf, svm, xgb, best_model]"
      ],
      "metadata": {
        "id": "03rwpiYpoAGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(df['diagnosis']).copy()\n",
        "X = df.drop(columns=['diagnosis']).copy()\n",
        "X = StandardScaler().fit_transform(X).copy()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=123)\n",
        "y_test_indi_ML = y_test.copy()"
      ],
      "metadata": {
        "id": "x5wrzn-qPaXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "C80ESe__xB5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(1)\n",
        "plt.rcParams[\"figure.figsize\"] = [10, 5]\n",
        "\n",
        "y_pred = ANNmodel.predict(X_test).ravel()\n",
        "y_test = y_test_indi_ML\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[0]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = model.predict(DX_test).ravel()\n",
        "y_test = Dy_test.copy()\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[1]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = knn.predict_proba(X_test)[:, 1]\n",
        "y_test = y_test_indi_ML\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[2]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = lr.predict_proba(X_test)[:, 1]\n",
        "y_test = y_test_indi_ML\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[3]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = rf.predict_proba(X_test)[:, 1]\n",
        "y_test = y_test_indi_ML\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[4]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = svm.predict_proba(X_test)[:, 1]\n",
        "y_test = y_test_indi_ML\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[5]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = xgb.predict_proba(X_test)[:, 1]\n",
        "y_test = y_test_indi_ML\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[6]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = pd.DataFrame(h2o.as_list(best_model.predict(valid)))\n",
        "y_test = h2o.as_list(valid['diagnosis'])\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred[\"p1\"])\n",
        "auc = metrics.roc_auc_score(y_test, y_pred[\"p1\"])\n",
        "plt.plot(fpr, tpr,label=type(best_model).__name__ + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = pd.DataFrame(h2o.as_list(sbest_model.predict(svalid)))\n",
        "y_test = h2o.as_list(svalid['y_test'])\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred[\"p1\"])\n",
        "auc = metrics.roc_auc_score(y_test, y_pred[\"p1\"])\n",
        "plt.plot(fpr, tpr,label=type(sbest_model).__name__ + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('AUC ROC curve')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "4Bi4CMUJm6yH",
        "outputId": "81732947-5292-430e-a2ed-0901aa4dfede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "xgboost prediction progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n",
            "deeplearning prediction progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tm = [aend,dend,kend,lend,rend,send,xend,autoend,sautoend]"
      ],
      "metadata": {
        "id": "6vUubKKMxLIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc['time'] = 0"
      ],
      "metadata": {
        "id": "_1wKoAe9wIPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc['time'] = tm"
      ],
      "metadata": {
        "id": "P-K86caJxhvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "Oc880RvD9ibh",
        "outputId": "bf8f455b-775b-4e02-8898-5524510a728b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             Model     train      test       avg BestModel  \\\n",
              "ANN        ArtificialNeuralNetwork  0.953846  0.964912  0.959379  not good   \n",
              "DNN              DeepNeuralNetwork  0.945055  0.912281  0.928668  not good   \n",
              "KNN    KNearestNeighborsClassifier  0.980220  0.991228  0.985724  not good   \n",
              "LR              LogisticRegression  0.980220  0.973684  0.976952  not good   \n",
              "RF          RandomForestClassifier  0.975824  0.991228  0.983526  not good   \n",
              "SVM        SupportVectorClassifier  0.951648  0.956140  0.953894  not good   \n",
              "XGB                        XGBoost  0.993407  0.982456  0.987931      best   \n",
              "H_OD           H2OXGBoostEstimator  0.973626  0.964912  0.969269  not good   \n",
              "H_SOD     H2ODeepLearningEstimator  0.953846  0.912281  0.933063  not good   \n",
              "\n",
              "       Precision    Recall  F1_Score         time  \n",
              "ANN     0.974026  0.951220  0.961026     3.060697  \n",
              "DNN     0.914005  0.894086  0.902564    41.554656  \n",
              "KNN     0.993243  0.987805  0.990426     0.000920  \n",
              "LR      0.980263  0.963415  0.970946     0.005973  \n",
              "RF      0.993243  0.987805  0.990426     0.958414  \n",
              "SVM     0.967949  0.939024  0.950976     0.046017  \n",
              "XGB     0.980956  0.980956  0.980956     2.190684  \n",
              "H_OD    0.958074  0.967257  0.962302    98.333856  \n",
              "H_SOD   0.914005  0.894086  0.902564  1675.899952  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ffb7e934-8180-44ba-b81f-f26cc00cc513\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "      <th>avg</th>\n",
              "      <th>BestModel</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1_Score</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ANN</th>\n",
              "      <td>ArtificialNeuralNetwork</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>0.964912</td>\n",
              "      <td>0.959379</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.974026</td>\n",
              "      <td>0.951220</td>\n",
              "      <td>0.961026</td>\n",
              "      <td>3.060697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DNN</th>\n",
              "      <td>DeepNeuralNetwork</td>\n",
              "      <td>0.945055</td>\n",
              "      <td>0.912281</td>\n",
              "      <td>0.928668</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.914005</td>\n",
              "      <td>0.894086</td>\n",
              "      <td>0.902564</td>\n",
              "      <td>41.554656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>KNearestNeighborsClassifier</td>\n",
              "      <td>0.980220</td>\n",
              "      <td>0.991228</td>\n",
              "      <td>0.985724</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.993243</td>\n",
              "      <td>0.987805</td>\n",
              "      <td>0.990426</td>\n",
              "      <td>0.000920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LR</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.980220</td>\n",
              "      <td>0.973684</td>\n",
              "      <td>0.976952</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.980263</td>\n",
              "      <td>0.963415</td>\n",
              "      <td>0.970946</td>\n",
              "      <td>0.005973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.975824</td>\n",
              "      <td>0.991228</td>\n",
              "      <td>0.983526</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.993243</td>\n",
              "      <td>0.987805</td>\n",
              "      <td>0.990426</td>\n",
              "      <td>0.958414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>SupportVectorClassifier</td>\n",
              "      <td>0.951648</td>\n",
              "      <td>0.956140</td>\n",
              "      <td>0.953894</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.967949</td>\n",
              "      <td>0.939024</td>\n",
              "      <td>0.950976</td>\n",
              "      <td>0.046017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGB</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.993407</td>\n",
              "      <td>0.982456</td>\n",
              "      <td>0.987931</td>\n",
              "      <td>best</td>\n",
              "      <td>0.980956</td>\n",
              "      <td>0.980956</td>\n",
              "      <td>0.980956</td>\n",
              "      <td>2.190684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H_OD</th>\n",
              "      <td>H2OXGBoostEstimator</td>\n",
              "      <td>0.973626</td>\n",
              "      <td>0.964912</td>\n",
              "      <td>0.969269</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.958074</td>\n",
              "      <td>0.967257</td>\n",
              "      <td>0.962302</td>\n",
              "      <td>98.333856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H_SOD</th>\n",
              "      <td>H2ODeepLearningEstimator</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>0.912281</td>\n",
              "      <td>0.933063</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.914005</td>\n",
              "      <td>0.894086</td>\n",
              "      <td>0.902564</td>\n",
              "      <td>1675.899952</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ffb7e934-8180-44ba-b81f-f26cc00cc513')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ffb7e934-8180-44ba-b81f-f26cc00cc513 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ffb7e934-8180-44ba-b81f-f26cc00cc513');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    }
  ]
}