{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashiqurrahmankhan21st/BreastCancer/blob/main/Breast_Cancer_V6_TVAE_DATA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUMYU_d6_J-X"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "#import keras_metrics\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from sklearn.inspection import PartialDependenceDisplay\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TVAE data\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/ashiqurrahmankhan21st/BreastCancer/main/tvae_SDV_BreastCancer.csv\")\n",
        "del df['Unnamed: 0']\n",
        "df"
      ],
      "metadata": {
        "id": "Ntdqq4T_aGXN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "outputId": "7f78d927-48bd-44f8-e18e-d96c40224b8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     diagnosis  radius_mean  texture_mean  perimeter_mean   area_mean  \\\n",
              "0            B     9.866787     14.637137       63.409325  283.713730   \n",
              "1            B    12.885053     21.506004       79.229176  336.364127   \n",
              "2            B    11.165762     15.516346       84.076405  356.413321   \n",
              "3            B    12.271667     19.807824       68.534578  428.143496   \n",
              "4            B     7.454015     12.357933       51.167853  202.087605   \n",
              "...        ...          ...           ...             ...         ...   \n",
              "9995         B    11.653797     19.591590       66.871153  347.640448   \n",
              "9996         B    12.779385     13.799951       71.689730  568.975097   \n",
              "9997         B    12.144682     17.091324       72.648862  363.638743   \n",
              "9998         B    11.440653     14.876270       83.906545  447.719512   \n",
              "9999         B    12.327089     21.793296       90.006683  585.450805   \n",
              "\n",
              "      smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0            0.084223          0.046159        0.016544             0.020951   \n",
              "1            0.081238          0.061742        0.030052             0.025329   \n",
              "2            0.112075          0.064143        0.012986             0.000000   \n",
              "3            0.088438          0.031222        0.028840             0.018988   \n",
              "4            0.088588          0.052791        0.051511             0.013281   \n",
              "...               ...               ...             ...                  ...   \n",
              "9995         0.114469          0.153040        0.098849             0.020412   \n",
              "9996         0.102959          0.126075        0.107483             0.026956   \n",
              "9997         0.115953          0.122028        0.112376             0.031809   \n",
              "9998         0.101748          0.135110        0.069284             0.093306   \n",
              "9999         0.097919          0.170219        0.093106             0.028075   \n",
              "\n",
              "      symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
              "0          0.170999  ...     13.174990      18.064878        79.308249   \n",
              "1          0.169469  ...     15.764673      27.487070        81.358017   \n",
              "2          0.159183  ...     12.177383      34.227039        87.682893   \n",
              "3          0.144926  ...     14.332578      18.433072        68.255508   \n",
              "4          0.174599  ...     10.671485      18.960872        60.949763   \n",
              "...             ...  ...           ...            ...              ...   \n",
              "9995       0.171224  ...     13.364227      31.212963        75.105110   \n",
              "9996       0.176738  ...     14.636441      25.387452        81.755763   \n",
              "9997       0.145315  ...     12.978866      21.222782        88.692189   \n",
              "9998       0.198483  ...     14.864455      19.688309       104.210820   \n",
              "9999       0.185964  ...     12.195219      29.697275        77.443915   \n",
              "\n",
              "      area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
              "0     368.916148          0.152767           0.166851         0.158809   \n",
              "1     726.979378          0.112737           0.137944         0.120542   \n",
              "2     644.261133          0.125459           0.256056         0.112901   \n",
              "3     505.092414          0.092259           0.116755         0.059426   \n",
              "4     340.397278          0.127406           0.107711         0.110993   \n",
              "...          ...               ...                ...              ...   \n",
              "9995  309.445867          0.150710           0.268134         0.244718   \n",
              "9996  675.860482          0.160312           0.562150         0.291571   \n",
              "9997  534.210501          0.185600           0.492610         0.452870   \n",
              "9998  711.314226          0.158937           0.555026         0.211123   \n",
              "9999  449.710078          0.147902           0.498236         0.346742   \n",
              "\n",
              "      concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
              "0                 0.035439        0.288579                 0.073689  \n",
              "1                 0.071356        0.271750                 0.068861  \n",
              "2                 0.045699        0.301039                 0.055040  \n",
              "3                 0.044334        0.235016                 0.079151  \n",
              "4                 0.000000        0.299682                 0.069818  \n",
              "...                    ...             ...                      ...  \n",
              "9995              0.056089        0.251965                 0.088369  \n",
              "9996              0.173512        0.298970                 0.102903  \n",
              "9997              0.090011        0.243860                 0.143752  \n",
              "9998              0.186335        0.263381                 0.072269  \n",
              "9999              0.067868        0.252371                 0.084630  \n",
              "\n",
              "[10000 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cf290bc0-3744-4409-90a4-7d156ac3fc3d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B</td>\n",
              "      <td>9.866787</td>\n",
              "      <td>14.637137</td>\n",
              "      <td>63.409325</td>\n",
              "      <td>283.713730</td>\n",
              "      <td>0.084223</td>\n",
              "      <td>0.046159</td>\n",
              "      <td>0.016544</td>\n",
              "      <td>0.020951</td>\n",
              "      <td>0.170999</td>\n",
              "      <td>...</td>\n",
              "      <td>13.174990</td>\n",
              "      <td>18.064878</td>\n",
              "      <td>79.308249</td>\n",
              "      <td>368.916148</td>\n",
              "      <td>0.152767</td>\n",
              "      <td>0.166851</td>\n",
              "      <td>0.158809</td>\n",
              "      <td>0.035439</td>\n",
              "      <td>0.288579</td>\n",
              "      <td>0.073689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B</td>\n",
              "      <td>12.885053</td>\n",
              "      <td>21.506004</td>\n",
              "      <td>79.229176</td>\n",
              "      <td>336.364127</td>\n",
              "      <td>0.081238</td>\n",
              "      <td>0.061742</td>\n",
              "      <td>0.030052</td>\n",
              "      <td>0.025329</td>\n",
              "      <td>0.169469</td>\n",
              "      <td>...</td>\n",
              "      <td>15.764673</td>\n",
              "      <td>27.487070</td>\n",
              "      <td>81.358017</td>\n",
              "      <td>726.979378</td>\n",
              "      <td>0.112737</td>\n",
              "      <td>0.137944</td>\n",
              "      <td>0.120542</td>\n",
              "      <td>0.071356</td>\n",
              "      <td>0.271750</td>\n",
              "      <td>0.068861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B</td>\n",
              "      <td>11.165762</td>\n",
              "      <td>15.516346</td>\n",
              "      <td>84.076405</td>\n",
              "      <td>356.413321</td>\n",
              "      <td>0.112075</td>\n",
              "      <td>0.064143</td>\n",
              "      <td>0.012986</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.159183</td>\n",
              "      <td>...</td>\n",
              "      <td>12.177383</td>\n",
              "      <td>34.227039</td>\n",
              "      <td>87.682893</td>\n",
              "      <td>644.261133</td>\n",
              "      <td>0.125459</td>\n",
              "      <td>0.256056</td>\n",
              "      <td>0.112901</td>\n",
              "      <td>0.045699</td>\n",
              "      <td>0.301039</td>\n",
              "      <td>0.055040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B</td>\n",
              "      <td>12.271667</td>\n",
              "      <td>19.807824</td>\n",
              "      <td>68.534578</td>\n",
              "      <td>428.143496</td>\n",
              "      <td>0.088438</td>\n",
              "      <td>0.031222</td>\n",
              "      <td>0.028840</td>\n",
              "      <td>0.018988</td>\n",
              "      <td>0.144926</td>\n",
              "      <td>...</td>\n",
              "      <td>14.332578</td>\n",
              "      <td>18.433072</td>\n",
              "      <td>68.255508</td>\n",
              "      <td>505.092414</td>\n",
              "      <td>0.092259</td>\n",
              "      <td>0.116755</td>\n",
              "      <td>0.059426</td>\n",
              "      <td>0.044334</td>\n",
              "      <td>0.235016</td>\n",
              "      <td>0.079151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B</td>\n",
              "      <td>7.454015</td>\n",
              "      <td>12.357933</td>\n",
              "      <td>51.167853</td>\n",
              "      <td>202.087605</td>\n",
              "      <td>0.088588</td>\n",
              "      <td>0.052791</td>\n",
              "      <td>0.051511</td>\n",
              "      <td>0.013281</td>\n",
              "      <td>0.174599</td>\n",
              "      <td>...</td>\n",
              "      <td>10.671485</td>\n",
              "      <td>18.960872</td>\n",
              "      <td>60.949763</td>\n",
              "      <td>340.397278</td>\n",
              "      <td>0.127406</td>\n",
              "      <td>0.107711</td>\n",
              "      <td>0.110993</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.299682</td>\n",
              "      <td>0.069818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>B</td>\n",
              "      <td>11.653797</td>\n",
              "      <td>19.591590</td>\n",
              "      <td>66.871153</td>\n",
              "      <td>347.640448</td>\n",
              "      <td>0.114469</td>\n",
              "      <td>0.153040</td>\n",
              "      <td>0.098849</td>\n",
              "      <td>0.020412</td>\n",
              "      <td>0.171224</td>\n",
              "      <td>...</td>\n",
              "      <td>13.364227</td>\n",
              "      <td>31.212963</td>\n",
              "      <td>75.105110</td>\n",
              "      <td>309.445867</td>\n",
              "      <td>0.150710</td>\n",
              "      <td>0.268134</td>\n",
              "      <td>0.244718</td>\n",
              "      <td>0.056089</td>\n",
              "      <td>0.251965</td>\n",
              "      <td>0.088369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>B</td>\n",
              "      <td>12.779385</td>\n",
              "      <td>13.799951</td>\n",
              "      <td>71.689730</td>\n",
              "      <td>568.975097</td>\n",
              "      <td>0.102959</td>\n",
              "      <td>0.126075</td>\n",
              "      <td>0.107483</td>\n",
              "      <td>0.026956</td>\n",
              "      <td>0.176738</td>\n",
              "      <td>...</td>\n",
              "      <td>14.636441</td>\n",
              "      <td>25.387452</td>\n",
              "      <td>81.755763</td>\n",
              "      <td>675.860482</td>\n",
              "      <td>0.160312</td>\n",
              "      <td>0.562150</td>\n",
              "      <td>0.291571</td>\n",
              "      <td>0.173512</td>\n",
              "      <td>0.298970</td>\n",
              "      <td>0.102903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>B</td>\n",
              "      <td>12.144682</td>\n",
              "      <td>17.091324</td>\n",
              "      <td>72.648862</td>\n",
              "      <td>363.638743</td>\n",
              "      <td>0.115953</td>\n",
              "      <td>0.122028</td>\n",
              "      <td>0.112376</td>\n",
              "      <td>0.031809</td>\n",
              "      <td>0.145315</td>\n",
              "      <td>...</td>\n",
              "      <td>12.978866</td>\n",
              "      <td>21.222782</td>\n",
              "      <td>88.692189</td>\n",
              "      <td>534.210501</td>\n",
              "      <td>0.185600</td>\n",
              "      <td>0.492610</td>\n",
              "      <td>0.452870</td>\n",
              "      <td>0.090011</td>\n",
              "      <td>0.243860</td>\n",
              "      <td>0.143752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>B</td>\n",
              "      <td>11.440653</td>\n",
              "      <td>14.876270</td>\n",
              "      <td>83.906545</td>\n",
              "      <td>447.719512</td>\n",
              "      <td>0.101748</td>\n",
              "      <td>0.135110</td>\n",
              "      <td>0.069284</td>\n",
              "      <td>0.093306</td>\n",
              "      <td>0.198483</td>\n",
              "      <td>...</td>\n",
              "      <td>14.864455</td>\n",
              "      <td>19.688309</td>\n",
              "      <td>104.210820</td>\n",
              "      <td>711.314226</td>\n",
              "      <td>0.158937</td>\n",
              "      <td>0.555026</td>\n",
              "      <td>0.211123</td>\n",
              "      <td>0.186335</td>\n",
              "      <td>0.263381</td>\n",
              "      <td>0.072269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>B</td>\n",
              "      <td>12.327089</td>\n",
              "      <td>21.793296</td>\n",
              "      <td>90.006683</td>\n",
              "      <td>585.450805</td>\n",
              "      <td>0.097919</td>\n",
              "      <td>0.170219</td>\n",
              "      <td>0.093106</td>\n",
              "      <td>0.028075</td>\n",
              "      <td>0.185964</td>\n",
              "      <td>...</td>\n",
              "      <td>12.195219</td>\n",
              "      <td>29.697275</td>\n",
              "      <td>77.443915</td>\n",
              "      <td>449.710078</td>\n",
              "      <td>0.147902</td>\n",
              "      <td>0.498236</td>\n",
              "      <td>0.346742</td>\n",
              "      <td>0.067868</td>\n",
              "      <td>0.252371</td>\n",
              "      <td>0.084630</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf290bc0-3744-4409-90a4-7d156ac3fc3d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cf290bc0-3744-4409-90a4-7d156ac3fc3d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cf290bc0-3744-4409-90a4-7d156ac3fc3d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(df['diagnosis']).copy()\n",
        "X = df.drop(columns=['diagnosis']).copy()\n",
        "X = StandardScaler().fit_transform(X).copy()"
      ],
      "metadata": {
        "id": "4cimS259ti6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['diagnosis'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bv9sG-P8M1Fe",
        "outputId": "7522e3c4-762f-48bf-be0d-efacc5c4278a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "B    6166\n",
              "M    3834\n",
              "Name: diagnosis, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(df['diagnosis']).copy()\n",
        "X = df.drop(columns=['diagnosis']).copy()\n",
        "X = StandardScaler().fit_transform(X).copy()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "#X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=123)\n",
        "y_test_indi_ML = y_test.copy()\n",
        "print(\"Original data : \",df.shape)\n",
        "print(\"tarin         : \",X_train.shape)\n",
        "print(\"test          : \",X_test.shape[0])\n",
        "#print(\"validation    : \",X_val.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpyVwv13CTut",
        "outputId": "0c11acc3-8cdb-457d-c659-5439b409f2db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original data :  (10000, 31)\n",
            "tarin         :  (8000, 30)\n",
            "test          :  2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM\n",
        "st = time.time()\n",
        "svm = SVC(C=0.1, gamma='auto', kernel = 'rbf',probability=True)\n",
        "svm.fit(X_train, y_train)\n",
        "send = time.time() - st\n",
        "STr = svm.score(X_train, y_train)\n",
        "STe = svm.score(X_test, y_test)\n",
        "y_pred_svm = svm.predict(X_test)"
      ],
      "metadata": {
        "id": "wnRYFOkyEEZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ANN\n",
        "st = time.time()\n",
        "tf.random.set_seed(123)\n",
        "ANNmodel = Sequential()\n",
        "ANNmodel.add(Dense(30, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "ANNmodel.add(Dense(10, activation='relu'))\n",
        "ANNmodel.add(Dense(1, activation='sigmoid'))\n",
        "ANNmodel.compile(loss='BinaryCrossentropy', optimizer='adam', metrics=['accuracy']) #tf.keras.metrics.Precision(), tf.keras.metrics.Recall()\n",
        "ANNmodel.fit(X_train,y_train, batch_size = 128, epochs = 20, validation_split = 0.1)\n",
        "aend = time.time() - st\n",
        "ATr = ANNmodel.evaluate(X_train,y_train,verbose=0)[1]\n",
        "ATe = ANNmodel.evaluate(X_test,y_test,verbose=0)[1]\n",
        "y_pred_ANN = (ANNmodel.predict(X_test) > 0.5).astype(\"int32\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZX7DbN-OIyu",
        "outputId": "3d88a85e-7db7-4d96-dd5b-c747e234e692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "57/57 [==============================] - 1s 7ms/step - loss: 0.4745 - accuracy: 0.7653 - val_loss: 0.2605 - val_accuracy: 0.9250\n",
            "Epoch 2/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.2101 - accuracy: 0.9178 - val_loss: 0.1624 - val_accuracy: 0.9413\n",
            "Epoch 3/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1541 - accuracy: 0.9349 - val_loss: 0.1317 - val_accuracy: 0.9500\n",
            "Epoch 4/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1342 - accuracy: 0.9421 - val_loss: 0.1215 - val_accuracy: 0.9488\n",
            "Epoch 5/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1250 - accuracy: 0.9469 - val_loss: 0.1156 - val_accuracy: 0.9538\n",
            "Epoch 6/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1204 - accuracy: 0.9485 - val_loss: 0.1130 - val_accuracy: 0.9538\n",
            "Epoch 7/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1174 - accuracy: 0.9488 - val_loss: 0.1109 - val_accuracy: 0.9525\n",
            "Epoch 8/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1157 - accuracy: 0.9503 - val_loss: 0.1115 - val_accuracy: 0.9525\n",
            "Epoch 9/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1137 - accuracy: 0.9510 - val_loss: 0.1097 - val_accuracy: 0.9538\n",
            "Epoch 10/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1120 - accuracy: 0.9508 - val_loss: 0.1082 - val_accuracy: 0.9538\n",
            "Epoch 11/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1112 - accuracy: 0.9511 - val_loss: 0.1105 - val_accuracy: 0.9550\n",
            "Epoch 12/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1103 - accuracy: 0.9510 - val_loss: 0.1080 - val_accuracy: 0.9525\n",
            "Epoch 13/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1085 - accuracy: 0.9529 - val_loss: 0.1079 - val_accuracy: 0.9538\n",
            "Epoch 14/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1078 - accuracy: 0.9535 - val_loss: 0.1077 - val_accuracy: 0.9550\n",
            "Epoch 15/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1065 - accuracy: 0.9531 - val_loss: 0.1079 - val_accuracy: 0.9563\n",
            "Epoch 16/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1055 - accuracy: 0.9547 - val_loss: 0.1068 - val_accuracy: 0.9563\n",
            "Epoch 17/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1049 - accuracy: 0.9549 - val_loss: 0.1082 - val_accuracy: 0.9575\n",
            "Epoch 18/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1043 - accuracy: 0.9564 - val_loss: 0.1062 - val_accuracy: 0.9575\n",
            "Epoch 19/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1033 - accuracy: 0.9563 - val_loss: 0.1064 - val_accuracy: 0.9575\n",
            "Epoch 20/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1026 - accuracy: 0.9563 - val_loss: 0.1078 - val_accuracy: 0.9550\n",
            "63/63 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ATr,ATe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sKNScl37zhV",
        "outputId": "b713dfc1-b200-4590-eae6-675a14921c54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9585000276565552, 0.9455000162124634)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XGBoost\n",
        "st = time.time()\n",
        "xgb = XGBClassifier(objective='binary:logistic',max_depth= 6,alpha= 50,learning_rate= 0.01,n_estimators=250)\n",
        "xgb.fit(X_train, y_train)\n",
        "xend = time.time() - st\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "XTr = accuracy_score(y_train, xgb.predict(X_train))\n",
        "XTe = accuracy_score(y_test, xgb.predict(X_test))\n",
        "XTr,XTe"
      ],
      "metadata": {
        "id": "PCP82YZ9RjgJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "254a7099-88ee-412f-b1ca-50ff86082b7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.956875, 0.941)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#KNN\n",
        "# Define the range of n_neighbors values to test\n",
        "n_neighbors_values = [1,3, 5, 7, 9, 11]\n",
        "\n",
        "best_accuracy = 0.0\n",
        "best_n_neighbors = None\n",
        "\n",
        "for n_neighbors in n_neighbors_values:\n",
        "    print(\"Number of Neighbors:\", n_neighbors)\n",
        "\n",
        "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    y_pred_knn = knn.predict(X_test)\n",
        "\n",
        "    train_accuracy = accuracy_score(y_train, knn.predict(X_train))\n",
        "    test_accuracy = accuracy_score(y_test, knn.predict(X_test))\n",
        "\n",
        "    print('KNN model train accuracy score: {0:0.4f}'.format(train_accuracy))\n",
        "    print('KNN model test accuracy score: {0:0.4f}'.format(test_accuracy))\n",
        "    print()\n",
        "\n",
        "    # Check if the current test accuracy is better than the previous best\n",
        "    if test_accuracy > best_accuracy:\n",
        "        best_accuracy = test_accuracy\n",
        "        best_n_neighbors = n_neighbors\n",
        "print(\"best neighbours: \", best_n_neighbors)\n",
        "\n",
        "st = time.time()\n",
        "knn = KNeighborsClassifier(n_neighbors=best_n_neighbors)\n",
        "knn.fit(X_train, y_train)\n",
        "kend = time.time() - st\n",
        "KTr = accuracy_score(y_train, knn.predict(X_train))\n",
        "KTe = accuracy_score(y_test, knn.predict(X_test))\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "KTr,KTe\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Y_6b33A1imy",
        "outputId": "068193b8-fee1-4f95-d1e0-f9341af1d82c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Neighbors: 1\n",
            "KNN model train accuracy score: 1.0000\n",
            "KNN model test accuracy score: 0.9180\n",
            "\n",
            "Number of Neighbors: 3\n",
            "KNN model train accuracy score: 0.9629\n",
            "KNN model test accuracy score: 0.9340\n",
            "\n",
            "Number of Neighbors: 5\n",
            "KNN model train accuracy score: 0.9549\n",
            "KNN model test accuracy score: 0.9445\n",
            "\n",
            "Number of Neighbors: 7\n",
            "KNN model train accuracy score: 0.9537\n",
            "KNN model test accuracy score: 0.9440\n",
            "\n",
            "Number of Neighbors: 9\n",
            "KNN model train accuracy score: 0.9523\n",
            "KNN model test accuracy score: 0.9445\n",
            "\n",
            "Number of Neighbors: 11\n",
            "KNN model train accuracy score: 0.9499\n",
            "KNN model test accuracy score: 0.9410\n",
            "\n",
            "best neighbours:  5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.954875, 0.9445)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RF\n",
        "st = time.time()\n",
        "rf = RandomForestClassifier(n_estimators= 500,max_features = 'sqrt', max_samples = 100, random_state=123)\n",
        "rf.fit(X_train, y_train)\n",
        "rend = time.time() - st\n",
        "RTr = accuracy_score(y_train, rf.predict(X_train))\n",
        "RTe = accuracy_score(y_test, rf.predict(X_test))\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "RTr,RTe"
      ],
      "metadata": {
        "id": "k_kyk_E92bSX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26051949-6ff4-4e27-bda5-7f26236e8575"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.943875, 0.9505)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LR\n",
        "st = time.time()\n",
        "lr = LogisticRegression(C= 0.1 , penalty='l1', solver='liblinear', max_iter = 1000, random_state=123)\n",
        "lr.fit(X_train, y_train)\n",
        "lend = time.time() - st\n",
        "LTr = accuracy_score(y_train, lr.predict(X_train))\n",
        "LTe = accuracy_score(y_test, lr.predict(X_test))\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "LTr,LTe"
      ],
      "metadata": {
        "id": "OWkZmwL23Fm_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dfa5110-5e70-4a4b-fe09-d99f54753e49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.95, 0.95)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E9_l6r5f0w5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CVal(ML):\n",
        "\n",
        "  df = pd.read_csv(\"https://raw.githubusercontent.com/ashiqurrahmankhan21st/BreastCancer/main/tvae_SDV_BreastCancer.csv\")\n",
        "  del df['Unnamed: 0']\n",
        "\n",
        "  s = 0\n",
        "  e = round(df.shape[0]*.2)\n",
        "\n",
        "  y_pred = []\n",
        "  y_original = []\n",
        "\n",
        "  for i in range(5):\n",
        "\n",
        "    test_set  = df.iloc[s:e,:]\n",
        "    train_set = df.drop(test_set.index)\n",
        "\n",
        "    X_train = StandardScaler().fit_transform(train_set.drop(columns=['diagnosis'])).copy()\n",
        "    y_train = encoder.fit_transform(train_set['diagnosis']).copy()\n",
        "    X_test = StandardScaler().fit_transform(test_set.drop(columns=['diagnosis'])).copy()\n",
        "    y_test = encoder.fit_transform(test_set['diagnosis']).copy()\n",
        "\n",
        "    #svm = SVC(C=0.1, gamma='auto', kernel = 'rbf')\n",
        "\n",
        "    ML.fit(X_train, y_train)\n",
        "    y_pred_ML = ML.predict(X_test)\n",
        "\n",
        "\n",
        "    y_pred.append(y_pred_ML)\n",
        "    y_original.append(y_test)\n",
        "\n",
        "    s = e\n",
        "    e = e + round(df.shape[0]*.2)\n",
        "    if e-s < round(df.shape[0]*.2):\n",
        "      e = df.shape[0]+1\n",
        "\n",
        "  y_pred_final = []\n",
        "  y_original_final = []\n",
        "\n",
        "  try:\n",
        "    for i in range(5):\n",
        "      for j in range(round(df.shape[0]*.2)):\n",
        "        y_pred_final.append(y_pred[i][j])\n",
        "        y_original_final.append(y_original[i][j])\n",
        "  except:\n",
        "    pass\n",
        "  return y_pred_final"
      ],
      "metadata": {
        "id": "XqaJZ1Mb0xAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CValANN():\n",
        "\n",
        "  df = pd.read_csv(\"https://raw.githubusercontent.com/ashiqurrahmankhan21st/BreastCancer/main/tvae_SDV_BreastCancer.csv\")\n",
        "  del df['Unnamed: 0']\n",
        "\n",
        "  s = 0\n",
        "  e = round(df.shape[0]*.2)\n",
        "\n",
        "  y_pred = []\n",
        "  y_original = []\n",
        "\n",
        "  for i in range(5):\n",
        "\n",
        "    test_set  = df.iloc[s:e,:]\n",
        "    train_set = df.drop(test_set.index)\n",
        "\n",
        "    X_train = StandardScaler().fit_transform(train_set.drop(columns=['diagnosis'])).copy()\n",
        "    y_train = encoder.fit_transform(train_set['diagnosis']).copy()\n",
        "    X_test = StandardScaler().fit_transform(test_set.drop(columns=['diagnosis'])).copy()\n",
        "    y_test = encoder.fit_transform(test_set['diagnosis']).copy()\n",
        "\n",
        "    #svm = SVC(C=0.1, gamma='auto', kernel = 'rbf')\n",
        "    tf.random.set_seed(123)\n",
        "    ANNmodel = Sequential()\n",
        "    ANNmodel.add(Dense(30, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "    ANNmodel.add(Dense(10, activation='relu'))\n",
        "    ANNmodel.add(Dense(1, activation='sigmoid'))\n",
        "    ANNmodel.compile(loss='BinaryCrossentropy', optimizer='adam', metrics=['accuracy']) #tf.keras.metrics.Precision(), tf.keras.metrics.Recall()\n",
        "    ANNmodel.fit(X_train,y_train, batch_size = 128, epochs = 20, validation_split = 0.1)\n",
        "    y_pred_ANN = (ANNmodel.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "\n",
        "    y_pred.append(y_pred_ANN)\n",
        "    y_original.append(y_test)\n",
        "\n",
        "    s = e\n",
        "    e = e + round(df.shape[0]*.2)\n",
        "    if e-s < round(df.shape[0]*.2):\n",
        "      e = df.shape[0]\n",
        "\n",
        "  y_pred_fina = []\n",
        "  y_original_final = []\n",
        "\n",
        "  try:\n",
        "    for i in range(5):\n",
        "      for j in range(round(df.shape[0]*.2)):\n",
        "        y_pred_fina.append(y_pred[i][j])\n",
        "        y_original_final.append(y_original[i][j])\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  y_pred_final = []\n",
        "\n",
        "  for i in range(len(y_pred_fina)):\n",
        "    y_pred_final.append(y_pred_fina[i][0])\n",
        "\n",
        "  return y_pred_final"
      ],
      "metadata": {
        "id": "jRa_a7EY0y6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newdata = pd.DataFrame({\n",
        "    \"SVM\": CVal(SVC(C=0.1, gamma='auto', kernel = 'rbf'))\n",
        "})\n",
        "newdata[\"KNN\"] = CVal(KNeighborsClassifier(n_neighbors=3))\n",
        "newdata[\"RF\"]  = CVal(RandomForestClassifier(n_estimators= 500,max_features = 'sqrt', max_samples = 100, random_state=123))\n",
        "newdata['LR']  = CVal(LogisticRegression(C= 0.1 , penalty='l1', solver='liblinear', max_iter = 1000, random_state=123))\n",
        "newdata[\"ANN\"] = CValANN()\n",
        "newdata[\"XGB\"] = CVal(XGBClassifier(objective='binary:logistic',max_depth= 7,alpha= 10,learning_rate= 1,n_estimators=100))\n",
        "newdata['y_test'] = encoder.fit_transform(df['diagnosis']).copy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CGgdO1V0zA9",
        "outputId": "fa7178a5-fcd1-4b38-f5d2-c3a00254da34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "57/57 [==============================] - 1s 5ms/step - loss: 0.3554 - accuracy: 0.8706 - val_loss: 0.2198 - val_accuracy: 0.9250\n",
            "Epoch 2/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1680 - accuracy: 0.9362 - val_loss: 0.1551 - val_accuracy: 0.9438\n",
            "Epoch 3/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1379 - accuracy: 0.9435 - val_loss: 0.1384 - val_accuracy: 0.9488\n",
            "Epoch 4/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1278 - accuracy: 0.9450 - val_loss: 0.1316 - val_accuracy: 0.9525\n",
            "Epoch 5/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1220 - accuracy: 0.9478 - val_loss: 0.1284 - val_accuracy: 0.9550\n",
            "Epoch 6/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1184 - accuracy: 0.9497 - val_loss: 0.1248 - val_accuracy: 0.9563\n",
            "Epoch 7/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1152 - accuracy: 0.9508 - val_loss: 0.1250 - val_accuracy: 0.9538\n",
            "Epoch 8/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1133 - accuracy: 0.9503 - val_loss: 0.1220 - val_accuracy: 0.9575\n",
            "Epoch 9/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1111 - accuracy: 0.9510 - val_loss: 0.1223 - val_accuracy: 0.9563\n",
            "Epoch 10/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1097 - accuracy: 0.9522 - val_loss: 0.1224 - val_accuracy: 0.9538\n",
            "Epoch 11/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1077 - accuracy: 0.9531 - val_loss: 0.1224 - val_accuracy: 0.9563\n",
            "Epoch 12/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1066 - accuracy: 0.9526 - val_loss: 0.1215 - val_accuracy: 0.9538\n",
            "Epoch 13/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1059 - accuracy: 0.9539 - val_loss: 0.1205 - val_accuracy: 0.9550\n",
            "Epoch 14/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1040 - accuracy: 0.9547 - val_loss: 0.1208 - val_accuracy: 0.9550\n",
            "Epoch 15/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1028 - accuracy: 0.9563 - val_loss: 0.1214 - val_accuracy: 0.9538\n",
            "Epoch 16/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1015 - accuracy: 0.9568 - val_loss: 0.1203 - val_accuracy: 0.9538\n",
            "Epoch 17/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1004 - accuracy: 0.9569 - val_loss: 0.1206 - val_accuracy: 0.9538\n",
            "Epoch 18/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0994 - accuracy: 0.9567 - val_loss: 0.1202 - val_accuracy: 0.9538\n",
            "Epoch 19/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0983 - accuracy: 0.9569 - val_loss: 0.1200 - val_accuracy: 0.9538\n",
            "Epoch 20/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0977 - accuracy: 0.9576 - val_loss: 0.1202 - val_accuracy: 0.9538\n",
            "63/63 [==============================] - 0s 1ms/step\n",
            "Epoch 1/20\n",
            "57/57 [==============================] - 1s 8ms/step - loss: 0.4553 - accuracy: 0.8143 - val_loss: 0.2953 - val_accuracy: 0.8963\n",
            "Epoch 2/20\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2131 - accuracy: 0.9222 - val_loss: 0.1735 - val_accuracy: 0.9262\n",
            "Epoch 3/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1487 - accuracy: 0.9390 - val_loss: 0.1432 - val_accuracy: 0.9375\n",
            "Epoch 4/20\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1327 - accuracy: 0.9447 - val_loss: 0.1335 - val_accuracy: 0.9438\n",
            "Epoch 5/20\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1257 - accuracy: 0.9475 - val_loss: 0.1284 - val_accuracy: 0.9538\n",
            "Epoch 6/20\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1215 - accuracy: 0.9492 - val_loss: 0.1242 - val_accuracy: 0.9550\n",
            "Epoch 7/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1179 - accuracy: 0.9494 - val_loss: 0.1226 - val_accuracy: 0.9538\n",
            "Epoch 8/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1155 - accuracy: 0.9497 - val_loss: 0.1199 - val_accuracy: 0.9550\n",
            "Epoch 9/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1132 - accuracy: 0.9511 - val_loss: 0.1192 - val_accuracy: 0.9550\n",
            "Epoch 10/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1113 - accuracy: 0.9507 - val_loss: 0.1188 - val_accuracy: 0.9563\n",
            "Epoch 11/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1098 - accuracy: 0.9529 - val_loss: 0.1197 - val_accuracy: 0.9550\n",
            "Epoch 12/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1087 - accuracy: 0.9533 - val_loss: 0.1192 - val_accuracy: 0.9538\n",
            "Epoch 13/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1070 - accuracy: 0.9544 - val_loss: 0.1182 - val_accuracy: 0.9488\n",
            "Epoch 14/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1055 - accuracy: 0.9551 - val_loss: 0.1184 - val_accuracy: 0.9513\n",
            "Epoch 15/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1042 - accuracy: 0.9560 - val_loss: 0.1198 - val_accuracy: 0.9500\n",
            "Epoch 16/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1028 - accuracy: 0.9578 - val_loss: 0.1187 - val_accuracy: 0.9513\n",
            "Epoch 17/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1015 - accuracy: 0.9571 - val_loss: 0.1193 - val_accuracy: 0.9525\n",
            "Epoch 18/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1006 - accuracy: 0.9568 - val_loss: 0.1207 - val_accuracy: 0.9525\n",
            "Epoch 19/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.0994 - accuracy: 0.9578 - val_loss: 0.1202 - val_accuracy: 0.9500\n",
            "Epoch 20/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0989 - accuracy: 0.9581 - val_loss: 0.1212 - val_accuracy: 0.9513\n",
            "63/63 [==============================] - 0s 1ms/step\n",
            "Epoch 1/20\n",
            "57/57 [==============================] - 1s 5ms/step - loss: 0.6223 - accuracy: 0.6222 - val_loss: 0.4484 - val_accuracy: 0.8775\n",
            "Epoch 2/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.2976 - accuracy: 0.9247 - val_loss: 0.1932 - val_accuracy: 0.9463\n",
            "Epoch 3/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1577 - accuracy: 0.9407 - val_loss: 0.1428 - val_accuracy: 0.9513\n",
            "Epoch 4/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1327 - accuracy: 0.9458 - val_loss: 0.1315 - val_accuracy: 0.9513\n",
            "Epoch 5/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1241 - accuracy: 0.9478 - val_loss: 0.1269 - val_accuracy: 0.9525\n",
            "Epoch 6/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1199 - accuracy: 0.9489 - val_loss: 0.1243 - val_accuracy: 0.9513\n",
            "Epoch 7/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1160 - accuracy: 0.9499 - val_loss: 0.1224 - val_accuracy: 0.9513\n",
            "Epoch 8/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1138 - accuracy: 0.9494 - val_loss: 0.1210 - val_accuracy: 0.9513\n",
            "Epoch 9/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1115 - accuracy: 0.9517 - val_loss: 0.1202 - val_accuracy: 0.9488\n",
            "Epoch 10/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1098 - accuracy: 0.9507 - val_loss: 0.1187 - val_accuracy: 0.9513\n",
            "Epoch 11/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1085 - accuracy: 0.9525 - val_loss: 0.1190 - val_accuracy: 0.9500\n",
            "Epoch 12/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1074 - accuracy: 0.9521 - val_loss: 0.1185 - val_accuracy: 0.9513\n",
            "Epoch 13/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1059 - accuracy: 0.9539 - val_loss: 0.1172 - val_accuracy: 0.9525\n",
            "Epoch 14/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1048 - accuracy: 0.9538 - val_loss: 0.1165 - val_accuracy: 0.9538\n",
            "Epoch 15/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1040 - accuracy: 0.9543 - val_loss: 0.1170 - val_accuracy: 0.9550\n",
            "Epoch 16/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1027 - accuracy: 0.9547 - val_loss: 0.1159 - val_accuracy: 0.9550\n",
            "Epoch 17/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1018 - accuracy: 0.9560 - val_loss: 0.1155 - val_accuracy: 0.9563\n",
            "Epoch 18/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1011 - accuracy: 0.9554 - val_loss: 0.1157 - val_accuracy: 0.9525\n",
            "Epoch 19/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0998 - accuracy: 0.9564 - val_loss: 0.1159 - val_accuracy: 0.9550\n",
            "Epoch 20/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0998 - accuracy: 0.9568 - val_loss: 0.1158 - val_accuracy: 0.9538\n",
            "63/63 [==============================] - 0s 1ms/step\n",
            "Epoch 1/20\n",
            "57/57 [==============================] - 1s 5ms/step - loss: 0.5164 - accuracy: 0.7994 - val_loss: 0.3283 - val_accuracy: 0.8925\n",
            "Epoch 2/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.2293 - accuracy: 0.9236 - val_loss: 0.1950 - val_accuracy: 0.9325\n",
            "Epoch 3/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1596 - accuracy: 0.9350 - val_loss: 0.1555 - val_accuracy: 0.9375\n",
            "Epoch 4/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1371 - accuracy: 0.9406 - val_loss: 0.1419 - val_accuracy: 0.9388\n",
            "Epoch 5/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1274 - accuracy: 0.9439 - val_loss: 0.1360 - val_accuracy: 0.9425\n",
            "Epoch 6/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1221 - accuracy: 0.9465 - val_loss: 0.1328 - val_accuracy: 0.9475\n",
            "Epoch 7/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1187 - accuracy: 0.9478 - val_loss: 0.1314 - val_accuracy: 0.9488\n",
            "Epoch 8/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1164 - accuracy: 0.9482 - val_loss: 0.1297 - val_accuracy: 0.9513\n",
            "Epoch 9/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1136 - accuracy: 0.9499 - val_loss: 0.1287 - val_accuracy: 0.9488\n",
            "Epoch 10/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1124 - accuracy: 0.9511 - val_loss: 0.1276 - val_accuracy: 0.9538\n",
            "Epoch 11/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1111 - accuracy: 0.9510 - val_loss: 0.1273 - val_accuracy: 0.9525\n",
            "Epoch 12/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1097 - accuracy: 0.9515 - val_loss: 0.1265 - val_accuracy: 0.9500\n",
            "Epoch 13/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1084 - accuracy: 0.9528 - val_loss: 0.1262 - val_accuracy: 0.9513\n",
            "Epoch 14/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1075 - accuracy: 0.9521 - val_loss: 0.1257 - val_accuracy: 0.9500\n",
            "Epoch 15/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1064 - accuracy: 0.9524 - val_loss: 0.1262 - val_accuracy: 0.9513\n",
            "Epoch 16/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1052 - accuracy: 0.9549 - val_loss: 0.1250 - val_accuracy: 0.9513\n",
            "Epoch 17/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1039 - accuracy: 0.9550 - val_loss: 0.1251 - val_accuracy: 0.9525\n",
            "Epoch 18/20\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1029 - accuracy: 0.9557 - val_loss: 0.1247 - val_accuracy: 0.9525\n",
            "Epoch 19/20\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1019 - accuracy: 0.9554 - val_loss: 0.1246 - val_accuracy: 0.9513\n",
            "Epoch 20/20\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1011 - accuracy: 0.9551 - val_loss: 0.1248 - val_accuracy: 0.9538\n",
            "63/63 [==============================] - 0s 1ms/step\n",
            "Epoch 1/20\n",
            "57/57 [==============================] - 1s 6ms/step - loss: 0.4413 - accuracy: 0.8414 - val_loss: 0.2329 - val_accuracy: 0.9275\n",
            "Epoch 2/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1892 - accuracy: 0.9362 - val_loss: 0.1495 - val_accuracy: 0.9337\n",
            "Epoch 3/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1423 - accuracy: 0.9443 - val_loss: 0.1302 - val_accuracy: 0.9362\n",
            "Epoch 4/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1274 - accuracy: 0.9492 - val_loss: 0.1232 - val_accuracy: 0.9413\n",
            "Epoch 5/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1205 - accuracy: 0.9514 - val_loss: 0.1192 - val_accuracy: 0.9362\n",
            "Epoch 6/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1162 - accuracy: 0.9515 - val_loss: 0.1178 - val_accuracy: 0.9413\n",
            "Epoch 7/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1128 - accuracy: 0.9531 - val_loss: 0.1155 - val_accuracy: 0.9413\n",
            "Epoch 8/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1111 - accuracy: 0.9532 - val_loss: 0.1145 - val_accuracy: 0.9525\n",
            "Epoch 9/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1086 - accuracy: 0.9540 - val_loss: 0.1098 - val_accuracy: 0.9488\n",
            "Epoch 10/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1073 - accuracy: 0.9543 - val_loss: 0.1097 - val_accuracy: 0.9488\n",
            "Epoch 11/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1057 - accuracy: 0.9553 - val_loss: 0.1092 - val_accuracy: 0.9513\n",
            "Epoch 12/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1042 - accuracy: 0.9561 - val_loss: 0.1094 - val_accuracy: 0.9513\n",
            "Epoch 13/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1026 - accuracy: 0.9560 - val_loss: 0.1079 - val_accuracy: 0.9525\n",
            "Epoch 14/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1014 - accuracy: 0.9565 - val_loss: 0.1081 - val_accuracy: 0.9513\n",
            "Epoch 15/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1004 - accuracy: 0.9564 - val_loss: 0.1056 - val_accuracy: 0.9513\n",
            "Epoch 16/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0988 - accuracy: 0.9588 - val_loss: 0.1076 - val_accuracy: 0.9525\n",
            "Epoch 17/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.0978 - accuracy: 0.9575 - val_loss: 0.1076 - val_accuracy: 0.9538\n",
            "Epoch 18/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0964 - accuracy: 0.9601 - val_loss: 0.1077 - val_accuracy: 0.9563\n",
            "Epoch 19/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0954 - accuracy: 0.9597 - val_loss: 0.1070 - val_accuracy: 0.9550\n",
            "Epoch 20/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0940 - accuracy: 0.9600 - val_loss: 0.1067 - val_accuracy: 0.9563\n",
            "63/63 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newdata.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "05ryfvyLzFVK",
        "outputId": "59a84a55-d138-408d-e410-9a60098a9d08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   SVM  KNN  RF  LR  ANN  XGB  y_test\n",
              "0    0    0   0   0    0    0       0\n",
              "1    0    0   0   0    0    0       0\n",
              "2    0    0   0   0    0    0       0\n",
              "3    0    0   0   0    0    0       0\n",
              "4    0    0   0   0    0    0       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4afc26fc-246b-4e1f-a426-b448fefba0ba\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SVM</th>\n",
              "      <th>KNN</th>\n",
              "      <th>RF</th>\n",
              "      <th>LR</th>\n",
              "      <th>ANN</th>\n",
              "      <th>XGB</th>\n",
              "      <th>y_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4afc26fc-246b-4e1f-a426-b448fefba0ba')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4afc26fc-246b-4e1f-a426-b448fefba0ba button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4afc26fc-246b-4e1f-a426-b448fefba0ba');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the DNN model\n",
        "DNNX = newdata.drop(columns=['y_test']).copy()\n",
        "DNNY = newdata.y_test.copy()\n",
        "DX_train, DX_test, Dy_train, Dy_test = train_test_split(\n",
        "    DNNX, DNNY, test_size=0.2, random_state=123)\n",
        "\n",
        "st = time.time()\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(30, activation='relu', input_shape=DNNX.shape[1:]),\n",
        "    tf.keras.layers.Dense(25, activation='relu'),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dense(15, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(DX_train, Dy_train, epochs=500, batch_size=64, validation_split=0.2)\n",
        "dend = time.time() - st"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4kf97a3yX15",
        "outputId": "73808a97-02f6-4952-cee2-46f7fad21275"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "100/100 [==============================] - 2s 6ms/step - loss: 0.6802 - accuracy: 0.7080 - val_loss: 0.6157 - val_accuracy: 0.9419\n",
            "Epoch 2/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.4836 - accuracy: 0.9427 - val_loss: 0.3441 - val_accuracy: 0.9525\n",
            "Epoch 3/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1874 - accuracy: 0.9467 - val_loss: 0.1510 - val_accuracy: 0.9506\n",
            "Epoch 4/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1560 - accuracy: 0.9472 - val_loss: 0.1452 - val_accuracy: 0.9506\n",
            "Epoch 5/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1539 - accuracy: 0.9480 - val_loss: 0.1425 - val_accuracy: 0.9500\n",
            "Epoch 6/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1523 - accuracy: 0.9484 - val_loss: 0.1456 - val_accuracy: 0.9488\n",
            "Epoch 7/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1532 - accuracy: 0.9488 - val_loss: 0.1428 - val_accuracy: 0.9506\n",
            "Epoch 8/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1517 - accuracy: 0.9494 - val_loss: 0.1426 - val_accuracy: 0.9500\n",
            "Epoch 9/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1522 - accuracy: 0.9481 - val_loss: 0.1543 - val_accuracy: 0.9481\n",
            "Epoch 10/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1522 - accuracy: 0.9495 - val_loss: 0.1439 - val_accuracy: 0.9494\n",
            "Epoch 11/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1507 - accuracy: 0.9483 - val_loss: 0.1451 - val_accuracy: 0.9488\n",
            "Epoch 12/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1507 - accuracy: 0.9500 - val_loss: 0.1440 - val_accuracy: 0.9488\n",
            "Epoch 13/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1508 - accuracy: 0.9492 - val_loss: 0.1419 - val_accuracy: 0.9500\n",
            "Epoch 14/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1511 - accuracy: 0.9494 - val_loss: 0.1428 - val_accuracy: 0.9500\n",
            "Epoch 15/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1513 - accuracy: 0.9488 - val_loss: 0.1424 - val_accuracy: 0.9481\n",
            "Epoch 16/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1510 - accuracy: 0.9498 - val_loss: 0.1432 - val_accuracy: 0.9488\n",
            "Epoch 17/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1499 - accuracy: 0.9495 - val_loss: 0.1421 - val_accuracy: 0.9506\n",
            "Epoch 18/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1505 - accuracy: 0.9506 - val_loss: 0.1433 - val_accuracy: 0.9481\n",
            "Epoch 19/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1500 - accuracy: 0.9495 - val_loss: 0.1435 - val_accuracy: 0.9500\n",
            "Epoch 20/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1502 - accuracy: 0.9505 - val_loss: 0.1419 - val_accuracy: 0.9494\n",
            "Epoch 21/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1500 - accuracy: 0.9502 - val_loss: 0.1440 - val_accuracy: 0.9494\n",
            "Epoch 22/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1502 - accuracy: 0.9489 - val_loss: 0.1431 - val_accuracy: 0.9494\n",
            "Epoch 23/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1517 - accuracy: 0.9497 - val_loss: 0.1430 - val_accuracy: 0.9500\n",
            "Epoch 24/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1496 - accuracy: 0.9502 - val_loss: 0.1430 - val_accuracy: 0.9500\n",
            "Epoch 25/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1499 - accuracy: 0.9500 - val_loss: 0.1446 - val_accuracy: 0.9481\n",
            "Epoch 26/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1500 - accuracy: 0.9488 - val_loss: 0.1444 - val_accuracy: 0.9481\n",
            "Epoch 27/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1494 - accuracy: 0.9500 - val_loss: 0.1441 - val_accuracy: 0.9500\n",
            "Epoch 28/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1501 - accuracy: 0.9505 - val_loss: 0.1442 - val_accuracy: 0.9481\n",
            "Epoch 29/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1508 - accuracy: 0.9491 - val_loss: 0.1424 - val_accuracy: 0.9475\n",
            "Epoch 30/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1491 - accuracy: 0.9514 - val_loss: 0.1431 - val_accuracy: 0.9500\n",
            "Epoch 31/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1494 - accuracy: 0.9495 - val_loss: 0.1507 - val_accuracy: 0.9481\n",
            "Epoch 32/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1499 - accuracy: 0.9503 - val_loss: 0.1436 - val_accuracy: 0.9494\n",
            "Epoch 33/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1499 - accuracy: 0.9509 - val_loss: 0.1455 - val_accuracy: 0.9494\n",
            "Epoch 34/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1492 - accuracy: 0.9513 - val_loss: 0.1436 - val_accuracy: 0.9475\n",
            "Epoch 35/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1498 - accuracy: 0.9511 - val_loss: 0.1434 - val_accuracy: 0.9494\n",
            "Epoch 36/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1494 - accuracy: 0.9519 - val_loss: 0.1434 - val_accuracy: 0.9500\n",
            "Epoch 37/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1499 - accuracy: 0.9508 - val_loss: 0.1450 - val_accuracy: 0.9481\n",
            "Epoch 38/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1488 - accuracy: 0.9522 - val_loss: 0.1440 - val_accuracy: 0.9494\n",
            "Epoch 39/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1487 - accuracy: 0.9508 - val_loss: 0.1467 - val_accuracy: 0.9481\n",
            "Epoch 40/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1491 - accuracy: 0.9516 - val_loss: 0.1436 - val_accuracy: 0.9469\n",
            "Epoch 41/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1491 - accuracy: 0.9513 - val_loss: 0.1444 - val_accuracy: 0.9475\n",
            "Epoch 42/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1502 - accuracy: 0.9513 - val_loss: 0.1444 - val_accuracy: 0.9500\n",
            "Epoch 43/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1493 - accuracy: 0.9522 - val_loss: 0.1442 - val_accuracy: 0.9494\n",
            "Epoch 44/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1495 - accuracy: 0.9505 - val_loss: 0.1444 - val_accuracy: 0.9450\n",
            "Epoch 45/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1488 - accuracy: 0.9516 - val_loss: 0.1443 - val_accuracy: 0.9469\n",
            "Epoch 46/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1483 - accuracy: 0.9509 - val_loss: 0.1448 - val_accuracy: 0.9469\n",
            "Epoch 47/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1486 - accuracy: 0.9520 - val_loss: 0.1463 - val_accuracy: 0.9469\n",
            "Epoch 48/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1483 - accuracy: 0.9505 - val_loss: 0.1437 - val_accuracy: 0.9475\n",
            "Epoch 49/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1483 - accuracy: 0.9527 - val_loss: 0.1446 - val_accuracy: 0.9469\n",
            "Epoch 50/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1487 - accuracy: 0.9508 - val_loss: 0.1453 - val_accuracy: 0.9469\n",
            "Epoch 51/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1491 - accuracy: 0.9516 - val_loss: 0.1457 - val_accuracy: 0.9463\n",
            "Epoch 52/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9508 - val_loss: 0.1451 - val_accuracy: 0.9469\n",
            "Epoch 53/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1489 - accuracy: 0.9523 - val_loss: 0.1473 - val_accuracy: 0.9456\n",
            "Epoch 54/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1488 - accuracy: 0.9522 - val_loss: 0.1448 - val_accuracy: 0.9469\n",
            "Epoch 55/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9519 - val_loss: 0.1449 - val_accuracy: 0.9463\n",
            "Epoch 56/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9525 - val_loss: 0.1454 - val_accuracy: 0.9469\n",
            "Epoch 57/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1483 - accuracy: 0.9523 - val_loss: 0.1461 - val_accuracy: 0.9469\n",
            "Epoch 58/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1484 - accuracy: 0.9508 - val_loss: 0.1446 - val_accuracy: 0.9444\n",
            "Epoch 59/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9525 - val_loss: 0.1449 - val_accuracy: 0.9450\n",
            "Epoch 60/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1483 - accuracy: 0.9525 - val_loss: 0.1478 - val_accuracy: 0.9469\n",
            "Epoch 61/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9522 - val_loss: 0.1496 - val_accuracy: 0.9469\n",
            "Epoch 62/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1484 - accuracy: 0.9523 - val_loss: 0.1450 - val_accuracy: 0.9469\n",
            "Epoch 63/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1486 - accuracy: 0.9516 - val_loss: 0.1460 - val_accuracy: 0.9463\n",
            "Epoch 64/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1486 - accuracy: 0.9523 - val_loss: 0.1455 - val_accuracy: 0.9463\n",
            "Epoch 65/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9522 - val_loss: 0.1453 - val_accuracy: 0.9469\n",
            "Epoch 66/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9516 - val_loss: 0.1469 - val_accuracy: 0.9469\n",
            "Epoch 67/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1473 - accuracy: 0.9520 - val_loss: 0.1460 - val_accuracy: 0.9456\n",
            "Epoch 68/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9519 - val_loss: 0.1457 - val_accuracy: 0.9475\n",
            "Epoch 69/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1471 - accuracy: 0.9527 - val_loss: 0.1463 - val_accuracy: 0.9469\n",
            "Epoch 70/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9523 - val_loss: 0.1462 - val_accuracy: 0.9494\n",
            "Epoch 71/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9520 - val_loss: 0.1460 - val_accuracy: 0.9488\n",
            "Epoch 72/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9514 - val_loss: 0.1492 - val_accuracy: 0.9469\n",
            "Epoch 73/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9516 - val_loss: 0.1484 - val_accuracy: 0.9469\n",
            "Epoch 74/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9523 - val_loss: 0.1460 - val_accuracy: 0.9469\n",
            "Epoch 75/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1472 - accuracy: 0.9527 - val_loss: 0.1479 - val_accuracy: 0.9463\n",
            "Epoch 76/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9520 - val_loss: 0.1466 - val_accuracy: 0.9469\n",
            "Epoch 77/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1470 - accuracy: 0.9530 - val_loss: 0.1477 - val_accuracy: 0.9475\n",
            "Epoch 78/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9525 - val_loss: 0.1478 - val_accuracy: 0.9469\n",
            "Epoch 79/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1473 - accuracy: 0.9531 - val_loss: 0.1491 - val_accuracy: 0.9469\n",
            "Epoch 80/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1470 - accuracy: 0.9531 - val_loss: 0.1478 - val_accuracy: 0.9469\n",
            "Epoch 81/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1472 - accuracy: 0.9525 - val_loss: 0.1481 - val_accuracy: 0.9469\n",
            "Epoch 82/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1480 - accuracy: 0.9514 - val_loss: 0.1479 - val_accuracy: 0.9469\n",
            "Epoch 83/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1471 - accuracy: 0.9525 - val_loss: 0.1487 - val_accuracy: 0.9469\n",
            "Epoch 84/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1463 - accuracy: 0.9533 - val_loss: 0.1481 - val_accuracy: 0.9456\n",
            "Epoch 85/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9522 - val_loss: 0.1493 - val_accuracy: 0.9469\n",
            "Epoch 86/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9525 - val_loss: 0.1479 - val_accuracy: 0.9481\n",
            "Epoch 87/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1471 - accuracy: 0.9520 - val_loss: 0.1487 - val_accuracy: 0.9469\n",
            "Epoch 88/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1471 - accuracy: 0.9523 - val_loss: 0.1481 - val_accuracy: 0.9469\n",
            "Epoch 89/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1469 - accuracy: 0.9530 - val_loss: 0.1478 - val_accuracy: 0.9463\n",
            "Epoch 90/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1471 - accuracy: 0.9528 - val_loss: 0.1487 - val_accuracy: 0.9469\n",
            "Epoch 91/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1470 - accuracy: 0.9517 - val_loss: 0.1498 - val_accuracy: 0.9469\n",
            "Epoch 92/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1472 - accuracy: 0.9528 - val_loss: 0.1495 - val_accuracy: 0.9469\n",
            "Epoch 93/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1460 - accuracy: 0.9530 - val_loss: 0.1504 - val_accuracy: 0.9488\n",
            "Epoch 94/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1467 - accuracy: 0.9517 - val_loss: 0.1491 - val_accuracy: 0.9456\n",
            "Epoch 95/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1474 - accuracy: 0.9538 - val_loss: 0.1490 - val_accuracy: 0.9469\n",
            "Epoch 96/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1468 - accuracy: 0.9527 - val_loss: 0.1511 - val_accuracy: 0.9469\n",
            "Epoch 97/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1470 - accuracy: 0.9527 - val_loss: 0.1501 - val_accuracy: 0.9469\n",
            "Epoch 98/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1472 - accuracy: 0.9520 - val_loss: 0.1496 - val_accuracy: 0.9475\n",
            "Epoch 99/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1464 - accuracy: 0.9527 - val_loss: 0.1501 - val_accuracy: 0.9481\n",
            "Epoch 100/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1467 - accuracy: 0.9528 - val_loss: 0.1529 - val_accuracy: 0.9469\n",
            "Epoch 101/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1466 - accuracy: 0.9525 - val_loss: 0.1496 - val_accuracy: 0.9488\n",
            "Epoch 102/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1464 - accuracy: 0.9528 - val_loss: 0.1504 - val_accuracy: 0.9488\n",
            "Epoch 103/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1472 - accuracy: 0.9533 - val_loss: 0.1532 - val_accuracy: 0.9475\n",
            "Epoch 104/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1468 - accuracy: 0.9520 - val_loss: 0.1543 - val_accuracy: 0.9469\n",
            "Epoch 105/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1470 - accuracy: 0.9525 - val_loss: 0.1513 - val_accuracy: 0.9469\n",
            "Epoch 106/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1462 - accuracy: 0.9519 - val_loss: 0.1512 - val_accuracy: 0.9475\n",
            "Epoch 107/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1465 - accuracy: 0.9528 - val_loss: 0.1504 - val_accuracy: 0.9463\n",
            "Epoch 108/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1464 - accuracy: 0.9534 - val_loss: 0.1526 - val_accuracy: 0.9469\n",
            "Epoch 109/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1462 - accuracy: 0.9513 - val_loss: 0.1532 - val_accuracy: 0.9469\n",
            "Epoch 110/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1464 - accuracy: 0.9522 - val_loss: 0.1528 - val_accuracy: 0.9481\n",
            "Epoch 111/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1466 - accuracy: 0.9538 - val_loss: 0.1515 - val_accuracy: 0.9456\n",
            "Epoch 112/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1462 - accuracy: 0.9519 - val_loss: 0.1517 - val_accuracy: 0.9469\n",
            "Epoch 113/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1466 - accuracy: 0.9522 - val_loss: 0.1554 - val_accuracy: 0.9488\n",
            "Epoch 114/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1462 - accuracy: 0.9534 - val_loss: 0.1541 - val_accuracy: 0.9469\n",
            "Epoch 115/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1464 - accuracy: 0.9522 - val_loss: 0.1526 - val_accuracy: 0.9481\n",
            "Epoch 116/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1461 - accuracy: 0.9519 - val_loss: 0.1543 - val_accuracy: 0.9469\n",
            "Epoch 117/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.1464 - accuracy: 0.9523 - val_loss: 0.1536 - val_accuracy: 0.9481\n",
            "Epoch 118/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1463 - accuracy: 0.9528 - val_loss: 0.1528 - val_accuracy: 0.9456\n",
            "Epoch 119/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1463 - accuracy: 0.9528 - val_loss: 0.1560 - val_accuracy: 0.9469\n",
            "Epoch 120/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1460 - accuracy: 0.9525 - val_loss: 0.1539 - val_accuracy: 0.9456\n",
            "Epoch 121/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1466 - accuracy: 0.9523 - val_loss: 0.1541 - val_accuracy: 0.9456\n",
            "Epoch 122/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1464 - accuracy: 0.9528 - val_loss: 0.1541 - val_accuracy: 0.9469\n",
            "Epoch 123/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1462 - accuracy: 0.9523 - val_loss: 0.1549 - val_accuracy: 0.9456\n",
            "Epoch 124/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1465 - accuracy: 0.9530 - val_loss: 0.1566 - val_accuracy: 0.9469\n",
            "Epoch 125/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1467 - accuracy: 0.9523 - val_loss: 0.1555 - val_accuracy: 0.9463\n",
            "Epoch 126/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1462 - accuracy: 0.9523 - val_loss: 0.1567 - val_accuracy: 0.9488\n",
            "Epoch 127/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1460 - accuracy: 0.9520 - val_loss: 0.1555 - val_accuracy: 0.9463\n",
            "Epoch 128/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9523 - val_loss: 0.1564 - val_accuracy: 0.9463\n",
            "Epoch 129/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1462 - accuracy: 0.9516 - val_loss: 0.1567 - val_accuracy: 0.9481\n",
            "Epoch 130/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9530 - val_loss: 0.1572 - val_accuracy: 0.9450\n",
            "Epoch 131/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9530 - val_loss: 0.1481 - val_accuracy: 0.9469\n",
            "Epoch 132/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1465 - accuracy: 0.9536 - val_loss: 0.1533 - val_accuracy: 0.9475\n",
            "Epoch 133/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1459 - accuracy: 0.9534 - val_loss: 0.1558 - val_accuracy: 0.9469\n",
            "Epoch 134/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1462 - accuracy: 0.9519 - val_loss: 0.1578 - val_accuracy: 0.9469\n",
            "Epoch 135/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9527 - val_loss: 0.1570 - val_accuracy: 0.9463\n",
            "Epoch 136/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1461 - accuracy: 0.9531 - val_loss: 0.1577 - val_accuracy: 0.9456\n",
            "Epoch 137/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1459 - accuracy: 0.9527 - val_loss: 0.1575 - val_accuracy: 0.9475\n",
            "Epoch 138/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1462 - accuracy: 0.9527 - val_loss: 0.1554 - val_accuracy: 0.9469\n",
            "Epoch 139/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1459 - accuracy: 0.9525 - val_loss: 0.1580 - val_accuracy: 0.9481\n",
            "Epoch 140/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9528 - val_loss: 0.1555 - val_accuracy: 0.9456\n",
            "Epoch 141/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1461 - accuracy: 0.9530 - val_loss: 0.1572 - val_accuracy: 0.9469\n",
            "Epoch 142/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9522 - val_loss: 0.1572 - val_accuracy: 0.9481\n",
            "Epoch 143/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1459 - accuracy: 0.9527 - val_loss: 0.1582 - val_accuracy: 0.9456\n",
            "Epoch 144/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1457 - accuracy: 0.9525 - val_loss: 0.1581 - val_accuracy: 0.9469\n",
            "Epoch 145/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1459 - accuracy: 0.9522 - val_loss: 0.1587 - val_accuracy: 0.9450\n",
            "Epoch 146/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1456 - accuracy: 0.9516 - val_loss: 0.1575 - val_accuracy: 0.9469\n",
            "Epoch 147/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1459 - accuracy: 0.9522 - val_loss: 0.1585 - val_accuracy: 0.9469\n",
            "Epoch 148/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1466 - accuracy: 0.9530 - val_loss: 0.1568 - val_accuracy: 0.9463\n",
            "Epoch 149/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1461 - accuracy: 0.9520 - val_loss: 0.1591 - val_accuracy: 0.9469\n",
            "Epoch 150/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1460 - accuracy: 0.9530 - val_loss: 0.1592 - val_accuracy: 0.9469\n",
            "Epoch 151/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1461 - accuracy: 0.9523 - val_loss: 0.1603 - val_accuracy: 0.9463\n",
            "Epoch 152/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9528 - val_loss: 0.1597 - val_accuracy: 0.9469\n",
            "Epoch 153/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1462 - accuracy: 0.9531 - val_loss: 0.1598 - val_accuracy: 0.9456\n",
            "Epoch 154/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1457 - accuracy: 0.9534 - val_loss: 0.1606 - val_accuracy: 0.9475\n",
            "Epoch 155/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1461 - accuracy: 0.9520 - val_loss: 0.1537 - val_accuracy: 0.9481\n",
            "Epoch 156/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9517 - val_loss: 0.1544 - val_accuracy: 0.9488\n",
            "Epoch 157/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1459 - accuracy: 0.9525 - val_loss: 0.1575 - val_accuracy: 0.9475\n",
            "Epoch 158/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9527 - val_loss: 0.1604 - val_accuracy: 0.9475\n",
            "Epoch 159/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1464 - accuracy: 0.9528 - val_loss: 0.1591 - val_accuracy: 0.9494\n",
            "Epoch 160/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1458 - accuracy: 0.9533 - val_loss: 0.1610 - val_accuracy: 0.9481\n",
            "Epoch 161/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1454 - accuracy: 0.9528 - val_loss: 0.1617 - val_accuracy: 0.9481\n",
            "Epoch 162/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1456 - accuracy: 0.9530 - val_loss: 0.1620 - val_accuracy: 0.9456\n",
            "Epoch 163/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9525 - val_loss: 0.1624 - val_accuracy: 0.9475\n",
            "Epoch 164/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9531 - val_loss: 0.1584 - val_accuracy: 0.9469\n",
            "Epoch 165/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1456 - accuracy: 0.9534 - val_loss: 0.1600 - val_accuracy: 0.9469\n",
            "Epoch 166/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1456 - accuracy: 0.9525 - val_loss: 0.1609 - val_accuracy: 0.9481\n",
            "Epoch 167/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1454 - accuracy: 0.9523 - val_loss: 0.1626 - val_accuracy: 0.9469\n",
            "Epoch 168/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1458 - accuracy: 0.9522 - val_loss: 0.1619 - val_accuracy: 0.9475\n",
            "Epoch 169/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9539 - val_loss: 0.1642 - val_accuracy: 0.9469\n",
            "Epoch 170/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1458 - accuracy: 0.9530 - val_loss: 0.1655 - val_accuracy: 0.9469\n",
            "Epoch 171/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1460 - accuracy: 0.9530 - val_loss: 0.1663 - val_accuracy: 0.9469\n",
            "Epoch 172/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1461 - accuracy: 0.9531 - val_loss: 0.1657 - val_accuracy: 0.9481\n",
            "Epoch 173/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1453 - accuracy: 0.9522 - val_loss: 0.1577 - val_accuracy: 0.9469\n",
            "Epoch 174/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1463 - accuracy: 0.9531 - val_loss: 0.1624 - val_accuracy: 0.9456\n",
            "Epoch 175/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9528 - val_loss: 0.1638 - val_accuracy: 0.9469\n",
            "Epoch 176/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1450 - accuracy: 0.9541 - val_loss: 0.1653 - val_accuracy: 0.9469\n",
            "Epoch 177/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1462 - accuracy: 0.9534 - val_loss: 0.1646 - val_accuracy: 0.9469\n",
            "Epoch 178/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9520 - val_loss: 0.1656 - val_accuracy: 0.9488\n",
            "Epoch 179/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1459 - accuracy: 0.9528 - val_loss: 0.1648 - val_accuracy: 0.9475\n",
            "Epoch 180/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1458 - accuracy: 0.9527 - val_loss: 0.1656 - val_accuracy: 0.9469\n",
            "Epoch 181/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1456 - accuracy: 0.9530 - val_loss: 0.1669 - val_accuracy: 0.9475\n",
            "Epoch 182/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1457 - accuracy: 0.9528 - val_loss: 0.1669 - val_accuracy: 0.9488\n",
            "Epoch 183/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9520 - val_loss: 0.1675 - val_accuracy: 0.9469\n",
            "Epoch 184/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9528 - val_loss: 0.1671 - val_accuracy: 0.9475\n",
            "Epoch 185/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9533 - val_loss: 0.1643 - val_accuracy: 0.9469\n",
            "Epoch 186/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9517 - val_loss: 0.1660 - val_accuracy: 0.9463\n",
            "Epoch 187/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9528 - val_loss: 0.1670 - val_accuracy: 0.9469\n",
            "Epoch 188/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1460 - accuracy: 0.9513 - val_loss: 0.1673 - val_accuracy: 0.9494\n",
            "Epoch 189/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1459 - accuracy: 0.9531 - val_loss: 0.1658 - val_accuracy: 0.9469\n",
            "Epoch 190/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9528 - val_loss: 0.1678 - val_accuracy: 0.9469\n",
            "Epoch 191/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9531 - val_loss: 0.1657 - val_accuracy: 0.9469\n",
            "Epoch 192/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9528 - val_loss: 0.1675 - val_accuracy: 0.9494\n",
            "Epoch 193/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9522 - val_loss: 0.1675 - val_accuracy: 0.9481\n",
            "Epoch 194/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1459 - accuracy: 0.9527 - val_loss: 0.1680 - val_accuracy: 0.9456\n",
            "Epoch 195/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9536 - val_loss: 0.1675 - val_accuracy: 0.9469\n",
            "Epoch 196/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9531 - val_loss: 0.1692 - val_accuracy: 0.9488\n",
            "Epoch 197/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1460 - accuracy: 0.9522 - val_loss: 0.1690 - val_accuracy: 0.9469\n",
            "Epoch 198/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9530 - val_loss: 0.1691 - val_accuracy: 0.9469\n",
            "Epoch 199/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9522 - val_loss: 0.1686 - val_accuracy: 0.9494\n",
            "Epoch 200/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9523 - val_loss: 0.1715 - val_accuracy: 0.9469\n",
            "Epoch 201/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9542 - val_loss: 0.1699 - val_accuracy: 0.9469\n",
            "Epoch 202/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9534 - val_loss: 0.1672 - val_accuracy: 0.9463\n",
            "Epoch 203/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9534 - val_loss: 0.1686 - val_accuracy: 0.9500\n",
            "Epoch 204/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9519 - val_loss: 0.1699 - val_accuracy: 0.9488\n",
            "Epoch 205/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9525 - val_loss: 0.1692 - val_accuracy: 0.9469\n",
            "Epoch 206/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9538 - val_loss: 0.1712 - val_accuracy: 0.9469\n",
            "Epoch 207/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1461 - accuracy: 0.9534 - val_loss: 0.1703 - val_accuracy: 0.9469\n",
            "Epoch 208/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1459 - accuracy: 0.9528 - val_loss: 0.1699 - val_accuracy: 0.9475\n",
            "Epoch 209/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9528 - val_loss: 0.1704 - val_accuracy: 0.9494\n",
            "Epoch 210/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9523 - val_loss: 0.1703 - val_accuracy: 0.9500\n",
            "Epoch 211/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9530 - val_loss: 0.1702 - val_accuracy: 0.9488\n",
            "Epoch 212/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9533 - val_loss: 0.1723 - val_accuracy: 0.9488\n",
            "Epoch 213/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1461 - accuracy: 0.9538 - val_loss: 0.1710 - val_accuracy: 0.9494\n",
            "Epoch 214/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1454 - accuracy: 0.9533 - val_loss: 0.1704 - val_accuracy: 0.9488\n",
            "Epoch 215/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1455 - accuracy: 0.9534 - val_loss: 0.1719 - val_accuracy: 0.9469\n",
            "Epoch 216/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1450 - accuracy: 0.9533 - val_loss: 0.1731 - val_accuracy: 0.9469\n",
            "Epoch 217/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1456 - accuracy: 0.9523 - val_loss: 0.1713 - val_accuracy: 0.9494\n",
            "Epoch 218/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1458 - accuracy: 0.9533 - val_loss: 0.1713 - val_accuracy: 0.9469\n",
            "Epoch 219/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9527 - val_loss: 0.1732 - val_accuracy: 0.9488\n",
            "Epoch 220/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9533 - val_loss: 0.1730 - val_accuracy: 0.9488\n",
            "Epoch 221/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9527 - val_loss: 0.1732 - val_accuracy: 0.9494\n",
            "Epoch 222/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1461 - accuracy: 0.9531 - val_loss: 0.1694 - val_accuracy: 0.9488\n",
            "Epoch 223/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9530 - val_loss: 0.1715 - val_accuracy: 0.9469\n",
            "Epoch 224/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9531 - val_loss: 0.1699 - val_accuracy: 0.9481\n",
            "Epoch 225/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9531 - val_loss: 0.1702 - val_accuracy: 0.9500\n",
            "Epoch 226/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9534 - val_loss: 0.1710 - val_accuracy: 0.9488\n",
            "Epoch 227/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9536 - val_loss: 0.1704 - val_accuracy: 0.9488\n",
            "Epoch 228/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9534 - val_loss: 0.1699 - val_accuracy: 0.9494\n",
            "Epoch 229/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9519 - val_loss: 0.1695 - val_accuracy: 0.9481\n",
            "Epoch 230/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9538 - val_loss: 0.1737 - val_accuracy: 0.9494\n",
            "Epoch 231/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9534 - val_loss: 0.1755 - val_accuracy: 0.9488\n",
            "Epoch 232/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9528 - val_loss: 0.1715 - val_accuracy: 0.9488\n",
            "Epoch 233/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1460 - accuracy: 0.9522 - val_loss: 0.1730 - val_accuracy: 0.9481\n",
            "Epoch 234/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9534 - val_loss: 0.1715 - val_accuracy: 0.9469\n",
            "Epoch 235/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9538 - val_loss: 0.1720 - val_accuracy: 0.9500\n",
            "Epoch 236/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9530 - val_loss: 0.1716 - val_accuracy: 0.9494\n",
            "Epoch 237/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9528 - val_loss: 0.1728 - val_accuracy: 0.9494\n",
            "Epoch 238/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9533 - val_loss: 0.1727 - val_accuracy: 0.9488\n",
            "Epoch 239/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9547 - val_loss: 0.1718 - val_accuracy: 0.9469\n",
            "Epoch 240/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9539 - val_loss: 0.1719 - val_accuracy: 0.9488\n",
            "Epoch 241/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9523 - val_loss: 0.1738 - val_accuracy: 0.9469\n",
            "Epoch 242/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9534 - val_loss: 0.1747 - val_accuracy: 0.9494\n",
            "Epoch 243/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9528 - val_loss: 0.1735 - val_accuracy: 0.9500\n",
            "Epoch 244/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1443 - accuracy: 0.9531 - val_loss: 0.1739 - val_accuracy: 0.9469\n",
            "Epoch 245/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9530 - val_loss: 0.1731 - val_accuracy: 0.9494\n",
            "Epoch 246/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1461 - accuracy: 0.9528 - val_loss: 0.1729 - val_accuracy: 0.9469\n",
            "Epoch 247/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9533 - val_loss: 0.1731 - val_accuracy: 0.9481\n",
            "Epoch 248/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9538 - val_loss: 0.1739 - val_accuracy: 0.9469\n",
            "Epoch 249/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1456 - accuracy: 0.9534 - val_loss: 0.1647 - val_accuracy: 0.9494\n",
            "Epoch 250/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9534 - val_loss: 0.1659 - val_accuracy: 0.9500\n",
            "Epoch 251/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1454 - accuracy: 0.9534 - val_loss: 0.1664 - val_accuracy: 0.9494\n",
            "Epoch 252/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1451 - accuracy: 0.9523 - val_loss: 0.1689 - val_accuracy: 0.9494\n",
            "Epoch 253/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1451 - accuracy: 0.9536 - val_loss: 0.1730 - val_accuracy: 0.9494\n",
            "Epoch 254/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1451 - accuracy: 0.9527 - val_loss: 0.1692 - val_accuracy: 0.9494\n",
            "Epoch 255/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1453 - accuracy: 0.9523 - val_loss: 0.1730 - val_accuracy: 0.9488\n",
            "Epoch 256/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9534 - val_loss: 0.1707 - val_accuracy: 0.9500\n",
            "Epoch 257/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9531 - val_loss: 0.1698 - val_accuracy: 0.9494\n",
            "Epoch 258/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9538 - val_loss: 0.1697 - val_accuracy: 0.9494\n",
            "Epoch 259/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9527 - val_loss: 0.1703 - val_accuracy: 0.9500\n",
            "Epoch 260/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9533 - val_loss: 0.1697 - val_accuracy: 0.9481\n",
            "Epoch 261/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9528 - val_loss: 0.1668 - val_accuracy: 0.9469\n",
            "Epoch 262/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9516 - val_loss: 0.1714 - val_accuracy: 0.9463\n",
            "Epoch 263/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9531 - val_loss: 0.1734 - val_accuracy: 0.9494\n",
            "Epoch 264/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9522 - val_loss: 0.1754 - val_accuracy: 0.9488\n",
            "Epoch 265/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9530 - val_loss: 0.1740 - val_accuracy: 0.9494\n",
            "Epoch 266/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9528 - val_loss: 0.1754 - val_accuracy: 0.9494\n",
            "Epoch 267/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9525 - val_loss: 0.1745 - val_accuracy: 0.9500\n",
            "Epoch 268/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9520 - val_loss: 0.1730 - val_accuracy: 0.9481\n",
            "Epoch 269/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9528 - val_loss: 0.1741 - val_accuracy: 0.9500\n",
            "Epoch 270/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9533 - val_loss: 0.1752 - val_accuracy: 0.9500\n",
            "Epoch 271/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9522 - val_loss: 0.1727 - val_accuracy: 0.9494\n",
            "Epoch 272/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9533 - val_loss: 0.1730 - val_accuracy: 0.9494\n",
            "Epoch 273/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9538 - val_loss: 0.1759 - val_accuracy: 0.9488\n",
            "Epoch 274/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9534 - val_loss: 0.1759 - val_accuracy: 0.9494\n",
            "Epoch 275/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9530 - val_loss: 0.1757 - val_accuracy: 0.9500\n",
            "Epoch 276/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9538 - val_loss: 0.1960 - val_accuracy: 0.9475\n",
            "Epoch 277/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1461 - accuracy: 0.9531 - val_loss: 0.1641 - val_accuracy: 0.9500\n",
            "Epoch 278/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9530 - val_loss: 0.1676 - val_accuracy: 0.9488\n",
            "Epoch 279/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9539 - val_loss: 0.1660 - val_accuracy: 0.9469\n",
            "Epoch 280/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9534 - val_loss: 0.1716 - val_accuracy: 0.9494\n",
            "Epoch 281/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9527 - val_loss: 0.1708 - val_accuracy: 0.9463\n",
            "Epoch 282/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9530 - val_loss: 0.1707 - val_accuracy: 0.9481\n",
            "Epoch 283/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9522 - val_loss: 0.1728 - val_accuracy: 0.9481\n",
            "Epoch 284/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9534 - val_loss: 0.1750 - val_accuracy: 0.9469\n",
            "Epoch 285/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9525 - val_loss: 0.1743 - val_accuracy: 0.9494\n",
            "Epoch 286/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9530 - val_loss: 0.1723 - val_accuracy: 0.9494\n",
            "Epoch 287/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9533 - val_loss: 0.1708 - val_accuracy: 0.9500\n",
            "Epoch 288/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1454 - accuracy: 0.9528 - val_loss: 0.1709 - val_accuracy: 0.9500\n",
            "Epoch 289/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1454 - accuracy: 0.9528 - val_loss: 0.1734 - val_accuracy: 0.9469\n",
            "Epoch 290/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1451 - accuracy: 0.9533 - val_loss: 0.1750 - val_accuracy: 0.9481\n",
            "Epoch 291/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1456 - accuracy: 0.9533 - val_loss: 0.1736 - val_accuracy: 0.9494\n",
            "Epoch 292/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1453 - accuracy: 0.9531 - val_loss: 0.1738 - val_accuracy: 0.9500\n",
            "Epoch 293/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9531 - val_loss: 0.1744 - val_accuracy: 0.9494\n",
            "Epoch 294/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1454 - accuracy: 0.9531 - val_loss: 0.1755 - val_accuracy: 0.9494\n",
            "Epoch 295/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9531 - val_loss: 0.1735 - val_accuracy: 0.9494\n",
            "Epoch 296/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9538 - val_loss: 0.1750 - val_accuracy: 0.9494\n",
            "Epoch 297/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9530 - val_loss: 0.1755 - val_accuracy: 0.9500\n",
            "Epoch 298/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9522 - val_loss: 0.1767 - val_accuracy: 0.9494\n",
            "Epoch 299/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9531 - val_loss: 0.1702 - val_accuracy: 0.9494\n",
            "Epoch 300/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9525 - val_loss: 0.1707 - val_accuracy: 0.9500\n",
            "Epoch 301/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9530 - val_loss: 0.1718 - val_accuracy: 0.9494\n",
            "Epoch 302/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9517 - val_loss: 0.1732 - val_accuracy: 0.9494\n",
            "Epoch 303/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9533 - val_loss: 0.1724 - val_accuracy: 0.9494\n",
            "Epoch 304/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9530 - val_loss: 0.1752 - val_accuracy: 0.9463\n",
            "Epoch 305/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9530 - val_loss: 0.1723 - val_accuracy: 0.9500\n",
            "Epoch 306/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9533 - val_loss: 0.1736 - val_accuracy: 0.9494\n",
            "Epoch 307/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9528 - val_loss: 0.1720 - val_accuracy: 0.9494\n",
            "Epoch 308/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9536 - val_loss: 0.1756 - val_accuracy: 0.9469\n",
            "Epoch 309/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9528 - val_loss: 0.1763 - val_accuracy: 0.9469\n",
            "Epoch 310/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9538 - val_loss: 0.1759 - val_accuracy: 0.9494\n",
            "Epoch 311/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9534 - val_loss: 0.1755 - val_accuracy: 0.9494\n",
            "Epoch 312/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9528 - val_loss: 0.1738 - val_accuracy: 0.9494\n",
            "Epoch 313/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9525 - val_loss: 0.1732 - val_accuracy: 0.9500\n",
            "Epoch 314/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9522 - val_loss: 0.1735 - val_accuracy: 0.9469\n",
            "Epoch 315/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9538 - val_loss: 0.1755 - val_accuracy: 0.9494\n",
            "Epoch 316/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9534 - val_loss: 0.1743 - val_accuracy: 0.9500\n",
            "Epoch 317/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9538 - val_loss: 0.1709 - val_accuracy: 0.9494\n",
            "Epoch 318/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9533 - val_loss: 0.1721 - val_accuracy: 0.9488\n",
            "Epoch 319/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9531 - val_loss: 0.1754 - val_accuracy: 0.9494\n",
            "Epoch 320/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9527 - val_loss: 0.1729 - val_accuracy: 0.9500\n",
            "Epoch 321/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9525 - val_loss: 0.1771 - val_accuracy: 0.9494\n",
            "Epoch 322/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9536 - val_loss: 0.1726 - val_accuracy: 0.9494\n",
            "Epoch 323/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9531 - val_loss: 0.1734 - val_accuracy: 0.9463\n",
            "Epoch 324/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9525 - val_loss: 0.1731 - val_accuracy: 0.9494\n",
            "Epoch 325/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1455 - accuracy: 0.9522 - val_loss: 0.1745 - val_accuracy: 0.9494\n",
            "Epoch 326/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1458 - accuracy: 0.9539 - val_loss: 0.1703 - val_accuracy: 0.9494\n",
            "Epoch 327/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1452 - accuracy: 0.9530 - val_loss: 0.1706 - val_accuracy: 0.9500\n",
            "Epoch 328/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1452 - accuracy: 0.9527 - val_loss: 0.1745 - val_accuracy: 0.9494\n",
            "Epoch 329/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1456 - accuracy: 0.9534 - val_loss: 0.1734 - val_accuracy: 0.9488\n",
            "Epoch 330/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9527 - val_loss: 0.1739 - val_accuracy: 0.9488\n",
            "Epoch 331/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9528 - val_loss: 0.1729 - val_accuracy: 0.9500\n",
            "Epoch 332/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9533 - val_loss: 0.1748 - val_accuracy: 0.9494\n",
            "Epoch 333/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9533 - val_loss: 0.1789 - val_accuracy: 0.9494\n",
            "Epoch 334/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1466 - accuracy: 0.9533 - val_loss: 0.1573 - val_accuracy: 0.9481\n",
            "Epoch 335/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9527 - val_loss: 0.1724 - val_accuracy: 0.9488\n",
            "Epoch 336/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1452 - accuracy: 0.9533 - val_loss: 0.1730 - val_accuracy: 0.9469\n",
            "Epoch 337/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1451 - accuracy: 0.9542 - val_loss: 0.1722 - val_accuracy: 0.9494\n",
            "Epoch 338/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1454 - accuracy: 0.9530 - val_loss: 0.1732 - val_accuracy: 0.9494\n",
            "Epoch 339/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1451 - accuracy: 0.9538 - val_loss: 0.1686 - val_accuracy: 0.9500\n",
            "Epoch 340/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1450 - accuracy: 0.9530 - val_loss: 0.1719 - val_accuracy: 0.9500\n",
            "Epoch 341/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1455 - accuracy: 0.9539 - val_loss: 0.1726 - val_accuracy: 0.9500\n",
            "Epoch 342/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1451 - accuracy: 0.9533 - val_loss: 0.1753 - val_accuracy: 0.9500\n",
            "Epoch 343/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1454 - accuracy: 0.9533 - val_loss: 0.1733 - val_accuracy: 0.9494\n",
            "Epoch 344/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1451 - accuracy: 0.9533 - val_loss: 0.1747 - val_accuracy: 0.9494\n",
            "Epoch 345/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1454 - accuracy: 0.9533 - val_loss: 0.1764 - val_accuracy: 0.9494\n",
            "Epoch 346/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1451 - accuracy: 0.9533 - val_loss: 0.1772 - val_accuracy: 0.9494\n",
            "Epoch 347/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1451 - accuracy: 0.9525 - val_loss: 0.1752 - val_accuracy: 0.9494\n",
            "Epoch 348/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1452 - accuracy: 0.9530 - val_loss: 0.1759 - val_accuracy: 0.9500\n",
            "Epoch 349/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1449 - accuracy: 0.9536 - val_loss: 0.1732 - val_accuracy: 0.9494\n",
            "Epoch 350/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9533 - val_loss: 0.1739 - val_accuracy: 0.9494\n",
            "Epoch 351/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1450 - accuracy: 0.9534 - val_loss: 0.1754 - val_accuracy: 0.9494\n",
            "Epoch 352/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1452 - accuracy: 0.9530 - val_loss: 0.1751 - val_accuracy: 0.9494\n",
            "Epoch 353/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9531 - val_loss: 0.1764 - val_accuracy: 0.9494\n",
            "Epoch 354/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1450 - accuracy: 0.9542 - val_loss: 0.1761 - val_accuracy: 0.9494\n",
            "Epoch 355/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1451 - accuracy: 0.9534 - val_loss: 0.1739 - val_accuracy: 0.9494\n",
            "Epoch 356/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.1448 - accuracy: 0.9527 - val_loss: 0.1736 - val_accuracy: 0.9494\n",
            "Epoch 357/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1458 - accuracy: 0.9534 - val_loss: 0.1726 - val_accuracy: 0.9494\n",
            "Epoch 358/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1455 - accuracy: 0.9536 - val_loss: 0.1747 - val_accuracy: 0.9494\n",
            "Epoch 359/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1449 - accuracy: 0.9533 - val_loss: 0.1741 - val_accuracy: 0.9494\n",
            "Epoch 360/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9534 - val_loss: 0.1658 - val_accuracy: 0.9494\n",
            "Epoch 361/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1454 - accuracy: 0.9530 - val_loss: 0.1785 - val_accuracy: 0.9500\n",
            "Epoch 362/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1445 - accuracy: 0.9530 - val_loss: 0.1816 - val_accuracy: 0.9500\n",
            "Epoch 363/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1454 - accuracy: 0.9531 - val_loss: 0.1764 - val_accuracy: 0.9494\n",
            "Epoch 364/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1455 - accuracy: 0.9534 - val_loss: 0.1780 - val_accuracy: 0.9494\n",
            "Epoch 365/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1450 - accuracy: 0.9531 - val_loss: 0.1783 - val_accuracy: 0.9494\n",
            "Epoch 366/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1449 - accuracy: 0.9534 - val_loss: 0.1782 - val_accuracy: 0.9494\n",
            "Epoch 367/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1453 - accuracy: 0.9530 - val_loss: 0.1791 - val_accuracy: 0.9500\n",
            "Epoch 368/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1449 - accuracy: 0.9525 - val_loss: 0.1790 - val_accuracy: 0.9500\n",
            "Epoch 369/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1452 - accuracy: 0.9530 - val_loss: 0.1795 - val_accuracy: 0.9494\n",
            "Epoch 370/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1445 - accuracy: 0.9536 - val_loss: 0.1820 - val_accuracy: 0.9469\n",
            "Epoch 371/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1449 - accuracy: 0.9525 - val_loss: 0.1812 - val_accuracy: 0.9494\n",
            "Epoch 372/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9531 - val_loss: 0.1811 - val_accuracy: 0.9494\n",
            "Epoch 373/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1457 - accuracy: 0.9530 - val_loss: 0.1824 - val_accuracy: 0.9494\n",
            "Epoch 374/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1454 - accuracy: 0.9536 - val_loss: 0.1809 - val_accuracy: 0.9488\n",
            "Epoch 375/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1450 - accuracy: 0.9538 - val_loss: 0.1802 - val_accuracy: 0.9494\n",
            "Epoch 376/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1451 - accuracy: 0.9534 - val_loss: 0.1780 - val_accuracy: 0.9494\n",
            "Epoch 377/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1449 - accuracy: 0.9533 - val_loss: 0.1783 - val_accuracy: 0.9494\n",
            "Epoch 378/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1453 - accuracy: 0.9531 - val_loss: 0.1742 - val_accuracy: 0.9500\n",
            "Epoch 379/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1449 - accuracy: 0.9538 - val_loss: 0.1744 - val_accuracy: 0.9488\n",
            "Epoch 380/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9530 - val_loss: 0.1796 - val_accuracy: 0.9494\n",
            "Epoch 381/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1448 - accuracy: 0.9534 - val_loss: 0.1793 - val_accuracy: 0.9494\n",
            "Epoch 382/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1451 - accuracy: 0.9531 - val_loss: 0.1787 - val_accuracy: 0.9488\n",
            "Epoch 383/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1451 - accuracy: 0.9533 - val_loss: 0.1796 - val_accuracy: 0.9500\n",
            "Epoch 384/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1447 - accuracy: 0.9528 - val_loss: 0.1711 - val_accuracy: 0.9488\n",
            "Epoch 385/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1456 - accuracy: 0.9534 - val_loss: 0.1713 - val_accuracy: 0.9494\n",
            "Epoch 386/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1448 - accuracy: 0.9519 - val_loss: 0.1752 - val_accuracy: 0.9494\n",
            "Epoch 387/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1451 - accuracy: 0.9527 - val_loss: 0.1750 - val_accuracy: 0.9500\n",
            "Epoch 388/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1445 - accuracy: 0.9530 - val_loss: 0.1752 - val_accuracy: 0.9494\n",
            "Epoch 389/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1455 - accuracy: 0.9531 - val_loss: 0.1770 - val_accuracy: 0.9494\n",
            "Epoch 390/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9533 - val_loss: 0.1772 - val_accuracy: 0.9469\n",
            "Epoch 391/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1451 - accuracy: 0.9527 - val_loss: 0.1774 - val_accuracy: 0.9494\n",
            "Epoch 392/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1450 - accuracy: 0.9534 - val_loss: 0.1789 - val_accuracy: 0.9494\n",
            "Epoch 393/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1449 - accuracy: 0.9533 - val_loss: 0.1790 - val_accuracy: 0.9494\n",
            "Epoch 394/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1456 - accuracy: 0.9534 - val_loss: 0.1772 - val_accuracy: 0.9469\n",
            "Epoch 395/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1452 - accuracy: 0.9525 - val_loss: 0.1749 - val_accuracy: 0.9494\n",
            "Epoch 396/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1447 - accuracy: 0.9538 - val_loss: 0.1751 - val_accuracy: 0.9494\n",
            "Epoch 397/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9533 - val_loss: 0.1769 - val_accuracy: 0.9494\n",
            "Epoch 398/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1450 - accuracy: 0.9534 - val_loss: 0.1788 - val_accuracy: 0.9494\n",
            "Epoch 399/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9534 - val_loss: 0.1789 - val_accuracy: 0.9494\n",
            "Epoch 400/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9528 - val_loss: 0.1801 - val_accuracy: 0.9500\n",
            "Epoch 401/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9530 - val_loss: 0.1788 - val_accuracy: 0.9488\n",
            "Epoch 402/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9533 - val_loss: 0.1789 - val_accuracy: 0.9488\n",
            "Epoch 403/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9538 - val_loss: 0.1796 - val_accuracy: 0.9494\n",
            "Epoch 404/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9533 - val_loss: 0.1808 - val_accuracy: 0.9494\n",
            "Epoch 405/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9538 - val_loss: 0.1798 - val_accuracy: 0.9494\n",
            "Epoch 406/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9538 - val_loss: 0.1805 - val_accuracy: 0.9469\n",
            "Epoch 407/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9530 - val_loss: 0.1800 - val_accuracy: 0.9494\n",
            "Epoch 408/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9536 - val_loss: 0.1777 - val_accuracy: 0.9494\n",
            "Epoch 409/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9533 - val_loss: 0.1790 - val_accuracy: 0.9494\n",
            "Epoch 410/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9539 - val_loss: 0.1827 - val_accuracy: 0.9494\n",
            "Epoch 411/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9539 - val_loss: 0.1833 - val_accuracy: 0.9494\n",
            "Epoch 412/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9541 - val_loss: 0.1832 - val_accuracy: 0.9481\n",
            "Epoch 413/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9527 - val_loss: 0.1689 - val_accuracy: 0.9488\n",
            "Epoch 414/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9541 - val_loss: 0.1796 - val_accuracy: 0.9488\n",
            "Epoch 415/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1450 - accuracy: 0.9534 - val_loss: 0.1801 - val_accuracy: 0.9488\n",
            "Epoch 416/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9538 - val_loss: 0.1796 - val_accuracy: 0.9494\n",
            "Epoch 417/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9534 - val_loss: 0.1802 - val_accuracy: 0.9494\n",
            "Epoch 418/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1445 - accuracy: 0.9531 - val_loss: 0.1850 - val_accuracy: 0.9494\n",
            "Epoch 419/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1451 - accuracy: 0.9534 - val_loss: 0.1823 - val_accuracy: 0.9494\n",
            "Epoch 420/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1449 - accuracy: 0.9533 - val_loss: 0.1827 - val_accuracy: 0.9494\n",
            "Epoch 421/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1450 - accuracy: 0.9536 - val_loss: 0.1896 - val_accuracy: 0.9481\n",
            "Epoch 422/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1455 - accuracy: 0.9528 - val_loss: 0.1743 - val_accuracy: 0.9488\n",
            "Epoch 423/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1450 - accuracy: 0.9525 - val_loss: 0.1753 - val_accuracy: 0.9494\n",
            "Epoch 424/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9528 - val_loss: 0.1759 - val_accuracy: 0.9488\n",
            "Epoch 425/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9531 - val_loss: 0.1763 - val_accuracy: 0.9488\n",
            "Epoch 426/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9530 - val_loss: 0.1772 - val_accuracy: 0.9488\n",
            "Epoch 427/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9538 - val_loss: 0.1788 - val_accuracy: 0.9494\n",
            "Epoch 428/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9531 - val_loss: 0.1766 - val_accuracy: 0.9494\n",
            "Epoch 429/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9534 - val_loss: 0.1759 - val_accuracy: 0.9494\n",
            "Epoch 430/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9531 - val_loss: 0.1727 - val_accuracy: 0.9494\n",
            "Epoch 431/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9538 - val_loss: 0.1768 - val_accuracy: 0.9488\n",
            "Epoch 432/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9536 - val_loss: 0.1777 - val_accuracy: 0.9494\n",
            "Epoch 433/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9534 - val_loss: 0.1709 - val_accuracy: 0.9494\n",
            "Epoch 434/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9530 - val_loss: 0.1693 - val_accuracy: 0.9494\n",
            "Epoch 435/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1449 - accuracy: 0.9541 - val_loss: 0.1727 - val_accuracy: 0.9488\n",
            "Epoch 436/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9534 - val_loss: 0.1728 - val_accuracy: 0.9488\n",
            "Epoch 437/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9528 - val_loss: 0.1716 - val_accuracy: 0.9488\n",
            "Epoch 438/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9534 - val_loss: 0.1730 - val_accuracy: 0.9488\n",
            "Epoch 439/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9533 - val_loss: 0.1740 - val_accuracy: 0.9488\n",
            "Epoch 440/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9525 - val_loss: 0.1746 - val_accuracy: 0.9488\n",
            "Epoch 441/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9538 - val_loss: 0.1755 - val_accuracy: 0.9488\n",
            "Epoch 442/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9533 - val_loss: 0.1753 - val_accuracy: 0.9494\n",
            "Epoch 443/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9534 - val_loss: 0.1757 - val_accuracy: 0.9494\n",
            "Epoch 444/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9533 - val_loss: 0.1770 - val_accuracy: 0.9494\n",
            "Epoch 445/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9530 - val_loss: 0.1771 - val_accuracy: 0.9488\n",
            "Epoch 446/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9522 - val_loss: 0.1765 - val_accuracy: 0.9488\n",
            "Epoch 447/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9531 - val_loss: 0.1772 - val_accuracy: 0.9494\n",
            "Epoch 448/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9528 - val_loss: 0.1764 - val_accuracy: 0.9494\n",
            "Epoch 449/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1447 - accuracy: 0.9534 - val_loss: 0.1755 - val_accuracy: 0.9494\n",
            "Epoch 450/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9533 - val_loss: 0.1711 - val_accuracy: 0.9494\n",
            "Epoch 451/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9534 - val_loss: 0.1798 - val_accuracy: 0.9481\n",
            "Epoch 452/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9536 - val_loss: 0.1747 - val_accuracy: 0.9494\n",
            "Epoch 453/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9533 - val_loss: 0.1770 - val_accuracy: 0.9494\n",
            "Epoch 454/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1448 - accuracy: 0.9528 - val_loss: 0.1790 - val_accuracy: 0.9475\n",
            "Epoch 455/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1454 - accuracy: 0.9534 - val_loss: 0.1803 - val_accuracy: 0.9488\n",
            "Epoch 456/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1450 - accuracy: 0.9528 - val_loss: 0.1800 - val_accuracy: 0.9494\n",
            "Epoch 457/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1453 - accuracy: 0.9539 - val_loss: 0.1788 - val_accuracy: 0.9500\n",
            "Epoch 458/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1450 - accuracy: 0.9534 - val_loss: 0.1791 - val_accuracy: 0.9500\n",
            "Epoch 459/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1452 - accuracy: 0.9531 - val_loss: 0.1800 - val_accuracy: 0.9494\n",
            "Epoch 460/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9541 - val_loss: 0.1744 - val_accuracy: 0.9494\n",
            "Epoch 461/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9536 - val_loss: 0.1743 - val_accuracy: 0.9494\n",
            "Epoch 462/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9528 - val_loss: 0.1763 - val_accuracy: 0.9494\n",
            "Epoch 463/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1450 - accuracy: 0.9531 - val_loss: 0.1784 - val_accuracy: 0.9481\n",
            "Epoch 464/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1449 - accuracy: 0.9527 - val_loss: 0.1792 - val_accuracy: 0.9475\n",
            "Epoch 465/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9531 - val_loss: 0.1767 - val_accuracy: 0.9494\n",
            "Epoch 466/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9528 - val_loss: 0.1781 - val_accuracy: 0.9488\n",
            "Epoch 467/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1448 - accuracy: 0.9536 - val_loss: 0.1763 - val_accuracy: 0.9494\n",
            "Epoch 468/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9536 - val_loss: 0.1808 - val_accuracy: 0.9494\n",
            "Epoch 469/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9533 - val_loss: 0.1780 - val_accuracy: 0.9494\n",
            "Epoch 470/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1445 - accuracy: 0.9527 - val_loss: 0.1802 - val_accuracy: 0.9488\n",
            "Epoch 471/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1449 - accuracy: 0.9531 - val_loss: 0.1770 - val_accuracy: 0.9494\n",
            "Epoch 472/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1446 - accuracy: 0.9531 - val_loss: 0.1767 - val_accuracy: 0.9494\n",
            "Epoch 473/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1449 - accuracy: 0.9527 - val_loss: 0.1792 - val_accuracy: 0.9494\n",
            "Epoch 474/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1447 - accuracy: 0.9528 - val_loss: 0.1800 - val_accuracy: 0.9494\n",
            "Epoch 475/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1448 - accuracy: 0.9538 - val_loss: 0.1829 - val_accuracy: 0.9488\n",
            "Epoch 476/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1446 - accuracy: 0.9536 - val_loss: 0.1829 - val_accuracy: 0.9500\n",
            "Epoch 477/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1457 - accuracy: 0.9536 - val_loss: 0.1823 - val_accuracy: 0.9494\n",
            "Epoch 478/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1445 - accuracy: 0.9533 - val_loss: 0.1847 - val_accuracy: 0.9475\n",
            "Epoch 479/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1455 - accuracy: 0.9541 - val_loss: 0.1807 - val_accuracy: 0.9494\n",
            "Epoch 480/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1450 - accuracy: 0.9528 - val_loss: 0.1846 - val_accuracy: 0.9494\n",
            "Epoch 481/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1448 - accuracy: 0.9539 - val_loss: 0.1812 - val_accuracy: 0.9488\n",
            "Epoch 482/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1447 - accuracy: 0.9530 - val_loss: 0.1850 - val_accuracy: 0.9494\n",
            "Epoch 483/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9536 - val_loss: 0.1828 - val_accuracy: 0.9494\n",
            "Epoch 484/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1449 - accuracy: 0.9533 - val_loss: 0.1776 - val_accuracy: 0.9500\n",
            "Epoch 485/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1450 - accuracy: 0.9536 - val_loss: 0.1802 - val_accuracy: 0.9500\n",
            "Epoch 486/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1450 - accuracy: 0.9530 - val_loss: 0.1835 - val_accuracy: 0.9475\n",
            "Epoch 487/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.1447 - accuracy: 0.9533 - val_loss: 0.1810 - val_accuracy: 0.9494\n",
            "Epoch 488/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1447 - accuracy: 0.9539 - val_loss: 0.1839 - val_accuracy: 0.9494\n",
            "Epoch 489/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1450 - accuracy: 0.9534 - val_loss: 0.1813 - val_accuracy: 0.9488\n",
            "Epoch 490/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1452 - accuracy: 0.9534 - val_loss: 0.1787 - val_accuracy: 0.9494\n",
            "Epoch 491/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1450 - accuracy: 0.9536 - val_loss: 0.1826 - val_accuracy: 0.9494\n",
            "Epoch 492/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1448 - accuracy: 0.9533 - val_loss: 0.1807 - val_accuracy: 0.9494\n",
            "Epoch 493/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1451 - accuracy: 0.9533 - val_loss: 0.1829 - val_accuracy: 0.9494\n",
            "Epoch 494/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1448 - accuracy: 0.9538 - val_loss: 0.1843 - val_accuracy: 0.9494\n",
            "Epoch 495/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1450 - accuracy: 0.9525 - val_loss: 0.1824 - val_accuracy: 0.9494\n",
            "Epoch 496/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1449 - accuracy: 0.9525 - val_loss: 0.1831 - val_accuracy: 0.9500\n",
            "Epoch 497/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1449 - accuracy: 0.9533 - val_loss: 0.1793 - val_accuracy: 0.9494\n",
            "Epoch 498/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1451 - accuracy: 0.9534 - val_loss: 0.1831 - val_accuracy: 0.9494\n",
            "Epoch 499/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1448 - accuracy: 0.9536 - val_loss: 0.1856 - val_accuracy: 0.9494\n",
            "Epoch 500/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1448 - accuracy: 0.9530 - val_loss: 0.1845 - val_accuracy: 0.9494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#y_pred_DNN = (model.predict(DNNX) > 0.5).astype(\"int32\")\n",
        "DTr = model.evaluate(DX_train, Dy_train,verbose=0)[1]\n",
        "DTe = model.evaluate(DX_test, Dy_test,verbose=0)[1]\n",
        "DTr,DTe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhG0YCbhASH9",
        "outputId": "0a2d9347-2943-4855-f9f7-a7d8f445afc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.952750027179718, 0.9465000033378601)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_DNN = (model.predict(DX_test) > 0.5).astype(\"int32\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKbxrS57kOBE",
        "outputId": "292e9115-c119-44f7-9b5a-2dc787417b09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = pd.DataFrame(\n",
        "    {\n",
        "    \"SVM\":[STr,STe],\n",
        "    \"KNN\":[KTr,KTe],\n",
        "    \"RF\" :[RTr,RTe],\n",
        "    \"LR\" :[LTr,LTe],\n",
        "    \"ANN\":[ATr,ATe],\n",
        "    \"XGB\":[XTr,XTe],\n",
        "    \"DNN\":[DTr,DTe]})\n",
        "acc.index = [\"train\", \"test\"]\n",
        "acc = acc.T\n",
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "v_YjlCdOO1JY",
        "outputId": "d9f0b47d-bd0b-47bc-ea26-c622b61faca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        train    test\n",
              "SVM  0.950500  0.9500\n",
              "KNN  0.954875  0.9445\n",
              "RF   0.943875  0.9505\n",
              "LR   0.950000  0.9500\n",
              "ANN  0.958500  0.9455\n",
              "XGB  0.956875  0.9410\n",
              "DNN  0.952750  0.9465"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0986b957-6a74-4e5d-bbe5-9fb7d36ba84b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>0.950500</td>\n",
              "      <td>0.9500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>0.954875</td>\n",
              "      <td>0.9445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>0.943875</td>\n",
              "      <td>0.9505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LR</th>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.9500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ANN</th>\n",
              "      <td>0.958500</td>\n",
              "      <td>0.9455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGB</th>\n",
              "      <td>0.956875</td>\n",
              "      <td>0.9410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DNN</th>\n",
              "      <td>0.952750</td>\n",
              "      <td>0.9465</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0986b957-6a74-4e5d-bbe5-9fb7d36ba84b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0986b957-6a74-4e5d-bbe5-9fb7d36ba84b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0986b957-6a74-4e5d-bbe5-9fb7d36ba84b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **AutoML Individual and AutoML DNN**"
      ],
      "metadata": {
        "id": "nJaAMLDKKfKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#H2O AutoML"
      ],
      "metadata": {
        "id": "EhNt_UkjDKcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h2o\n",
        "import h2o\n",
        "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
        "h2o.init()\n",
        "from h2o.model.segment_models import H2OFrame\n",
        "from h2o.automl import H2OAutoML\n",
        "print(\"All Library Loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 873
        },
        "id": "iwMF9ROeDOzF",
        "outputId": "afdb7201-d831-4b7c-e27d-69b9101ae7e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting h2o\n",
            "  Downloading h2o-3.40.0.4.tar.gz (177.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from h2o) (2.27.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from h2o) (0.8.10)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from h2o) (0.18.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (3.4)\n",
            "Building wheels for collected packages: h2o\n",
            "  Building wheel for h2o (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for h2o: filename=h2o-3.40.0.4-py2.py3-none-any.whl size=177697886 sha256=894ec31dbf15465b7a35e00f4dfa6bb46efc166a9742ed182207bb65062746f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/f2/b0/5bb4d702a0467e82d77c45088db3eef25114c26b0eec8e7f6a\n",
            "Successfully built h2o\n",
            "Installing collected packages: h2o\n",
            "Successfully installed h2o-3.40.0.4\n",
            "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
            "Attempting to start a local H2O server...\n",
            "  Java Version: openjdk version \"11.0.19\" 2023-04-18; OpenJDK Runtime Environment (build 11.0.19+7-post-Ubuntu-0ubuntu120.04.1); OpenJDK 64-Bit Server VM (build 11.0.19+7-post-Ubuntu-0ubuntu120.04.1, mixed mode, sharing)\n",
            "  Starting server from /usr/local/lib/python3.10/dist-packages/h2o/backend/bin/h2o.jar\n",
            "  Ice root: /tmp/tmprni3hnkr\n",
            "  JVM stdout: /tmp/tmprni3hnkr/h2o_unknownUser_started_from_python.out\n",
            "  JVM stderr: /tmp/tmprni3hnkr/h2o_unknownUser_started_from_python.err\n",
            "  Server is running at http://127.0.0.1:54321\n",
            "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "--------------------------  -----------------------------------------------------------------------------------------\n",
              "H2O_cluster_uptime:         02 secs\n",
              "H2O_cluster_timezone:       Etc/UTC\n",
              "H2O_data_parsing_timezone:  UTC\n",
              "H2O_cluster_version:        3.40.0.4\n",
              "H2O_cluster_version_age:    2 months and 7 days\n",
              "H2O_cluster_name:           H2O_from_python_unknownUser_uso7vg\n",
              "H2O_cluster_total_nodes:    1\n",
              "H2O_cluster_free_memory:    3.170 Gb\n",
              "H2O_cluster_total_cores:    2\n",
              "H2O_cluster_allowed_cores:  2\n",
              "H2O_cluster_status:         locked, healthy\n",
              "H2O_connection_url:         http://127.0.0.1:54321\n",
              "H2O_connection_proxy:       {\"http\": null, \"https\": null, \"colab_language_server\": \"/usr/colab/bin/language_service\"}\n",
              "H2O_internal_security:      False\n",
              "Python_version:             3.10.12 final\n",
              "--------------------------  -----------------------------------------------------------------------------------------"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "#h2o-table-1.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-1 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-1 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-1 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-1 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-1 .h2o-table th,\n",
              "#h2o-table-1 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption></caption>\n",
              "    <thead></thead>\n",
              "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
              "<td>02 secs</td></tr>\n",
              "<tr><td>H2O_cluster_timezone:</td>\n",
              "<td>Etc/UTC</td></tr>\n",
              "<tr><td>H2O_data_parsing_timezone:</td>\n",
              "<td>UTC</td></tr>\n",
              "<tr><td>H2O_cluster_version:</td>\n",
              "<td>3.40.0.4</td></tr>\n",
              "<tr><td>H2O_cluster_version_age:</td>\n",
              "<td>2 months and 7 days</td></tr>\n",
              "<tr><td>H2O_cluster_name:</td>\n",
              "<td>H2O_from_python_unknownUser_uso7vg</td></tr>\n",
              "<tr><td>H2O_cluster_total_nodes:</td>\n",
              "<td>1</td></tr>\n",
              "<tr><td>H2O_cluster_free_memory:</td>\n",
              "<td>3.170 Gb</td></tr>\n",
              "<tr><td>H2O_cluster_total_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_allowed_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_status:</td>\n",
              "<td>locked, healthy</td></tr>\n",
              "<tr><td>H2O_connection_url:</td>\n",
              "<td>http://127.0.0.1:54321</td></tr>\n",
              "<tr><td>H2O_connection_proxy:</td>\n",
              "<td>{\"http\": null, \"https\": null, \"colab_language_server\": \"/usr/colab/bin/language_service\"}</td></tr>\n",
              "<tr><td>H2O_internal_security:</td>\n",
              "<td>False</td></tr>\n",
              "<tr><td>Python_version:</td>\n",
              "<td>3.10.12 final</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Library Loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kWdoOLbsF2qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X-QiglXeF_XE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8P1HTOHbugE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "asKywHvIu83f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z5wVvB0pvWHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train, valid = hdf.split_frame(ratios=[.8], seed=123)\n",
        "#hdf = h2o.H2OFrame(df)\n",
        "#hdf[\"diagnosis\"] = hdf[\"diagnosis\"].asfactor()\n",
        "hy = \"diagnosis\"\n",
        "hx = list(df.columns)\n",
        "hx.remove(hy)\n",
        "hdf  = df.copy()\n",
        "hdf.iloc[:,1:] = StandardScaler().fit_transform(hdf.iloc[:,1:])\n",
        "hdf.iloc[:,0] = LabelEncoder().fit_transform(hdf.iloc[:,0])\n",
        "hdf.iloc[:,0] = hdf.iloc[:,0].astype('category')\n",
        "train1, valid1 = train_test_split(hdf, test_size=0.2,random_state=123)\n",
        "train = h2o.H2OFrame(train1)\n",
        "valid = h2o.H2OFrame(valid1)\n",
        "train[\"diagnosis\"] = train[\"diagnosis\"].asfactor()\n",
        "valid[\"diagnosis\"] = valid[\"diagnosis\"].asfactor()"
      ],
      "metadata": {
        "id": "NVoFNbYCGxGh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43e448c0-9b9c-4b2c-9e0b-f4d503d95bfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-460708a37676>:9: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  hdf.iloc[:,0] = LabelEncoder().fit_transform(hdf.iloc[:,0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "st = time.time()\n",
        "aml = H2OAutoML(max_models = 10, seed = 123, verbosity=\"info\",\n",
        "                nfolds=10, sort_metric='accuracy')\n",
        "aml.train(x = hx, y = hy, training_frame = train,\n",
        "          validation_frame = valid)\n",
        "autoend = time.time() - st"
      ],
      "metadata": {
        "id": "7JNO6XnVHH5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48ab8779-b76b-469a-f78e-3c83a65b96a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoML progress: |\n",
            "16:25:21.181: Project: AutoML_1_20230705_162521\n",
            "16:25:21.182: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n",
            "16:25:21.196: Setting stopping tolerance adaptively based on the training frame: 0.011180339887498949\n",
            "16:25:21.196: Build control seed: 123\n",
            "16:25:21.197: training frame: Frame key: AutoML_1_20230705_162521_training_py_1_sid_ba5a    cols: 31    rows: 8000  chunks: 2    size: 1926168  checksum: -5600652261642703400\n",
            "16:25:21.199: validation frame: Frame key: py_2_sid_ba5a    cols: 31    rows: 2000  chunks: 1    size: 482912  checksum: -8629894929602001568\n",
            "16:25:21.199: leaderboard frame: NULL\n",
            "16:25:21.199: blending frame: NULL\n",
            "16:25:21.199: response column: diagnosis\n",
            "16:25:21.199: fold column: null\n",
            "16:25:21.199: weights column: null\n",
            "16:25:21.228: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (7g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (7g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (6g, 60w)]}, {StackedEnsemble : [monotonic (9g, 10w), best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
            "16:25:21.264: AutoML job created: 2023.07.05 16:25:21.129\n",
            "16:25:21.265: AutoML build started: 2023.07.05 16:25:21.265\n",
            "16:25:21.327: AutoML: starting XGBoost_1_AutoML_1_20230705_162521 model training\n",
            "\n",
            "██\n",
            "16:25:52.140: New leader: XGBoost_1_AutoML_1_20230705_162521, accuracy: 0.94825\n",
            "16:25:52.146: AutoML: starting GLM_1_AutoML_1_20230705_162521 model training\n",
            "\n",
            "███\n",
            "16:26:11.629: AutoML: starting GBM_1_AutoML_1_20230705_162521 model training\n",
            "\n",
            "█\n",
            "16:27:12.26: AutoML: starting XGBoost_2_AutoML_1_20230705_162521 model training\n",
            "\n",
            "█\n",
            "16:27:31.706: AutoML: starting DRF_1_AutoML_1_20230705_162521 model training\n",
            "\n",
            "███\n",
            "16:28:00.345: New leader: DRF_1_AutoML_1_20230705_162521, accuracy: 0.945125\n",
            "16:28:00.346: AutoML: starting GBM_2_AutoML_1_20230705_162521 model training\n",
            "\n",
            "█\n",
            "16:28:34.591: AutoML: starting GBM_3_AutoML_1_20230705_162521 model training\n",
            "\n",
            "█\n",
            "16:29:09.800: AutoML: starting GBM_4_AutoML_1_20230705_162521 model training\n",
            "\n",
            "█\n",
            "16:29:48.973: AutoML: starting XGBoost_3_AutoML_1_20230705_162521 model training\n",
            "\n",
            "█\n",
            "16:30:05.903: AutoML: starting XRT_1_AutoML_1_20230705_162521 model training\n",
            "\n",
            "███\n",
            "16:30:41.554: No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'monotonic'.\n",
            "16:30:41.569: AutoML: starting StackedEnsemble_BestOfFamily_1_AutoML_1_20230705_162521 model training\n",
            "\n",
            "██\n",
            "16:30:56.236: AutoML: starting StackedEnsemble_AllModels_1_AutoML_1_20230705_162521 model training\n",
            "\n",
            "████████████████████████████████████████████| (done) 100%\n",
            "\n",
            "16:31:15.574: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GLM : [def_1 (1g, 10w)]}, {GBM : [def_5 (1g, 10w)]}, {XGBoost : [def_1 (2g, 10w)]}, {DRF : [def_1 (2g, 10w)]}, {GBM : [def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w)]}, {XGBoost : [def_3 (3g, 10w)]}, {DRF : [XRT (3g, 10w)]}, {StackedEnsemble : [best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
            "16:31:15.574: AutoML build stopped: 2023.07.05 16:31:15.574\n",
            "16:31:15.574: AutoML build done: built 10 models\n",
            "16:31:15.575: AutoML duration:  5 min 54.309 sec\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lbo606kFH4Zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lb = aml.leaderboard\n",
        "lb.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "gmCXw_D_4y1D",
        "outputId": "c16a0af0-9105-4c58-be0d-bc2eb99d3a1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model_id                              accuracy       auc    logloss     aucpr    mean_per_class_error      rmse        mse\n",
              "----------------------------------  ----------  --------  ---------  --------  ----------------------  --------  ---------\n",
              "DRF_1_AutoML_1_20230705_162521        0.945125  0.989177   0.141093  0.984216               0.056397   0.202717  0.0410943\n",
              "XRT_1_AutoML_1_20230705_162521        0.945625  0.989034   0.15255   0.984006               0.0589083  0.202303  0.0409264\n",
              "XGBoost_3_AutoML_1_20230705_162521    0.948     0.990641   0.125343  0.986013               0.0535747  0.196101  0.0384557\n",
              "XGBoost_1_AutoML_1_20230705_162521    0.94825   0.990807   0.12301   0.986256               0.0542833  0.194461  0.037815\n",
              "GBM_2_AutoML_1_20230705_162521        0.949125  0.990889   0.122321  0.986528               0.055881   0.193309  0.0373683\n",
              "GBM_4_AutoML_1_20230705_162521        0.949125  0.990796   0.12375   0.986334               0.0527628  0.193394  0.0374012\n",
              "GBM_3_AutoML_1_20230705_162521        0.949375  0.991048   0.122135  0.986551               0.0517268  0.19245   0.037037\n",
              "XGBoost_2_AutoML_1_20230705_162521    0.9495    0.990286   0.129042  0.985682               0.0508957  0.196218  0.0385014\n",
              "GLM_1_AutoML_1_20230705_162521        0.949625  0.990625   0.120152  0.986297               0.0545628  0.192167  0.0369281\n",
              "GBM_1_AutoML_1_20230705_162521        0.94975   0.991147   0.117772  0.986794               0.051422   0.190749  0.0363851\n",
              "[10 rows x 8 columns]\n"
            ],
            "text/html": [
              "<table class='dataframe'>\n",
              "<thead>\n",
              "<tr><th>model_id                          </th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">      mse</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DRF_1_AutoML_1_20230705_162521    </td><td style=\"text-align: right;\">  0.945125</td><td style=\"text-align: right;\">0.989177</td><td style=\"text-align: right;\"> 0.141093</td><td style=\"text-align: right;\">0.984216</td><td style=\"text-align: right;\">             0.056397 </td><td style=\"text-align: right;\">0.202717</td><td style=\"text-align: right;\">0.0410943</td></tr>\n",
              "<tr><td>XRT_1_AutoML_1_20230705_162521    </td><td style=\"text-align: right;\">  0.945625</td><td style=\"text-align: right;\">0.989034</td><td style=\"text-align: right;\"> 0.15255 </td><td style=\"text-align: right;\">0.984006</td><td style=\"text-align: right;\">             0.0589083</td><td style=\"text-align: right;\">0.202303</td><td style=\"text-align: right;\">0.0409264</td></tr>\n",
              "<tr><td>XGBoost_3_AutoML_1_20230705_162521</td><td style=\"text-align: right;\">  0.948   </td><td style=\"text-align: right;\">0.990641</td><td style=\"text-align: right;\"> 0.125343</td><td style=\"text-align: right;\">0.986013</td><td style=\"text-align: right;\">             0.0535747</td><td style=\"text-align: right;\">0.196101</td><td style=\"text-align: right;\">0.0384557</td></tr>\n",
              "<tr><td>XGBoost_1_AutoML_1_20230705_162521</td><td style=\"text-align: right;\">  0.94825 </td><td style=\"text-align: right;\">0.990807</td><td style=\"text-align: right;\"> 0.12301 </td><td style=\"text-align: right;\">0.986256</td><td style=\"text-align: right;\">             0.0542833</td><td style=\"text-align: right;\">0.194461</td><td style=\"text-align: right;\">0.037815 </td></tr>\n",
              "<tr><td>GBM_2_AutoML_1_20230705_162521    </td><td style=\"text-align: right;\">  0.949125</td><td style=\"text-align: right;\">0.990889</td><td style=\"text-align: right;\"> 0.122321</td><td style=\"text-align: right;\">0.986528</td><td style=\"text-align: right;\">             0.055881 </td><td style=\"text-align: right;\">0.193309</td><td style=\"text-align: right;\">0.0373683</td></tr>\n",
              "<tr><td>GBM_4_AutoML_1_20230705_162521    </td><td style=\"text-align: right;\">  0.949125</td><td style=\"text-align: right;\">0.990796</td><td style=\"text-align: right;\"> 0.12375 </td><td style=\"text-align: right;\">0.986334</td><td style=\"text-align: right;\">             0.0527628</td><td style=\"text-align: right;\">0.193394</td><td style=\"text-align: right;\">0.0374012</td></tr>\n",
              "<tr><td>GBM_3_AutoML_1_20230705_162521    </td><td style=\"text-align: right;\">  0.949375</td><td style=\"text-align: right;\">0.991048</td><td style=\"text-align: right;\"> 0.122135</td><td style=\"text-align: right;\">0.986551</td><td style=\"text-align: right;\">             0.0517268</td><td style=\"text-align: right;\">0.19245 </td><td style=\"text-align: right;\">0.037037 </td></tr>\n",
              "<tr><td>XGBoost_2_AutoML_1_20230705_162521</td><td style=\"text-align: right;\">  0.9495  </td><td style=\"text-align: right;\">0.990286</td><td style=\"text-align: right;\"> 0.129042</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">             0.0508957</td><td style=\"text-align: right;\">0.196218</td><td style=\"text-align: right;\">0.0385014</td></tr>\n",
              "<tr><td>GLM_1_AutoML_1_20230705_162521    </td><td style=\"text-align: right;\">  0.949625</td><td style=\"text-align: right;\">0.990625</td><td style=\"text-align: right;\"> 0.120152</td><td style=\"text-align: right;\">0.986297</td><td style=\"text-align: right;\">             0.0545628</td><td style=\"text-align: right;\">0.192167</td><td style=\"text-align: right;\">0.0369281</td></tr>\n",
              "<tr><td>GBM_1_AutoML_1_20230705_162521    </td><td style=\"text-align: right;\">  0.94975 </td><td style=\"text-align: right;\">0.991147</td><td style=\"text-align: right;\"> 0.117772</td><td style=\"text-align: right;\">0.986794</td><td style=\"text-align: right;\">             0.051422 </td><td style=\"text-align: right;\">0.190749</td><td style=\"text-align: right;\">0.0363851</td></tr>\n",
              "</tbody>\n",
              "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[10 rows x 8 columns]</pre>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = aml.get_best_model()\n",
        "best_model"
      ],
      "metadata": {
        "id": "vlH8zwtisQU1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f3820e5f-8f85-498a-c01f-a210a26e609c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model Details\n",
              "=============\n",
              "H2ORandomForestEstimator : Distributed Random Forest\n",
              "Model Key: DRF_1_AutoML_1_20230705_162521\n",
              "\n",
              "\n",
              "Model Summary: \n",
              "    number_of_trees    number_of_internal_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n",
              "--  -----------------  --------------------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n",
              "    46                 46                          199285                 15           20           18.2174       311           369           340\n",
              "\n",
              "ModelMetricsBinomial: drf\n",
              "** Reported on train data. **\n",
              "\n",
              "MSE: 0.04326800279168445\n",
              "RMSE: 0.2080096218728462\n",
              "LogLoss: 0.20428151575245082\n",
              "Mean Per-Class Error: 0.057211674235314855\n",
              "AUC: 0.9860384526971423\n",
              "AUCPR: 0.9800859943345126\n",
              "Gini: 0.9720769053942846\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4666666666666667\n",
              "       0     1     Error    Rate\n",
              "-----  ----  ----  -------  --------------\n",
              "0      4652  269   0.0547   (269.0/4921.0)\n",
              "1      184   2895  0.0598   (184.0/3079.0)\n",
              "Total  4836  3164  0.0566   (453.0/8000.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.466667     0.927439  105\n",
              "max f2                       0.294118     0.945237  140\n",
              "max f0point5                 0.647059     0.94207   70\n",
              "max accuracy                 0.5          0.94375   100\n",
              "max precision                0.956522     0.998262  4\n",
              "max recall                   0            1         197\n",
              "max specificity              1            0.99939   0\n",
              "max absolute_mcc             0.5          0.881501  100\n",
              "max min_per_class_accuracy   0.454545     0.942839  108\n",
              "max mean_per_class_accuracy  0.45         0.943213  109\n",
              "max tns                      1            4918      0\n",
              "max fns                      1            1374      0\n",
              "max fps                      0            4921      197\n",
              "max tps                      0            3079      197\n",
              "max tnr                      1            0.99939   0\n",
              "max fnr                      1            0.446249  0\n",
              "max fpr                      0            1         197\n",
              "max tpr                      0            1         197\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 38.49 %, avg score: 38.54 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.2135                      1                  2.59368    2.59368            0.998244         1          0.998244                    1                   0.553751        0.553751                   159.368   159.368            0.553142\n",
              "2        0.30125                     0.789474           2.47611    2.55943            0.952991         0.893171   0.985062                    0.968882            0.217278        0.77103                    147.611   155.943            0.763714\n",
              "3        0.40025                     0.444444           1.75841    2.3613             0.676768         0.62211    0.908807                    0.88311             0.174082        0.945112                   75.8409   136.13             0.885775\n",
              "4        0.504                       0.117647           0.438258   1.96544            0.168675         0.255875   0.756448                    0.753991            0.0454693       0.990581                   -56.1742  96.5439            0.791028\n",
              "5        1                           0                  0.0189892  1                  0.00730847       0.0108765  0.384875                    0.385406            0.00941864      1                          -98.1011  0                  0\n",
              "\n",
              "ModelMetricsBinomial: drf\n",
              "** Reported on validation data. **\n",
              "\n",
              "MSE: 0.036937276832765605\n",
              "RMSE: 0.19219073035077838\n",
              "LogLoss: 0.14079214212429528\n",
              "Mean Per-Class Error: 0.04713423229341206\n",
              "AUC: 0.9915375408920449\n",
              "AUCPR: 0.9873978367714009\n",
              "Gini: 0.9830750817840899\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4565217391304348\n",
              "       0     1    Error    Rate\n",
              "-----  ----  ---  -------  -------------\n",
              "0      1187  58   0.0466   (58.0/1245.0)\n",
              "1      36    719  0.0477   (36.0/755.0)\n",
              "Total  1223  777  0.047    (94.0/2000.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.456522     0.938642  27\n",
              "max f2                       0.304348     0.956846  34\n",
              "max f0point5                 0.652174     0.952449  17\n",
              "max accuracy                 0.492754     0.953     25\n",
              "max precision                1            1         0\n",
              "max recall                   0            1         48\n",
              "max specificity              1            1         0\n",
              "max absolute_mcc             0.456522     0.900811  27\n",
              "max min_per_class_accuracy   0.456522     0.952318  27\n",
              "max mean_per_class_accuracy  0.434783     0.953084  28\n",
              "max tns                      1            1245      0\n",
              "max fns                      1            445       0\n",
              "max fps                      0            1245      48\n",
              "max tps                      0            755       48\n",
              "max tnr                      1            1         0\n",
              "max fnr                      1            0.589404  0\n",
              "max fpr                      0            1         48\n",
              "max tpr                      0            1         48\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 37.75 %, avg score: 37.82 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.155                       1                  2.64901     2.64901            1                1          1                           1                   0.410596        0.410596                   164.901   164.901            0.410596\n",
              "2        0.2005                      0.978261           2.64901     2.64901            1                0.978261   1                           0.995067            0.12053         0.531126                   164.901   164.901            0.531126\n",
              "3        0.3025                      0.782609           2.55811     2.61836            0.965686         0.890239   0.98843                     0.95972             0.260927        0.792053                   155.811   161.836            0.78643\n",
              "4        0.401                       0.413043           1.73463     2.40128            0.654822         0.59229    0.906484                    0.869466            0.170861        0.962914                   73.4629   140.128            0.902673\n",
              "5        0.5015                      0.108696           0.342658    1.98874            0.129353         0.241834   0.750748                    0.743689            0.0344371       0.997351                   -65.7342  98.8736            0.796548\n",
              "6        0.6315                      0.0217391          0.0101885   1.58143            0.00384615       0.0399666  0.596991                    0.598822            0.0013245       0.998675                   -98.9812  58.1434            0.58984\n",
              "7        1                           0                  0.00359431  1                  0.00135685       0          0.3775                      0.378156            0.0013245       1                          -99.6406  0                  0\n",
              "\n",
              "ModelMetricsBinomial: drf\n",
              "** Reported on cross-validation data. **\n",
              "\n",
              "MSE: 0.04109426250888458\n",
              "RMSE: 0.20271719835496094\n",
              "LogLoss: 0.14109268080346257\n",
              "Mean Per-Class Error: 0.05639704934588783\n",
              "AUC: 0.9891767351896238\n",
              "AUCPR: 0.984216068014286\n",
              "Gini: 0.9783534703792476\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.48\n",
              "       0     1     Error    Rate\n",
              "-----  ----  ----  -------  --------------\n",
              "0      4676  245   0.0498   (245.0/4921.0)\n",
              "1      194   2885  0.063    (194.0/3079.0)\n",
              "Total  4870  3130  0.0549   (439.0/8000.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.48         0.929296  54\n",
              "max f2                       0.32         0.949712  76\n",
              "max f0point5                 0.68         0.947539  29\n",
              "max accuracy                 0.52         0.945125  51\n",
              "max precision                1            1         0\n",
              "max recall                   0            1         135\n",
              "max specificity              1            1         0\n",
              "max absolute_mcc             0.48         0.884544  54\n",
              "max min_per_class_accuracy   0.44         0.940459  59\n",
              "max mean_per_class_accuracy  0.48         0.943603  54\n",
              "max tns                      1            4921      0\n",
              "max fns                      1            1720      0\n",
              "max fps                      0            4921      135\n",
              "max tps                      0            3079      135\n",
              "max tnr                      1            1         0\n",
              "max fnr                      1            0.558623  0\n",
              "max fpr                      0            1         135\n",
              "max tpr                      0            1         135\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 38.49 %, avg score: 38.55 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift         cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  -----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.169875                    1                  2.59825      2.59825            1                1            1                           1                   0.441377        0.441377                   159.825   159.825            0.441377\n",
              "2        0.20075                     0.98               2.58773      2.59663            0.995951         0.98         0.999377                    0.996924            0.0798961       0.521273                   158.773   159.663            0.52107\n",
              "3        0.3025                      0.8                2.52483      2.57248            0.971744         0.89986      0.990083                    0.964275            0.256902        0.778175                   152.483   157.248            0.773298\n",
              "4        0.4005                      0.44               1.70676      2.36064            0.656888         0.621349     0.908552                    0.880363            0.167262        0.945437                   70.6756   136.064            0.885896\n",
              "5        0.50625                     0.12               0.45454      1.96248            0.174941         0.253057     0.755309                    0.749326            0.0480676       0.993504                   -54.546   96.2478            0.792123\n",
              "6        0.647375                    0.02               0.043726     1.5442             0.0168291        0.0437432    0.594323                    0.595512            0.00617083      0.999675                   -95.6274  54.4198            0.572729\n",
              "7        1                           0                  0.000921037  1                  0.000354484      1.41147e-06  0.384875                    0.38552             0.000324781     1                          -99.9079  0                  0\n",
              "\n",
              "Cross-Validation Metrics Summary: \n",
              "                         mean       sd          cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid    cv_6_valid    cv_7_valid    cv_8_valid    cv_9_valid    cv_10_valid\n",
              "-----------------------  ---------  ----------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  -------------\n",
              "accuracy                 0.948625   0.00961859  0.95125       0.96875       0.955         0.94375       0.94375       0.94125       0.95875       0.94125       0.93875       0.94375\n",
              "auc                      0.989321   0.0026153   0.98965       0.994138      0.992543      0.987122      0.987971      0.987636      0.991501      0.989148      0.9872        0.986305\n",
              "err                      0.051375   0.00961859  0.04875       0.03125       0.045         0.05625       0.05625       0.05875       0.04125       0.05875       0.06125       0.05625\n",
              "err_count                41.1       7.69488     39            25            36            45            45            47            33            47            49            45\n",
              "f0point5                 0.928636   0.0171784   0.933852      0.957588      0.933713      0.904153      0.920285      0.909362      0.952694      0.916619      0.928526      0.929569\n",
              "f1                       0.934123   0.0109179   0.936585      0.958541      0.935714      0.92635       0.926591      0.928463      0.946166      0.931785      0.922345      0.928685\n",
              "f2                       0.939882   0.0123253   0.939335      0.959495      0.937724      0.949664      0.932983      0.948383      0.939728      0.947462      0.916247      0.927802\n",
              "lift_top_group           2.60421    0.132402    2.61438       2.65781       2.86738       2.73038       2.64026       2.52366       2.58065       2.38806       2.50784       2.53165\n",
              "logloss                  0.141121   0.0190486   0.13218       0.112811      0.131677      0.145857      0.142523      0.143419      0.128312      0.141626      0.146125      0.186684\n",
              "max_per_class_error      0.0659869  0.0123332   0.0588235     0.0398671     0.0609319     0.0690335     0.0627063     0.0724638     0.0645161     0.0709677     0.0877743     0.0727848\n",
              "mcc                      0.892432   0.0188935   0.897021      0.933469      0.901113      0.882905      0.881158      0.880277      0.912895      0.881295      0.871934      0.882248\n",
              "mean_per_class_accuracy  0.947668   0.00891056  0.949333      0.96704       0.9513        0.948418      0.94249       0.944841      0.954477      0.943621      0.934283      0.94088\n",
              "mean_per_class_error     0.0523317  0.00891056  0.0506668     0.0329596     0.0487001     0.0515816     0.0575101     0.0551593     0.0455234     0.0563794     0.0657167     0.0591197\n",
              "mse                      0.0410048  0.00441369  0.0389478     0.0313437     0.0385018     0.0451063     0.0434138     0.0434346     0.0373019     0.0427476     0.04465       0.0446002\n",
              "pr_auc                   0.98442    0.00342295  0.984525      0.990966      0.986631      0.979124      0.981952      0.982806      0.987586      0.985864      0.98284       0.981901\n",
              "precision                0.925123   0.0227588   0.932039      0.956954      0.932384      0.889937      0.916129      0.897059      0.957096      0.90678       0.932692      0.930159\n",
              "r2                       0.826597   0.0179854   0.835102      0.866444      0.830481      0.805669      0.815495      0.818445      0.842836      0.824372      0.813763      0.813369\n",
              "recall                   0.943882   0.0173548   0.941176      0.960133      0.939068      0.96587       0.937294      0.962145      0.935484      0.958209      0.912226      0.927215\n",
              "rmse                     0.202215   0.0112496   0.197352      0.177042      0.196219      0.212382      0.20836       0.20841       0.193137      0.206755      0.211305      0.211188\n",
              "specificity              0.951455   0.017369    0.95749       0.973948      0.963532      0.930967      0.947686      0.927536      0.973469      0.929032      0.956341      0.954545\n",
              "\n",
              "Scoring History: \n",
              "    timestamp            duration    number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
              "--  -------------------  ----------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ----------------  -------------------  -----------------  ---------------------------------\n",
              "    2023-07-05 16:27:57  26.211 sec  0                  nan              nan                 nan             nan                nan              nan                              nan                nan                   nan               nan                  nan                nan\n",
              "    2023-07-05 16:27:58  26.700 sec  5                  0.276754         1.99677             0.930839        0.892501           2.40932          0.0920443                        0.219089           0.36694               0.978939          0.967803             2.62383            0.063\n",
              "    2023-07-05 16:27:58  26.927 sec  10                 0.244527         0.966394            0.960549        0.936435           2.49968          0.0761556                        0.205803           0.166559              0.987595          0.980153             2.64312            0.0595\n",
              "    2023-07-05 16:27:58  27.126 sec  15                 0.226197         0.502812            0.975243        0.959903           2.54954          0.0665666                        0.199182           0.146057              0.989664          0.984612             2.64901            0.056\n",
              "    2023-07-05 16:27:59  27.346 sec  20                 0.218721         0.361284            0.980319        0.968143           2.56604          0.0632579                        0.19652            0.143699              0.990551          0.986053             2.64901            0.0505\n",
              "    2023-07-05 16:27:59  27.554 sec  25                 0.21393          0.274676            0.982997        0.975362           2.58606          0.060625                         0.195892           0.143851              0.990808          0.986377             2.64901            0.0495\n",
              "    2023-07-05 16:27:59  27.803 sec  30                 0.212194         0.24252             0.984234        0.976963           2.58844          0.059                            0.19497            0.143397              0.990969          0.986596             2.64901            0.0475\n",
              "    2023-07-05 16:27:59  28.008 sec  35                 0.209698         0.22074             0.985319        0.978713           2.591            0.057                            0.194784           0.143048              0.991071          0.986761             2.64901            0.0485\n",
              "    2023-07-05 16:27:59  28.225 sec  40                 0.208903         0.216606            0.985538        0.979325           2.59233          0.056125                         0.193185           0.141788              0.991383          0.9872               2.64901            0.046\n",
              "    2023-07-05 16:28:00  28.458 sec  45                 0.20799          0.204199            0.98606         0.980122           2.59371          0.056625                         0.192606           0.14129               0.991463          0.987275             2.64901            0.0455\n",
              "    2023-07-05 16:28:00  28.541 sec  46                 0.20801          0.204282            0.986038        0.980086           2.59368          0.056625                         0.192191           0.140792              0.991538          0.987398             2.64901            0.047\n",
              "\n",
              "Variable Importances: \n",
              "variable                 relative_importance    scaled_importance     percentage\n",
              "-----------------------  ---------------------  --------------------  ---------------------\n",
              "concave points_mean      12892.1552734375       1.0                   0.18433499477221202\n",
              "perimeter_worst          12409.1396484375       0.9625341446208621    0.17742872651676217\n",
              "concave points_worst     6141.6552734375        0.4763870076938594    0.0878147965727973\n",
              "radius_worst             5617.19189453125       0.4357061930602632    0.08031589881998402\n",
              "radius_se                4640.35546875          0.35993636210004465   0.06634886742604074\n",
              "perimeter_mean           4096.8095703125        0.3177753822709077    0.058577123429645446\n",
              "area_worst               3825.361083984375      0.29672005982320127   0.05469589067632025\n",
              "area_se                  3570.8486328125        0.27697840718454103   0.05105681324037799\n",
              "concavity_mean           3542.318115234375      0.2747653933809524    0.050648877352462644\n",
              "area_mean                1562.5438232421875     0.12120113278976655   0.02234161017918779\n",
              "---                      ---                    ---                   ---\n",
              "symmetry_worst           398.6156921386719      0.03091924381022344   0.005699498646118286\n",
              "smoothness_mean          397.4166564941406      0.03082623875256627   0.005682354559301263\n",
              "texture_se               372.990234375          0.028931565472492773  0.005333099970123865\n",
              "symmetry_mean            357.383544921875       0.027721008422712242  0.0051099519426811065\n",
              "smoothness_se            350.05841064453125     0.02715282303229609   0.005005215491709098\n",
              "fractal_dimension_worst  340.31817626953125     0.02639730666064112   0.004865947385289758\n",
              "symmetry_se              333.9683532714844      0.025904772800834933  0.0047751561588172476\n",
              "concavity_se             327.7789611816406      0.025424683013008986  0.004686658810288159\n",
              "concave points_se        309.9120178222656      0.02403880586675809   0.004431193153779072\n",
              "fractal_dimension_se     298.4029541015625      0.023146087506127115  0.0042666339194391036\n",
              "[30 rows x 4 columns]\n",
              "\n",
              "\n",
              "[tips]\n",
              "Use `model.explain()` to inspect the model.\n",
              "--\n",
              "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
            ],
            "text/html": [
              "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
              "=============\n",
              "H2ORandomForestEstimator : Distributed Random Forest\n",
              "Model Key: DRF_1_AutoML_1_20230705_162521\n",
              "</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-2.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-2 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-2 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-2 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-2 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-2 .h2o-table th,\n",
              "#h2o-table-2 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Model Summary: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>number_of_trees</th>\n",
              "<th>number_of_internal_trees</th>\n",
              "<th>model_size_in_bytes</th>\n",
              "<th>min_depth</th>\n",
              "<th>max_depth</th>\n",
              "<th>mean_depth</th>\n",
              "<th>min_leaves</th>\n",
              "<th>max_leaves</th>\n",
              "<th>mean_leaves</th></tr></thead>\n",
              "    <tbody><tr><td></td>\n",
              "<td>46.0</td>\n",
              "<td>46.0</td>\n",
              "<td>199285.0</td>\n",
              "<td>15.0</td>\n",
              "<td>20.0</td>\n",
              "<td>18.217392</td>\n",
              "<td>311.0</td>\n",
              "<td>369.0</td>\n",
              "<td>340.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: drf\n",
              "** Reported on train data. **\n",
              "\n",
              "MSE: 0.04326800279168445\n",
              "RMSE: 0.2080096218728462\n",
              "LogLoss: 0.20428151575245082\n",
              "Mean Per-Class Error: 0.057211674235314855\n",
              "AUC: 0.9860384526971423\n",
              "AUCPR: 0.9800859943345126\n",
              "Gini: 0.9720769053942846</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-3.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-3 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-3 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-3 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-3 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-3 .h2o-table th,\n",
              "#h2o-table-3 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-3 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-3\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4666666666666667</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>0</th>\n",
              "<th>1</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>0</td>\n",
              "<td>4652.0</td>\n",
              "<td>269.0</td>\n",
              "<td>0.0547</td>\n",
              "<td> (269.0/4921.0)</td></tr>\n",
              "<tr><td>1</td>\n",
              "<td>184.0</td>\n",
              "<td>2895.0</td>\n",
              "<td>0.0598</td>\n",
              "<td> (184.0/3079.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>4836.0</td>\n",
              "<td>3164.0</td>\n",
              "<td>0.0566</td>\n",
              "<td> (453.0/8000.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-4.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-4 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-4 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-4 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-4 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-4 .h2o-table th,\n",
              "#h2o-table-4 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-4 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-4\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.4666667</td>\n",
              "<td>0.9274387</td>\n",
              "<td>105.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.2941176</td>\n",
              "<td>0.9452375</td>\n",
              "<td>140.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.6470588</td>\n",
              "<td>0.9420699</td>\n",
              "<td>70.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.5</td>\n",
              "<td>0.94375</td>\n",
              "<td>100.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>0.9565217</td>\n",
              "<td>0.9982619</td>\n",
              "<td>4.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>197.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9993904</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.5</td>\n",
              "<td>0.8815009</td>\n",
              "<td>100.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.4545455</td>\n",
              "<td>0.9428386</td>\n",
              "<td>108.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.4500000</td>\n",
              "<td>0.9432129</td>\n",
              "<td>109.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>1.0</td>\n",
              "<td>4918.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>1.0</td>\n",
              "<td>1374.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0</td>\n",
              "<td>4921.0</td>\n",
              "<td>197.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0</td>\n",
              "<td>3079.0</td>\n",
              "<td>197.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9993904</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>1.0</td>\n",
              "<td>0.4462488</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>197.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>197.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-5.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-5 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-5 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-5 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-5 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-5 .h2o-table th,\n",
              "#h2o-table-5 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-5 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-5\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 38.49 %, avg score: 38.54 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.2135</td>\n",
              "<td>1.0</td>\n",
              "<td>2.5936825</td>\n",
              "<td>2.5936825</td>\n",
              "<td>0.9982436</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9982436</td>\n",
              "<td>1.0</td>\n",
              "<td>0.5537512</td>\n",
              "<td>0.5537512</td>\n",
              "<td>159.3682520</td>\n",
              "<td>159.3682520</td>\n",
              "<td>0.5531416</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.30125</td>\n",
              "<td>0.7894737</td>\n",
              "<td>2.4761064</td>\n",
              "<td>2.5594342</td>\n",
              "<td>0.9529915</td>\n",
              "<td>0.8931708</td>\n",
              "<td>0.9850622</td>\n",
              "<td>0.9688821</td>\n",
              "<td>0.2172783</td>\n",
              "<td>0.7710296</td>\n",
              "<td>147.6106406</td>\n",
              "<td>155.9434208</td>\n",
              "<td>0.7637140</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.40025</td>\n",
              "<td>0.4444444</td>\n",
              "<td>1.7584090</td>\n",
              "<td>2.3613043</td>\n",
              "<td>0.6767677</td>\n",
              "<td>0.6221101</td>\n",
              "<td>0.9088070</td>\n",
              "<td>0.8831097</td>\n",
              "<td>0.1740825</td>\n",
              "<td>0.9451120</td>\n",
              "<td>75.8409033</td>\n",
              "<td>136.1304308</td>\n",
              "<td>0.8857745</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.504</td>\n",
              "<td>0.1176471</td>\n",
              "<td>0.4382584</td>\n",
              "<td>1.9654392</td>\n",
              "<td>0.1686747</td>\n",
              "<td>0.2558749</td>\n",
              "<td>0.7564484</td>\n",
              "<td>0.7539914</td>\n",
              "<td>0.0454693</td>\n",
              "<td>0.9905814</td>\n",
              "<td>-56.1741608</td>\n",
              "<td>96.5439202</td>\n",
              "<td>0.7910284</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0189892</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0073085</td>\n",
              "<td>0.0108765</td>\n",
              "<td>0.384875</td>\n",
              "<td>0.3854064</td>\n",
              "<td>0.0094186</td>\n",
              "<td>1.0</td>\n",
              "<td>-98.1010802</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: drf\n",
              "** Reported on validation data. **\n",
              "\n",
              "MSE: 0.036937276832765605\n",
              "RMSE: 0.19219073035077838\n",
              "LogLoss: 0.14079214212429528\n",
              "Mean Per-Class Error: 0.04713423229341206\n",
              "AUC: 0.9915375408920449\n",
              "AUCPR: 0.9873978367714009\n",
              "Gini: 0.9830750817840899</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-6.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-6 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-6 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-6 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-6 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-6 .h2o-table th,\n",
              "#h2o-table-6 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-6 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-6\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4565217391304348</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>0</th>\n",
              "<th>1</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>0</td>\n",
              "<td>1187.0</td>\n",
              "<td>58.0</td>\n",
              "<td>0.0466</td>\n",
              "<td> (58.0/1245.0)</td></tr>\n",
              "<tr><td>1</td>\n",
              "<td>36.0</td>\n",
              "<td>719.0</td>\n",
              "<td>0.0477</td>\n",
              "<td> (36.0/755.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>1223.0</td>\n",
              "<td>777.0</td>\n",
              "<td>0.047</td>\n",
              "<td> (94.0/2000.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-7.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-7 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-7 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-7 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-7 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-7 .h2o-table th,\n",
              "#h2o-table-7 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-7 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-7\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.4565217</td>\n",
              "<td>0.9386423</td>\n",
              "<td>27.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.3043478</td>\n",
              "<td>0.9568456</td>\n",
              "<td>34.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.6521739</td>\n",
              "<td>0.9524492</td>\n",
              "<td>17.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.4927536</td>\n",
              "<td>0.953</td>\n",
              "<td>25.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>48.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.4565217</td>\n",
              "<td>0.9008115</td>\n",
              "<td>27.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.4565217</td>\n",
              "<td>0.9523179</td>\n",
              "<td>27.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.4347826</td>\n",
              "<td>0.9530839</td>\n",
              "<td>28.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>1.0</td>\n",
              "<td>1245.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>1.0</td>\n",
              "<td>445.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0</td>\n",
              "<td>1245.0</td>\n",
              "<td>48.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0</td>\n",
              "<td>755.0</td>\n",
              "<td>48.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>1.0</td>\n",
              "<td>0.5894040</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>48.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>48.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-8.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-8 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-8 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-8 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-8 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-8 .h2o-table th,\n",
              "#h2o-table-8 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-8 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-8\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 37.75 %, avg score: 37.82 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.155</td>\n",
              "<td>1.0</td>\n",
              "<td>2.6490066</td>\n",
              "<td>2.6490066</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.4105960</td>\n",
              "<td>0.4105960</td>\n",
              "<td>164.9006623</td>\n",
              "<td>164.9006623</td>\n",
              "<td>0.4105960</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.2005</td>\n",
              "<td>0.9782609</td>\n",
              "<td>2.6490066</td>\n",
              "<td>2.6490066</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9782609</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9950667</td>\n",
              "<td>0.1205298</td>\n",
              "<td>0.5311258</td>\n",
              "<td>164.9006623</td>\n",
              "<td>164.9006623</td>\n",
              "<td>0.5311258</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.3025</td>\n",
              "<td>0.7826087</td>\n",
              "<td>2.5581093</td>\n",
              "<td>2.6183570</td>\n",
              "<td>0.9656863</td>\n",
              "<td>0.8902387</td>\n",
              "<td>0.9884298</td>\n",
              "<td>0.9597197</td>\n",
              "<td>0.2609272</td>\n",
              "<td>0.7920530</td>\n",
              "<td>155.8109336</td>\n",
              "<td>161.8356959</td>\n",
              "<td>0.7864305</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.401</td>\n",
              "<td>0.4130435</td>\n",
              "<td>1.7346287</td>\n",
              "<td>2.4012816</td>\n",
              "<td>0.6548223</td>\n",
              "<td>0.5922901</td>\n",
              "<td>0.9064838</td>\n",
              "<td>0.8694658</td>\n",
              "<td>0.1708609</td>\n",
              "<td>0.9629139</td>\n",
              "<td>73.4628702</td>\n",
              "<td>140.1281564</td>\n",
              "<td>0.9026729</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.5015</td>\n",
              "<td>0.1086957</td>\n",
              "<td>0.3426576</td>\n",
              "<td>1.9887358</td>\n",
              "<td>0.1293532</td>\n",
              "<td>0.2418343</td>\n",
              "<td>0.7507478</td>\n",
              "<td>0.7436892</td>\n",
              "<td>0.0344371</td>\n",
              "<td>0.9973510</td>\n",
              "<td>-65.7342427</td>\n",
              "<td>98.8735779</td>\n",
              "<td>0.7965478</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.6315</td>\n",
              "<td>0.0217391</td>\n",
              "<td>0.0101885</td>\n",
              "<td>1.5814339</td>\n",
              "<td>0.0038462</td>\n",
              "<td>0.0399666</td>\n",
              "<td>0.5969913</td>\n",
              "<td>0.5988215</td>\n",
              "<td>0.0013245</td>\n",
              "<td>0.9986755</td>\n",
              "<td>-98.9811513</td>\n",
              "<td>58.1433882</td>\n",
              "<td>0.5898402</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0035943</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0013569</td>\n",
              "<td>0.0</td>\n",
              "<td>0.3775</td>\n",
              "<td>0.3781558</td>\n",
              "<td>0.0013245</td>\n",
              "<td>1.0</td>\n",
              "<td>-99.6405690</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: drf\n",
              "** Reported on cross-validation data. **\n",
              "\n",
              "MSE: 0.04109426250888458\n",
              "RMSE: 0.20271719835496094\n",
              "LogLoss: 0.14109268080346257\n",
              "Mean Per-Class Error: 0.05639704934588783\n",
              "AUC: 0.9891767351896238\n",
              "AUCPR: 0.984216068014286\n",
              "Gini: 0.9783534703792476</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-9.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-9 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-9 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-9 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-9 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-9 .h2o-table th,\n",
              "#h2o-table-9 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-9 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-9\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.48</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>0</th>\n",
              "<th>1</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>0</td>\n",
              "<td>4676.0</td>\n",
              "<td>245.0</td>\n",
              "<td>0.0498</td>\n",
              "<td> (245.0/4921.0)</td></tr>\n",
              "<tr><td>1</td>\n",
              "<td>194.0</td>\n",
              "<td>2885.0</td>\n",
              "<td>0.063</td>\n",
              "<td> (194.0/3079.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>4870.0</td>\n",
              "<td>3130.0</td>\n",
              "<td>0.0549</td>\n",
              "<td> (439.0/8000.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-10.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-10 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-10 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-10 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-10 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-10 .h2o-table th,\n",
              "#h2o-table-10 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-10 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-10\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.48</td>\n",
              "<td>0.9292962</td>\n",
              "<td>54.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.3200000</td>\n",
              "<td>0.9497118</td>\n",
              "<td>76.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.6800000</td>\n",
              "<td>0.9475386</td>\n",
              "<td>29.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.52</td>\n",
              "<td>0.945125</td>\n",
              "<td>51.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>135.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.48</td>\n",
              "<td>0.8845437</td>\n",
              "<td>54.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.4400000</td>\n",
              "<td>0.9404593</td>\n",
              "<td>59.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.48</td>\n",
              "<td>0.9436030</td>\n",
              "<td>54.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>1.0</td>\n",
              "<td>4921.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>1.0</td>\n",
              "<td>1720.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0</td>\n",
              "<td>4921.0</td>\n",
              "<td>135.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0</td>\n",
              "<td>3079.0</td>\n",
              "<td>135.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>1.0</td>\n",
              "<td>0.5586229</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>135.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>135.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-11.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-11 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-11 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-11 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-11 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-11 .h2o-table th,\n",
              "#h2o-table-11 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-11 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-11\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 38.49 %, avg score: 38.55 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.169875</td>\n",
              "<td>1.0</td>\n",
              "<td>2.5982462</td>\n",
              "<td>2.5982462</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.4413771</td>\n",
              "<td>0.4413771</td>\n",
              "<td>159.8246184</td>\n",
              "<td>159.8246184</td>\n",
              "<td>0.4413771</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.20075</td>\n",
              "<td>0.98</td>\n",
              "<td>2.5877270</td>\n",
              "<td>2.5966283</td>\n",
              "<td>0.9959514</td>\n",
              "<td>0.9800000</td>\n",
              "<td>0.9993773</td>\n",
              "<td>0.9969240</td>\n",
              "<td>0.0798961</td>\n",
              "<td>0.5212731</td>\n",
              "<td>158.7726969</td>\n",
              "<td>159.6628347</td>\n",
              "<td>0.5210699</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.3025</td>\n",
              "<td>0.8</td>\n",
              "<td>2.5248314</td>\n",
              "<td>2.5724785</td>\n",
              "<td>0.9717445</td>\n",
              "<td>0.8998605</td>\n",
              "<td>0.9900826</td>\n",
              "<td>0.9642754</td>\n",
              "<td>0.2569016</td>\n",
              "<td>0.7781747</td>\n",
              "<td>152.4831365</td>\n",
              "<td>157.2478453</td>\n",
              "<td>0.7732977</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.4005</td>\n",
              "<td>0.44</td>\n",
              "<td>1.7067561</td>\n",
              "<td>2.3606413</td>\n",
              "<td>0.6568878</td>\n",
              "<td>0.6213488</td>\n",
              "<td>0.9085518</td>\n",
              "<td>0.8803633</td>\n",
              "<td>0.1672621</td>\n",
              "<td>0.9454368</td>\n",
              "<td>70.6756103</td>\n",
              "<td>136.0641274</td>\n",
              "<td>0.8858961</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.50625</td>\n",
              "<td>0.12</td>\n",
              "<td>0.4545395</td>\n",
              "<td>1.9624778</td>\n",
              "<td>0.1749409</td>\n",
              "<td>0.2530573</td>\n",
              "<td>0.7553086</td>\n",
              "<td>0.7493260</td>\n",
              "<td>0.0480676</td>\n",
              "<td>0.9935044</td>\n",
              "<td>-54.5460478</td>\n",
              "<td>96.2477797</td>\n",
              "<td>0.7921226</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.647375</td>\n",
              "<td>0.02</td>\n",
              "<td>0.0437260</td>\n",
              "<td>1.5441981</td>\n",
              "<td>0.0168291</td>\n",
              "<td>0.0437432</td>\n",
              "<td>0.5943232</td>\n",
              "<td>0.5955120</td>\n",
              "<td>0.0061708</td>\n",
              "<td>0.9996752</td>\n",
              "<td>-95.6273979</td>\n",
              "<td>54.4198060</td>\n",
              "<td>0.5727295</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0009210</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0003545</td>\n",
              "<td>0.0000014</td>\n",
              "<td>0.384875</td>\n",
              "<td>0.3855201</td>\n",
              "<td>0.0003248</td>\n",
              "<td>1.0</td>\n",
              "<td>-99.9078963</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-12.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-12 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-12 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-12 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-12 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-12 .h2o-table th,\n",
              "#h2o-table-12 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-12 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-12\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Cross-Validation Metrics Summary: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>mean</th>\n",
              "<th>sd</th>\n",
              "<th>cv_1_valid</th>\n",
              "<th>cv_2_valid</th>\n",
              "<th>cv_3_valid</th>\n",
              "<th>cv_4_valid</th>\n",
              "<th>cv_5_valid</th>\n",
              "<th>cv_6_valid</th>\n",
              "<th>cv_7_valid</th>\n",
              "<th>cv_8_valid</th>\n",
              "<th>cv_9_valid</th>\n",
              "<th>cv_10_valid</th></tr></thead>\n",
              "    <tbody><tr><td>accuracy</td>\n",
              "<td>0.948625</td>\n",
              "<td>0.0096186</td>\n",
              "<td>0.95125</td>\n",
              "<td>0.96875</td>\n",
              "<td>0.955</td>\n",
              "<td>0.94375</td>\n",
              "<td>0.94375</td>\n",
              "<td>0.94125</td>\n",
              "<td>0.95875</td>\n",
              "<td>0.94125</td>\n",
              "<td>0.93875</td>\n",
              "<td>0.94375</td></tr>\n",
              "<tr><td>auc</td>\n",
              "<td>0.9893215</td>\n",
              "<td>0.0026153</td>\n",
              "<td>0.9896503</td>\n",
              "<td>0.9941378</td>\n",
              "<td>0.9925426</td>\n",
              "<td>0.9871223</td>\n",
              "<td>0.9879707</td>\n",
              "<td>0.9876364</td>\n",
              "<td>0.991501</td>\n",
              "<td>0.9891478</td>\n",
              "<td>0.9872001</td>\n",
              "<td>0.9863054</td></tr>\n",
              "<tr><td>err</td>\n",
              "<td>0.051375</td>\n",
              "<td>0.0096186</td>\n",
              "<td>0.04875</td>\n",
              "<td>0.03125</td>\n",
              "<td>0.045</td>\n",
              "<td>0.05625</td>\n",
              "<td>0.05625</td>\n",
              "<td>0.05875</td>\n",
              "<td>0.04125</td>\n",
              "<td>0.05875</td>\n",
              "<td>0.06125</td>\n",
              "<td>0.05625</td></tr>\n",
              "<tr><td>err_count</td>\n",
              "<td>41.1</td>\n",
              "<td>7.6948757</td>\n",
              "<td>39.0</td>\n",
              "<td>25.0</td>\n",
              "<td>36.0</td>\n",
              "<td>45.0</td>\n",
              "<td>45.0</td>\n",
              "<td>47.0</td>\n",
              "<td>33.0</td>\n",
              "<td>47.0</td>\n",
              "<td>49.0</td>\n",
              "<td>45.0</td></tr>\n",
              "<tr><td>f0point5</td>\n",
              "<td>0.9286361</td>\n",
              "<td>0.0171784</td>\n",
              "<td>0.9338521</td>\n",
              "<td>0.9575878</td>\n",
              "<td>0.9337135</td>\n",
              "<td>0.9041533</td>\n",
              "<td>0.9202852</td>\n",
              "<td>0.9093620</td>\n",
              "<td>0.9526938</td>\n",
              "<td>0.9166191</td>\n",
              "<td>0.9285259</td>\n",
              "<td>0.9295685</td></tr>\n",
              "<tr><td>f1</td>\n",
              "<td>0.9341226</td>\n",
              "<td>0.0109179</td>\n",
              "<td>0.9365854</td>\n",
              "<td>0.9585406</td>\n",
              "<td>0.9357143</td>\n",
              "<td>0.9263502</td>\n",
              "<td>0.9265906</td>\n",
              "<td>0.9284627</td>\n",
              "<td>0.9461664</td>\n",
              "<td>0.9317852</td>\n",
              "<td>0.9223455</td>\n",
              "<td>0.9286847</td></tr>\n",
              "<tr><td>f2</td>\n",
              "<td>0.9398823</td>\n",
              "<td>0.0123253</td>\n",
              "<td>0.9393346</td>\n",
              "<td>0.9594954</td>\n",
              "<td>0.9377237</td>\n",
              "<td>0.9496644</td>\n",
              "<td>0.9329829</td>\n",
              "<td>0.9483831</td>\n",
              "<td>0.9397278</td>\n",
              "<td>0.9474616</td>\n",
              "<td>0.9162468</td>\n",
              "<td>0.9278024</td></tr>\n",
              "<tr><td>lift_top_group</td>\n",
              "<td>2.6042056</td>\n",
              "<td>0.1324018</td>\n",
              "<td>2.6143792</td>\n",
              "<td>2.6578074</td>\n",
              "<td>2.8673835</td>\n",
              "<td>2.7303755</td>\n",
              "<td>2.640264</td>\n",
              "<td>2.5236592</td>\n",
              "<td>2.580645</td>\n",
              "<td>2.3880596</td>\n",
              "<td>2.507837</td>\n",
              "<td>2.5316455</td></tr>\n",
              "<tr><td>logloss</td>\n",
              "<td>0.1411213</td>\n",
              "<td>0.0190486</td>\n",
              "<td>0.1321801</td>\n",
              "<td>0.1128110</td>\n",
              "<td>0.1316768</td>\n",
              "<td>0.1458569</td>\n",
              "<td>0.1425228</td>\n",
              "<td>0.1434189</td>\n",
              "<td>0.1283116</td>\n",
              "<td>0.1416261</td>\n",
              "<td>0.1461246</td>\n",
              "<td>0.1866843</td></tr>\n",
              "<tr><td>max_per_class_error</td>\n",
              "<td>0.0659869</td>\n",
              "<td>0.0123332</td>\n",
              "<td>0.0588235</td>\n",
              "<td>0.0398671</td>\n",
              "<td>0.0609319</td>\n",
              "<td>0.0690335</td>\n",
              "<td>0.0627063</td>\n",
              "<td>0.0724638</td>\n",
              "<td>0.0645161</td>\n",
              "<td>0.0709677</td>\n",
              "<td>0.0877743</td>\n",
              "<td>0.0727848</td></tr>\n",
              "<tr><td>mcc</td>\n",
              "<td>0.8924317</td>\n",
              "<td>0.0188935</td>\n",
              "<td>0.8970212</td>\n",
              "<td>0.9334688</td>\n",
              "<td>0.9011132</td>\n",
              "<td>0.8829053</td>\n",
              "<td>0.8811584</td>\n",
              "<td>0.8802769</td>\n",
              "<td>0.9128952</td>\n",
              "<td>0.8812954</td>\n",
              "<td>0.8719344</td>\n",
              "<td>0.8822482</td></tr>\n",
              "<tr><td>mean_per_class_accuracy</td>\n",
              "<td>0.9476683</td>\n",
              "<td>0.0089106</td>\n",
              "<td>0.9493332</td>\n",
              "<td>0.9670404</td>\n",
              "<td>0.9512999</td>\n",
              "<td>0.9484184</td>\n",
              "<td>0.9424899</td>\n",
              "<td>0.9448407</td>\n",
              "<td>0.9544767</td>\n",
              "<td>0.9436206</td>\n",
              "<td>0.9342833</td>\n",
              "<td>0.9408803</td></tr>\n",
              "<tr><td>mean_per_class_error</td>\n",
              "<td>0.0523317</td>\n",
              "<td>0.0089106</td>\n",
              "<td>0.0506668</td>\n",
              "<td>0.0329596</td>\n",
              "<td>0.0487001</td>\n",
              "<td>0.0515816</td>\n",
              "<td>0.0575101</td>\n",
              "<td>0.0551593</td>\n",
              "<td>0.0455234</td>\n",
              "<td>0.0563794</td>\n",
              "<td>0.0657167</td>\n",
              "<td>0.0591197</td></tr>\n",
              "<tr><td>mse</td>\n",
              "<td>0.0410048</td>\n",
              "<td>0.0044137</td>\n",
              "<td>0.0389478</td>\n",
              "<td>0.0313437</td>\n",
              "<td>0.0385018</td>\n",
              "<td>0.0451063</td>\n",
              "<td>0.0434138</td>\n",
              "<td>0.0434346</td>\n",
              "<td>0.0373019</td>\n",
              "<td>0.0427476</td>\n",
              "<td>0.04465</td>\n",
              "<td>0.0446002</td></tr>\n",
              "<tr><td>pr_auc</td>\n",
              "<td>0.9844196</td>\n",
              "<td>0.0034229</td>\n",
              "<td>0.9845253</td>\n",
              "<td>0.9909664</td>\n",
              "<td>0.986631</td>\n",
              "<td>0.9791239</td>\n",
              "<td>0.9819524</td>\n",
              "<td>0.9828061</td>\n",
              "<td>0.9875858</td>\n",
              "<td>0.9858642</td>\n",
              "<td>0.9828396</td>\n",
              "<td>0.981901</td></tr>\n",
              "<tr><td>precision</td>\n",
              "<td>0.9251228</td>\n",
              "<td>0.0227588</td>\n",
              "<td>0.9320388</td>\n",
              "<td>0.9569536</td>\n",
              "<td>0.9323843</td>\n",
              "<td>0.8899371</td>\n",
              "<td>0.9161291</td>\n",
              "<td>0.8970588</td>\n",
              "<td>0.9570957</td>\n",
              "<td>0.9067797</td>\n",
              "<td>0.9326923</td>\n",
              "<td>0.9301587</td></tr>\n",
              "<tr><td>r2</td>\n",
              "<td>0.8265975</td>\n",
              "<td>0.0179854</td>\n",
              "<td>0.8351024</td>\n",
              "<td>0.866444</td>\n",
              "<td>0.8304807</td>\n",
              "<td>0.8056693</td>\n",
              "<td>0.8154945</td>\n",
              "<td>0.8184445</td>\n",
              "<td>0.8428361</td>\n",
              "<td>0.8243719</td>\n",
              "<td>0.8137631</td>\n",
              "<td>0.8133687</td></tr>\n",
              "<tr><td>recall</td>\n",
              "<td>0.9438821</td>\n",
              "<td>0.0173548</td>\n",
              "<td>0.9411765</td>\n",
              "<td>0.9601329</td>\n",
              "<td>0.9390681</td>\n",
              "<td>0.9658703</td>\n",
              "<td>0.9372937</td>\n",
              "<td>0.9621451</td>\n",
              "<td>0.9354839</td>\n",
              "<td>0.958209</td>\n",
              "<td>0.9122257</td>\n",
              "<td>0.9272152</td></tr>\n",
              "<tr><td>rmse</td>\n",
              "<td>0.2022149</td>\n",
              "<td>0.0112496</td>\n",
              "<td>0.1973519</td>\n",
              "<td>0.1770416</td>\n",
              "<td>0.1962188</td>\n",
              "<td>0.2123824</td>\n",
              "<td>0.2083599</td>\n",
              "<td>0.2084097</td>\n",
              "<td>0.1931369</td>\n",
              "<td>0.2067550</td>\n",
              "<td>0.2113055</td>\n",
              "<td>0.2111877</td></tr>\n",
              "<tr><td>specificity</td>\n",
              "<td>0.9514546</td>\n",
              "<td>0.0173690</td>\n",
              "<td>0.9574899</td>\n",
              "<td>0.9739479</td>\n",
              "<td>0.9635317</td>\n",
              "<td>0.9309665</td>\n",
              "<td>0.9476861</td>\n",
              "<td>0.9275362</td>\n",
              "<td>0.9734694</td>\n",
              "<td>0.9290323</td>\n",
              "<td>0.9563410</td>\n",
              "<td>0.9545454</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-13.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-13 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-13 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-13 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-13 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-13 .h2o-table th,\n",
              "#h2o-table-13 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-13 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-13\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Scoring History: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>timestamp</th>\n",
              "<th>duration</th>\n",
              "<th>number_of_trees</th>\n",
              "<th>training_rmse</th>\n",
              "<th>training_logloss</th>\n",
              "<th>training_auc</th>\n",
              "<th>training_pr_auc</th>\n",
              "<th>training_lift</th>\n",
              "<th>training_classification_error</th>\n",
              "<th>validation_rmse</th>\n",
              "<th>validation_logloss</th>\n",
              "<th>validation_auc</th>\n",
              "<th>validation_pr_auc</th>\n",
              "<th>validation_lift</th>\n",
              "<th>validation_classification_error</th></tr></thead>\n",
              "    <tbody><tr><td></td>\n",
              "<td>2023-07-05 16:27:57</td>\n",
              "<td>26.211 sec</td>\n",
              "<td>0.0</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-07-05 16:27:58</td>\n",
              "<td>26.700 sec</td>\n",
              "<td>5.0</td>\n",
              "<td>0.2767544</td>\n",
              "<td>1.9967730</td>\n",
              "<td>0.9308393</td>\n",
              "<td>0.8925009</td>\n",
              "<td>2.4093223</td>\n",
              "<td>0.0920443</td>\n",
              "<td>0.2190890</td>\n",
              "<td>0.3669400</td>\n",
              "<td>0.9789388</td>\n",
              "<td>0.9678027</td>\n",
              "<td>2.6238260</td>\n",
              "<td>0.063</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-07-05 16:27:58</td>\n",
              "<td>26.927 sec</td>\n",
              "<td>10.0</td>\n",
              "<td>0.2445273</td>\n",
              "<td>0.9663935</td>\n",
              "<td>0.9605493</td>\n",
              "<td>0.9364353</td>\n",
              "<td>2.4996767</td>\n",
              "<td>0.0761556</td>\n",
              "<td>0.2058033</td>\n",
              "<td>0.1665588</td>\n",
              "<td>0.9875954</td>\n",
              "<td>0.9801532</td>\n",
              "<td>2.6431199</td>\n",
              "<td>0.0595</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-07-05 16:27:58</td>\n",
              "<td>27.126 sec</td>\n",
              "<td>15.0</td>\n",
              "<td>0.2261966</td>\n",
              "<td>0.5028121</td>\n",
              "<td>0.9752431</td>\n",
              "<td>0.9599033</td>\n",
              "<td>2.5495443</td>\n",
              "<td>0.0665666</td>\n",
              "<td>0.1991817</td>\n",
              "<td>0.1460567</td>\n",
              "<td>0.9896636</td>\n",
              "<td>0.9846118</td>\n",
              "<td>2.6490066</td>\n",
              "<td>0.056</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-07-05 16:27:59</td>\n",
              "<td>27.346 sec</td>\n",
              "<td>20.0</td>\n",
              "<td>0.2187206</td>\n",
              "<td>0.3612843</td>\n",
              "<td>0.9803188</td>\n",
              "<td>0.9681426</td>\n",
              "<td>2.5660418</td>\n",
              "<td>0.0632579</td>\n",
              "<td>0.1965201</td>\n",
              "<td>0.1436989</td>\n",
              "<td>0.9905513</td>\n",
              "<td>0.9860533</td>\n",
              "<td>2.6490066</td>\n",
              "<td>0.0505</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-07-05 16:27:59</td>\n",
              "<td>27.554 sec</td>\n",
              "<td>25.0</td>\n",
              "<td>0.2139304</td>\n",
              "<td>0.2746755</td>\n",
              "<td>0.9829967</td>\n",
              "<td>0.9753618</td>\n",
              "<td>2.5860606</td>\n",
              "<td>0.060625</td>\n",
              "<td>0.1958920</td>\n",
              "<td>0.1438512</td>\n",
              "<td>0.9908077</td>\n",
              "<td>0.9863770</td>\n",
              "<td>2.6490066</td>\n",
              "<td>0.0495</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-07-05 16:27:59</td>\n",
              "<td>27.803 sec</td>\n",
              "<td>30.0</td>\n",
              "<td>0.2121942</td>\n",
              "<td>0.2425199</td>\n",
              "<td>0.9842336</td>\n",
              "<td>0.9769625</td>\n",
              "<td>2.5884415</td>\n",
              "<td>0.059</td>\n",
              "<td>0.1949704</td>\n",
              "<td>0.1433966</td>\n",
              "<td>0.9909694</td>\n",
              "<td>0.9865957</td>\n",
              "<td>2.6490066</td>\n",
              "<td>0.0475</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-07-05 16:27:59</td>\n",
              "<td>28.008 sec</td>\n",
              "<td>35.0</td>\n",
              "<td>0.2096984</td>\n",
              "<td>0.2207400</td>\n",
              "<td>0.9853191</td>\n",
              "<td>0.9787134</td>\n",
              "<td>2.5910047</td>\n",
              "<td>0.057</td>\n",
              "<td>0.1947836</td>\n",
              "<td>0.1430478</td>\n",
              "<td>0.9910710</td>\n",
              "<td>0.9867606</td>\n",
              "<td>2.6490066</td>\n",
              "<td>0.0485</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-07-05 16:27:59</td>\n",
              "<td>28.225 sec</td>\n",
              "<td>40.0</td>\n",
              "<td>0.2089029</td>\n",
              "<td>0.2166056</td>\n",
              "<td>0.9855383</td>\n",
              "<td>0.9793254</td>\n",
              "<td>2.5923310</td>\n",
              "<td>0.056125</td>\n",
              "<td>0.1931846</td>\n",
              "<td>0.1417876</td>\n",
              "<td>0.9913833</td>\n",
              "<td>0.9872003</td>\n",
              "<td>2.6490066</td>\n",
              "<td>0.046</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-07-05 16:28:00</td>\n",
              "<td>28.458 sec</td>\n",
              "<td>45.0</td>\n",
              "<td>0.2079904</td>\n",
              "<td>0.2041993</td>\n",
              "<td>0.9860597</td>\n",
              "<td>0.9801217</td>\n",
              "<td>2.5937064</td>\n",
              "<td>0.056625</td>\n",
              "<td>0.1926063</td>\n",
              "<td>0.1412901</td>\n",
              "<td>0.9914631</td>\n",
              "<td>0.9872754</td>\n",
              "<td>2.6490066</td>\n",
              "<td>0.0455</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-07-05 16:28:00</td>\n",
              "<td>28.541 sec</td>\n",
              "<td>46.0</td>\n",
              "<td>0.2080096</td>\n",
              "<td>0.2042815</td>\n",
              "<td>0.9860385</td>\n",
              "<td>0.9800860</td>\n",
              "<td>2.5936825</td>\n",
              "<td>0.056625</td>\n",
              "<td>0.1921907</td>\n",
              "<td>0.1407921</td>\n",
              "<td>0.9915375</td>\n",
              "<td>0.9873978</td>\n",
              "<td>2.6490066</td>\n",
              "<td>0.047</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-14.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-14 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-14 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-14 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-14 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-14 .h2o-table th,\n",
              "#h2o-table-14 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-14 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-14\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Variable Importances: </caption>\n",
              "    <thead><tr><th>variable</th>\n",
              "<th>relative_importance</th>\n",
              "<th>scaled_importance</th>\n",
              "<th>percentage</th></tr></thead>\n",
              "    <tbody><tr><td>concave points_mean</td>\n",
              "<td>12892.1552734</td>\n",
              "<td>1.0</td>\n",
              "<td>0.1843350</td></tr>\n",
              "<tr><td>perimeter_worst</td>\n",
              "<td>12409.1396484</td>\n",
              "<td>0.9625341</td>\n",
              "<td>0.1774287</td></tr>\n",
              "<tr><td>concave points_worst</td>\n",
              "<td>6141.6552734</td>\n",
              "<td>0.4763870</td>\n",
              "<td>0.0878148</td></tr>\n",
              "<tr><td>radius_worst</td>\n",
              "<td>5617.1918945</td>\n",
              "<td>0.4357062</td>\n",
              "<td>0.0803159</td></tr>\n",
              "<tr><td>radius_se</td>\n",
              "<td>4640.3554688</td>\n",
              "<td>0.3599364</td>\n",
              "<td>0.0663489</td></tr>\n",
              "<tr><td>perimeter_mean</td>\n",
              "<td>4096.8095703</td>\n",
              "<td>0.3177754</td>\n",
              "<td>0.0585771</td></tr>\n",
              "<tr><td>area_worst</td>\n",
              "<td>3825.3610840</td>\n",
              "<td>0.2967201</td>\n",
              "<td>0.0546959</td></tr>\n",
              "<tr><td>area_se</td>\n",
              "<td>3570.8486328</td>\n",
              "<td>0.2769784</td>\n",
              "<td>0.0510568</td></tr>\n",
              "<tr><td>concavity_mean</td>\n",
              "<td>3542.3181152</td>\n",
              "<td>0.2747654</td>\n",
              "<td>0.0506489</td></tr>\n",
              "<tr><td>area_mean</td>\n",
              "<td>1562.5438232</td>\n",
              "<td>0.1212011</td>\n",
              "<td>0.0223416</td></tr>\n",
              "<tr><td>---</td>\n",
              "<td>---</td>\n",
              "<td>---</td>\n",
              "<td>---</td></tr>\n",
              "<tr><td>symmetry_worst</td>\n",
              "<td>398.6156921</td>\n",
              "<td>0.0309192</td>\n",
              "<td>0.0056995</td></tr>\n",
              "<tr><td>smoothness_mean</td>\n",
              "<td>397.4166565</td>\n",
              "<td>0.0308262</td>\n",
              "<td>0.0056824</td></tr>\n",
              "<tr><td>texture_se</td>\n",
              "<td>372.9902344</td>\n",
              "<td>0.0289316</td>\n",
              "<td>0.0053331</td></tr>\n",
              "<tr><td>symmetry_mean</td>\n",
              "<td>357.3835449</td>\n",
              "<td>0.0277210</td>\n",
              "<td>0.0051100</td></tr>\n",
              "<tr><td>smoothness_se</td>\n",
              "<td>350.0584106</td>\n",
              "<td>0.0271528</td>\n",
              "<td>0.0050052</td></tr>\n",
              "<tr><td>fractal_dimension_worst</td>\n",
              "<td>340.3181763</td>\n",
              "<td>0.0263973</td>\n",
              "<td>0.0048659</td></tr>\n",
              "<tr><td>symmetry_se</td>\n",
              "<td>333.9683533</td>\n",
              "<td>0.0259048</td>\n",
              "<td>0.0047752</td></tr>\n",
              "<tr><td>concavity_se</td>\n",
              "<td>327.7789612</td>\n",
              "<td>0.0254247</td>\n",
              "<td>0.0046867</td></tr>\n",
              "<tr><td>concave points_se</td>\n",
              "<td>309.9120178</td>\n",
              "<td>0.0240388</td>\n",
              "<td>0.0044312</td></tr>\n",
              "<tr><td>fractal_dimension_se</td>\n",
              "<td>298.4029541</td>\n",
              "<td>0.0231461</td>\n",
              "<td>0.0042666</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "<pre style='font-size: smaller; margin-bottom: 1em;'>[30 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
              "\n",
              "[tips]\n",
              "Use `model.explain()` to inspect the model.\n",
              "--\n",
              "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.model_performance(train).accuracy()"
      ],
      "metadata": {
        "id": "G_PyYFNMs97_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9957c5f7-f5f0-4c26-d1c9-e26c1d3b18a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.5434782608695652, 1.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = aml.get_best_model()\n",
        "HATr  = best_model.model_performance(train)\n",
        "HATe  = best_model.model_performance(valid)"
      ],
      "metadata": {
        "id": "jKquKjVVJBL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_h2o = pd.DataFrame(h2o.as_list(best_model.predict(valid)))['predict']\n",
        "y_test_h2o = np.array(valid1['diagnosis']).copy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-caBWGPlp8P",
        "outputId": "adce423d-51a7-480d-ddd8-50032edb6525"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drf prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SFOLD DATA AUTOML\n",
        "#strain, svalid = shdf.split_frame(ratios=[.8], seed=123)\n",
        "shdf  = newdata.copy()\n",
        "#shdf['y_test'] = shdf['y_test'].replace(0,\"B\")\n",
        "#shdf['y_test'] = shdf['y_test'].replace(1,\"M\")\n",
        "shy = \"y_test\"\n",
        "shx = list(shdf.columns)\n",
        "shx.remove(shy)\n",
        "\n",
        "shdf.iloc[:,0:6] = StandardScaler().fit_transform(shdf.iloc[:,0:6])\n",
        "#shdf.iloc[:,-1] = LabelEncoder().fit_transform(shdf.iloc[:,-1])\n",
        "strain1, svalid1 = train_test_split(shdf, test_size=0.2,random_state=123)\n",
        "strain = h2o.H2OFrame(strain1)\n",
        "svalid = h2o.H2OFrame(svalid1)\n",
        "strain[\"y_test\"] = strain[\"y_test\"].asfactor()\n",
        "svalid[\"y_test\"] = svalid[\"y_test\"].asfactor()\n",
        "\n",
        "st = time.time()\n",
        "\n",
        "saml = H2OAutoML(include_algos = ['DeepLearning'], max_models = 10, seed = 123, verbosity=\"info\", nfolds=10, sort_metric='accuracy')\n",
        "\n",
        "saml.train(x = shx, y = shy, training_frame = strain, validation_frame = svalid)\n",
        "sautoend = time.time() - st\n",
        "sbest_model = saml.get_best_model()\n",
        "sHATr  = sbest_model.model_performance(strain)\n",
        "sHATe  = sbest_model.model_performance(svalid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMDqylVK7svS",
        "outputId": "2d425de3-4982-4160-c18d-54e3a46d3bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
            "AutoML progress: |\n",
            "16:31:21.955: Project: AutoML_2_20230705_163121\n",
            "16:31:21.955: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n",
            "16:31:21.956: Setting stopping tolerance adaptively based on the training frame: 0.011180339887498949\n",
            "16:31:21.956: Build control seed: 123\n",
            "16:31:21.956: training frame: Frame key: AutoML_2_20230705_163121_training_py_11_sid_ba5a    cols: 7    rows: 8000  chunks: 1    size: 98174  checksum: -2050260270905888720\n",
            "16:31:21.957: validation frame: Frame key: py_12_sid_ba5a    cols: 7    rows: 2000  chunks: 1    size: 25424  checksum: -8588193482595113200\n",
            "16:31:21.957: leaderboard frame: NULL\n",
            "16:31:21.957: blending frame: NULL\n",
            "16:31:21.957: response column: y_test\n",
            "16:31:21.957: fold column: null\n",
            "16:31:21.957: weights column: null\n",
            "16:31:21.957: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (7g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (7g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (6g, 60w)]}, {StackedEnsemble : [monotonic (9g, 10w), best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
            "16:31:21.960: Disabling Algo: GBM as requested by the user.\n",
            "16:31:21.960: Disabling Algo: XGBoost as requested by the user.\n",
            "16:31:21.960: Disabling Algo: GLM as requested by the user.\n",
            "16:31:21.960: Disabling Algo: DRF as requested by the user.\n",
            "16:31:21.960: Disabling Algo: StackedEnsemble as requested by the user.\n",
            "16:31:21.960: AutoML job created: 2023.07.05 16:31:21.955\n",
            "16:31:21.967: AutoML build started: 2023.07.05 16:31:21.967\n",
            "16:31:21.977: AutoML: starting DeepLearning_1_AutoML_2_20230705_163121 model training\n",
            "\n",
            "███\n",
            "16:31:34.323: New leader: DeepLearning_1_AutoML_2_20230705_163121, accuracy: 0.947375\n",
            "16:31:34.333: AutoML: starting DeepLearning_grid_1_AutoML_2_20230705_163121 hyperparameter search\n",
            "\n",
            "█████████████████████████████████████████████████████████\n",
            "16:48:02.49: AutoML: starting DeepLearning_grid_2_AutoML_2_20230705_163121 hyperparameter search\n",
            "\n",
            "██\n",
            "17:16:13.992: AutoML: starting DeepLearning_grid_3_AutoML_2_20230705_163121 hyperparameter search\n",
            "\n",
            "█| (done) 100%\n",
            "\n",
            "17:54:17.394: Skipping StackedEnsemble 'monotonic' due to the exclude_algos option or it is already trained.\n",
            "17:54:17.395: Skipping StackedEnsemble 'best_of_family_xglm' due to the exclude_algos option or it is already trained.\n",
            "17:54:17.395: Skipping StackedEnsemble 'all_xglm' due to the exclude_algos option or it is already trained.\n",
            "17:54:17.395: Actual modeling steps: [{DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}]\n",
            "17:54:17.395: AutoML build stopped: 2023.07.05 17:54:17.395\n",
            "17:54:17.395: AutoML build done: built 10 models\n",
            "17:54:17.395: AutoML duration:  1:22:55.428\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_sh2o = pd.DataFrame(h2o.as_list(sbest_model.predict(svalid)))['predict']\n",
        "y_test_sh2o = np.array(svalid1['y_test']).copy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivMaaDNNmYY2",
        "outputId": "ea9b1c9a-9156-4cd2-dd45-adcc4975ae69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.bar(acc.index, acc['train'], color ='black',width = 0.4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "nJrcI3Gn8we2",
        "outputId": "60b56713-b8e6-4c14-ab00-a610714d1323"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 7 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = [ANNmodel, model, knn, lr, rf, svm, xgb, best_model]\n",
        "\n",
        "label = [\"ArtificialNeuralNetwork\", 'DeepNeuralNetwork',\n",
        "         'KNearestNeighborsClassifier', 'LogisticRegression',\n",
        "         'RandomForestClassifier', 'SupportVectorClassifier',\n",
        "         'XGBoost', type(best_model).__name__, type(sbest_model).__name__ ]\n",
        "\n",
        "acc = pd.DataFrame(\n",
        "    {\n",
        "    \"ANN\":[ATr,ATe],\n",
        "    \"DNN\":[DTr,DTe],\n",
        "    \"KNN\":[KTr,KTe],\n",
        "    \"LR\" :[LTr,LTe],\n",
        "    \"RF\" :[RTr,RTe],\n",
        "    \"SVM\":[STr,STe],\n",
        "    \"XGB\":[XTr,XTe],\n",
        "    \"H_OD\":[HATr.accuracy()[0][1],HATe.accuracy()[0][1]],\n",
        "    \"H_SOD\":[sHATr.accuracy()[0][1],sHATe.accuracy()[0][1]]\n",
        "    })\n",
        "acc.index = [\"train\", \"test\"]\n",
        "acc = acc.T\n",
        "acc['Model'] = label\n",
        "\n",
        "acc = acc[['Model', 'train', 'test']]\n",
        "acc['avg'] = round((acc['train'] + acc['test'])/2, 6)\n",
        "acc[acc[\"avg\"] == acc[\"avg\"].max()]\n",
        "acc['BestModel'] = 0\n",
        "for i in range(len(acc)):\n",
        "  if acc['avg'][i] >= 90 and acc['avg'][i] < acc['avg'].max():\n",
        "    acc.iloc[i,-1] = \"good\"\n",
        "  elif acc['avg'][i] == acc['avg'].max():\n",
        "    acc.iloc[i,-1] = \"best\"\n",
        "  else:\n",
        "    acc.iloc[i,-1] = \"not good\"\n",
        "\n",
        "acc[\"Precision\"] = np.zeros(len(acc))\n",
        "acc[\"Recall\"]    = np.zeros(len(acc))\n",
        "acc[\"F1_Score\"]  = np.zeros(len(acc))\n",
        "\n"
      ],
      "metadata": {
        "id": "Ba6kRO-eI60S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_ANNn = []\n",
        "y_pred_DNNn = []\n",
        "for i in range(len(y_pred_ANN)):\n",
        "  y_pred_ANNn.append(y_pred_ANN[i][0])\n",
        "  y_pred_DNNn.append(y_pred_DNN[i][0])"
      ],
      "metadata": {
        "id": "S7pf8G6ao4oF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = [np.array(y_pred_ANNn), np.array(y_pred_DNNn), y_pred_knn,\n",
        "        y_pred_lr, y_pred_rf,\n",
        "        y_pred_svm, y_pred_xgb, y_pred_h2o, y_pred_sh2o]\n",
        "\n",
        "tes  = [y_test_indi_ML, np.array(Dy_test), y_test_indi_ML, y_test_indi_ML,\n",
        "        y_test_indi_ML, y_test_indi_ML, y_test_indi_ML,\n",
        "        y_test_h2o.copy(), y_test_sh2o.copy()]"
      ],
      "metadata": {
        "id": "D2n2VnW1jKp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(y_pred_ANNn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1F7SoCqUI9px",
        "outputId": "42b43537-7362-4b66-a107-5622db7cb14e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 0, 0, 0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(pred)):\n",
        "  p,r,f,_ = precision_recall_fscore_support(tes[i], pred[i],average='macro')\n",
        "  acc.iloc[i,5]= p\n",
        "  acc.iloc[i,6]= r\n",
        "  acc.iloc[i,7]= f\n",
        "  p = 0\n",
        "  r = 0\n",
        "  f = 0\n",
        "  print(i)\n",
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "2DlSQ29moN9T",
        "outputId": "61139a0d-aa5d-40e0-816c-069add4b0696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             Model     train    test       avg BestModel  \\\n",
              "ANN        ArtificialNeuralNetwork  0.958500  0.9455  0.952000  not good   \n",
              "DNN              DeepNeuralNetwork  0.952750  0.9465  0.949625  not good   \n",
              "KNN    KNearestNeighborsClassifier  0.954875  0.9445  0.949688  not good   \n",
              "LR              LogisticRegression  0.950000  0.9500  0.950000  not good   \n",
              "RF          RandomForestClassifier  0.943875  0.9505  0.947188  not good   \n",
              "SVM        SupportVectorClassifier  0.950500  0.9500  0.950250  not good   \n",
              "XGB                        XGBoost  0.956875  0.9410  0.948938  not good   \n",
              "H_OD      H2ORandomForestEstimator  1.000000  0.9530  0.976500      best   \n",
              "H_SOD     H2ODeepLearningEstimator  0.949875  0.9515  0.950688  not good   \n",
              "\n",
              "       Precision    Recall  F1_Score  \n",
              "ANN     0.943874  0.939804  0.941757  \n",
              "DNN     0.945681  0.940086  0.942732  \n",
              "KNN     0.945655  0.935873  0.940325  \n",
              "LR      0.946807  0.946807  0.946807  \n",
              "RF      0.949487  0.944863  0.947072  \n",
              "SVM     0.947226  0.946286  0.946751  \n",
              "XGB     0.938046  0.936190  0.937100  \n",
              "H_OD    0.947959  0.952866  0.950277  \n",
              "H_SOD   0.946970  0.950358  0.948601  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-90b49597-757a-4690-898b-b8b821866d72\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "      <th>avg</th>\n",
              "      <th>BestModel</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ANN</th>\n",
              "      <td>ArtificialNeuralNetwork</td>\n",
              "      <td>0.958500</td>\n",
              "      <td>0.9455</td>\n",
              "      <td>0.952000</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.943874</td>\n",
              "      <td>0.939804</td>\n",
              "      <td>0.941757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DNN</th>\n",
              "      <td>DeepNeuralNetwork</td>\n",
              "      <td>0.952750</td>\n",
              "      <td>0.9465</td>\n",
              "      <td>0.949625</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.945681</td>\n",
              "      <td>0.940086</td>\n",
              "      <td>0.942732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>KNearestNeighborsClassifier</td>\n",
              "      <td>0.954875</td>\n",
              "      <td>0.9445</td>\n",
              "      <td>0.949688</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.945655</td>\n",
              "      <td>0.935873</td>\n",
              "      <td>0.940325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LR</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.9500</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.946807</td>\n",
              "      <td>0.946807</td>\n",
              "      <td>0.946807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.943875</td>\n",
              "      <td>0.9505</td>\n",
              "      <td>0.947188</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.949487</td>\n",
              "      <td>0.944863</td>\n",
              "      <td>0.947072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>SupportVectorClassifier</td>\n",
              "      <td>0.950500</td>\n",
              "      <td>0.9500</td>\n",
              "      <td>0.950250</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.947226</td>\n",
              "      <td>0.946286</td>\n",
              "      <td>0.946751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGB</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.956875</td>\n",
              "      <td>0.9410</td>\n",
              "      <td>0.948938</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.938046</td>\n",
              "      <td>0.936190</td>\n",
              "      <td>0.937100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H_OD</th>\n",
              "      <td>H2ORandomForestEstimator</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.9530</td>\n",
              "      <td>0.976500</td>\n",
              "      <td>best</td>\n",
              "      <td>0.947959</td>\n",
              "      <td>0.952866</td>\n",
              "      <td>0.950277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H_SOD</th>\n",
              "      <td>H2ODeepLearningEstimator</td>\n",
              "      <td>0.949875</td>\n",
              "      <td>0.9515</td>\n",
              "      <td>0.950688</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.946970</td>\n",
              "      <td>0.950358</td>\n",
              "      <td>0.948601</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90b49597-757a-4690-898b-b8b821866d72')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-90b49597-757a-4690-898b-b8b821866d72 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-90b49597-757a-4690-898b-b8b821866d72');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.bar(acc.index, acc['train'], color ='black',width = 0.4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "ru4oH6-YzGPw",
        "outputId": "6d0b4ce6-a4e9-4d75-aaf6-fb2ff6a86d7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 9 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve"
      ],
      "metadata": {
        "id": "Qma6hWrmDBvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = [ANNmodel, model, knn, lr, rf, svm, xgb, best_model]"
      ],
      "metadata": {
        "id": "03rwpiYpoAGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(df['diagnosis']).copy()\n",
        "X = df.drop(columns=['diagnosis']).copy()\n",
        "X = StandardScaler().fit_transform(X).copy()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=123)\n",
        "y_test_indi_ML = y_test.copy()"
      ],
      "metadata": {
        "id": "x5wrzn-qPaXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "C80ESe__xB5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(1)\n",
        "plt.rcParams[\"figure.figsize\"] = [10, 5]\n",
        "\n",
        "y_pred = ANNmodel.predict(X_test).ravel()\n",
        "y_test = y_test_indi_ML\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[0]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = model.predict(DX_test).ravel()\n",
        "y_test = Dy_test.copy()\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[1]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = knn.predict_proba(X_test)[:, 1]\n",
        "y_test = y_test_indi_ML\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[2]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = lr.predict_proba(X_test)[:, 1]\n",
        "y_test = y_test_indi_ML\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[3]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = rf.predict_proba(X_test)[:, 1]\n",
        "y_test = y_test_indi_ML\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[4]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = svm.predict_proba(X_test)[:, 1]\n",
        "y_test = y_test_indi_ML\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[5]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = xgb.predict_proba(X_test)[:, 1]\n",
        "y_test = y_test_indi_ML\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[6]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = pd.DataFrame(h2o.as_list(best_model.predict(valid)))\n",
        "y_test = h2o.as_list(valid['diagnosis'])\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred[\"p1\"])\n",
        "auc = metrics.roc_auc_score(y_test, y_pred[\"p1\"])\n",
        "plt.plot(fpr, tpr,label=type(best_model).__name__ + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = pd.DataFrame(h2o.as_list(sbest_model.predict(svalid)))\n",
        "y_test = h2o.as_list(svalid['y_test'])\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred[\"p1\"])\n",
        "auc = metrics.roc_auc_score(y_test, y_pred[\"p1\"])\n",
        "plt.plot(fpr, tpr,label=type(sbest_model).__name__ + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('AUC ROC curve')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "4Bi4CMUJm6yH",
        "outputId": "10ec8173-ab8c-4613-8d09-d3847bf99a3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 2ms/step\n",
            "63/63 [==============================] - 0s 2ms/step\n",
            "drf prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
            "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tm = [aend,dend,kend,lend,rend,send,xend,autoend,sautoend]"
      ],
      "metadata": {
        "id": "6vUubKKMxLIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc['time'] = 0#tm\n",
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "_1wKoAe9wIPn",
        "outputId": "9eed7b10-d881-4f8b-a8ab-fc7bc4719a88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             Model     train    test       avg BestModel  \\\n",
              "ANN        ArtificialNeuralNetwork  0.958500  0.9455  0.952000  not good   \n",
              "DNN              DeepNeuralNetwork  0.952750  0.9465  0.949625  not good   \n",
              "KNN    KNearestNeighborsClassifier  0.954875  0.9445  0.949688  not good   \n",
              "LR              LogisticRegression  0.950000  0.9500  0.950000  not good   \n",
              "RF          RandomForestClassifier  0.943875  0.9505  0.947188  not good   \n",
              "SVM        SupportVectorClassifier  0.950500  0.9500  0.950250  not good   \n",
              "XGB                        XGBoost  0.956875  0.9410  0.948938  not good   \n",
              "H_OD      H2ORandomForestEstimator  1.000000  0.9530  0.976500      best   \n",
              "H_SOD     H2ODeepLearningEstimator  0.949875  0.9515  0.950688  not good   \n",
              "\n",
              "       Precision    Recall  F1_Score  time  \n",
              "ANN     0.943874  0.939804  0.941757     0  \n",
              "DNN     0.945681  0.940086  0.942732     0  \n",
              "KNN     0.945655  0.935873  0.940325     0  \n",
              "LR      0.946807  0.946807  0.946807     0  \n",
              "RF      0.949487  0.944863  0.947072     0  \n",
              "SVM     0.947226  0.946286  0.946751     0  \n",
              "XGB     0.938046  0.936190  0.937100     0  \n",
              "H_OD    0.947959  0.952866  0.950277     0  \n",
              "H_SOD   0.946970  0.950358  0.948601     0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-014b2653-de62-438c-8c5c-630eee2d7764\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "      <th>avg</th>\n",
              "      <th>BestModel</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1_Score</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ANN</th>\n",
              "      <td>ArtificialNeuralNetwork</td>\n",
              "      <td>0.958500</td>\n",
              "      <td>0.9455</td>\n",
              "      <td>0.952000</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.943874</td>\n",
              "      <td>0.939804</td>\n",
              "      <td>0.941757</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DNN</th>\n",
              "      <td>DeepNeuralNetwork</td>\n",
              "      <td>0.952750</td>\n",
              "      <td>0.9465</td>\n",
              "      <td>0.949625</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.945681</td>\n",
              "      <td>0.940086</td>\n",
              "      <td>0.942732</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>KNearestNeighborsClassifier</td>\n",
              "      <td>0.954875</td>\n",
              "      <td>0.9445</td>\n",
              "      <td>0.949688</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.945655</td>\n",
              "      <td>0.935873</td>\n",
              "      <td>0.940325</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LR</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.9500</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.946807</td>\n",
              "      <td>0.946807</td>\n",
              "      <td>0.946807</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.943875</td>\n",
              "      <td>0.9505</td>\n",
              "      <td>0.947188</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.949487</td>\n",
              "      <td>0.944863</td>\n",
              "      <td>0.947072</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>SupportVectorClassifier</td>\n",
              "      <td>0.950500</td>\n",
              "      <td>0.9500</td>\n",
              "      <td>0.950250</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.947226</td>\n",
              "      <td>0.946286</td>\n",
              "      <td>0.946751</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGB</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.956875</td>\n",
              "      <td>0.9410</td>\n",
              "      <td>0.948938</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.938046</td>\n",
              "      <td>0.936190</td>\n",
              "      <td>0.937100</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H_OD</th>\n",
              "      <td>H2ORandomForestEstimator</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.9530</td>\n",
              "      <td>0.976500</td>\n",
              "      <td>best</td>\n",
              "      <td>0.947959</td>\n",
              "      <td>0.952866</td>\n",
              "      <td>0.950277</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H_SOD</th>\n",
              "      <td>H2ODeepLearningEstimator</td>\n",
              "      <td>0.949875</td>\n",
              "      <td>0.9515</td>\n",
              "      <td>0.950688</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.946970</td>\n",
              "      <td>0.950358</td>\n",
              "      <td>0.948601</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-014b2653-de62-438c-8c5c-630eee2d7764')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-014b2653-de62-438c-8c5c-630eee2d7764 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-014b2653-de62-438c-8c5c-630eee2d7764');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc['time'] = tm"
      ],
      "metadata": {
        "id": "P-K86caJxhvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "H9pBjIrPQ3nu",
        "outputId": "6f21ace4-feb4-479c-eb54-c57b19136875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             Model     train    test       avg BestModel  \\\n",
              "ANN        ArtificialNeuralNetwork  0.958500  0.9455  0.952000  not good   \n",
              "DNN              DeepNeuralNetwork  0.952750  0.9465  0.949625  not good   \n",
              "KNN    KNearestNeighborsClassifier  0.954875  0.9445  0.949688  not good   \n",
              "LR              LogisticRegression  0.950000  0.9500  0.950000  not good   \n",
              "RF          RandomForestClassifier  0.943875  0.9505  0.947188  not good   \n",
              "SVM        SupportVectorClassifier  0.950500  0.9500  0.950250  not good   \n",
              "XGB                        XGBoost  0.956875  0.9410  0.948938  not good   \n",
              "H_OD      H2ORandomForestEstimator  1.000000  0.9530  0.976500      best   \n",
              "H_SOD     H2ODeepLearningEstimator  0.949875  0.9515  0.950688  not good   \n",
              "\n",
              "       Precision    Recall  F1_Score         time  \n",
              "ANN     0.943874  0.939804  0.941757     5.272370  \n",
              "DNN     0.945681  0.940086  0.942732   180.911107  \n",
              "KNN     0.945655  0.935873  0.940325     0.003450  \n",
              "LR      0.946807  0.946807  0.946807     0.048313  \n",
              "RF      0.949487  0.944863  0.947072     1.165447  \n",
              "SVM     0.947226  0.946286  0.946751     6.861105  \n",
              "XGB     0.938046  0.936190  0.937100    14.681447  \n",
              "H_OD    0.947959  0.952866  0.950277   357.466846  \n",
              "H_SOD   0.946970  0.950358  0.948601  4977.571883  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-13f19c99-10ba-40c2-ae55-1f0559a80650\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "      <th>avg</th>\n",
              "      <th>BestModel</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1_Score</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ANN</th>\n",
              "      <td>ArtificialNeuralNetwork</td>\n",
              "      <td>0.958500</td>\n",
              "      <td>0.9455</td>\n",
              "      <td>0.952000</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.943874</td>\n",
              "      <td>0.939804</td>\n",
              "      <td>0.941757</td>\n",
              "      <td>5.272370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DNN</th>\n",
              "      <td>DeepNeuralNetwork</td>\n",
              "      <td>0.952750</td>\n",
              "      <td>0.9465</td>\n",
              "      <td>0.949625</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.945681</td>\n",
              "      <td>0.940086</td>\n",
              "      <td>0.942732</td>\n",
              "      <td>180.911107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>KNearestNeighborsClassifier</td>\n",
              "      <td>0.954875</td>\n",
              "      <td>0.9445</td>\n",
              "      <td>0.949688</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.945655</td>\n",
              "      <td>0.935873</td>\n",
              "      <td>0.940325</td>\n",
              "      <td>0.003450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LR</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.9500</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.946807</td>\n",
              "      <td>0.946807</td>\n",
              "      <td>0.946807</td>\n",
              "      <td>0.048313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.943875</td>\n",
              "      <td>0.9505</td>\n",
              "      <td>0.947188</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.949487</td>\n",
              "      <td>0.944863</td>\n",
              "      <td>0.947072</td>\n",
              "      <td>1.165447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>SupportVectorClassifier</td>\n",
              "      <td>0.950500</td>\n",
              "      <td>0.9500</td>\n",
              "      <td>0.950250</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.947226</td>\n",
              "      <td>0.946286</td>\n",
              "      <td>0.946751</td>\n",
              "      <td>6.861105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGB</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.956875</td>\n",
              "      <td>0.9410</td>\n",
              "      <td>0.948938</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.938046</td>\n",
              "      <td>0.936190</td>\n",
              "      <td>0.937100</td>\n",
              "      <td>14.681447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H_OD</th>\n",
              "      <td>H2ORandomForestEstimator</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.9530</td>\n",
              "      <td>0.976500</td>\n",
              "      <td>best</td>\n",
              "      <td>0.947959</td>\n",
              "      <td>0.952866</td>\n",
              "      <td>0.950277</td>\n",
              "      <td>357.466846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H_SOD</th>\n",
              "      <td>H2ODeepLearningEstimator</td>\n",
              "      <td>0.949875</td>\n",
              "      <td>0.9515</td>\n",
              "      <td>0.950688</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.946970</td>\n",
              "      <td>0.950358</td>\n",
              "      <td>0.948601</td>\n",
              "      <td>4977.571883</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13f19c99-10ba-40c2-ae55-1f0559a80650')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-13f19c99-10ba-40c2-ae55-1f0559a80650 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-13f19c99-10ba-40c2-ae55-1f0559a80650');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    }
  ]
}