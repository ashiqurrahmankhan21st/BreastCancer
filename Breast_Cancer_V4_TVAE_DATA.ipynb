{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashiqurrahmankhan21st/BreastCancer/blob/main/Breast_Cancer_V4_TVAE_DATA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUMYU_d6_J-X"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "#import keras_metrics\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from sklearn.inspection import PartialDependenceDisplay\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TVAE data\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/ashiqurrahmankhan21st/BreastCancer/main/tvae_SDV_BreastCancer.csv\")\n",
        "del df['Unnamed: 0']\n",
        "df"
      ],
      "metadata": {
        "id": "Ntdqq4T_aGXN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "outputId": "9104c827-26c0-49a6-fe25-ee6b2fcf3207"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     diagnosis  radius_mean  texture_mean  perimeter_mean   area_mean  \\\n",
              "0            B     9.866787     14.637137       63.409325  283.713730   \n",
              "1            B    12.885053     21.506004       79.229176  336.364127   \n",
              "2            B    11.165762     15.516346       84.076405  356.413321   \n",
              "3            B    12.271667     19.807824       68.534578  428.143496   \n",
              "4            B     7.454015     12.357933       51.167853  202.087605   \n",
              "...        ...          ...           ...             ...         ...   \n",
              "9995         B    11.653797     19.591590       66.871153  347.640448   \n",
              "9996         B    12.779385     13.799951       71.689730  568.975097   \n",
              "9997         B    12.144682     17.091324       72.648862  363.638743   \n",
              "9998         B    11.440653     14.876270       83.906545  447.719512   \n",
              "9999         B    12.327089     21.793296       90.006683  585.450805   \n",
              "\n",
              "      smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0            0.084223          0.046159        0.016544             0.020951   \n",
              "1            0.081238          0.061742        0.030052             0.025329   \n",
              "2            0.112075          0.064143        0.012986             0.000000   \n",
              "3            0.088438          0.031222        0.028840             0.018988   \n",
              "4            0.088588          0.052791        0.051511             0.013281   \n",
              "...               ...               ...             ...                  ...   \n",
              "9995         0.114469          0.153040        0.098849             0.020412   \n",
              "9996         0.102959          0.126075        0.107483             0.026956   \n",
              "9997         0.115953          0.122028        0.112376             0.031809   \n",
              "9998         0.101748          0.135110        0.069284             0.093306   \n",
              "9999         0.097919          0.170219        0.093106             0.028075   \n",
              "\n",
              "      symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
              "0          0.170999  ...     13.174990      18.064878        79.308249   \n",
              "1          0.169469  ...     15.764673      27.487070        81.358017   \n",
              "2          0.159183  ...     12.177383      34.227039        87.682893   \n",
              "3          0.144926  ...     14.332578      18.433072        68.255508   \n",
              "4          0.174599  ...     10.671485      18.960872        60.949763   \n",
              "...             ...  ...           ...            ...              ...   \n",
              "9995       0.171224  ...     13.364227      31.212963        75.105110   \n",
              "9996       0.176738  ...     14.636441      25.387452        81.755763   \n",
              "9997       0.145315  ...     12.978866      21.222782        88.692189   \n",
              "9998       0.198483  ...     14.864455      19.688309       104.210820   \n",
              "9999       0.185964  ...     12.195219      29.697275        77.443915   \n",
              "\n",
              "      area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
              "0     368.916148          0.152767           0.166851         0.158809   \n",
              "1     726.979378          0.112737           0.137944         0.120542   \n",
              "2     644.261133          0.125459           0.256056         0.112901   \n",
              "3     505.092414          0.092259           0.116755         0.059426   \n",
              "4     340.397278          0.127406           0.107711         0.110993   \n",
              "...          ...               ...                ...              ...   \n",
              "9995  309.445867          0.150710           0.268134         0.244718   \n",
              "9996  675.860482          0.160312           0.562150         0.291571   \n",
              "9997  534.210501          0.185600           0.492610         0.452870   \n",
              "9998  711.314226          0.158937           0.555026         0.211123   \n",
              "9999  449.710078          0.147902           0.498236         0.346742   \n",
              "\n",
              "      concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
              "0                 0.035439        0.288579                 0.073689  \n",
              "1                 0.071356        0.271750                 0.068861  \n",
              "2                 0.045699        0.301039                 0.055040  \n",
              "3                 0.044334        0.235016                 0.079151  \n",
              "4                 0.000000        0.299682                 0.069818  \n",
              "...                    ...             ...                      ...  \n",
              "9995              0.056089        0.251965                 0.088369  \n",
              "9996              0.173512        0.298970                 0.102903  \n",
              "9997              0.090011        0.243860                 0.143752  \n",
              "9998              0.186335        0.263381                 0.072269  \n",
              "9999              0.067868        0.252371                 0.084630  \n",
              "\n",
              "[10000 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-778e5c8a-d6bd-4adb-ab8d-8898e3f5d72e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B</td>\n",
              "      <td>9.866787</td>\n",
              "      <td>14.637137</td>\n",
              "      <td>63.409325</td>\n",
              "      <td>283.713730</td>\n",
              "      <td>0.084223</td>\n",
              "      <td>0.046159</td>\n",
              "      <td>0.016544</td>\n",
              "      <td>0.020951</td>\n",
              "      <td>0.170999</td>\n",
              "      <td>...</td>\n",
              "      <td>13.174990</td>\n",
              "      <td>18.064878</td>\n",
              "      <td>79.308249</td>\n",
              "      <td>368.916148</td>\n",
              "      <td>0.152767</td>\n",
              "      <td>0.166851</td>\n",
              "      <td>0.158809</td>\n",
              "      <td>0.035439</td>\n",
              "      <td>0.288579</td>\n",
              "      <td>0.073689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B</td>\n",
              "      <td>12.885053</td>\n",
              "      <td>21.506004</td>\n",
              "      <td>79.229176</td>\n",
              "      <td>336.364127</td>\n",
              "      <td>0.081238</td>\n",
              "      <td>0.061742</td>\n",
              "      <td>0.030052</td>\n",
              "      <td>0.025329</td>\n",
              "      <td>0.169469</td>\n",
              "      <td>...</td>\n",
              "      <td>15.764673</td>\n",
              "      <td>27.487070</td>\n",
              "      <td>81.358017</td>\n",
              "      <td>726.979378</td>\n",
              "      <td>0.112737</td>\n",
              "      <td>0.137944</td>\n",
              "      <td>0.120542</td>\n",
              "      <td>0.071356</td>\n",
              "      <td>0.271750</td>\n",
              "      <td>0.068861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B</td>\n",
              "      <td>11.165762</td>\n",
              "      <td>15.516346</td>\n",
              "      <td>84.076405</td>\n",
              "      <td>356.413321</td>\n",
              "      <td>0.112075</td>\n",
              "      <td>0.064143</td>\n",
              "      <td>0.012986</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.159183</td>\n",
              "      <td>...</td>\n",
              "      <td>12.177383</td>\n",
              "      <td>34.227039</td>\n",
              "      <td>87.682893</td>\n",
              "      <td>644.261133</td>\n",
              "      <td>0.125459</td>\n",
              "      <td>0.256056</td>\n",
              "      <td>0.112901</td>\n",
              "      <td>0.045699</td>\n",
              "      <td>0.301039</td>\n",
              "      <td>0.055040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B</td>\n",
              "      <td>12.271667</td>\n",
              "      <td>19.807824</td>\n",
              "      <td>68.534578</td>\n",
              "      <td>428.143496</td>\n",
              "      <td>0.088438</td>\n",
              "      <td>0.031222</td>\n",
              "      <td>0.028840</td>\n",
              "      <td>0.018988</td>\n",
              "      <td>0.144926</td>\n",
              "      <td>...</td>\n",
              "      <td>14.332578</td>\n",
              "      <td>18.433072</td>\n",
              "      <td>68.255508</td>\n",
              "      <td>505.092414</td>\n",
              "      <td>0.092259</td>\n",
              "      <td>0.116755</td>\n",
              "      <td>0.059426</td>\n",
              "      <td>0.044334</td>\n",
              "      <td>0.235016</td>\n",
              "      <td>0.079151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B</td>\n",
              "      <td>7.454015</td>\n",
              "      <td>12.357933</td>\n",
              "      <td>51.167853</td>\n",
              "      <td>202.087605</td>\n",
              "      <td>0.088588</td>\n",
              "      <td>0.052791</td>\n",
              "      <td>0.051511</td>\n",
              "      <td>0.013281</td>\n",
              "      <td>0.174599</td>\n",
              "      <td>...</td>\n",
              "      <td>10.671485</td>\n",
              "      <td>18.960872</td>\n",
              "      <td>60.949763</td>\n",
              "      <td>340.397278</td>\n",
              "      <td>0.127406</td>\n",
              "      <td>0.107711</td>\n",
              "      <td>0.110993</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.299682</td>\n",
              "      <td>0.069818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>B</td>\n",
              "      <td>11.653797</td>\n",
              "      <td>19.591590</td>\n",
              "      <td>66.871153</td>\n",
              "      <td>347.640448</td>\n",
              "      <td>0.114469</td>\n",
              "      <td>0.153040</td>\n",
              "      <td>0.098849</td>\n",
              "      <td>0.020412</td>\n",
              "      <td>0.171224</td>\n",
              "      <td>...</td>\n",
              "      <td>13.364227</td>\n",
              "      <td>31.212963</td>\n",
              "      <td>75.105110</td>\n",
              "      <td>309.445867</td>\n",
              "      <td>0.150710</td>\n",
              "      <td>0.268134</td>\n",
              "      <td>0.244718</td>\n",
              "      <td>0.056089</td>\n",
              "      <td>0.251965</td>\n",
              "      <td>0.088369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>B</td>\n",
              "      <td>12.779385</td>\n",
              "      <td>13.799951</td>\n",
              "      <td>71.689730</td>\n",
              "      <td>568.975097</td>\n",
              "      <td>0.102959</td>\n",
              "      <td>0.126075</td>\n",
              "      <td>0.107483</td>\n",
              "      <td>0.026956</td>\n",
              "      <td>0.176738</td>\n",
              "      <td>...</td>\n",
              "      <td>14.636441</td>\n",
              "      <td>25.387452</td>\n",
              "      <td>81.755763</td>\n",
              "      <td>675.860482</td>\n",
              "      <td>0.160312</td>\n",
              "      <td>0.562150</td>\n",
              "      <td>0.291571</td>\n",
              "      <td>0.173512</td>\n",
              "      <td>0.298970</td>\n",
              "      <td>0.102903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>B</td>\n",
              "      <td>12.144682</td>\n",
              "      <td>17.091324</td>\n",
              "      <td>72.648862</td>\n",
              "      <td>363.638743</td>\n",
              "      <td>0.115953</td>\n",
              "      <td>0.122028</td>\n",
              "      <td>0.112376</td>\n",
              "      <td>0.031809</td>\n",
              "      <td>0.145315</td>\n",
              "      <td>...</td>\n",
              "      <td>12.978866</td>\n",
              "      <td>21.222782</td>\n",
              "      <td>88.692189</td>\n",
              "      <td>534.210501</td>\n",
              "      <td>0.185600</td>\n",
              "      <td>0.492610</td>\n",
              "      <td>0.452870</td>\n",
              "      <td>0.090011</td>\n",
              "      <td>0.243860</td>\n",
              "      <td>0.143752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>B</td>\n",
              "      <td>11.440653</td>\n",
              "      <td>14.876270</td>\n",
              "      <td>83.906545</td>\n",
              "      <td>447.719512</td>\n",
              "      <td>0.101748</td>\n",
              "      <td>0.135110</td>\n",
              "      <td>0.069284</td>\n",
              "      <td>0.093306</td>\n",
              "      <td>0.198483</td>\n",
              "      <td>...</td>\n",
              "      <td>14.864455</td>\n",
              "      <td>19.688309</td>\n",
              "      <td>104.210820</td>\n",
              "      <td>711.314226</td>\n",
              "      <td>0.158937</td>\n",
              "      <td>0.555026</td>\n",
              "      <td>0.211123</td>\n",
              "      <td>0.186335</td>\n",
              "      <td>0.263381</td>\n",
              "      <td>0.072269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>B</td>\n",
              "      <td>12.327089</td>\n",
              "      <td>21.793296</td>\n",
              "      <td>90.006683</td>\n",
              "      <td>585.450805</td>\n",
              "      <td>0.097919</td>\n",
              "      <td>0.170219</td>\n",
              "      <td>0.093106</td>\n",
              "      <td>0.028075</td>\n",
              "      <td>0.185964</td>\n",
              "      <td>...</td>\n",
              "      <td>12.195219</td>\n",
              "      <td>29.697275</td>\n",
              "      <td>77.443915</td>\n",
              "      <td>449.710078</td>\n",
              "      <td>0.147902</td>\n",
              "      <td>0.498236</td>\n",
              "      <td>0.346742</td>\n",
              "      <td>0.067868</td>\n",
              "      <td>0.252371</td>\n",
              "      <td>0.084630</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-778e5c8a-d6bd-4adb-ab8d-8898e3f5d72e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-778e5c8a-d6bd-4adb-ab8d-8898e3f5d72e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-778e5c8a-d6bd-4adb-ab8d-8898e3f5d72e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(df['diagnosis']).copy()\n",
        "X = df.drop(columns=['diagnosis']).copy()\n",
        "X = StandardScaler().fit_transform(X).copy()"
      ],
      "metadata": {
        "id": "4cimS259ti6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['diagnosis'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bv9sG-P8M1Fe",
        "outputId": "ea084deb-f893-4e1c-b5b6-9efe3f014cec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "B    6166\n",
              "M    3834\n",
              "Name: diagnosis, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(df['diagnosis']).copy()\n",
        "X = df.drop(columns=['diagnosis']).copy()\n",
        "X = StandardScaler().fit_transform(X).copy()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "#X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=123)\n",
        "y_test_indi_ML = y_test.copy()\n",
        "print(\"Original data : \",df.shape)\n",
        "print(\"tarin         : \",X_train.shape)\n",
        "print(\"test          : \",X_test.shape[0])\n",
        "#print(\"validation    : \",X_val.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpyVwv13CTut",
        "outputId": "8a449af7-6d4b-47eb-e45b-7914d34d3b28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original data :  (10000, 31)\n",
            "tarin         :  (8000, 30)\n",
            "test          :  2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM\n",
        "st = time.time()\n",
        "svm = SVC(C=0.1, gamma='auto', kernel = 'rbf',probability=True)\n",
        "svm.fit(X_train, y_train)\n",
        "send = time.time() - st\n",
        "STr = svm.score(X_train, y_train)\n",
        "STe = svm.score(X_test, y_test)\n",
        "y_pred_svm = svm.predict(X_test)"
      ],
      "metadata": {
        "id": "wnRYFOkyEEZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ANN\n",
        "st = time.time()\n",
        "tf.random.set_seed(123)\n",
        "ANNmodel = Sequential()\n",
        "ANNmodel.add(Dense(30, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "ANNmodel.add(Dense(10, activation='relu'))\n",
        "ANNmodel.add(Dense(1, activation='sigmoid'))\n",
        "ANNmodel.compile(loss='BinaryCrossentropy', optimizer='adam', metrics=['accuracy']) #tf.keras.metrics.Precision(), tf.keras.metrics.Recall()\n",
        "ANNmodel.fit(X_train,y_train, batch_size = 128, epochs = 20, validation_split = 0.1)\n",
        "aend = time.time() - st\n",
        "ATr = ANNmodel.evaluate(X_train,y_train,verbose=0)[1]\n",
        "ATe = ANNmodel.evaluate(X_test,y_test,verbose=0)[1]\n",
        "y_pred_ANN = (ANNmodel.predict(X_test) > 0.5).astype(\"int32\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZX7DbN-OIyu",
        "outputId": "76b78b6e-90c0-43b8-d9a3-ef08469552fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "57/57 [==============================] - 1s 7ms/step - loss: 0.3905 - accuracy: 0.8578 - val_loss: 0.2133 - val_accuracy: 0.9413\n",
            "Epoch 2/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1752 - accuracy: 0.9357 - val_loss: 0.1415 - val_accuracy: 0.9513\n",
            "Epoch 3/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1403 - accuracy: 0.9418 - val_loss: 0.1236 - val_accuracy: 0.9525\n",
            "Epoch 4/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1294 - accuracy: 0.9450 - val_loss: 0.1176 - val_accuracy: 0.9500\n",
            "Epoch 5/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1238 - accuracy: 0.9475 - val_loss: 0.1153 - val_accuracy: 0.9488\n",
            "Epoch 6/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1205 - accuracy: 0.9479 - val_loss: 0.1132 - val_accuracy: 0.9525\n",
            "Epoch 7/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1180 - accuracy: 0.9499 - val_loss: 0.1120 - val_accuracy: 0.9525\n",
            "Epoch 8/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1163 - accuracy: 0.9497 - val_loss: 0.1124 - val_accuracy: 0.9500\n",
            "Epoch 9/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1143 - accuracy: 0.9510 - val_loss: 0.1114 - val_accuracy: 0.9513\n",
            "Epoch 10/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1127 - accuracy: 0.9515 - val_loss: 0.1101 - val_accuracy: 0.9513\n",
            "Epoch 11/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1118 - accuracy: 0.9528 - val_loss: 0.1122 - val_accuracy: 0.9525\n",
            "Epoch 12/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1110 - accuracy: 0.9540 - val_loss: 0.1105 - val_accuracy: 0.9500\n",
            "Epoch 13/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1091 - accuracy: 0.9544 - val_loss: 0.1099 - val_accuracy: 0.9513\n",
            "Epoch 14/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1083 - accuracy: 0.9551 - val_loss: 0.1101 - val_accuracy: 0.9500\n",
            "Epoch 15/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1068 - accuracy: 0.9557 - val_loss: 0.1108 - val_accuracy: 0.9513\n",
            "Epoch 16/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1059 - accuracy: 0.9572 - val_loss: 0.1099 - val_accuracy: 0.9500\n",
            "Epoch 17/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1053 - accuracy: 0.9563 - val_loss: 0.1108 - val_accuracy: 0.9525\n",
            "Epoch 18/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1045 - accuracy: 0.9576 - val_loss: 0.1089 - val_accuracy: 0.9500\n",
            "Epoch 19/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1031 - accuracy: 0.9575 - val_loss: 0.1096 - val_accuracy: 0.9513\n",
            "Epoch 20/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1023 - accuracy: 0.9581 - val_loss: 0.1110 - val_accuracy: 0.9538\n",
            "63/63 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ATr,ATe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sKNScl37zhV",
        "outputId": "1f478d00-fe4d-40b8-b010-7c57e1b8de7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9576249718666077, 0.9514999985694885)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XGBoost\n",
        "st = time.time()\n",
        "xgb = XGBClassifier(objective='binary:logistic',max_depth= 6,alpha= 50,learning_rate= 0.01,n_estimators=250)\n",
        "xgb.fit(X_train, y_train)\n",
        "xend = time.time() - st\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "XTr = accuracy_score(y_train, xgb.predict(X_train))\n",
        "XTe = accuracy_score(y_test, xgb.predict(X_test))\n",
        "XTr,XTe"
      ],
      "metadata": {
        "id": "PCP82YZ9RjgJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9de154f-c07f-4323-ff46-70757b6cef84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.956875, 0.941)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#KNN\n",
        "# Define the range of n_neighbors values to test\n",
        "n_neighbors_values = [1,3, 5, 7, 9, 11]\n",
        "\n",
        "best_accuracy = 0.0\n",
        "best_n_neighbors = None\n",
        "\n",
        "for n_neighbors in n_neighbors_values:\n",
        "    print(\"Number of Neighbors:\", n_neighbors)\n",
        "\n",
        "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    y_pred_knn = knn.predict(X_test)\n",
        "\n",
        "    train_accuracy = accuracy_score(y_train, knn.predict(X_train))\n",
        "    test_accuracy = accuracy_score(y_test, knn.predict(X_test))\n",
        "\n",
        "    print('KNN model train accuracy score: {0:0.4f}'.format(train_accuracy))\n",
        "    print('KNN model test accuracy score: {0:0.4f}'.format(test_accuracy))\n",
        "    print()\n",
        "\n",
        "    # Check if the current test accuracy is better than the previous best\n",
        "    if test_accuracy > best_accuracy:\n",
        "        best_accuracy = test_accuracy\n",
        "        best_n_neighbors = n_neighbors\n",
        "print(\"best neighbours: \", best_n_neighbors)\n",
        "\n",
        "st = time.time()\n",
        "knn = KNeighborsClassifier(n_neighbors=best_n_neighbors)\n",
        "knn.fit(X_train, y_train)\n",
        "kend = time.time() - st\n",
        "KTr = accuracy_score(y_train, knn.predict(X_train))\n",
        "KTe = accuracy_score(y_test, knn.predict(X_test))\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "KTr,KTe\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Y_6b33A1imy",
        "outputId": "9afffc94-0df6-4512-b3f0-6e9f7bc8e9f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Neighbors: 1\n",
            "KNN model train accuracy score: 1.0000\n",
            "KNN model test accuracy score: 0.9180\n",
            "\n",
            "Number of Neighbors: 3\n",
            "KNN model train accuracy score: 0.9629\n",
            "KNN model test accuracy score: 0.9340\n",
            "\n",
            "Number of Neighbors: 5\n",
            "KNN model train accuracy score: 0.9549\n",
            "KNN model test accuracy score: 0.9445\n",
            "\n",
            "Number of Neighbors: 7\n",
            "KNN model train accuracy score: 0.9537\n",
            "KNN model test accuracy score: 0.9440\n",
            "\n",
            "Number of Neighbors: 9\n",
            "KNN model train accuracy score: 0.9523\n",
            "KNN model test accuracy score: 0.9445\n",
            "\n",
            "Number of Neighbors: 11\n",
            "KNN model train accuracy score: 0.9499\n",
            "KNN model test accuracy score: 0.9410\n",
            "\n",
            "best neighbours:  5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.954875, 0.9445)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RF\n",
        "st = time.time()\n",
        "rf = RandomForestClassifier(n_estimators= 500,max_features = 'sqrt', max_samples = 100, random_state=123)\n",
        "rf.fit(X_train, y_train)\n",
        "rend = time.time() - st\n",
        "RTr = accuracy_score(y_train, rf.predict(X_train))\n",
        "RTe = accuracy_score(y_test, rf.predict(X_test))\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "RTr,RTe"
      ],
      "metadata": {
        "id": "k_kyk_E92bSX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec345907-edb8-4f30-937e-65179b89bbf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.943875, 0.9505)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LR\n",
        "st = time.time()\n",
        "lr = LogisticRegression(C= 0.1 , penalty='l1', solver='liblinear', max_iter = 1000, random_state=123)\n",
        "lr.fit(X_train, y_train)\n",
        "lend = time.time() - st\n",
        "LTr = accuracy_score(y_train, lr.predict(X_train))\n",
        "LTe = accuracy_score(y_test, lr.predict(X_test))\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "LTr,LTe"
      ],
      "metadata": {
        "id": "OWkZmwL23Fm_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fb3e58a-c10a-4aa4-e16f-9f43026e4df2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.95, 0.95)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E9_l6r5f0w5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CVal(ML):\n",
        "\n",
        "  df = pd.read_csv(\"https://raw.githubusercontent.com/ashiqurrahmankhan21st/BreastCancer/main/tvae_SDV_BreastCancer.csv\")\n",
        "  del df['Unnamed: 0']\n",
        "\n",
        "  s = 0\n",
        "  e = round(df.shape[0]*.2)\n",
        "\n",
        "  y_pred = []\n",
        "  y_original = []\n",
        "\n",
        "  for i in range(5):\n",
        "\n",
        "    test_set  = df.iloc[s:e,:]\n",
        "    train_set = df.drop(test_set.index)\n",
        "\n",
        "    X_train = StandardScaler().fit_transform(train_set.drop(columns=['diagnosis'])).copy()\n",
        "    y_train = encoder.fit_transform(train_set['diagnosis']).copy()\n",
        "    X_test = StandardScaler().fit_transform(test_set.drop(columns=['diagnosis'])).copy()\n",
        "    y_test = encoder.fit_transform(test_set['diagnosis']).copy()\n",
        "\n",
        "    #svm = SVC(C=0.1, gamma='auto', kernel = 'rbf')\n",
        "\n",
        "    ML.fit(X_train, y_train)\n",
        "    y_pred_ML = ML.predict(X_test)\n",
        "\n",
        "\n",
        "    y_pred.append(y_pred_ML)\n",
        "    y_original.append(y_test)\n",
        "\n",
        "    s = e\n",
        "    e = e + round(df.shape[0]*.2)\n",
        "    if e-s < round(df.shape[0]*.2):\n",
        "      e = df.shape[0]+1\n",
        "\n",
        "  y_pred_final = []\n",
        "  y_original_final = []\n",
        "\n",
        "  try:\n",
        "    for i in range(5):\n",
        "      for j in range(round(df.shape[0]*.2)):\n",
        "        y_pred_final.append(y_pred[i][j])\n",
        "        y_original_final.append(y_original[i][j])\n",
        "  except:\n",
        "    pass\n",
        "  return y_pred_final"
      ],
      "metadata": {
        "id": "XqaJZ1Mb0xAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CValANN():\n",
        "\n",
        "  df = pd.read_csv(\"https://raw.githubusercontent.com/ashiqurrahmankhan21st/BreastCancer/main/tvae_SDV_BreastCancer.csv\")\n",
        "  del df['Unnamed: 0']\n",
        "\n",
        "  s = 0\n",
        "  e = round(df.shape[0]*.2)\n",
        "\n",
        "  y_pred = []\n",
        "  y_original = []\n",
        "\n",
        "  for i in range(5):\n",
        "\n",
        "    test_set  = df.iloc[s:e,:]\n",
        "    train_set = df.drop(test_set.index)\n",
        "\n",
        "    X_train = StandardScaler().fit_transform(train_set.drop(columns=['diagnosis'])).copy()\n",
        "    y_train = encoder.fit_transform(train_set['diagnosis']).copy()\n",
        "    X_test = StandardScaler().fit_transform(test_set.drop(columns=['diagnosis'])).copy()\n",
        "    y_test = encoder.fit_transform(test_set['diagnosis']).copy()\n",
        "\n",
        "    #svm = SVC(C=0.1, gamma='auto', kernel = 'rbf')\n",
        "    tf.random.set_seed(123)\n",
        "    ANNmodel = Sequential()\n",
        "    ANNmodel.add(Dense(30, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "    ANNmodel.add(Dense(10, activation='relu'))\n",
        "    ANNmodel.add(Dense(1, activation='sigmoid'))\n",
        "    ANNmodel.compile(loss='BinaryCrossentropy', optimizer='adam', metrics=['accuracy']) #tf.keras.metrics.Precision(), tf.keras.metrics.Recall()\n",
        "    ANNmodel.fit(X_train,y_train, batch_size = 128, epochs = 20, validation_split = 0.1)\n",
        "    y_pred_ANN = (ANNmodel.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "\n",
        "    y_pred.append(y_pred_ANN)\n",
        "    y_original.append(y_test)\n",
        "\n",
        "    s = e\n",
        "    e = e + round(df.shape[0]*.2)\n",
        "    if e-s < round(df.shape[0]*.2):\n",
        "      e = df.shape[0]\n",
        "\n",
        "  y_pred_fina = []\n",
        "  y_original_final = []\n",
        "\n",
        "  try:\n",
        "    for i in range(5):\n",
        "      for j in range(round(df.shape[0]*.2)):\n",
        "        y_pred_fina.append(y_pred[i][j])\n",
        "        y_original_final.append(y_original[i][j])\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  y_pred_final = []\n",
        "\n",
        "  for i in range(len(y_pred_fina)):\n",
        "    y_pred_final.append(y_pred_fina[i][0])\n",
        "\n",
        "  return y_pred_final"
      ],
      "metadata": {
        "id": "jRa_a7EY0y6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newdata = pd.DataFrame({\n",
        "    \"SVM\": CVal(SVC(C=0.1, gamma='auto', kernel = 'rbf'))\n",
        "})\n",
        "newdata[\"KNN\"] = CVal(KNeighborsClassifier(n_neighbors=3))\n",
        "newdata[\"RF\"]  = CVal(RandomForestClassifier(n_estimators= 500,max_features = 'sqrt', max_samples = 100, random_state=123))\n",
        "newdata['LR']  = CVal(LogisticRegression(C= 0.1 , penalty='l1', solver='liblinear', max_iter = 1000, random_state=123))\n",
        "newdata[\"ANN\"] = CValANN()\n",
        "newdata[\"XGB\"] = CVal(XGBClassifier(objective='binary:logistic',max_depth= 7,alpha= 10,learning_rate= 1,n_estimators=100))\n",
        "newdata['y_test'] = encoder.fit_transform(df['diagnosis']).copy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CGgdO1V0zA9",
        "outputId": "1c727b29-ddfe-47a1-bec7-d6b22d9effb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "57/57 [==============================] - 1s 6ms/step - loss: 0.5787 - accuracy: 0.7063 - val_loss: 0.4691 - val_accuracy: 0.8763\n",
            "Epoch 2/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3512 - accuracy: 0.9169 - val_loss: 0.2669 - val_accuracy: 0.9337\n",
            "Epoch 3/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1943 - accuracy: 0.9404 - val_loss: 0.1722 - val_accuracy: 0.9475\n",
            "Epoch 4/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1437 - accuracy: 0.9450 - val_loss: 0.1471 - val_accuracy: 0.9475\n",
            "Epoch 5/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1288 - accuracy: 0.9468 - val_loss: 0.1384 - val_accuracy: 0.9463\n",
            "Epoch 6/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1234 - accuracy: 0.9492 - val_loss: 0.1330 - val_accuracy: 0.9475\n",
            "Epoch 7/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1199 - accuracy: 0.9506 - val_loss: 0.1318 - val_accuracy: 0.9488\n",
            "Epoch 8/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1174 - accuracy: 0.9515 - val_loss: 0.1282 - val_accuracy: 0.9475\n",
            "Epoch 9/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1153 - accuracy: 0.9526 - val_loss: 0.1282 - val_accuracy: 0.9463\n",
            "Epoch 10/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1140 - accuracy: 0.9532 - val_loss: 0.1269 - val_accuracy: 0.9463\n",
            "Epoch 11/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1121 - accuracy: 0.9533 - val_loss: 0.1269 - val_accuracy: 0.9475\n",
            "Epoch 12/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1113 - accuracy: 0.9540 - val_loss: 0.1254 - val_accuracy: 0.9463\n",
            "Epoch 13/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1105 - accuracy: 0.9540 - val_loss: 0.1243 - val_accuracy: 0.9475\n",
            "Epoch 14/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1089 - accuracy: 0.9542 - val_loss: 0.1245 - val_accuracy: 0.9475\n",
            "Epoch 15/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1078 - accuracy: 0.9556 - val_loss: 0.1257 - val_accuracy: 0.9488\n",
            "Epoch 16/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1069 - accuracy: 0.9554 - val_loss: 0.1240 - val_accuracy: 0.9475\n",
            "Epoch 17/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1059 - accuracy: 0.9554 - val_loss: 0.1249 - val_accuracy: 0.9475\n",
            "Epoch 18/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1052 - accuracy: 0.9561 - val_loss: 0.1241 - val_accuracy: 0.9488\n",
            "Epoch 19/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1042 - accuracy: 0.9574 - val_loss: 0.1236 - val_accuracy: 0.9488\n",
            "Epoch 20/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1034 - accuracy: 0.9568 - val_loss: 0.1243 - val_accuracy: 0.9513\n",
            "63/63 [==============================] - 0s 1ms/step\n",
            "Epoch 1/20\n",
            "57/57 [==============================] - 1s 8ms/step - loss: 0.4647 - accuracy: 0.8072 - val_loss: 0.2894 - val_accuracy: 0.9125\n",
            "Epoch 2/20\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2104 - accuracy: 0.9224 - val_loss: 0.1662 - val_accuracy: 0.9388\n",
            "Epoch 3/20\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1503 - accuracy: 0.9396 - val_loss: 0.1372 - val_accuracy: 0.9488\n",
            "Epoch 4/20\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1334 - accuracy: 0.9435 - val_loss: 0.1264 - val_accuracy: 0.9500\n",
            "Epoch 5/20\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1256 - accuracy: 0.9449 - val_loss: 0.1207 - val_accuracy: 0.9513\n",
            "Epoch 6/20\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1217 - accuracy: 0.9463 - val_loss: 0.1168 - val_accuracy: 0.9525\n",
            "Epoch 7/20\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1182 - accuracy: 0.9492 - val_loss: 0.1151 - val_accuracy: 0.9513\n",
            "Epoch 8/20\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1163 - accuracy: 0.9497 - val_loss: 0.1130 - val_accuracy: 0.9525\n",
            "Epoch 9/20\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1139 - accuracy: 0.9506 - val_loss: 0.1123 - val_accuracy: 0.9525\n",
            "Epoch 10/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1125 - accuracy: 0.9517 - val_loss: 0.1121 - val_accuracy: 0.9488\n",
            "Epoch 11/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1110 - accuracy: 0.9519 - val_loss: 0.1129 - val_accuracy: 0.9538\n",
            "Epoch 12/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1105 - accuracy: 0.9522 - val_loss: 0.1124 - val_accuracy: 0.9538\n",
            "Epoch 13/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1089 - accuracy: 0.9547 - val_loss: 0.1114 - val_accuracy: 0.9525\n",
            "Epoch 14/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1079 - accuracy: 0.9538 - val_loss: 0.1119 - val_accuracy: 0.9538\n",
            "Epoch 15/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1066 - accuracy: 0.9554 - val_loss: 0.1132 - val_accuracy: 0.9550\n",
            "Epoch 16/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1058 - accuracy: 0.9558 - val_loss: 0.1120 - val_accuracy: 0.9563\n",
            "Epoch 17/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1044 - accuracy: 0.9560 - val_loss: 0.1130 - val_accuracy: 0.9563\n",
            "Epoch 18/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1038 - accuracy: 0.9571 - val_loss: 0.1137 - val_accuracy: 0.9600\n",
            "Epoch 19/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1026 - accuracy: 0.9565 - val_loss: 0.1134 - val_accuracy: 0.9575\n",
            "Epoch 20/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1022 - accuracy: 0.9574 - val_loss: 0.1139 - val_accuracy: 0.9613\n",
            "63/63 [==============================] - 0s 1ms/step\n",
            "Epoch 1/20\n",
            "57/57 [==============================] - 1s 6ms/step - loss: 0.3818 - accuracy: 0.8568 - val_loss: 0.2428 - val_accuracy: 0.9087\n",
            "Epoch 2/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1778 - accuracy: 0.9314 - val_loss: 0.1555 - val_accuracy: 0.9350\n",
            "Epoch 3/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1384 - accuracy: 0.9417 - val_loss: 0.1338 - val_accuracy: 0.9475\n",
            "Epoch 4/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1283 - accuracy: 0.9451 - val_loss: 0.1271 - val_accuracy: 0.9500\n",
            "Epoch 5/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1229 - accuracy: 0.9475 - val_loss: 0.1240 - val_accuracy: 0.9525\n",
            "Epoch 6/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1200 - accuracy: 0.9482 - val_loss: 0.1222 - val_accuracy: 0.9538\n",
            "Epoch 7/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1162 - accuracy: 0.9500 - val_loss: 0.1202 - val_accuracy: 0.9550\n",
            "Epoch 8/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1141 - accuracy: 0.9506 - val_loss: 0.1189 - val_accuracy: 0.9538\n",
            "Epoch 9/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1118 - accuracy: 0.9531 - val_loss: 0.1183 - val_accuracy: 0.9538\n",
            "Epoch 10/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1103 - accuracy: 0.9517 - val_loss: 0.1171 - val_accuracy: 0.9575\n",
            "Epoch 11/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1085 - accuracy: 0.9531 - val_loss: 0.1173 - val_accuracy: 0.9575\n",
            "Epoch 12/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1072 - accuracy: 0.9535 - val_loss: 0.1172 - val_accuracy: 0.9575\n",
            "Epoch 13/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1057 - accuracy: 0.9547 - val_loss: 0.1157 - val_accuracy: 0.9575\n",
            "Epoch 14/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1045 - accuracy: 0.9550 - val_loss: 0.1158 - val_accuracy: 0.9575\n",
            "Epoch 15/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1036 - accuracy: 0.9564 - val_loss: 0.1166 - val_accuracy: 0.9575\n",
            "Epoch 16/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1021 - accuracy: 0.9564 - val_loss: 0.1152 - val_accuracy: 0.9575\n",
            "Epoch 17/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1011 - accuracy: 0.9565 - val_loss: 0.1153 - val_accuracy: 0.9588\n",
            "Epoch 18/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1004 - accuracy: 0.9578 - val_loss: 0.1152 - val_accuracy: 0.9575\n",
            "Epoch 19/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0993 - accuracy: 0.9575 - val_loss: 0.1152 - val_accuracy: 0.9575\n",
            "Epoch 20/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0992 - accuracy: 0.9567 - val_loss: 0.1156 - val_accuracy: 0.9588\n",
            "63/63 [==============================] - 0s 1ms/step\n",
            "Epoch 1/20\n",
            "57/57 [==============================] - 1s 6ms/step - loss: 0.4297 - accuracy: 0.8172 - val_loss: 0.2641 - val_accuracy: 0.9225\n",
            "Epoch 2/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1980 - accuracy: 0.9353 - val_loss: 0.1620 - val_accuracy: 0.9450\n",
            "Epoch 3/20\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1459 - accuracy: 0.9422 - val_loss: 0.1341 - val_accuracy: 0.9425\n",
            "Epoch 4/20\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1307 - accuracy: 0.9451 - val_loss: 0.1244 - val_accuracy: 0.9488\n",
            "Epoch 5/20\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1239 - accuracy: 0.9474 - val_loss: 0.1200 - val_accuracy: 0.9513\n",
            "Epoch 6/20\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1200 - accuracy: 0.9482 - val_loss: 0.1172 - val_accuracy: 0.9575\n",
            "Epoch 7/20\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1172 - accuracy: 0.9497 - val_loss: 0.1160 - val_accuracy: 0.9588\n",
            "Epoch 8/20\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1153 - accuracy: 0.9506 - val_loss: 0.1148 - val_accuracy: 0.9575\n",
            "Epoch 9/20\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1127 - accuracy: 0.9517 - val_loss: 0.1136 - val_accuracy: 0.9575\n",
            "Epoch 10/20\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1113 - accuracy: 0.9524 - val_loss: 0.1131 - val_accuracy: 0.9588\n",
            "Epoch 11/20\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1099 - accuracy: 0.9528 - val_loss: 0.1128 - val_accuracy: 0.9600\n",
            "Epoch 12/20\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1084 - accuracy: 0.9531 - val_loss: 0.1130 - val_accuracy: 0.9600\n",
            "Epoch 13/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1071 - accuracy: 0.9557 - val_loss: 0.1127 - val_accuracy: 0.9600\n",
            "Epoch 14/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1063 - accuracy: 0.9557 - val_loss: 0.1123 - val_accuracy: 0.9588\n",
            "Epoch 15/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1052 - accuracy: 0.9564 - val_loss: 0.1127 - val_accuracy: 0.9588\n",
            "Epoch 16/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1040 - accuracy: 0.9568 - val_loss: 0.1128 - val_accuracy: 0.9588\n",
            "Epoch 17/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1026 - accuracy: 0.9554 - val_loss: 0.1131 - val_accuracy: 0.9600\n",
            "Epoch 18/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1018 - accuracy: 0.9565 - val_loss: 0.1132 - val_accuracy: 0.9600\n",
            "Epoch 19/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1007 - accuracy: 0.9569 - val_loss: 0.1135 - val_accuracy: 0.9600\n",
            "Epoch 20/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1000 - accuracy: 0.9576 - val_loss: 0.1137 - val_accuracy: 0.9600\n",
            "63/63 [==============================] - 0s 1ms/step\n",
            "Epoch 1/20\n",
            "57/57 [==============================] - 1s 6ms/step - loss: 0.3461 - accuracy: 0.8699 - val_loss: 0.2034 - val_accuracy: 0.9225\n",
            "Epoch 2/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1706 - accuracy: 0.9343 - val_loss: 0.1524 - val_accuracy: 0.9350\n",
            "Epoch 3/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1389 - accuracy: 0.9419 - val_loss: 0.1391 - val_accuracy: 0.9362\n",
            "Epoch 4/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1276 - accuracy: 0.9449 - val_loss: 0.1330 - val_accuracy: 0.9362\n",
            "Epoch 5/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1211 - accuracy: 0.9486 - val_loss: 0.1292 - val_accuracy: 0.9425\n",
            "Epoch 6/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1165 - accuracy: 0.9510 - val_loss: 0.1272 - val_accuracy: 0.9463\n",
            "Epoch 7/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1122 - accuracy: 0.9531 - val_loss: 0.1250 - val_accuracy: 0.9463\n",
            "Epoch 8/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1102 - accuracy: 0.9529 - val_loss: 0.1235 - val_accuracy: 0.9450\n",
            "Epoch 9/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1073 - accuracy: 0.9554 - val_loss: 0.1210 - val_accuracy: 0.9488\n",
            "Epoch 10/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1057 - accuracy: 0.9554 - val_loss: 0.1209 - val_accuracy: 0.9475\n",
            "Epoch 11/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1041 - accuracy: 0.9567 - val_loss: 0.1201 - val_accuracy: 0.9463\n",
            "Epoch 12/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1026 - accuracy: 0.9572 - val_loss: 0.1210 - val_accuracy: 0.9463\n",
            "Epoch 13/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1010 - accuracy: 0.9579 - val_loss: 0.1185 - val_accuracy: 0.9475\n",
            "Epoch 14/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0998 - accuracy: 0.9579 - val_loss: 0.1199 - val_accuracy: 0.9463\n",
            "Epoch 15/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0990 - accuracy: 0.9581 - val_loss: 0.1169 - val_accuracy: 0.9475\n",
            "Epoch 16/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0976 - accuracy: 0.9582 - val_loss: 0.1194 - val_accuracy: 0.9475\n",
            "Epoch 17/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0967 - accuracy: 0.9583 - val_loss: 0.1196 - val_accuracy: 0.9488\n",
            "Epoch 18/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0953 - accuracy: 0.9599 - val_loss: 0.1195 - val_accuracy: 0.9463\n",
            "Epoch 19/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0943 - accuracy: 0.9599 - val_loss: 0.1192 - val_accuracy: 0.9475\n",
            "Epoch 20/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0934 - accuracy: 0.9601 - val_loss: 0.1197 - val_accuracy: 0.9500\n",
            "63/63 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newdata.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "05ryfvyLzFVK",
        "outputId": "19d75490-9167-439d-ea85-2080cdfda173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   SVM  KNN  RF  LR  ANN  XGB  y_test\n",
              "0    0    0   0   0    0    0       0\n",
              "1    0    0   0   0    0    0       0\n",
              "2    0    0   0   0    0    0       0\n",
              "3    0    0   0   0    0    0       0\n",
              "4    0    0   0   0    0    0       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a63c90af-4e58-4fcd-94d3-b6bd344dd799\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SVM</th>\n",
              "      <th>KNN</th>\n",
              "      <th>RF</th>\n",
              "      <th>LR</th>\n",
              "      <th>ANN</th>\n",
              "      <th>XGB</th>\n",
              "      <th>y_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a63c90af-4e58-4fcd-94d3-b6bd344dd799')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a63c90af-4e58-4fcd-94d3-b6bd344dd799 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a63c90af-4e58-4fcd-94d3-b6bd344dd799');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the DNN model\n",
        "DNNX = newdata.drop(columns=['y_test']).copy()\n",
        "DNNY = newdata.y_test.copy()\n",
        "DX_train, DX_test, Dy_train, Dy_test = train_test_split(\n",
        "    DNNX, DNNY, test_size=0.2, random_state=123)\n",
        "\n",
        "st = time.time()\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(30, activation='relu', input_shape=DNNX.shape[1:]),\n",
        "    tf.keras.layers.Dense(25, activation='relu'),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dense(15, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(DX_train, Dy_train, epochs=500, batch_size=64, validation_split=0.2)\n",
        "dend = time.time() - st"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4kf97a3yX15",
        "outputId": "a5709f31-844e-4348-a058-838e5cf89158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "100/100 [==============================] - 2s 5ms/step - loss: 0.4793 - accuracy: 0.6833 - val_loss: 0.3532 - val_accuracy: 0.9488\n",
            "Epoch 2/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.3351 - accuracy: 0.9480 - val_loss: 0.3342 - val_accuracy: 0.9506\n",
            "Epoch 3/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.3188 - accuracy: 0.9473 - val_loss: 0.3184 - val_accuracy: 0.9494\n",
            "Epoch 4/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.3044 - accuracy: 0.9484 - val_loss: 0.3041 - val_accuracy: 0.9506\n",
            "Epoch 5/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2918 - accuracy: 0.9498 - val_loss: 0.2917 - val_accuracy: 0.9506\n",
            "Epoch 6/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2803 - accuracy: 0.9498 - val_loss: 0.2805 - val_accuracy: 0.9519\n",
            "Epoch 7/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.2712 - accuracy: 0.9503 - val_loss: 0.2698 - val_accuracy: 0.9506\n",
            "Epoch 8/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2607 - accuracy: 0.9508 - val_loss: 0.2601 - val_accuracy: 0.9506\n",
            "Epoch 9/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2522 - accuracy: 0.9508 - val_loss: 0.2531 - val_accuracy: 0.9494\n",
            "Epoch 10/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2439 - accuracy: 0.9513 - val_loss: 0.2439 - val_accuracy: 0.9475\n",
            "Epoch 11/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.2367 - accuracy: 0.9514 - val_loss: 0.2362 - val_accuracy: 0.9500\n",
            "Epoch 12/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2301 - accuracy: 0.9509 - val_loss: 0.2294 - val_accuracy: 0.9506\n",
            "Epoch 13/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2239 - accuracy: 0.9520 - val_loss: 0.2225 - val_accuracy: 0.9506\n",
            "Epoch 14/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2189 - accuracy: 0.9511 - val_loss: 0.2176 - val_accuracy: 0.9506\n",
            "Epoch 15/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2136 - accuracy: 0.9500 - val_loss: 0.2121 - val_accuracy: 0.9494\n",
            "Epoch 16/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2094 - accuracy: 0.9514 - val_loss: 0.2078 - val_accuracy: 0.9494\n",
            "Epoch 17/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2046 - accuracy: 0.9509 - val_loss: 0.2036 - val_accuracy: 0.9500\n",
            "Epoch 18/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2004 - accuracy: 0.9511 - val_loss: 0.1996 - val_accuracy: 0.9494\n",
            "Epoch 19/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1970 - accuracy: 0.9523 - val_loss: 0.1964 - val_accuracy: 0.9500\n",
            "Epoch 20/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1936 - accuracy: 0.9519 - val_loss: 0.1911 - val_accuracy: 0.9481\n",
            "Epoch 21/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1907 - accuracy: 0.9514 - val_loss: 0.1880 - val_accuracy: 0.9500\n",
            "Epoch 22/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1874 - accuracy: 0.9516 - val_loss: 0.1860 - val_accuracy: 0.9506\n",
            "Epoch 23/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1853 - accuracy: 0.9509 - val_loss: 0.1814 - val_accuracy: 0.9506\n",
            "Epoch 24/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1822 - accuracy: 0.9517 - val_loss: 0.1809 - val_accuracy: 0.9500\n",
            "Epoch 25/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1802 - accuracy: 0.9516 - val_loss: 0.1782 - val_accuracy: 0.9500\n",
            "Epoch 26/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1778 - accuracy: 0.9506 - val_loss: 0.1744 - val_accuracy: 0.9513\n",
            "Epoch 27/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1758 - accuracy: 0.9516 - val_loss: 0.1740 - val_accuracy: 0.9506\n",
            "Epoch 28/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1745 - accuracy: 0.9519 - val_loss: 0.1708 - val_accuracy: 0.9525\n",
            "Epoch 29/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1722 - accuracy: 0.9523 - val_loss: 0.1697 - val_accuracy: 0.9500\n",
            "Epoch 30/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1701 - accuracy: 0.9519 - val_loss: 0.1661 - val_accuracy: 0.9531\n",
            "Epoch 31/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1695 - accuracy: 0.9506 - val_loss: 0.1651 - val_accuracy: 0.9506\n",
            "Epoch 32/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1681 - accuracy: 0.9527 - val_loss: 0.1655 - val_accuracy: 0.9513\n",
            "Epoch 33/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1665 - accuracy: 0.9523 - val_loss: 0.1638 - val_accuracy: 0.9506\n",
            "Epoch 34/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1645 - accuracy: 0.9533 - val_loss: 0.1617 - val_accuracy: 0.9525\n",
            "Epoch 35/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1634 - accuracy: 0.9538 - val_loss: 0.1604 - val_accuracy: 0.9513\n",
            "Epoch 36/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1624 - accuracy: 0.9525 - val_loss: 0.1599 - val_accuracy: 0.9506\n",
            "Epoch 37/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1614 - accuracy: 0.9533 - val_loss: 0.1573 - val_accuracy: 0.9525\n",
            "Epoch 38/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1598 - accuracy: 0.9534 - val_loss: 0.1564 - val_accuracy: 0.9506\n",
            "Epoch 39/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1585 - accuracy: 0.9528 - val_loss: 0.1578 - val_accuracy: 0.9525\n",
            "Epoch 40/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1582 - accuracy: 0.9528 - val_loss: 0.1563 - val_accuracy: 0.9519\n",
            "Epoch 41/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1574 - accuracy: 0.9525 - val_loss: 0.1556 - val_accuracy: 0.9519\n",
            "Epoch 42/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1569 - accuracy: 0.9528 - val_loss: 0.1538 - val_accuracy: 0.9519\n",
            "Epoch 43/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1559 - accuracy: 0.9544 - val_loss: 0.1559 - val_accuracy: 0.9519\n",
            "Epoch 44/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1558 - accuracy: 0.9531 - val_loss: 0.1533 - val_accuracy: 0.9513\n",
            "Epoch 45/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1544 - accuracy: 0.9534 - val_loss: 0.1523 - val_accuracy: 0.9513\n",
            "Epoch 46/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1532 - accuracy: 0.9534 - val_loss: 0.1520 - val_accuracy: 0.9500\n",
            "Epoch 47/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1531 - accuracy: 0.9530 - val_loss: 0.1500 - val_accuracy: 0.9531\n",
            "Epoch 48/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1523 - accuracy: 0.9528 - val_loss: 0.1521 - val_accuracy: 0.9519\n",
            "Epoch 49/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1521 - accuracy: 0.9536 - val_loss: 0.1509 - val_accuracy: 0.9519\n",
            "Epoch 50/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1514 - accuracy: 0.9534 - val_loss: 0.1506 - val_accuracy: 0.9519\n",
            "Epoch 51/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1518 - accuracy: 0.9530 - val_loss: 0.1483 - val_accuracy: 0.9531\n",
            "Epoch 52/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1505 - accuracy: 0.9525 - val_loss: 0.1500 - val_accuracy: 0.9525\n",
            "Epoch 53/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1509 - accuracy: 0.9527 - val_loss: 0.1494 - val_accuracy: 0.9525\n",
            "Epoch 54/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1502 - accuracy: 0.9525 - val_loss: 0.1472 - val_accuracy: 0.9538\n",
            "Epoch 55/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1495 - accuracy: 0.9517 - val_loss: 0.1486 - val_accuracy: 0.9538\n",
            "Epoch 56/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1498 - accuracy: 0.9541 - val_loss: 0.1472 - val_accuracy: 0.9519\n",
            "Epoch 57/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1490 - accuracy: 0.9538 - val_loss: 0.1463 - val_accuracy: 0.9519\n",
            "Epoch 58/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1486 - accuracy: 0.9530 - val_loss: 0.1462 - val_accuracy: 0.9500\n",
            "Epoch 59/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9538 - val_loss: 0.1481 - val_accuracy: 0.9538\n",
            "Epoch 60/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1488 - accuracy: 0.9542 - val_loss: 0.1485 - val_accuracy: 0.9538\n",
            "Epoch 61/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1492 - accuracy: 0.9533 - val_loss: 0.1479 - val_accuracy: 0.9538\n",
            "Epoch 62/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1478 - accuracy: 0.9536 - val_loss: 0.1447 - val_accuracy: 0.9519\n",
            "Epoch 63/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1470 - accuracy: 0.9541 - val_loss: 0.1459 - val_accuracy: 0.9519\n",
            "Epoch 64/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1488 - accuracy: 0.9536 - val_loss: 0.1450 - val_accuracy: 0.9519\n",
            "Epoch 65/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1474 - accuracy: 0.9547 - val_loss: 0.1451 - val_accuracy: 0.9538\n",
            "Epoch 66/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1474 - accuracy: 0.9533 - val_loss: 0.1451 - val_accuracy: 0.9538\n",
            "Epoch 67/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1467 - accuracy: 0.9531 - val_loss: 0.1438 - val_accuracy: 0.9531\n",
            "Epoch 68/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1463 - accuracy: 0.9545 - val_loss: 0.1449 - val_accuracy: 0.9500\n",
            "Epoch 69/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1461 - accuracy: 0.9542 - val_loss: 0.1458 - val_accuracy: 0.9519\n",
            "Epoch 70/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1469 - accuracy: 0.9542 - val_loss: 0.1455 - val_accuracy: 0.9519\n",
            "Epoch 71/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1466 - accuracy: 0.9544 - val_loss: 0.1445 - val_accuracy: 0.9519\n",
            "Epoch 72/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1470 - accuracy: 0.9536 - val_loss: 0.1464 - val_accuracy: 0.9500\n",
            "Epoch 73/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1466 - accuracy: 0.9534 - val_loss: 0.1469 - val_accuracy: 0.9500\n",
            "Epoch 74/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1462 - accuracy: 0.9539 - val_loss: 0.1450 - val_accuracy: 0.9513\n",
            "Epoch 75/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1459 - accuracy: 0.9541 - val_loss: 0.1466 - val_accuracy: 0.9513\n",
            "Epoch 76/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1472 - accuracy: 0.9545 - val_loss: 0.1440 - val_accuracy: 0.9519\n",
            "Epoch 77/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9555 - val_loss: 0.1446 - val_accuracy: 0.9531\n",
            "Epoch 78/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9538 - val_loss: 0.1444 - val_accuracy: 0.9519\n",
            "Epoch 79/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9541 - val_loss: 0.1443 - val_accuracy: 0.9500\n",
            "Epoch 80/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1457 - accuracy: 0.9544 - val_loss: 0.1441 - val_accuracy: 0.9519\n",
            "Epoch 81/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1454 - accuracy: 0.9548 - val_loss: 0.1444 - val_accuracy: 0.9513\n",
            "Epoch 82/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1457 - accuracy: 0.9536 - val_loss: 0.1439 - val_accuracy: 0.9500\n",
            "Epoch 83/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1452 - accuracy: 0.9544 - val_loss: 0.1447 - val_accuracy: 0.9525\n",
            "Epoch 84/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1444 - accuracy: 0.9541 - val_loss: 0.1451 - val_accuracy: 0.9500\n",
            "Epoch 85/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9531 - val_loss: 0.1445 - val_accuracy: 0.9513\n",
            "Epoch 86/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1459 - accuracy: 0.9538 - val_loss: 0.1441 - val_accuracy: 0.9519\n",
            "Epoch 87/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9548 - val_loss: 0.1439 - val_accuracy: 0.9538\n",
            "Epoch 88/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9541 - val_loss: 0.1440 - val_accuracy: 0.9513\n",
            "Epoch 89/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9542 - val_loss: 0.1442 - val_accuracy: 0.9513\n",
            "Epoch 90/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9539 - val_loss: 0.1444 - val_accuracy: 0.9519\n",
            "Epoch 91/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9534 - val_loss: 0.1450 - val_accuracy: 0.9519\n",
            "Epoch 92/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9552 - val_loss: 0.1441 - val_accuracy: 0.9519\n",
            "Epoch 93/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1444 - accuracy: 0.9544 - val_loss: 0.1450 - val_accuracy: 0.9513\n",
            "Epoch 94/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9545 - val_loss: 0.1438 - val_accuracy: 0.9538\n",
            "Epoch 95/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9544 - val_loss: 0.1449 - val_accuracy: 0.9513\n",
            "Epoch 96/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9538 - val_loss: 0.1447 - val_accuracy: 0.9500\n",
            "Epoch 97/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9542 - val_loss: 0.1443 - val_accuracy: 0.9513\n",
            "Epoch 98/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9541 - val_loss: 0.1439 - val_accuracy: 0.9519\n",
            "Epoch 99/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1444 - accuracy: 0.9547 - val_loss: 0.1460 - val_accuracy: 0.9519\n",
            "Epoch 100/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9544 - val_loss: 0.1454 - val_accuracy: 0.9500\n",
            "Epoch 101/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9547 - val_loss: 0.1438 - val_accuracy: 0.9513\n",
            "Epoch 102/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9536 - val_loss: 0.1442 - val_accuracy: 0.9513\n",
            "Epoch 103/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9545 - val_loss: 0.1483 - val_accuracy: 0.9500\n",
            "Epoch 104/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9536 - val_loss: 0.1454 - val_accuracy: 0.9500\n",
            "Epoch 105/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9534 - val_loss: 0.1446 - val_accuracy: 0.9531\n",
            "Epoch 106/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9541 - val_loss: 0.1451 - val_accuracy: 0.9538\n",
            "Epoch 107/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9547 - val_loss: 0.1461 - val_accuracy: 0.9513\n",
            "Epoch 108/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1441 - accuracy: 0.9544 - val_loss: 0.1459 - val_accuracy: 0.9513\n",
            "Epoch 109/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9541 - val_loss: 0.1441 - val_accuracy: 0.9531\n",
            "Epoch 110/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9538 - val_loss: 0.1441 - val_accuracy: 0.9531\n",
            "Epoch 111/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9545 - val_loss: 0.1432 - val_accuracy: 0.9513\n",
            "Epoch 112/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1443 - accuracy: 0.9544 - val_loss: 0.1451 - val_accuracy: 0.9513\n",
            "Epoch 113/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1441 - accuracy: 0.9544 - val_loss: 0.1465 - val_accuracy: 0.9531\n",
            "Epoch 114/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1440 - accuracy: 0.9545 - val_loss: 0.1493 - val_accuracy: 0.9513\n",
            "Epoch 115/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9542 - val_loss: 0.1457 - val_accuracy: 0.9531\n",
            "Epoch 116/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1445 - accuracy: 0.9545 - val_loss: 0.1460 - val_accuracy: 0.9538\n",
            "Epoch 117/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1448 - accuracy: 0.9544 - val_loss: 0.1461 - val_accuracy: 0.9531\n",
            "Epoch 118/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1439 - accuracy: 0.9547 - val_loss: 0.1460 - val_accuracy: 0.9525\n",
            "Epoch 119/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1442 - accuracy: 0.9539 - val_loss: 0.1448 - val_accuracy: 0.9513\n",
            "Epoch 120/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1437 - accuracy: 0.9548 - val_loss: 0.1448 - val_accuracy: 0.9519\n",
            "Epoch 121/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1439 - accuracy: 0.9548 - val_loss: 0.1461 - val_accuracy: 0.9531\n",
            "Epoch 122/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1442 - accuracy: 0.9542 - val_loss: 0.1455 - val_accuracy: 0.9519\n",
            "Epoch 123/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9541 - val_loss: 0.1450 - val_accuracy: 0.9513\n",
            "Epoch 124/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1439 - accuracy: 0.9545 - val_loss: 0.1453 - val_accuracy: 0.9538\n",
            "Epoch 125/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1444 - accuracy: 0.9545 - val_loss: 0.1469 - val_accuracy: 0.9513\n",
            "Epoch 126/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9547 - val_loss: 0.1451 - val_accuracy: 0.9531\n",
            "Epoch 127/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1440 - accuracy: 0.9544 - val_loss: 0.1452 - val_accuracy: 0.9538\n",
            "Epoch 128/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1438 - accuracy: 0.9550 - val_loss: 0.1465 - val_accuracy: 0.9531\n",
            "Epoch 129/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1442 - accuracy: 0.9544 - val_loss: 0.1453 - val_accuracy: 0.9531\n",
            "Epoch 130/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1436 - accuracy: 0.9541 - val_loss: 0.1467 - val_accuracy: 0.9538\n",
            "Epoch 131/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1440 - accuracy: 0.9545 - val_loss: 0.1466 - val_accuracy: 0.9531\n",
            "Epoch 132/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1444 - accuracy: 0.9550 - val_loss: 0.1476 - val_accuracy: 0.9519\n",
            "Epoch 133/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1442 - accuracy: 0.9542 - val_loss: 0.1450 - val_accuracy: 0.9519\n",
            "Epoch 134/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1440 - accuracy: 0.9538 - val_loss: 0.1479 - val_accuracy: 0.9531\n",
            "Epoch 135/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1442 - accuracy: 0.9547 - val_loss: 0.1463 - val_accuracy: 0.9538\n",
            "Epoch 136/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1442 - accuracy: 0.9544 - val_loss: 0.1461 - val_accuracy: 0.9538\n",
            "Epoch 137/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1438 - accuracy: 0.9539 - val_loss: 0.1452 - val_accuracy: 0.9513\n",
            "Epoch 138/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1438 - accuracy: 0.9539 - val_loss: 0.1500 - val_accuracy: 0.9500\n",
            "Epoch 139/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1438 - accuracy: 0.9539 - val_loss: 0.1475 - val_accuracy: 0.9519\n",
            "Epoch 140/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1437 - accuracy: 0.9544 - val_loss: 0.1476 - val_accuracy: 0.9531\n",
            "Epoch 141/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1440 - accuracy: 0.9544 - val_loss: 0.1464 - val_accuracy: 0.9519\n",
            "Epoch 142/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1438 - accuracy: 0.9550 - val_loss: 0.1473 - val_accuracy: 0.9538\n",
            "Epoch 143/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1439 - accuracy: 0.9541 - val_loss: 0.1460 - val_accuracy: 0.9531\n",
            "Epoch 144/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1440 - accuracy: 0.9544 - val_loss: 0.1449 - val_accuracy: 0.9500\n",
            "Epoch 145/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1440 - accuracy: 0.9541 - val_loss: 0.1459 - val_accuracy: 0.9538\n",
            "Epoch 146/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1436 - accuracy: 0.9541 - val_loss: 0.1476 - val_accuracy: 0.9519\n",
            "Epoch 147/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1439 - accuracy: 0.9544 - val_loss: 0.1452 - val_accuracy: 0.9538\n",
            "Epoch 148/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9548 - val_loss: 0.1460 - val_accuracy: 0.9538\n",
            "Epoch 149/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1438 - accuracy: 0.9539 - val_loss: 0.1471 - val_accuracy: 0.9538\n",
            "Epoch 150/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1436 - accuracy: 0.9544 - val_loss: 0.1479 - val_accuracy: 0.9500\n",
            "Epoch 151/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1437 - accuracy: 0.9542 - val_loss: 0.1470 - val_accuracy: 0.9538\n",
            "Epoch 152/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1435 - accuracy: 0.9550 - val_loss: 0.1478 - val_accuracy: 0.9538\n",
            "Epoch 153/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1444 - accuracy: 0.9542 - val_loss: 0.1463 - val_accuracy: 0.9538\n",
            "Epoch 154/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1443 - accuracy: 0.9550 - val_loss: 0.1461 - val_accuracy: 0.9519\n",
            "Epoch 155/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1441 - accuracy: 0.9542 - val_loss: 0.1476 - val_accuracy: 0.9538\n",
            "Epoch 156/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1436 - accuracy: 0.9545 - val_loss: 0.1463 - val_accuracy: 0.9538\n",
            "Epoch 157/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1445 - accuracy: 0.9544 - val_loss: 0.1432 - val_accuracy: 0.9500\n",
            "Epoch 158/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9538 - val_loss: 0.1479 - val_accuracy: 0.9525\n",
            "Epoch 159/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1440 - accuracy: 0.9533 - val_loss: 0.1454 - val_accuracy: 0.9513\n",
            "Epoch 160/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1439 - accuracy: 0.9542 - val_loss: 0.1444 - val_accuracy: 0.9519\n",
            "Epoch 161/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1437 - accuracy: 0.9547 - val_loss: 0.1467 - val_accuracy: 0.9531\n",
            "Epoch 162/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1438 - accuracy: 0.9545 - val_loss: 0.1469 - val_accuracy: 0.9519\n",
            "Epoch 163/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1434 - accuracy: 0.9536 - val_loss: 0.1471 - val_accuracy: 0.9538\n",
            "Epoch 164/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1436 - accuracy: 0.9547 - val_loss: 0.1467 - val_accuracy: 0.9500\n",
            "Epoch 165/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9552 - val_loss: 0.1479 - val_accuracy: 0.9500\n",
            "Epoch 166/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1434 - accuracy: 0.9547 - val_loss: 0.1490 - val_accuracy: 0.9538\n",
            "Epoch 167/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9548 - val_loss: 0.1477 - val_accuracy: 0.9538\n",
            "Epoch 168/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1435 - accuracy: 0.9545 - val_loss: 0.1479 - val_accuracy: 0.9538\n",
            "Epoch 169/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9547 - val_loss: 0.1473 - val_accuracy: 0.9531\n",
            "Epoch 170/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1440 - accuracy: 0.9547 - val_loss: 0.1463 - val_accuracy: 0.9519\n",
            "Epoch 171/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9547 - val_loss: 0.1492 - val_accuracy: 0.9519\n",
            "Epoch 172/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1442 - accuracy: 0.9542 - val_loss: 0.1483 - val_accuracy: 0.9538\n",
            "Epoch 173/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9541 - val_loss: 0.1480 - val_accuracy: 0.9513\n",
            "Epoch 174/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1438 - accuracy: 0.9548 - val_loss: 0.1483 - val_accuracy: 0.9519\n",
            "Epoch 175/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1430 - accuracy: 0.9547 - val_loss: 0.1485 - val_accuracy: 0.9531\n",
            "Epoch 176/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9545 - val_loss: 0.1485 - val_accuracy: 0.9531\n",
            "Epoch 177/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1440 - accuracy: 0.9548 - val_loss: 0.1489 - val_accuracy: 0.9531\n",
            "Epoch 178/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1435 - accuracy: 0.9538 - val_loss: 0.1474 - val_accuracy: 0.9519\n",
            "Epoch 179/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1439 - accuracy: 0.9539 - val_loss: 0.1455 - val_accuracy: 0.9500\n",
            "Epoch 180/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1442 - accuracy: 0.9555 - val_loss: 0.1459 - val_accuracy: 0.9538\n",
            "Epoch 181/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9541 - val_loss: 0.1469 - val_accuracy: 0.9519\n",
            "Epoch 182/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9545 - val_loss: 0.1489 - val_accuracy: 0.9531\n",
            "Epoch 183/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1441 - accuracy: 0.9548 - val_loss: 0.1482 - val_accuracy: 0.9519\n",
            "Epoch 184/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1434 - accuracy: 0.9544 - val_loss: 0.1470 - val_accuracy: 0.9538\n",
            "Epoch 185/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9547 - val_loss: 0.1491 - val_accuracy: 0.9519\n",
            "Epoch 186/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1436 - accuracy: 0.9544 - val_loss: 0.1486 - val_accuracy: 0.9519\n",
            "Epoch 187/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9542 - val_loss: 0.1499 - val_accuracy: 0.9531\n",
            "Epoch 188/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1436 - accuracy: 0.9544 - val_loss: 0.1462 - val_accuracy: 0.9519\n",
            "Epoch 189/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1436 - accuracy: 0.9548 - val_loss: 0.1505 - val_accuracy: 0.9519\n",
            "Epoch 190/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1437 - accuracy: 0.9548 - val_loss: 0.1495 - val_accuracy: 0.9519\n",
            "Epoch 191/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1436 - accuracy: 0.9547 - val_loss: 0.1479 - val_accuracy: 0.9538\n",
            "Epoch 192/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1432 - accuracy: 0.9544 - val_loss: 0.1500 - val_accuracy: 0.9538\n",
            "Epoch 193/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1433 - accuracy: 0.9544 - val_loss: 0.1504 - val_accuracy: 0.9519\n",
            "Epoch 194/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1436 - accuracy: 0.9548 - val_loss: 0.1495 - val_accuracy: 0.9531\n",
            "Epoch 195/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9548 - val_loss: 0.1490 - val_accuracy: 0.9519\n",
            "Epoch 196/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9547 - val_loss: 0.1492 - val_accuracy: 0.9531\n",
            "Epoch 197/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1440 - accuracy: 0.9536 - val_loss: 0.1499 - val_accuracy: 0.9519\n",
            "Epoch 198/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1439 - accuracy: 0.9544 - val_loss: 0.1475 - val_accuracy: 0.9500\n",
            "Epoch 199/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1440 - accuracy: 0.9541 - val_loss: 0.1480 - val_accuracy: 0.9513\n",
            "Epoch 200/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1439 - accuracy: 0.9544 - val_loss: 0.1500 - val_accuracy: 0.9513\n",
            "Epoch 201/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9541 - val_loss: 0.1469 - val_accuracy: 0.9538\n",
            "Epoch 202/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9542 - val_loss: 0.1470 - val_accuracy: 0.9538\n",
            "Epoch 203/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9545 - val_loss: 0.1490 - val_accuracy: 0.9519\n",
            "Epoch 204/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1435 - accuracy: 0.9545 - val_loss: 0.1488 - val_accuracy: 0.9500\n",
            "Epoch 205/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9545 - val_loss: 0.1478 - val_accuracy: 0.9519\n",
            "Epoch 206/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1435 - accuracy: 0.9544 - val_loss: 0.1490 - val_accuracy: 0.9531\n",
            "Epoch 207/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9548 - val_loss: 0.1485 - val_accuracy: 0.9531\n",
            "Epoch 208/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1434 - accuracy: 0.9548 - val_loss: 0.1501 - val_accuracy: 0.9519\n",
            "Epoch 209/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9545 - val_loss: 0.1454 - val_accuracy: 0.9538\n",
            "Epoch 210/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9548 - val_loss: 0.1480 - val_accuracy: 0.9519\n",
            "Epoch 211/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1434 - accuracy: 0.9544 - val_loss: 0.1503 - val_accuracy: 0.9519\n",
            "Epoch 212/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9542 - val_loss: 0.1503 - val_accuracy: 0.9538\n",
            "Epoch 213/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1436 - accuracy: 0.9544 - val_loss: 0.1461 - val_accuracy: 0.9538\n",
            "Epoch 214/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9548 - val_loss: 0.1485 - val_accuracy: 0.9538\n",
            "Epoch 215/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9536 - val_loss: 0.1487 - val_accuracy: 0.9519\n",
            "Epoch 216/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9539 - val_loss: 0.1506 - val_accuracy: 0.9538\n",
            "Epoch 217/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1440 - accuracy: 0.9545 - val_loss: 0.1493 - val_accuracy: 0.9531\n",
            "Epoch 218/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1438 - accuracy: 0.9552 - val_loss: 0.1480 - val_accuracy: 0.9519\n",
            "Epoch 219/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1434 - accuracy: 0.9539 - val_loss: 0.1502 - val_accuracy: 0.9538\n",
            "Epoch 220/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9548 - val_loss: 0.1491 - val_accuracy: 0.9538\n",
            "Epoch 221/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9545 - val_loss: 0.1505 - val_accuracy: 0.9538\n",
            "Epoch 222/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1435 - accuracy: 0.9544 - val_loss: 0.1509 - val_accuracy: 0.9538\n",
            "Epoch 223/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9542 - val_loss: 0.1506 - val_accuracy: 0.9538\n",
            "Epoch 224/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1430 - accuracy: 0.9545 - val_loss: 0.1521 - val_accuracy: 0.9519\n",
            "Epoch 225/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1433 - accuracy: 0.9536 - val_loss: 0.1505 - val_accuracy: 0.9531\n",
            "Epoch 226/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1431 - accuracy: 0.9544 - val_loss: 0.1502 - val_accuracy: 0.9519\n",
            "Epoch 227/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1430 - accuracy: 0.9547 - val_loss: 0.1505 - val_accuracy: 0.9519\n",
            "Epoch 228/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1431 - accuracy: 0.9548 - val_loss: 0.1512 - val_accuracy: 0.9531\n",
            "Epoch 229/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1429 - accuracy: 0.9548 - val_loss: 0.1500 - val_accuracy: 0.9538\n",
            "Epoch 230/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9552 - val_loss: 0.1496 - val_accuracy: 0.9531\n",
            "Epoch 231/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9550 - val_loss: 0.1515 - val_accuracy: 0.9538\n",
            "Epoch 232/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1430 - accuracy: 0.9545 - val_loss: 0.1506 - val_accuracy: 0.9538\n",
            "Epoch 233/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9542 - val_loss: 0.1516 - val_accuracy: 0.9519\n",
            "Epoch 234/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1435 - accuracy: 0.9548 - val_loss: 0.1495 - val_accuracy: 0.9538\n",
            "Epoch 235/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1437 - accuracy: 0.9541 - val_loss: 0.1496 - val_accuracy: 0.9519\n",
            "Epoch 236/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9548 - val_loss: 0.1494 - val_accuracy: 0.9519\n",
            "Epoch 237/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9544 - val_loss: 0.1495 - val_accuracy: 0.9531\n",
            "Epoch 238/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9547 - val_loss: 0.1500 - val_accuracy: 0.9538\n",
            "Epoch 239/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1434 - accuracy: 0.9538 - val_loss: 0.1500 - val_accuracy: 0.9538\n",
            "Epoch 240/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1435 - accuracy: 0.9550 - val_loss: 0.1490 - val_accuracy: 0.9538\n",
            "Epoch 241/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1430 - accuracy: 0.9550 - val_loss: 0.1494 - val_accuracy: 0.9538\n",
            "Epoch 242/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9548 - val_loss: 0.1514 - val_accuracy: 0.9519\n",
            "Epoch 243/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9545 - val_loss: 0.1499 - val_accuracy: 0.9538\n",
            "Epoch 244/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9542 - val_loss: 0.1501 - val_accuracy: 0.9519\n",
            "Epoch 245/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9545 - val_loss: 0.1512 - val_accuracy: 0.9544\n",
            "Epoch 246/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9539 - val_loss: 0.1492 - val_accuracy: 0.9531\n",
            "Epoch 247/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9545 - val_loss: 0.1491 - val_accuracy: 0.9519\n",
            "Epoch 248/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9545 - val_loss: 0.1530 - val_accuracy: 0.9519\n",
            "Epoch 249/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9544 - val_loss: 0.1491 - val_accuracy: 0.9538\n",
            "Epoch 250/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9542 - val_loss: 0.1520 - val_accuracy: 0.9519\n",
            "Epoch 251/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1435 - accuracy: 0.9541 - val_loss: 0.1492 - val_accuracy: 0.9538\n",
            "Epoch 252/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1430 - accuracy: 0.9544 - val_loss: 0.1501 - val_accuracy: 0.9538\n",
            "Epoch 253/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9545 - val_loss: 0.1505 - val_accuracy: 0.9531\n",
            "Epoch 254/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1435 - accuracy: 0.9539 - val_loss: 0.1499 - val_accuracy: 0.9538\n",
            "Epoch 255/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9545 - val_loss: 0.1507 - val_accuracy: 0.9519\n",
            "Epoch 256/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9545 - val_loss: 0.1511 - val_accuracy: 0.9538\n",
            "Epoch 257/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9544 - val_loss: 0.1515 - val_accuracy: 0.9538\n",
            "Epoch 258/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1438 - accuracy: 0.9539 - val_loss: 0.1497 - val_accuracy: 0.9519\n",
            "Epoch 259/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1436 - accuracy: 0.9542 - val_loss: 0.1500 - val_accuracy: 0.9519\n",
            "Epoch 260/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1436 - accuracy: 0.9552 - val_loss: 0.1485 - val_accuracy: 0.9538\n",
            "Epoch 261/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1430 - accuracy: 0.9550 - val_loss: 0.1500 - val_accuracy: 0.9538\n",
            "Epoch 262/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1430 - accuracy: 0.9541 - val_loss: 0.1512 - val_accuracy: 0.9538\n",
            "Epoch 263/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1434 - accuracy: 0.9544 - val_loss: 0.1490 - val_accuracy: 0.9538\n",
            "Epoch 264/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1429 - accuracy: 0.9555 - val_loss: 0.1508 - val_accuracy: 0.9519\n",
            "Epoch 265/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1432 - accuracy: 0.9548 - val_loss: 0.1504 - val_accuracy: 0.9538\n",
            "Epoch 266/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1430 - accuracy: 0.9548 - val_loss: 0.1515 - val_accuracy: 0.9519\n",
            "Epoch 267/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1434 - accuracy: 0.9542 - val_loss: 0.1512 - val_accuracy: 0.9519\n",
            "Epoch 268/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9547 - val_loss: 0.1504 - val_accuracy: 0.9538\n",
            "Epoch 269/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1427 - accuracy: 0.9542 - val_loss: 0.1532 - val_accuracy: 0.9519\n",
            "Epoch 270/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1427 - accuracy: 0.9545 - val_loss: 0.1530 - val_accuracy: 0.9538\n",
            "Epoch 271/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1430 - accuracy: 0.9545 - val_loss: 0.1522 - val_accuracy: 0.9519\n",
            "Epoch 272/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9542 - val_loss: 0.1517 - val_accuracy: 0.9519\n",
            "Epoch 273/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1430 - accuracy: 0.9545 - val_loss: 0.1517 - val_accuracy: 0.9538\n",
            "Epoch 274/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1435 - accuracy: 0.9550 - val_loss: 0.1498 - val_accuracy: 0.9538\n",
            "Epoch 275/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9547 - val_loss: 0.1510 - val_accuracy: 0.9519\n",
            "Epoch 276/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1434 - accuracy: 0.9545 - val_loss: 0.1512 - val_accuracy: 0.9538\n",
            "Epoch 277/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1430 - accuracy: 0.9544 - val_loss: 0.1510 - val_accuracy: 0.9538\n",
            "Epoch 278/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9548 - val_loss: 0.1513 - val_accuracy: 0.9538\n",
            "Epoch 279/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9542 - val_loss: 0.1534 - val_accuracy: 0.9519\n",
            "Epoch 280/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1429 - accuracy: 0.9547 - val_loss: 0.1517 - val_accuracy: 0.9519\n",
            "Epoch 281/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9542 - val_loss: 0.1509 - val_accuracy: 0.9531\n",
            "Epoch 282/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1430 - accuracy: 0.9545 - val_loss: 0.1541 - val_accuracy: 0.9519\n",
            "Epoch 283/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9548 - val_loss: 0.1523 - val_accuracy: 0.9538\n",
            "Epoch 284/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1430 - accuracy: 0.9542 - val_loss: 0.1507 - val_accuracy: 0.9538\n",
            "Epoch 285/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1428 - accuracy: 0.9544 - val_loss: 0.1520 - val_accuracy: 0.9538\n",
            "Epoch 286/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1430 - accuracy: 0.9544 - val_loss: 0.1525 - val_accuracy: 0.9538\n",
            "Epoch 287/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9544 - val_loss: 0.1524 - val_accuracy: 0.9519\n",
            "Epoch 288/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1430 - accuracy: 0.9548 - val_loss: 0.1530 - val_accuracy: 0.9538\n",
            "Epoch 289/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9545 - val_loss: 0.1530 - val_accuracy: 0.9519\n",
            "Epoch 290/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1430 - accuracy: 0.9548 - val_loss: 0.1525 - val_accuracy: 0.9519\n",
            "Epoch 291/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9544 - val_loss: 0.1535 - val_accuracy: 0.9519\n",
            "Epoch 292/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9542 - val_loss: 0.1534 - val_accuracy: 0.9519\n",
            "Epoch 293/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9553 - val_loss: 0.1524 - val_accuracy: 0.9519\n",
            "Epoch 294/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9548 - val_loss: 0.1529 - val_accuracy: 0.9519\n",
            "Epoch 295/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1429 - accuracy: 0.9545 - val_loss: 0.1547 - val_accuracy: 0.9519\n",
            "Epoch 296/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1436 - accuracy: 0.9548 - val_loss: 0.1541 - val_accuracy: 0.9538\n",
            "Epoch 297/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1428 - accuracy: 0.9548 - val_loss: 0.1543 - val_accuracy: 0.9519\n",
            "Epoch 298/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1431 - accuracy: 0.9547 - val_loss: 0.1531 - val_accuracy: 0.9519\n",
            "Epoch 299/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1431 - accuracy: 0.9547 - val_loss: 0.1522 - val_accuracy: 0.9519\n",
            "Epoch 300/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1430 - accuracy: 0.9536 - val_loss: 0.1528 - val_accuracy: 0.9519\n",
            "Epoch 301/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9545 - val_loss: 0.1530 - val_accuracy: 0.9538\n",
            "Epoch 302/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1434 - accuracy: 0.9547 - val_loss: 0.1547 - val_accuracy: 0.9538\n",
            "Epoch 303/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9541 - val_loss: 0.1524 - val_accuracy: 0.9538\n",
            "Epoch 304/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9548 - val_loss: 0.1544 - val_accuracy: 0.9531\n",
            "Epoch 305/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1434 - accuracy: 0.9548 - val_loss: 0.1539 - val_accuracy: 0.9531\n",
            "Epoch 306/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1434 - accuracy: 0.9547 - val_loss: 0.1550 - val_accuracy: 0.9519\n",
            "Epoch 307/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9541 - val_loss: 0.1538 - val_accuracy: 0.9519\n",
            "Epoch 308/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1430 - accuracy: 0.9547 - val_loss: 0.1557 - val_accuracy: 0.9531\n",
            "Epoch 309/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1430 - accuracy: 0.9545 - val_loss: 0.1520 - val_accuracy: 0.9538\n",
            "Epoch 310/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1430 - accuracy: 0.9545 - val_loss: 0.1531 - val_accuracy: 0.9519\n",
            "Epoch 311/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9547 - val_loss: 0.1540 - val_accuracy: 0.9519\n",
            "Epoch 312/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9545 - val_loss: 0.1544 - val_accuracy: 0.9519\n",
            "Epoch 313/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1427 - accuracy: 0.9545 - val_loss: 0.1542 - val_accuracy: 0.9519\n",
            "Epoch 314/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9548 - val_loss: 0.1548 - val_accuracy: 0.9531\n",
            "Epoch 315/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1426 - accuracy: 0.9552 - val_loss: 0.1560 - val_accuracy: 0.9519\n",
            "Epoch 316/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9547 - val_loss: 0.1555 - val_accuracy: 0.9519\n",
            "Epoch 317/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9544 - val_loss: 0.1544 - val_accuracy: 0.9519\n",
            "Epoch 318/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1437 - accuracy: 0.9542 - val_loss: 0.1541 - val_accuracy: 0.9538\n",
            "Epoch 319/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9545 - val_loss: 0.1536 - val_accuracy: 0.9538\n",
            "Epoch 320/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9545 - val_loss: 0.1552 - val_accuracy: 0.9519\n",
            "Epoch 321/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9552 - val_loss: 0.1551 - val_accuracy: 0.9531\n",
            "Epoch 322/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1430 - accuracy: 0.9545 - val_loss: 0.1556 - val_accuracy: 0.9519\n",
            "Epoch 323/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9547 - val_loss: 0.1514 - val_accuracy: 0.9538\n",
            "Epoch 324/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9544 - val_loss: 0.1542 - val_accuracy: 0.9538\n",
            "Epoch 325/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1437 - accuracy: 0.9542 - val_loss: 0.1475 - val_accuracy: 0.9538\n",
            "Epoch 326/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9545 - val_loss: 0.1506 - val_accuracy: 0.9519\n",
            "Epoch 327/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9547 - val_loss: 0.1519 - val_accuracy: 0.9519\n",
            "Epoch 328/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1435 - accuracy: 0.9541 - val_loss: 0.1537 - val_accuracy: 0.9538\n",
            "Epoch 329/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9548 - val_loss: 0.1508 - val_accuracy: 0.9519\n",
            "Epoch 330/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1429 - accuracy: 0.9544 - val_loss: 0.1520 - val_accuracy: 0.9538\n",
            "Epoch 331/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1428 - accuracy: 0.9552 - val_loss: 0.1524 - val_accuracy: 0.9519\n",
            "Epoch 332/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1430 - accuracy: 0.9550 - val_loss: 0.1524 - val_accuracy: 0.9538\n",
            "Epoch 333/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1431 - accuracy: 0.9544 - val_loss: 0.1527 - val_accuracy: 0.9538\n",
            "Epoch 334/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1430 - accuracy: 0.9555 - val_loss: 0.1539 - val_accuracy: 0.9519\n",
            "Epoch 335/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1432 - accuracy: 0.9544 - val_loss: 0.1509 - val_accuracy: 0.9531\n",
            "Epoch 336/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1429 - accuracy: 0.9550 - val_loss: 0.1523 - val_accuracy: 0.9531\n",
            "Epoch 337/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1431 - accuracy: 0.9544 - val_loss: 0.1527 - val_accuracy: 0.9519\n",
            "Epoch 338/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9544 - val_loss: 0.1530 - val_accuracy: 0.9538\n",
            "Epoch 339/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9550 - val_loss: 0.1528 - val_accuracy: 0.9538\n",
            "Epoch 340/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1427 - accuracy: 0.9547 - val_loss: 0.1528 - val_accuracy: 0.9519\n",
            "Epoch 341/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1432 - accuracy: 0.9548 - val_loss: 0.1544 - val_accuracy: 0.9519\n",
            "Epoch 342/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1427 - accuracy: 0.9545 - val_loss: 0.1550 - val_accuracy: 0.9538\n",
            "Epoch 343/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9548 - val_loss: 0.1551 - val_accuracy: 0.9538\n",
            "Epoch 344/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9547 - val_loss: 0.1535 - val_accuracy: 0.9538\n",
            "Epoch 345/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9544 - val_loss: 0.1533 - val_accuracy: 0.9538\n",
            "Epoch 346/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9548 - val_loss: 0.1540 - val_accuracy: 0.9538\n",
            "Epoch 347/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9539 - val_loss: 0.1556 - val_accuracy: 0.9531\n",
            "Epoch 348/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9547 - val_loss: 0.1532 - val_accuracy: 0.9538\n",
            "Epoch 349/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9547 - val_loss: 0.1532 - val_accuracy: 0.9519\n",
            "Epoch 350/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1427 - accuracy: 0.9545 - val_loss: 0.1545 - val_accuracy: 0.9538\n",
            "Epoch 351/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1429 - accuracy: 0.9544 - val_loss: 0.1542 - val_accuracy: 0.9519\n",
            "Epoch 352/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1432 - accuracy: 0.9542 - val_loss: 0.1510 - val_accuracy: 0.9531\n",
            "Epoch 353/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9550 - val_loss: 0.1524 - val_accuracy: 0.9538\n",
            "Epoch 354/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1426 - accuracy: 0.9548 - val_loss: 0.1550 - val_accuracy: 0.9531\n",
            "Epoch 355/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1431 - accuracy: 0.9545 - val_loss: 0.1553 - val_accuracy: 0.9538\n",
            "Epoch 356/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1430 - accuracy: 0.9545 - val_loss: 0.1557 - val_accuracy: 0.9519\n",
            "Epoch 357/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9547 - val_loss: 0.1557 - val_accuracy: 0.9519\n",
            "Epoch 358/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1432 - accuracy: 0.9548 - val_loss: 0.1530 - val_accuracy: 0.9531\n",
            "Epoch 359/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9545 - val_loss: 0.1546 - val_accuracy: 0.9519\n",
            "Epoch 360/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9544 - val_loss: 0.1535 - val_accuracy: 0.9538\n",
            "Epoch 361/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1429 - accuracy: 0.9545 - val_loss: 0.1544 - val_accuracy: 0.9519\n",
            "Epoch 362/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9553 - val_loss: 0.1538 - val_accuracy: 0.9525\n",
            "Epoch 363/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1437 - accuracy: 0.9538 - val_loss: 0.1541 - val_accuracy: 0.9519\n",
            "Epoch 364/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9545 - val_loss: 0.1547 - val_accuracy: 0.9538\n",
            "Epoch 365/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9545 - val_loss: 0.1527 - val_accuracy: 0.9519\n",
            "Epoch 366/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1432 - accuracy: 0.9541 - val_loss: 0.1517 - val_accuracy: 0.9538\n",
            "Epoch 367/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1428 - accuracy: 0.9550 - val_loss: 0.1522 - val_accuracy: 0.9519\n",
            "Epoch 368/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1429 - accuracy: 0.9547 - val_loss: 0.1533 - val_accuracy: 0.9519\n",
            "Epoch 369/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1429 - accuracy: 0.9545 - val_loss: 0.1535 - val_accuracy: 0.9538\n",
            "Epoch 370/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1426 - accuracy: 0.9547 - val_loss: 0.1533 - val_accuracy: 0.9531\n",
            "Epoch 371/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1427 - accuracy: 0.9545 - val_loss: 0.1545 - val_accuracy: 0.9531\n",
            "Epoch 372/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9547 - val_loss: 0.1547 - val_accuracy: 0.9538\n",
            "Epoch 373/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9545 - val_loss: 0.1530 - val_accuracy: 0.9538\n",
            "Epoch 374/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1427 - accuracy: 0.9548 - val_loss: 0.1543 - val_accuracy: 0.9531\n",
            "Epoch 375/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9547 - val_loss: 0.1552 - val_accuracy: 0.9538\n",
            "Epoch 376/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1427 - accuracy: 0.9545 - val_loss: 0.1542 - val_accuracy: 0.9538\n",
            "Epoch 377/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1426 - accuracy: 0.9547 - val_loss: 0.1556 - val_accuracy: 0.9519\n",
            "Epoch 378/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9545 - val_loss: 0.1534 - val_accuracy: 0.9519\n",
            "Epoch 379/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9552 - val_loss: 0.1535 - val_accuracy: 0.9538\n",
            "Epoch 380/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1428 - accuracy: 0.9544 - val_loss: 0.1540 - val_accuracy: 0.9538\n",
            "Epoch 381/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1427 - accuracy: 0.9550 - val_loss: 0.1544 - val_accuracy: 0.9538\n",
            "Epoch 382/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1428 - accuracy: 0.9548 - val_loss: 0.1538 - val_accuracy: 0.9538\n",
            "Epoch 383/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9541 - val_loss: 0.1558 - val_accuracy: 0.9519\n",
            "Epoch 384/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9550 - val_loss: 0.1548 - val_accuracy: 0.9519\n",
            "Epoch 385/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1434 - accuracy: 0.9544 - val_loss: 0.1534 - val_accuracy: 0.9538\n",
            "Epoch 386/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1427 - accuracy: 0.9548 - val_loss: 0.1536 - val_accuracy: 0.9538\n",
            "Epoch 387/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1466 - accuracy: 0.9539 - val_loss: 0.1557 - val_accuracy: 0.9538\n",
            "Epoch 388/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1433 - accuracy: 0.9542 - val_loss: 0.1488 - val_accuracy: 0.9538\n",
            "Epoch 389/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9545 - val_loss: 0.1514 - val_accuracy: 0.9519\n",
            "Epoch 390/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1427 - accuracy: 0.9553 - val_loss: 0.1495 - val_accuracy: 0.9531\n",
            "Epoch 391/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9541 - val_loss: 0.1514 - val_accuracy: 0.9538\n",
            "Epoch 392/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1426 - accuracy: 0.9548 - val_loss: 0.1523 - val_accuracy: 0.9538\n",
            "Epoch 393/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1427 - accuracy: 0.9545 - val_loss: 0.1522 - val_accuracy: 0.9519\n",
            "Epoch 394/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1432 - accuracy: 0.9550 - val_loss: 0.1533 - val_accuracy: 0.9538\n",
            "Epoch 395/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1429 - accuracy: 0.9541 - val_loss: 0.1530 - val_accuracy: 0.9538\n",
            "Epoch 396/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1427 - accuracy: 0.9548 - val_loss: 0.1539 - val_accuracy: 0.9519\n",
            "Epoch 397/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1430 - accuracy: 0.9548 - val_loss: 0.1545 - val_accuracy: 0.9519\n",
            "Epoch 398/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1429 - accuracy: 0.9547 - val_loss: 0.1538 - val_accuracy: 0.9538\n",
            "Epoch 399/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1427 - accuracy: 0.9548 - val_loss: 0.1540 - val_accuracy: 0.9538\n",
            "Epoch 400/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1431 - accuracy: 0.9545 - val_loss: 0.1542 - val_accuracy: 0.9538\n",
            "Epoch 401/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1428 - accuracy: 0.9544 - val_loss: 0.1543 - val_accuracy: 0.9538\n",
            "Epoch 402/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1427 - accuracy: 0.9548 - val_loss: 0.1544 - val_accuracy: 0.9519\n",
            "Epoch 403/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1427 - accuracy: 0.9547 - val_loss: 0.1554 - val_accuracy: 0.9519\n",
            "Epoch 404/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1428 - accuracy: 0.9547 - val_loss: 0.1541 - val_accuracy: 0.9538\n",
            "Epoch 405/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1430 - accuracy: 0.9542 - val_loss: 0.1549 - val_accuracy: 0.9538\n",
            "Epoch 406/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1427 - accuracy: 0.9545 - val_loss: 0.1548 - val_accuracy: 0.9531\n",
            "Epoch 407/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9550 - val_loss: 0.1549 - val_accuracy: 0.9538\n",
            "Epoch 408/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1428 - accuracy: 0.9548 - val_loss: 0.1542 - val_accuracy: 0.9519\n",
            "Epoch 409/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9547 - val_loss: 0.1547 - val_accuracy: 0.9519\n",
            "Epoch 410/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9544 - val_loss: 0.1543 - val_accuracy: 0.9519\n",
            "Epoch 411/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9545 - val_loss: 0.1549 - val_accuracy: 0.9519\n",
            "Epoch 412/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1429 - accuracy: 0.9545 - val_loss: 0.1542 - val_accuracy: 0.9538\n",
            "Epoch 413/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1426 - accuracy: 0.9545 - val_loss: 0.1544 - val_accuracy: 0.9531\n",
            "Epoch 414/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1428 - accuracy: 0.9553 - val_loss: 0.1561 - val_accuracy: 0.9531\n",
            "Epoch 415/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1427 - accuracy: 0.9544 - val_loss: 0.1570 - val_accuracy: 0.9538\n",
            "Epoch 416/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9544 - val_loss: 0.1564 - val_accuracy: 0.9519\n",
            "Epoch 417/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1430 - accuracy: 0.9552 - val_loss: 0.1565 - val_accuracy: 0.9519\n",
            "Epoch 418/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1426 - accuracy: 0.9550 - val_loss: 0.1553 - val_accuracy: 0.9531\n",
            "Epoch 419/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1427 - accuracy: 0.9545 - val_loss: 0.1572 - val_accuracy: 0.9538\n",
            "Epoch 420/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9547 - val_loss: 0.1574 - val_accuracy: 0.9531\n",
            "Epoch 421/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1430 - accuracy: 0.9545 - val_loss: 0.1559 - val_accuracy: 0.9531\n",
            "Epoch 422/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9548 - val_loss: 0.1580 - val_accuracy: 0.9538\n",
            "Epoch 423/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9544 - val_loss: 0.1583 - val_accuracy: 0.9519\n",
            "Epoch 424/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9547 - val_loss: 0.1590 - val_accuracy: 0.9538\n",
            "Epoch 425/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1437 - accuracy: 0.9544 - val_loss: 0.1466 - val_accuracy: 0.9519\n",
            "Epoch 426/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9544 - val_loss: 0.1493 - val_accuracy: 0.9538\n",
            "Epoch 427/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1430 - accuracy: 0.9547 - val_loss: 0.1530 - val_accuracy: 0.9500\n",
            "Epoch 428/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1431 - accuracy: 0.9548 - val_loss: 0.1542 - val_accuracy: 0.9519\n",
            "Epoch 429/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9541 - val_loss: 0.1544 - val_accuracy: 0.9519\n",
            "Epoch 430/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1430 - accuracy: 0.9547 - val_loss: 0.1534 - val_accuracy: 0.9538\n",
            "Epoch 431/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9552 - val_loss: 0.1547 - val_accuracy: 0.9519\n",
            "Epoch 432/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9547 - val_loss: 0.1545 - val_accuracy: 0.9538\n",
            "Epoch 433/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1426 - accuracy: 0.9552 - val_loss: 0.1557 - val_accuracy: 0.9519\n",
            "Epoch 434/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9545 - val_loss: 0.1527 - val_accuracy: 0.9538\n",
            "Epoch 435/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1425 - accuracy: 0.9547 - val_loss: 0.1535 - val_accuracy: 0.9519\n",
            "Epoch 436/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1429 - accuracy: 0.9547 - val_loss: 0.1540 - val_accuracy: 0.9519\n",
            "Epoch 437/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1429 - accuracy: 0.9545 - val_loss: 0.1536 - val_accuracy: 0.9538\n",
            "Epoch 438/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1427 - accuracy: 0.9550 - val_loss: 0.1556 - val_accuracy: 0.9519\n",
            "Epoch 439/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1431 - accuracy: 0.9544 - val_loss: 0.1548 - val_accuracy: 0.9538\n",
            "Epoch 440/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1426 - accuracy: 0.9552 - val_loss: 0.1543 - val_accuracy: 0.9519\n",
            "Epoch 441/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1427 - accuracy: 0.9542 - val_loss: 0.1547 - val_accuracy: 0.9519\n",
            "Epoch 442/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9545 - val_loss: 0.1539 - val_accuracy: 0.9513\n",
            "Epoch 443/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1429 - accuracy: 0.9550 - val_loss: 0.1560 - val_accuracy: 0.9519\n",
            "Epoch 444/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9547 - val_loss: 0.1557 - val_accuracy: 0.9519\n",
            "Epoch 445/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1428 - accuracy: 0.9547 - val_loss: 0.1596 - val_accuracy: 0.9519\n",
            "Epoch 446/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1441 - accuracy: 0.9548 - val_loss: 0.1490 - val_accuracy: 0.9519\n",
            "Epoch 447/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1430 - accuracy: 0.9547 - val_loss: 0.1529 - val_accuracy: 0.9519\n",
            "Epoch 448/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9544 - val_loss: 0.1527 - val_accuracy: 0.9538\n",
            "Epoch 449/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1426 - accuracy: 0.9550 - val_loss: 0.1542 - val_accuracy: 0.9538\n",
            "Epoch 450/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9550 - val_loss: 0.1563 - val_accuracy: 0.9519\n",
            "Epoch 451/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1427 - accuracy: 0.9547 - val_loss: 0.1561 - val_accuracy: 0.9519\n",
            "Epoch 452/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1427 - accuracy: 0.9548 - val_loss: 0.1563 - val_accuracy: 0.9519\n",
            "Epoch 453/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1430 - accuracy: 0.9547 - val_loss: 0.1553 - val_accuracy: 0.9519\n",
            "Epoch 454/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9548 - val_loss: 0.1555 - val_accuracy: 0.9531\n",
            "Epoch 455/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1429 - accuracy: 0.9550 - val_loss: 0.1549 - val_accuracy: 0.9531\n",
            "Epoch 456/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9548 - val_loss: 0.1555 - val_accuracy: 0.9538\n",
            "Epoch 457/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1427 - accuracy: 0.9548 - val_loss: 0.1548 - val_accuracy: 0.9531\n",
            "Epoch 458/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1430 - accuracy: 0.9544 - val_loss: 0.1543 - val_accuracy: 0.9538\n",
            "Epoch 459/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1430 - accuracy: 0.9542 - val_loss: 0.1566 - val_accuracy: 0.9519\n",
            "Epoch 460/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9547 - val_loss: 0.1583 - val_accuracy: 0.9519\n",
            "Epoch 461/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9545 - val_loss: 0.1575 - val_accuracy: 0.9538\n",
            "Epoch 462/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1428 - accuracy: 0.9545 - val_loss: 0.1543 - val_accuracy: 0.9519\n",
            "Epoch 463/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1426 - accuracy: 0.9544 - val_loss: 0.1557 - val_accuracy: 0.9519\n",
            "Epoch 464/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9541 - val_loss: 0.1558 - val_accuracy: 0.9519\n",
            "Epoch 465/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9545 - val_loss: 0.1560 - val_accuracy: 0.9519\n",
            "Epoch 466/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1426 - accuracy: 0.9544 - val_loss: 0.1547 - val_accuracy: 0.9538\n",
            "Epoch 467/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1426 - accuracy: 0.9542 - val_loss: 0.1564 - val_accuracy: 0.9519\n",
            "Epoch 468/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1430 - accuracy: 0.9550 - val_loss: 0.1547 - val_accuracy: 0.9538\n",
            "Epoch 469/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1427 - accuracy: 0.9545 - val_loss: 0.1542 - val_accuracy: 0.9519\n",
            "Epoch 470/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1424 - accuracy: 0.9545 - val_loss: 0.1535 - val_accuracy: 0.9531\n",
            "Epoch 471/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1427 - accuracy: 0.9544 - val_loss: 0.1543 - val_accuracy: 0.9519\n",
            "Epoch 472/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1427 - accuracy: 0.9545 - val_loss: 0.1532 - val_accuracy: 0.9538\n",
            "Epoch 473/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1428 - accuracy: 0.9548 - val_loss: 0.1545 - val_accuracy: 0.9531\n",
            "Epoch 474/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1429 - accuracy: 0.9550 - val_loss: 0.1549 - val_accuracy: 0.9519\n",
            "Epoch 475/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1428 - accuracy: 0.9548 - val_loss: 0.1545 - val_accuracy: 0.9538\n",
            "Epoch 476/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1425 - accuracy: 0.9552 - val_loss: 0.1545 - val_accuracy: 0.9531\n",
            "Epoch 477/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9547 - val_loss: 0.1544 - val_accuracy: 0.9538\n",
            "Epoch 478/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1430 - accuracy: 0.9548 - val_loss: 0.1559 - val_accuracy: 0.9531\n",
            "Epoch 479/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9545 - val_loss: 0.1555 - val_accuracy: 0.9538\n",
            "Epoch 480/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1430 - accuracy: 0.9545 - val_loss: 0.1548 - val_accuracy: 0.9538\n",
            "Epoch 481/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1425 - accuracy: 0.9545 - val_loss: 0.1548 - val_accuracy: 0.9538\n",
            "Epoch 482/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9547 - val_loss: 0.1547 - val_accuracy: 0.9538\n",
            "Epoch 483/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1426 - accuracy: 0.9544 - val_loss: 0.1566 - val_accuracy: 0.9531\n",
            "Epoch 484/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9547 - val_loss: 0.1579 - val_accuracy: 0.9538\n",
            "Epoch 485/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9548 - val_loss: 0.1577 - val_accuracy: 0.9531\n",
            "Epoch 486/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9541 - val_loss: 0.1567 - val_accuracy: 0.9538\n",
            "Epoch 487/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1427 - accuracy: 0.9545 - val_loss: 0.1572 - val_accuracy: 0.9538\n",
            "Epoch 488/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1427 - accuracy: 0.9545 - val_loss: 0.1590 - val_accuracy: 0.9519\n",
            "Epoch 489/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1426 - accuracy: 0.9548 - val_loss: 0.1581 - val_accuracy: 0.9538\n",
            "Epoch 490/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1426 - accuracy: 0.9547 - val_loss: 0.1587 - val_accuracy: 0.9519\n",
            "Epoch 491/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9548 - val_loss: 0.1595 - val_accuracy: 0.9519\n",
            "Epoch 492/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1428 - accuracy: 0.9544 - val_loss: 0.1577 - val_accuracy: 0.9538\n",
            "Epoch 493/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1431 - accuracy: 0.9545 - val_loss: 0.1579 - val_accuracy: 0.9538\n",
            "Epoch 494/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1427 - accuracy: 0.9552 - val_loss: 0.1551 - val_accuracy: 0.9519\n",
            "Epoch 495/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1428 - accuracy: 0.9548 - val_loss: 0.1545 - val_accuracy: 0.9538\n",
            "Epoch 496/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1426 - accuracy: 0.9544 - val_loss: 0.1561 - val_accuracy: 0.9538\n",
            "Epoch 497/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1428 - accuracy: 0.9541 - val_loss: 0.1592 - val_accuracy: 0.9519\n",
            "Epoch 498/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1435 - accuracy: 0.9545 - val_loss: 0.1526 - val_accuracy: 0.9519\n",
            "Epoch 499/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9545 - val_loss: 0.1550 - val_accuracy: 0.9519\n",
            "Epoch 500/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1432 - accuracy: 0.9545 - val_loss: 0.1565 - val_accuracy: 0.9538\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#y_pred_DNN = (model.predict(DNNX) > 0.5).astype(\"int32\")\n",
        "DTr = model.evaluate(DX_train, Dy_train,verbose=0)[1]\n",
        "DTe = model.evaluate(DX_test, Dy_test,verbose=0)[1]\n",
        "DTr,DTe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhG0YCbhASH9",
        "outputId": "2000faa9-6242-45ff-bad9-d6d629978702"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9547500014305115, 0.9514999985694885)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_DNN = (model.predict(DX_test) > 0.5).astype(\"int32\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKbxrS57kOBE",
        "outputId": "cc6f757a-68a8-4db9-81d3-becd2e5d096e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = pd.DataFrame(\n",
        "    {\n",
        "    \"SVM\":[STr,STe],\n",
        "    \"KNN\":[KTr,KTe],\n",
        "    \"RF\" :[RTr,RTe],\n",
        "    \"LR\" :[LTr,LTe],\n",
        "    \"ANN\":[ATr,ATe],\n",
        "    \"XGB\":[XTr,XTe],\n",
        "    \"DNN\":[DTr,DTe]})\n",
        "acc.index = [\"train\", \"test\"]\n",
        "acc = acc.T\n",
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "v_YjlCdOO1JY",
        "outputId": "94e71038-f04c-4331-83dd-d797b46f2e77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        train    test\n",
              "SVM  0.950500  0.9500\n",
              "KNN  0.954875  0.9445\n",
              "RF   0.943875  0.9505\n",
              "LR   0.950000  0.9500\n",
              "ANN  0.957625  0.9515\n",
              "XGB  0.956875  0.9410\n",
              "DNN  0.954750  0.9515"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-48bca2a4-fc9e-4831-ae59-8a6fd19b8396\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>0.950500</td>\n",
              "      <td>0.9500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>0.954875</td>\n",
              "      <td>0.9445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>0.943875</td>\n",
              "      <td>0.9505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LR</th>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.9500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ANN</th>\n",
              "      <td>0.957625</td>\n",
              "      <td>0.9515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGB</th>\n",
              "      <td>0.956875</td>\n",
              "      <td>0.9410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DNN</th>\n",
              "      <td>0.954750</td>\n",
              "      <td>0.9515</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48bca2a4-fc9e-4831-ae59-8a6fd19b8396')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-48bca2a4-fc9e-4831-ae59-8a6fd19b8396 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-48bca2a4-fc9e-4831-ae59-8a6fd19b8396');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **AutoML Individual and AutoML DNN**"
      ],
      "metadata": {
        "id": "nJaAMLDKKfKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#H2O AutoML"
      ],
      "metadata": {
        "id": "EhNt_UkjDKcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h2o\n",
        "import h2o\n",
        "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
        "h2o.init()\n",
        "from h2o.model.segment_models import H2OFrame\n",
        "from h2o.automl import H2OAutoML\n",
        "print(\"All Library Loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "id": "iwMF9ROeDOzF",
        "outputId": "7cc02517-6f02-45b6-bb2a-bd43e325b1ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: h2o in /usr/local/lib/python3.10/dist-packages (3.40.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from h2o) (2.27.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from h2o) (0.8.10)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from h2o) (0.18.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (3.4)\n",
            "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
            "Attempting to start a local H2O server...\n",
            "  Java Version: openjdk version \"11.0.19\" 2023-04-18; OpenJDK Runtime Environment (build 11.0.19+7-post-Ubuntu-0ubuntu120.04.1); OpenJDK 64-Bit Server VM (build 11.0.19+7-post-Ubuntu-0ubuntu120.04.1, mixed mode, sharing)\n",
            "  Starting server from /usr/local/lib/python3.10/dist-packages/h2o/backend/bin/h2o.jar\n",
            "  Ice root: /tmp/tmpgio1mir5\n",
            "  JVM stdout: /tmp/tmpgio1mir5/h2o_unknownUser_started_from_python.out\n",
            "  JVM stderr: /tmp/tmpgio1mir5/h2o_unknownUser_started_from_python.err\n",
            "  Server is running at http://127.0.0.1:54321\n",
            "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "--------------------------  -----------------------------------------------------------------------------------------\n",
              "H2O_cluster_uptime:         03 secs\n",
              "H2O_cluster_timezone:       Etc/UTC\n",
              "H2O_data_parsing_timezone:  UTC\n",
              "H2O_cluster_version:        3.40.0.4\n",
              "H2O_cluster_version_age:    2 months and 5 days\n",
              "H2O_cluster_name:           H2O_from_python_unknownUser_u0obwu\n",
              "H2O_cluster_total_nodes:    1\n",
              "H2O_cluster_free_memory:    3.170 Gb\n",
              "H2O_cluster_total_cores:    2\n",
              "H2O_cluster_allowed_cores:  2\n",
              "H2O_cluster_status:         locked, healthy\n",
              "H2O_connection_url:         http://127.0.0.1:54321\n",
              "H2O_connection_proxy:       {\"http\": null, \"https\": null, \"colab_language_server\": \"/usr/colab/bin/language_service\"}\n",
              "H2O_internal_security:      False\n",
              "Python_version:             3.10.12 final\n",
              "--------------------------  -----------------------------------------------------------------------------------------"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "#h2o-table-1.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-1 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-1 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-1 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-1 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-1 .h2o-table th,\n",
              "#h2o-table-1 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption></caption>\n",
              "    <thead></thead>\n",
              "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
              "<td>03 secs</td></tr>\n",
              "<tr><td>H2O_cluster_timezone:</td>\n",
              "<td>Etc/UTC</td></tr>\n",
              "<tr><td>H2O_data_parsing_timezone:</td>\n",
              "<td>UTC</td></tr>\n",
              "<tr><td>H2O_cluster_version:</td>\n",
              "<td>3.40.0.4</td></tr>\n",
              "<tr><td>H2O_cluster_version_age:</td>\n",
              "<td>2 months and 5 days</td></tr>\n",
              "<tr><td>H2O_cluster_name:</td>\n",
              "<td>H2O_from_python_unknownUser_u0obwu</td></tr>\n",
              "<tr><td>H2O_cluster_total_nodes:</td>\n",
              "<td>1</td></tr>\n",
              "<tr><td>H2O_cluster_free_memory:</td>\n",
              "<td>3.170 Gb</td></tr>\n",
              "<tr><td>H2O_cluster_total_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_allowed_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_status:</td>\n",
              "<td>locked, healthy</td></tr>\n",
              "<tr><td>H2O_connection_url:</td>\n",
              "<td>http://127.0.0.1:54321</td></tr>\n",
              "<tr><td>H2O_connection_proxy:</td>\n",
              "<td>{\"http\": null, \"https\": null, \"colab_language_server\": \"/usr/colab/bin/language_service\"}</td></tr>\n",
              "<tr><td>H2O_internal_security:</td>\n",
              "<td>False</td></tr>\n",
              "<tr><td>Python_version:</td>\n",
              "<td>3.10.12 final</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Library Loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kWdoOLbsF2qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X-QiglXeF_XE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8P1HTOHbugE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "asKywHvIu83f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z5wVvB0pvWHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train, valid = hdf.split_frame(ratios=[.8], seed=123)\n",
        "#hdf = h2o.H2OFrame(df)\n",
        "#hdf[\"diagnosis\"] = hdf[\"diagnosis\"].asfactor()\n",
        "hy = \"diagnosis\"\n",
        "hx = list(df.columns)\n",
        "hx.remove(hy)\n",
        "hdf  = df.copy()\n",
        "hdf.iloc[:,1:] = StandardScaler().fit_transform(hdf.iloc[:,1:])\n",
        "hdf.iloc[:,0] = LabelEncoder().fit_transform(hdf.iloc[:,0])\n",
        "hdf.iloc[:,0] = hdf.iloc[:,0].astype('category')\n",
        "train1, valid1 = train_test_split(hdf, test_size=0.2,random_state=123)\n",
        "train = h2o.H2OFrame(train1)\n",
        "valid = h2o.H2OFrame(valid1)\n",
        "train[\"diagnosis\"] = train[\"diagnosis\"].asfactor()\n",
        "valid[\"diagnosis\"] = valid[\"diagnosis\"].asfactor()"
      ],
      "metadata": {
        "id": "NVoFNbYCGxGh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26526340-fa15-4736-b58f-82a2298bcc9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-460708a37676>:9: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  hdf.iloc[:,0] = LabelEncoder().fit_transform(hdf.iloc[:,0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "st = time.time()\n",
        "aml = H2OAutoML(max_models = 10, seed = 123, verbosity=\"info\",\n",
        "                nfolds=10, sort_metric='accuracy')\n",
        "aml.train(x = hx, y = hy, training_frame = train,\n",
        "          validation_frame = valid)\n",
        "autoend = time.time() - st"
      ],
      "metadata": {
        "id": "7JNO6XnVHH5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a83716dc-e56b-4fe0-b425-f6449500e94c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoML progress: |\n",
            "11:20:08.750: Project: AutoML_1_20230704_112008\n",
            "11:20:08.752: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n",
            "11:20:08.758: Setting stopping tolerance adaptively based on the training frame: 0.011180339887498949\n",
            "11:20:08.758: Build control seed: 123\n",
            "11:20:08.759: training frame: Frame key: AutoML_1_20230704_112008_training_py_1_sid_bee4    cols: 31    rows: 8000  chunks: 2    size: 1926168  checksum: -5600652261642703400\n",
            "11:20:08.765: validation frame: Frame key: py_2_sid_bee4    cols: 31    rows: 2000  chunks: 1    size: 482912  checksum: -8629894929602001568\n",
            "11:20:08.765: leaderboard frame: NULL\n",
            "11:20:08.765: blending frame: NULL\n",
            "11:20:08.765: response column: diagnosis\n",
            "11:20:08.765: fold column: null\n",
            "11:20:08.766: weights column: null\n",
            "11:20:08.800: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (7g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (7g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (6g, 60w)]}, {StackedEnsemble : [monotonic (9g, 10w), best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
            "11:20:08.837: AutoML job created: 2023.07.04 11:20:08.709\n",
            "11:20:08.838: AutoML build started: 2023.07.04 11:20:08.838\n",
            "11:20:08.889: AutoML: starting XGBoost_1_AutoML_1_20230704_112008 model training\n",
            "\n",
            "██\n",
            "11:20:40.800: New leader: XGBoost_1_AutoML_1_20230704_112008, accuracy: 0.94825\n",
            "11:20:40.806: AutoML: starting GLM_1_AutoML_1_20230704_112008 model training\n",
            "\n",
            "███\n",
            "11:20:57.447: AutoML: starting GBM_1_AutoML_1_20230704_112008 model training\n",
            "\n",
            "█\n",
            "11:21:56.875: AutoML: starting XGBoost_2_AutoML_1_20230704_112008 model training\n",
            "\n",
            "█\n",
            "11:22:16.226: AutoML: starting DRF_1_AutoML_1_20230704_112008 model training\n",
            "\n",
            "███\n",
            "11:22:44.58: New leader: DRF_1_AutoML_1_20230704_112008, accuracy: 0.945125\n",
            "11:22:44.60: AutoML: starting GBM_2_AutoML_1_20230704_112008 model training\n",
            "\n",
            "█\n",
            "11:23:18.481: AutoML: starting GBM_3_AutoML_1_20230704_112008 model training\n",
            "\n",
            "█\n",
            "11:23:52.87: AutoML: starting GBM_4_AutoML_1_20230704_112008 model training\n",
            "\n",
            "█\n",
            "11:24:28.782: AutoML: starting XGBoost_3_AutoML_1_20230704_112008 model training\n",
            "\n",
            "█\n",
            "11:24:45.739: AutoML: starting XRT_1_AutoML_1_20230704_112008 model training\n",
            "\n",
            "██\n",
            "11:25:19.666: No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'monotonic'.\n",
            "11:25:19.682: AutoML: starting StackedEnsemble_BestOfFamily_1_AutoML_1_20230704_112008 model training\n",
            "\n",
            "███\n",
            "11:25:33.195: AutoML: starting StackedEnsemble_AllModels_1_AutoML_1_20230704_112008 model training\n",
            "\n",
            "████████████████████████████████████████████| (done) 100%\n",
            "\n",
            "11:25:50.441: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GLM : [def_1 (1g, 10w)]}, {GBM : [def_5 (1g, 10w)]}, {XGBoost : [def_1 (2g, 10w)]}, {DRF : [def_1 (2g, 10w)]}, {GBM : [def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w)]}, {XGBoost : [def_3 (3g, 10w)]}, {DRF : [XRT (3g, 10w)]}, {StackedEnsemble : [best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
            "11:25:50.441: AutoML build stopped: 2023.07.04 11:25:50.441\n",
            "11:25:50.441: AutoML build done: built 10 models\n",
            "11:25:50.442: AutoML duration:  5 min 41.603 sec\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lbo606kFH4Zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lb = aml.leaderboard\n",
        "lb.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "gmCXw_D_4y1D",
        "outputId": "f9081f5f-0b6a-497e-f11e-2a0424b77b87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model_id                              accuracy       auc    logloss     aucpr    mean_per_class_error      rmse        mse\n",
              "----------------------------------  ----------  --------  ---------  --------  ----------------------  --------  ---------\n",
              "DRF_1_AutoML_1_20230704_112008        0.945125  0.989177   0.141093  0.984216               0.056397   0.202717  0.0410943\n",
              "XRT_1_AutoML_1_20230704_112008        0.945625  0.989034   0.15255   0.984006               0.0589083  0.202303  0.0409264\n",
              "XGBoost_3_AutoML_1_20230704_112008    0.948     0.990641   0.125343  0.986013               0.0535747  0.196101  0.0384557\n",
              "XGBoost_1_AutoML_1_20230704_112008    0.94825   0.990807   0.12301   0.986256               0.0542833  0.194461  0.037815\n",
              "GBM_4_AutoML_1_20230704_112008        0.949125  0.990796   0.12375   0.986334               0.0527628  0.193394  0.0374012\n",
              "GBM_2_AutoML_1_20230704_112008        0.949125  0.990889   0.122321  0.986528               0.055881   0.193309  0.0373683\n",
              "GBM_3_AutoML_1_20230704_112008        0.949375  0.991048   0.122135  0.986551               0.0517268  0.19245   0.037037\n",
              "XGBoost_2_AutoML_1_20230704_112008    0.9495    0.990286   0.129042  0.985682               0.0508957  0.196218  0.0385014\n",
              "GLM_1_AutoML_1_20230704_112008        0.949625  0.990625   0.120152  0.986297               0.0545628  0.192167  0.0369281\n",
              "GBM_1_AutoML_1_20230704_112008        0.94975   0.991147   0.117772  0.986794               0.051422   0.190749  0.0363851\n",
              "[10 rows x 8 columns]\n"
            ],
            "text/html": [
              "<table class='dataframe'>\n",
              "<thead>\n",
              "<tr><th>model_id                          </th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">      mse</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DRF_1_AutoML_1_20230704_112008    </td><td style=\"text-align: right;\">  0.945125</td><td style=\"text-align: right;\">0.989177</td><td style=\"text-align: right;\"> 0.141093</td><td style=\"text-align: right;\">0.984216</td><td style=\"text-align: right;\">             0.056397 </td><td style=\"text-align: right;\">0.202717</td><td style=\"text-align: right;\">0.0410943</td></tr>\n",
              "<tr><td>XRT_1_AutoML_1_20230704_112008    </td><td style=\"text-align: right;\">  0.945625</td><td style=\"text-align: right;\">0.989034</td><td style=\"text-align: right;\"> 0.15255 </td><td style=\"text-align: right;\">0.984006</td><td style=\"text-align: right;\">             0.0589083</td><td style=\"text-align: right;\">0.202303</td><td style=\"text-align: right;\">0.0409264</td></tr>\n",
              "<tr><td>XGBoost_3_AutoML_1_20230704_112008</td><td style=\"text-align: right;\">  0.948   </td><td style=\"text-align: right;\">0.990641</td><td style=\"text-align: right;\"> 0.125343</td><td style=\"text-align: right;\">0.986013</td><td style=\"text-align: right;\">             0.0535747</td><td style=\"text-align: right;\">0.196101</td><td style=\"text-align: right;\">0.0384557</td></tr>\n",
              "<tr><td>XGBoost_1_AutoML_1_20230704_112008</td><td style=\"text-align: right;\">  0.94825 </td><td style=\"text-align: right;\">0.990807</td><td style=\"text-align: right;\"> 0.12301 </td><td style=\"text-align: right;\">0.986256</td><td style=\"text-align: right;\">             0.0542833</td><td style=\"text-align: right;\">0.194461</td><td style=\"text-align: right;\">0.037815 </td></tr>\n",
              "<tr><td>GBM_4_AutoML_1_20230704_112008    </td><td style=\"text-align: right;\">  0.949125</td><td style=\"text-align: right;\">0.990796</td><td style=\"text-align: right;\"> 0.12375 </td><td style=\"text-align: right;\">0.986334</td><td style=\"text-align: right;\">             0.0527628</td><td style=\"text-align: right;\">0.193394</td><td style=\"text-align: right;\">0.0374012</td></tr>\n",
              "<tr><td>GBM_2_AutoML_1_20230704_112008    </td><td style=\"text-align: right;\">  0.949125</td><td style=\"text-align: right;\">0.990889</td><td style=\"text-align: right;\"> 0.122321</td><td style=\"text-align: right;\">0.986528</td><td style=\"text-align: right;\">             0.055881 </td><td style=\"text-align: right;\">0.193309</td><td style=\"text-align: right;\">0.0373683</td></tr>\n",
              "<tr><td>GBM_3_AutoML_1_20230704_112008    </td><td style=\"text-align: right;\">  0.949375</td><td style=\"text-align: right;\">0.991048</td><td style=\"text-align: right;\"> 0.122135</td><td style=\"text-align: right;\">0.986551</td><td style=\"text-align: right;\">             0.0517268</td><td style=\"text-align: right;\">0.19245 </td><td style=\"text-align: right;\">0.037037 </td></tr>\n",
              "<tr><td>XGBoost_2_AutoML_1_20230704_112008</td><td style=\"text-align: right;\">  0.9495  </td><td style=\"text-align: right;\">0.990286</td><td style=\"text-align: right;\"> 0.129042</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">             0.0508957</td><td style=\"text-align: right;\">0.196218</td><td style=\"text-align: right;\">0.0385014</td></tr>\n",
              "<tr><td>GLM_1_AutoML_1_20230704_112008    </td><td style=\"text-align: right;\">  0.949625</td><td style=\"text-align: right;\">0.990625</td><td style=\"text-align: right;\"> 0.120152</td><td style=\"text-align: right;\">0.986297</td><td style=\"text-align: right;\">             0.0545628</td><td style=\"text-align: right;\">0.192167</td><td style=\"text-align: right;\">0.0369281</td></tr>\n",
              "<tr><td>GBM_1_AutoML_1_20230704_112008    </td><td style=\"text-align: right;\">  0.94975 </td><td style=\"text-align: right;\">0.991147</td><td style=\"text-align: right;\"> 0.117772</td><td style=\"text-align: right;\">0.986794</td><td style=\"text-align: right;\">             0.051422 </td><td style=\"text-align: right;\">0.190749</td><td style=\"text-align: right;\">0.0363851</td></tr>\n",
              "</tbody>\n",
              "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[10 rows x 8 columns]</pre>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = aml.get_best_model()\n",
        "best_model"
      ],
      "metadata": {
        "id": "vlH8zwtisQU1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5f71c877-e6fc-44d0-fc8a-f043fc8d7383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model Details\n",
              "=============\n",
              "H2ORandomForestEstimator : Distributed Random Forest\n",
              "Model Key: DRF_1_AutoML_1_20230704_112008\n",
              "\n",
              "\n",
              "Model Summary: \n",
              "    number_of_trees    number_of_internal_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n",
              "--  -----------------  --------------------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n",
              "    46                 46                          199280                 15           20           18.2174       311           369           340\n",
              "\n",
              "ModelMetricsBinomial: drf\n",
              "** Reported on train data. **\n",
              "\n",
              "MSE: 0.04326800279168445\n",
              "RMSE: 0.2080096218728462\n",
              "LogLoss: 0.20428151575245082\n",
              "Mean Per-Class Error: 0.057211674235314855\n",
              "AUC: 0.9860384526971423\n",
              "AUCPR: 0.9800859943345126\n",
              "Gini: 0.9720769053942846\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4666666666666667\n",
              "       0     1     Error    Rate\n",
              "-----  ----  ----  -------  --------------\n",
              "0      4652  269   0.0547   (269.0/4921.0)\n",
              "1      184   2895  0.0598   (184.0/3079.0)\n",
              "Total  4836  3164  0.0566   (453.0/8000.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.466667     0.927439  105\n",
              "max f2                       0.294118     0.945237  140\n",
              "max f0point5                 0.647059     0.94207   70\n",
              "max accuracy                 0.5          0.94375   100\n",
              "max precision                0.956522     0.998262  4\n",
              "max recall                   0            1         197\n",
              "max specificity              1            0.99939   0\n",
              "max absolute_mcc             0.5          0.881501  100\n",
              "max min_per_class_accuracy   0.454545     0.942839  108\n",
              "max mean_per_class_accuracy  0.45         0.943213  109\n",
              "max tns                      1            4918      0\n",
              "max fns                      1            1374      0\n",
              "max fps                      0            4921      197\n",
              "max tps                      0            3079      197\n",
              "max tnr                      1            0.99939   0\n",
              "max fnr                      1            0.446249  0\n",
              "max fpr                      0            1         197\n",
              "max tpr                      0            1         197\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 38.49 %, avg score: 38.54 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.2135                      1                  2.59368    2.59368            0.998244         1          0.998244                    1                   0.553751        0.553751                   159.368   159.368            0.553142\n",
              "2        0.30125                     0.789474           2.47611    2.55943            0.952991         0.893171   0.985062                    0.968882            0.217278        0.77103                    147.611   155.943            0.763714\n",
              "3        0.40025                     0.444444           1.75841    2.3613             0.676768         0.62211    0.908807                    0.88311             0.174082        0.945112                   75.8409   136.13             0.885775\n",
              "4        0.504                       0.117647           0.438258   1.96544            0.168675         0.255875   0.756448                    0.753991            0.0454693       0.990581                   -56.1742  96.5439            0.791028\n",
              "5        1                           0                  0.0189892  1                  0.00730847       0.0108765  0.384875                    0.385406            0.00941864      1                          -98.1011  0                  0\n",
              "\n",
              "ModelMetricsBinomial: drf\n",
              "** Reported on validation data. **\n",
              "\n",
              "MSE: 0.036937276832765605\n",
              "RMSE: 0.19219073035077838\n",
              "LogLoss: 0.14079214212429528\n",
              "Mean Per-Class Error: 0.04713423229341206\n",
              "AUC: 0.9915375408920449\n",
              "AUCPR: 0.9873978367714009\n",
              "Gini: 0.9830750817840899\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4565217391304348\n",
              "       0     1    Error    Rate\n",
              "-----  ----  ---  -------  -------------\n",
              "0      1187  58   0.0466   (58.0/1245.0)\n",
              "1      36    719  0.0477   (36.0/755.0)\n",
              "Total  1223  777  0.047    (94.0/2000.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.456522     0.938642  27\n",
              "max f2                       0.304348     0.956846  34\n",
              "max f0point5                 0.652174     0.952449  17\n",
              "max accuracy                 0.492754     0.953     25\n",
              "max precision                1            1         0\n",
              "max recall                   0            1         48\n",
              "max specificity              1            1         0\n",
              "max absolute_mcc             0.456522     0.900811  27\n",
              "max min_per_class_accuracy   0.456522     0.952318  27\n",
              "max mean_per_class_accuracy  0.434783     0.953084  28\n",
              "max tns                      1            1245      0\n",
              "max fns                      1            445       0\n",
              "max fps                      0            1245      48\n",
              "max tps                      0            755       48\n",
              "max tnr                      1            1         0\n",
              "max fnr                      1            0.589404  0\n",
              "max fpr                      0            1         48\n",
              "max tpr                      0            1         48\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 37.75 %, avg score: 37.82 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.155                       1                  2.64901     2.64901            1                1          1                           1                   0.410596        0.410596                   164.901   164.901            0.410596\n",
              "2        0.2005                      0.978261           2.64901     2.64901            1                0.978261   1                           0.995067            0.12053         0.531126                   164.901   164.901            0.531126\n",
              "3        0.3025                      0.782609           2.55811     2.61836            0.965686         0.890239   0.98843                     0.95972             0.260927        0.792053                   155.811   161.836            0.78643\n",
              "4        0.401                       0.413043           1.73463     2.40128            0.654822         0.59229    0.906484                    0.869466            0.170861        0.962914                   73.4629   140.128            0.902673\n",
              "5        0.5015                      0.108696           0.342658    1.98874            0.129353         0.241834   0.750748                    0.743689            0.0344371       0.997351                   -65.7342  98.8736            0.796548\n",
              "6        0.6315                      0.0217391          0.0101885   1.58143            0.00384615       0.0399666  0.596991                    0.598822            0.0013245       0.998675                   -98.9812  58.1434            0.58984\n",
              "7        1                           0                  0.00359431  1                  0.00135685       0          0.3775                      0.378156            0.0013245       1                          -99.6406  0                  0\n",
              "\n",
              "ModelMetricsBinomial: drf\n",
              "** Reported on cross-validation data. **\n",
              "\n",
              "MSE: 0.04109426250888458\n",
              "RMSE: 0.20271719835496094\n",
              "LogLoss: 0.14109268080346257\n",
              "Mean Per-Class Error: 0.05639704934588783\n",
              "AUC: 0.9891767351896238\n",
              "AUCPR: 0.984216068014286\n",
              "Gini: 0.9783534703792476\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.48\n",
              "       0     1     Error    Rate\n",
              "-----  ----  ----  -------  --------------\n",
              "0      4676  245   0.0498   (245.0/4921.0)\n",
              "1      194   2885  0.063    (194.0/3079.0)\n",
              "Total  4870  3130  0.0549   (439.0/8000.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.48         0.929296  54\n",
              "max f2                       0.32         0.949712  76\n",
              "max f0point5                 0.68         0.947539  29\n",
              "max accuracy                 0.52         0.945125  51\n",
              "max precision                1            1         0\n",
              "max recall                   0            1         135\n",
              "max specificity              1            1         0\n",
              "max absolute_mcc             0.48         0.884544  54\n",
              "max min_per_class_accuracy   0.44         0.940459  59\n",
              "max mean_per_class_accuracy  0.48         0.943603  54\n",
              "max tns                      1            4921      0\n",
              "max fns                      1            1720      0\n",
              "max fps                      0            4921      135\n",
              "max tps                      0            3079      135\n",
              "max tnr                      1            1         0\n",
              "max fnr                      1            0.558623  0\n",
              "max fpr                      0            1         135\n",
              "max tpr                      0            1         135\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 38.49 %, avg score: 38.55 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift         cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  -----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.169875                    1                  2.59825      2.59825            1                1            1                           1                   0.441377        0.441377                   159.825   159.825            0.441377\n",
              "2        0.20075                     0.98               2.58773      2.59663            0.995951         0.98         0.999377                    0.996924            0.0798961       0.521273                   158.773   159.663            0.52107\n",
              "3        0.3025                      0.8                2.52483      2.57248            0.971744         0.89986      0.990083                    0.964275            0.256902        0.778175                   152.483   157.248            0.773298\n",
              "4        0.4005                      0.44               1.70676      2.36064            0.656888         0.621349     0.908552                    0.880363            0.167262        0.945437                   70.6756   136.064            0.885896\n",
              "5        0.50625                     0.12               0.45454      1.96248            0.174941         0.253057     0.755309                    0.749326            0.0480676       0.993504                   -54.546   96.2478            0.792123\n",
              "6        0.647375                    0.02               0.043726     1.5442             0.0168291        0.0437432    0.594323                    0.595512            0.00617083      0.999675                   -95.6274  54.4198            0.572729\n",
              "7        1                           0                  0.000921037  1                  0.000354484      1.41147e-06  0.384875                    0.38552             0.000324781     1                          -99.9079  0                  0\n",
              "\n",
              "Cross-Validation Metrics Summary: \n",
              "                         mean       sd          cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid    cv_6_valid    cv_7_valid    cv_8_valid    cv_9_valid    cv_10_valid\n",
              "-----------------------  ---------  ----------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  -------------\n",
              "accuracy                 0.948625   0.00961859  0.95125       0.96875       0.955         0.94375       0.94375       0.94125       0.95875       0.94125       0.93875       0.94375\n",
              "auc                      0.989321   0.0026153   0.98965       0.994138      0.992543      0.987122      0.987971      0.987636      0.991501      0.989148      0.9872        0.986305\n",
              "err                      0.051375   0.00961859  0.04875       0.03125       0.045         0.05625       0.05625       0.05875       0.04125       0.05875       0.06125       0.05625\n",
              "err_count                41.1       7.69488     39            25            36            45            45            47            33            47            49            45\n",
              "f0point5                 0.928636   0.0171784   0.933852      0.957588      0.933713      0.904153      0.920285      0.909362      0.952694      0.916619      0.928526      0.929569\n",
              "f1                       0.934123   0.0109179   0.936585      0.958541      0.935714      0.92635       0.926591      0.928463      0.946166      0.931785      0.922345      0.928685\n",
              "f2                       0.939882   0.0123253   0.939335      0.959495      0.937724      0.949664      0.932983      0.948383      0.939728      0.947462      0.916247      0.927802\n",
              "lift_top_group           2.60421    0.132402    2.61438       2.65781       2.86738       2.73038       2.64026       2.52366       2.58065       2.38806       2.50784       2.53165\n",
              "logloss                  0.141121   0.0190486   0.13218       0.112811      0.131677      0.145857      0.142523      0.143419      0.128312      0.141626      0.146125      0.186684\n",
              "max_per_class_error      0.0659869  0.0123332   0.0588235     0.0398671     0.0609319     0.0690335     0.0627063     0.0724638     0.0645161     0.0709677     0.0877743     0.0727848\n",
              "mcc                      0.892432   0.0188935   0.897021      0.933469      0.901113      0.882905      0.881158      0.880277      0.912895      0.881295      0.871934      0.882248\n",
              "mean_per_class_accuracy  0.947668   0.00891056  0.949333      0.96704       0.9513        0.948418      0.94249       0.944841      0.954477      0.943621      0.934283      0.94088\n",
              "mean_per_class_error     0.0523317  0.00891056  0.0506668     0.0329596     0.0487001     0.0515816     0.0575101     0.0551593     0.0455234     0.0563794     0.0657167     0.0591197\n",
              "mse                      0.0410048  0.00441369  0.0389478     0.0313437     0.0385018     0.0451063     0.0434138     0.0434346     0.0373019     0.0427476     0.04465       0.0446002\n",
              "pr_auc                   0.98442    0.00342295  0.984525      0.990966      0.986631      0.979124      0.981952      0.982806      0.987586      0.985864      0.98284       0.981901\n",
              "precision                0.925123   0.0227588   0.932039      0.956954      0.932384      0.889937      0.916129      0.897059      0.957096      0.90678       0.932692      0.930159\n",
              "r2                       0.826597   0.0179854   0.835102      0.866444      0.830481      0.805669      0.815495      0.818445      0.842836      0.824372      0.813763      0.813369\n",
              "recall                   0.943882   0.0173548   0.941176      0.960133      0.939068      0.96587       0.937294      0.962145      0.935484      0.958209      0.912226      0.927215\n",
              "rmse                     0.202215   0.0112496   0.197352      0.177042      0.196219      0.212382      0.20836       0.20841       0.193137      0.206755      0.211305      0.211188\n",
              "specificity              0.951455   0.017369    0.95749       0.973948      0.963532      0.930967      0.947686      0.927536      0.973469      0.929032      0.956341      0.954545\n",
              "\n",
              "Scoring History: \n",
              "    timestamp            duration    number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
              "--  -------------------  ----------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ----------------  -------------------  -----------------  ---------------------------------\n",
              "    2023-07-04 11:22:41  25.527 sec  0                  nan              nan                 nan             nan                nan              nan                              nan                nan                   nan               nan                  nan                nan\n",
              "    2023-07-04 11:22:41  25.759 sec  5                  0.276754         1.99677             0.930839        0.892501           2.40932          0.0920443                        0.219089           0.36694               0.978939          0.967803             2.62383            0.063\n",
              "    2023-07-04 11:22:42  26.012 sec  10                 0.244527         0.966394            0.960549        0.936435           2.49968          0.0761556                        0.205803           0.166559              0.987595          0.980153             2.64312            0.0595\n",
              "    2023-07-04 11:22:42  26.283 sec  15                 0.226197         0.502812            0.975243        0.959903           2.54954          0.0665666                        0.199182           0.146057              0.989664          0.984612             2.64901            0.056\n",
              "    2023-07-04 11:22:42  26.497 sec  20                 0.218721         0.361284            0.980319        0.968143           2.56604          0.0632579                        0.19652            0.143699              0.990551          0.986053             2.64901            0.0505\n",
              "    2023-07-04 11:22:42  26.704 sec  25                 0.21393          0.274676            0.982997        0.975362           2.58606          0.060625                         0.195892           0.143851              0.990808          0.986377             2.64901            0.0495\n",
              "    2023-07-04 11:22:43  26.940 sec  30                 0.212194         0.24252             0.984234        0.976963           2.58844          0.059                            0.19497            0.143397              0.990969          0.986596             2.64901            0.0475\n",
              "    2023-07-04 11:22:43  27.197 sec  35                 0.209698         0.22074             0.985319        0.978713           2.591            0.057                            0.194784           0.143048              0.991071          0.986761             2.64901            0.0485\n",
              "    2023-07-04 11:22:43  27.446 sec  40                 0.208903         0.216606            0.985538        0.979325           2.59233          0.056125                         0.193185           0.141788              0.991383          0.9872               2.64901            0.046\n",
              "    2023-07-04 11:22:43  27.675 sec  45                 0.20799          0.204199            0.98606         0.980122           2.59371          0.056625                         0.192606           0.14129               0.991463          0.987275             2.64901            0.0455\n",
              "    2023-07-04 11:22:43  27.749 sec  46                 0.20801          0.204282            0.986038        0.980086           2.59368          0.056625                         0.192191           0.140792              0.991538          0.987398             2.64901            0.047\n",
              "\n",
              "Variable Importances: \n",
              "variable                 relative_importance    scaled_importance     percentage\n",
              "-----------------------  ---------------------  --------------------  ---------------------\n",
              "concave points_mean      12892.1552734375       1.0                   0.18433499477221202\n",
              "perimeter_worst          12409.1396484375       0.9625341446208621    0.17742872651676217\n",
              "concave points_worst     6141.6552734375        0.4763870076938594    0.0878147965727973\n",
              "radius_worst             5617.19189453125       0.4357061930602632    0.08031589881998402\n",
              "radius_se                4640.35546875          0.35993636210004465   0.06634886742604074\n",
              "perimeter_mean           4096.8095703125        0.3177753822709077    0.058577123429645446\n",
              "area_worst               3825.361083984375      0.29672005982320127   0.05469589067632025\n",
              "area_se                  3570.8486328125        0.27697840718454103   0.05105681324037799\n",
              "concavity_mean           3542.318115234375      0.2747653933809524    0.050648877352462644\n",
              "area_mean                1562.5438232421875     0.12120113278976655   0.02234161017918779\n",
              "---                      ---                    ---                   ---\n",
              "symmetry_worst           398.6156921386719      0.03091924381022344   0.005699498646118286\n",
              "smoothness_mean          397.4166564941406      0.03082623875256627   0.005682354559301263\n",
              "texture_se               372.990234375          0.028931565472492773  0.005333099970123865\n",
              "symmetry_mean            357.383544921875       0.027721008422712242  0.0051099519426811065\n",
              "smoothness_se            350.05841064453125     0.02715282303229609   0.005005215491709098\n",
              "fractal_dimension_worst  340.31817626953125     0.02639730666064112   0.004865947385289758\n",
              "symmetry_se              333.9683532714844      0.025904772800834933  0.0047751561588172476\n",
              "concavity_se             327.7789611816406      0.025424683013008986  0.004686658810288159\n",
              "concave points_se        309.9120178222656      0.02403880586675809   0.004431193153779072\n",
              "fractal_dimension_se     298.4029541015625      0.023146087506127115  0.0042666339194391036\n",
              "[30 rows x 4 columns]\n",
              "\n",
              "\n",
              "[tips]\n",
              "Use `model.explain()` to inspect the model.\n",
              "--\n",
              "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
            ],
            "text/html": [
              "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
              "=============\n",
              "H2ORandomForestEstimator : Distributed Random Forest\n",
              "Model Key: DRF_1_AutoML_1_20230704_112008\n",
              "</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-2.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-2 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-2 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-2 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-2 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-2 .h2o-table th,\n",
              "#h2o-table-2 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Model Summary: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>number_of_trees</th>\n",
              "<th>number_of_internal_trees</th>\n",
              "<th>model_size_in_bytes</th>\n",
              "<th>min_depth</th>\n",
              "<th>max_depth</th>\n",
              "<th>mean_depth</th>\n",
              "<th>min_leaves</th>\n",
              "<th>max_leaves</th>\n",
              "<th>mean_leaves</th></tr></thead>\n",
              "    <tbody><tr><td></td>\n",
              "<td>46.0</td>\n",
              "<td>46.0</td>\n",
              "<td>199280.0</td>\n",
              "<td>15.0</td>\n",
              "<td>20.0</td>\n",
              "<td>18.217392</td>\n",
              "<td>311.0</td>\n",
              "<td>369.0</td>\n",
              "<td>340.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: drf\n",
              "** Reported on train data. **\n",
              "\n",
              "MSE: 0.04326800279168445\n",
              "RMSE: 0.2080096218728462\n",
              "LogLoss: 0.20428151575245082\n",
              "Mean Per-Class Error: 0.057211674235314855\n",
              "AUC: 0.9860384526971423\n",
              "AUCPR: 0.9800859943345126\n",
              "Gini: 0.9720769053942846</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-3.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-3 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-3 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-3 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-3 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-3 .h2o-table th,\n",
              "#h2o-table-3 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-3 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-3\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4666666666666667</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>0</th>\n",
              "<th>1</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>0</td>\n",
              "<td>4652.0</td>\n",
              "<td>269.0</td>\n",
              "<td>0.0547</td>\n",
              "<td> (269.0/4921.0)</td></tr>\n",
              "<tr><td>1</td>\n",
              "<td>184.0</td>\n",
              "<td>2895.0</td>\n",
              "<td>0.0598</td>\n",
              "<td> (184.0/3079.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>4836.0</td>\n",
              "<td>3164.0</td>\n",
              "<td>0.0566</td>\n",
              "<td> (453.0/8000.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-4.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-4 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-4 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-4 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-4 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-4 .h2o-table th,\n",
              "#h2o-table-4 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-4 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-4\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.4666667</td>\n",
              "<td>0.9274387</td>\n",
              "<td>105.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.2941176</td>\n",
              "<td>0.9452375</td>\n",
              "<td>140.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.6470588</td>\n",
              "<td>0.9420699</td>\n",
              "<td>70.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.5</td>\n",
              "<td>0.94375</td>\n",
              "<td>100.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>0.9565217</td>\n",
              "<td>0.9982619</td>\n",
              "<td>4.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>197.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9993904</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.5</td>\n",
              "<td>0.8815009</td>\n",
              "<td>100.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.4545455</td>\n",
              "<td>0.9428386</td>\n",
              "<td>108.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.4500000</td>\n",
              "<td>0.9432129</td>\n",
              "<td>109.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>1.0</td>\n",
              "<td>4918.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>1.0</td>\n",
              "<td>1374.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0</td>\n",
              "<td>4921.0</td>\n",
              "<td>197.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0</td>\n",
              "<td>3079.0</td>\n",
              "<td>197.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9993904</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>1.0</td>\n",
              "<td>0.4462488</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>197.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>197.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-5.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-5 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-5 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-5 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-5 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-5 .h2o-table th,\n",
              "#h2o-table-5 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-5 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-5\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 38.49 %, avg score: 38.54 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.2135</td>\n",
              "<td>1.0</td>\n",
              "<td>2.5936825</td>\n",
              "<td>2.5936825</td>\n",
              "<td>0.9982436</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9982436</td>\n",
              "<td>1.0</td>\n",
              "<td>0.5537512</td>\n",
              "<td>0.5537512</td>\n",
              "<td>159.3682520</td>\n",
              "<td>159.3682520</td>\n",
              "<td>0.5531416</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.30125</td>\n",
              "<td>0.7894737</td>\n",
              "<td>2.4761064</td>\n",
              "<td>2.5594342</td>\n",
              "<td>0.9529915</td>\n",
              "<td>0.8931708</td>\n",
              "<td>0.9850622</td>\n",
              "<td>0.9688821</td>\n",
              "<td>0.2172783</td>\n",
              "<td>0.7710296</td>\n",
              "<td>147.6106406</td>\n",
              "<td>155.9434208</td>\n",
              "<td>0.7637140</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.40025</td>\n",
              "<td>0.4444444</td>\n",
              "<td>1.7584090</td>\n",
              "<td>2.3613043</td>\n",
              "<td>0.6767677</td>\n",
              "<td>0.6221101</td>\n",
              "<td>0.9088070</td>\n",
              "<td>0.8831097</td>\n",
              "<td>0.1740825</td>\n",
              "<td>0.9451120</td>\n",
              "<td>75.8409033</td>\n",
              "<td>136.1304308</td>\n",
              "<td>0.8857745</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.504</td>\n",
              "<td>0.1176471</td>\n",
              "<td>0.4382584</td>\n",
              "<td>1.9654392</td>\n",
              "<td>0.1686747</td>\n",
              "<td>0.2558749</td>\n",
              "<td>0.7564484</td>\n",
              "<td>0.7539914</td>\n",
              "<td>0.0454693</td>\n",
              "<td>0.9905814</td>\n",
              "<td>-56.1741608</td>\n",
              "<td>96.5439202</td>\n",
              "<td>0.7910284</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0189892</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0073085</td>\n",
              "<td>0.0108765</td>\n",
              "<td>0.384875</td>\n",
              "<td>0.3854064</td>\n",
              "<td>0.0094186</td>\n",
              "<td>1.0</td>\n",
              "<td>-98.1010802</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: drf\n",
              "** Reported on validation data. **\n",
              "\n",
              "MSE: 0.036937276832765605\n",
              "RMSE: 0.19219073035077838\n",
              "LogLoss: 0.14079214212429528\n",
              "Mean Per-Class Error: 0.04713423229341206\n",
              "AUC: 0.9915375408920449\n",
              "AUCPR: 0.9873978367714009\n",
              "Gini: 0.9830750817840899</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-6.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-6 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-6 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-6 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-6 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-6 .h2o-table th,\n",
              "#h2o-table-6 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-6 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-6\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4565217391304348</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>0</th>\n",
              "<th>1</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>0</td>\n",
              "<td>1187.0</td>\n",
              "<td>58.0</td>\n",
              "<td>0.0466</td>\n",
              "<td> (58.0/1245.0)</td></tr>\n",
              "<tr><td>1</td>\n",
              "<td>36.0</td>\n",
              "<td>719.0</td>\n",
              "<td>0.0477</td>\n",
              "<td> (36.0/755.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>1223.0</td>\n",
              "<td>777.0</td>\n",
              "<td>0.047</td>\n",
              "<td> (94.0/2000.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-7.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-7 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-7 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-7 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-7 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-7 .h2o-table th,\n",
              "#h2o-table-7 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-7 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-7\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.4565217</td>\n",
              "<td>0.9386423</td>\n",
              "<td>27.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.3043478</td>\n",
              "<td>0.9568456</td>\n",
              "<td>34.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.6521739</td>\n",
              "<td>0.9524492</td>\n",
              "<td>17.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.4927536</td>\n",
              "<td>0.953</td>\n",
              "<td>25.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>48.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.4565217</td>\n",
              "<td>0.9008115</td>\n",
              "<td>27.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.4565217</td>\n",
              "<td>0.9523179</td>\n",
              "<td>27.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.4347826</td>\n",
              "<td>0.9530839</td>\n",
              "<td>28.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>1.0</td>\n",
              "<td>1245.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>1.0</td>\n",
              "<td>445.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0</td>\n",
              "<td>1245.0</td>\n",
              "<td>48.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0</td>\n",
              "<td>755.0</td>\n",
              "<td>48.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>1.0</td>\n",
              "<td>0.5894040</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>48.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>48.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-8.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-8 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-8 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-8 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-8 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-8 .h2o-table th,\n",
              "#h2o-table-8 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-8 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-8\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 37.75 %, avg score: 37.82 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.155</td>\n",
              "<td>1.0</td>\n",
              "<td>2.6490066</td>\n",
              "<td>2.6490066</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.4105960</td>\n",
              "<td>0.4105960</td>\n",
              "<td>164.9006623</td>\n",
              "<td>164.9006623</td>\n",
              "<td>0.4105960</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.2005</td>\n",
              "<td>0.9782609</td>\n",
              "<td>2.6490066</td>\n",
              "<td>2.6490066</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9782609</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9950667</td>\n",
              "<td>0.1205298</td>\n",
              "<td>0.5311258</td>\n",
              "<td>164.9006623</td>\n",
              "<td>164.9006623</td>\n",
              "<td>0.5311258</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.3025</td>\n",
              "<td>0.7826087</td>\n",
              "<td>2.5581093</td>\n",
              "<td>2.6183570</td>\n",
              "<td>0.9656863</td>\n",
              "<td>0.8902387</td>\n",
              "<td>0.9884298</td>\n",
              "<td>0.9597197</td>\n",
              "<td>0.2609272</td>\n",
              "<td>0.7920530</td>\n",
              "<td>155.8109336</td>\n",
              "<td>161.8356959</td>\n",
              "<td>0.7864305</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.401</td>\n",
              "<td>0.4130435</td>\n",
              "<td>1.7346287</td>\n",
              "<td>2.4012816</td>\n",
              "<td>0.6548223</td>\n",
              "<td>0.5922901</td>\n",
              "<td>0.9064838</td>\n",
              "<td>0.8694658</td>\n",
              "<td>0.1708609</td>\n",
              "<td>0.9629139</td>\n",
              "<td>73.4628702</td>\n",
              "<td>140.1281564</td>\n",
              "<td>0.9026729</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.5015</td>\n",
              "<td>0.1086957</td>\n",
              "<td>0.3426576</td>\n",
              "<td>1.9887358</td>\n",
              "<td>0.1293532</td>\n",
              "<td>0.2418343</td>\n",
              "<td>0.7507478</td>\n",
              "<td>0.7436892</td>\n",
              "<td>0.0344371</td>\n",
              "<td>0.9973510</td>\n",
              "<td>-65.7342427</td>\n",
              "<td>98.8735779</td>\n",
              "<td>0.7965478</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.6315</td>\n",
              "<td>0.0217391</td>\n",
              "<td>0.0101885</td>\n",
              "<td>1.5814339</td>\n",
              "<td>0.0038462</td>\n",
              "<td>0.0399666</td>\n",
              "<td>0.5969913</td>\n",
              "<td>0.5988215</td>\n",
              "<td>0.0013245</td>\n",
              "<td>0.9986755</td>\n",
              "<td>-98.9811513</td>\n",
              "<td>58.1433882</td>\n",
              "<td>0.5898402</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0035943</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0013569</td>\n",
              "<td>0.0</td>\n",
              "<td>0.3775</td>\n",
              "<td>0.3781558</td>\n",
              "<td>0.0013245</td>\n",
              "<td>1.0</td>\n",
              "<td>-99.6405690</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: drf\n",
              "** Reported on cross-validation data. **\n",
              "\n",
              "MSE: 0.04109426250888458\n",
              "RMSE: 0.20271719835496094\n",
              "LogLoss: 0.14109268080346257\n",
              "Mean Per-Class Error: 0.05639704934588783\n",
              "AUC: 0.9891767351896238\n",
              "AUCPR: 0.984216068014286\n",
              "Gini: 0.9783534703792476</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-9.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-9 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-9 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-9 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-9 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-9 .h2o-table th,\n",
              "#h2o-table-9 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-9 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-9\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.48</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>0</th>\n",
              "<th>1</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>0</td>\n",
              "<td>4676.0</td>\n",
              "<td>245.0</td>\n",
              "<td>0.0498</td>\n",
              "<td> (245.0/4921.0)</td></tr>\n",
              "<tr><td>1</td>\n",
              "<td>194.0</td>\n",
              "<td>2885.0</td>\n",
              "<td>0.063</td>\n",
              "<td> (194.0/3079.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>4870.0</td>\n",
              "<td>3130.0</td>\n",
              "<td>0.0549</td>\n",
              "<td> (439.0/8000.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-10.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-10 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-10 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-10 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-10 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-10 .h2o-table th,\n",
              "#h2o-table-10 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-10 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-10\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.48</td>\n",
              "<td>0.9292962</td>\n",
              "<td>54.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.3200000</td>\n",
              "<td>0.9497118</td>\n",
              "<td>76.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.6800000</td>\n",
              "<td>0.9475386</td>\n",
              "<td>29.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.52</td>\n",
              "<td>0.945125</td>\n",
              "<td>51.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>135.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.48</td>\n",
              "<td>0.8845437</td>\n",
              "<td>54.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.4400000</td>\n",
              "<td>0.9404593</td>\n",
              "<td>59.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.48</td>\n",
              "<td>0.9436030</td>\n",
              "<td>54.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>1.0</td>\n",
              "<td>4921.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>1.0</td>\n",
              "<td>1720.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0</td>\n",
              "<td>4921.0</td>\n",
              "<td>135.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0</td>\n",
              "<td>3079.0</td>\n",
              "<td>135.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>1.0</td>\n",
              "<td>0.5586229</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>135.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>135.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-11.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-11 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-11 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-11 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-11 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-11 .h2o-table th,\n",
              "#h2o-table-11 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-11 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-11\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 38.49 %, avg score: 38.55 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.169875</td>\n",
              "<td>1.0</td>\n",
              "<td>2.5982462</td>\n",
              "<td>2.5982462</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.4413771</td>\n",
              "<td>0.4413771</td>\n",
              "<td>159.8246184</td>\n",
              "<td>159.8246184</td>\n",
              "<td>0.4413771</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.20075</td>\n",
              "<td>0.98</td>\n",
              "<td>2.5877270</td>\n",
              "<td>2.5966283</td>\n",
              "<td>0.9959514</td>\n",
              "<td>0.9800000</td>\n",
              "<td>0.9993773</td>\n",
              "<td>0.9969240</td>\n",
              "<td>0.0798961</td>\n",
              "<td>0.5212731</td>\n",
              "<td>158.7726969</td>\n",
              "<td>159.6628347</td>\n",
              "<td>0.5210699</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.3025</td>\n",
              "<td>0.8</td>\n",
              "<td>2.5248314</td>\n",
              "<td>2.5724785</td>\n",
              "<td>0.9717445</td>\n",
              "<td>0.8998605</td>\n",
              "<td>0.9900826</td>\n",
              "<td>0.9642754</td>\n",
              "<td>0.2569016</td>\n",
              "<td>0.7781747</td>\n",
              "<td>152.4831365</td>\n",
              "<td>157.2478453</td>\n",
              "<td>0.7732977</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.4005</td>\n",
              "<td>0.44</td>\n",
              "<td>1.7067561</td>\n",
              "<td>2.3606413</td>\n",
              "<td>0.6568878</td>\n",
              "<td>0.6213488</td>\n",
              "<td>0.9085518</td>\n",
              "<td>0.8803633</td>\n",
              "<td>0.1672621</td>\n",
              "<td>0.9454368</td>\n",
              "<td>70.6756103</td>\n",
              "<td>136.0641274</td>\n",
              "<td>0.8858961</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.50625</td>\n",
              "<td>0.12</td>\n",
              "<td>0.4545395</td>\n",
              "<td>1.9624778</td>\n",
              "<td>0.1749409</td>\n",
              "<td>0.2530573</td>\n",
              "<td>0.7553086</td>\n",
              "<td>0.7493260</td>\n",
              "<td>0.0480676</td>\n",
              "<td>0.9935044</td>\n",
              "<td>-54.5460478</td>\n",
              "<td>96.2477797</td>\n",
              "<td>0.7921226</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.647375</td>\n",
              "<td>0.02</td>\n",
              "<td>0.0437260</td>\n",
              "<td>1.5441981</td>\n",
              "<td>0.0168291</td>\n",
              "<td>0.0437432</td>\n",
              "<td>0.5943232</td>\n",
              "<td>0.5955120</td>\n",
              "<td>0.0061708</td>\n",
              "<td>0.9996752</td>\n",
              "<td>-95.6273979</td>\n",
              "<td>54.4198060</td>\n",
              "<td>0.5727295</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0009210</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0003545</td>\n",
              "<td>0.0000014</td>\n",
              "<td>0.384875</td>\n",
              "<td>0.3855201</td>\n",
              "<td>0.0003248</td>\n",
              "<td>1.0</td>\n",
              "<td>-99.9078963</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-12.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-12 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-12 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-12 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-12 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-12 .h2o-table th,\n",
              "#h2o-table-12 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-12 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-12\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Cross-Validation Metrics Summary: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>mean</th>\n",
              "<th>sd</th>\n",
              "<th>cv_1_valid</th>\n",
              "<th>cv_2_valid</th>\n",
              "<th>cv_3_valid</th>\n",
              "<th>cv_4_valid</th>\n",
              "<th>cv_5_valid</th>\n",
              "<th>cv_6_valid</th>\n",
              "<th>cv_7_valid</th>\n",
              "<th>cv_8_valid</th>\n",
              "<th>cv_9_valid</th>\n",
              "<th>cv_10_valid</th></tr></thead>\n",
              "    <tbody><tr><td>accuracy</td>\n",
              "<td>0.948625</td>\n",
              "<td>0.0096186</td>\n",
              "<td>0.95125</td>\n",
              "<td>0.96875</td>\n",
              "<td>0.955</td>\n",
              "<td>0.94375</td>\n",
              "<td>0.94375</td>\n",
              "<td>0.94125</td>\n",
              "<td>0.95875</td>\n",
              "<td>0.94125</td>\n",
              "<td>0.93875</td>\n",
              "<td>0.94375</td></tr>\n",
              "<tr><td>auc</td>\n",
              "<td>0.9893215</td>\n",
              "<td>0.0026153</td>\n",
              "<td>0.9896503</td>\n",
              "<td>0.9941378</td>\n",
              "<td>0.9925426</td>\n",
              "<td>0.9871223</td>\n",
              "<td>0.9879707</td>\n",
              "<td>0.9876364</td>\n",
              "<td>0.991501</td>\n",
              "<td>0.9891478</td>\n",
              "<td>0.9872001</td>\n",
              "<td>0.9863054</td></tr>\n",
              "<tr><td>err</td>\n",
              "<td>0.051375</td>\n",
              "<td>0.0096186</td>\n",
              "<td>0.04875</td>\n",
              "<td>0.03125</td>\n",
              "<td>0.045</td>\n",
              "<td>0.05625</td>\n",
              "<td>0.05625</td>\n",
              "<td>0.05875</td>\n",
              "<td>0.04125</td>\n",
              "<td>0.05875</td>\n",
              "<td>0.06125</td>\n",
              "<td>0.05625</td></tr>\n",
              "<tr><td>err_count</td>\n",
              "<td>41.1</td>\n",
              "<td>7.6948757</td>\n",
              "<td>39.0</td>\n",
              "<td>25.0</td>\n",
              "<td>36.0</td>\n",
              "<td>45.0</td>\n",
              "<td>45.0</td>\n",
              "<td>47.0</td>\n",
              "<td>33.0</td>\n",
              "<td>47.0</td>\n",
              "<td>49.0</td>\n",
              "<td>45.0</td></tr>\n",
              "<tr><td>f0point5</td>\n",
              "<td>0.9286361</td>\n",
              "<td>0.0171784</td>\n",
              "<td>0.9338521</td>\n",
              "<td>0.9575878</td>\n",
              "<td>0.9337135</td>\n",
              "<td>0.9041533</td>\n",
              "<td>0.9202852</td>\n",
              "<td>0.9093620</td>\n",
              "<td>0.9526938</td>\n",
              "<td>0.9166191</td>\n",
              "<td>0.9285259</td>\n",
              "<td>0.9295685</td></tr>\n",
              "<tr><td>f1</td>\n",
              "<td>0.9341226</td>\n",
              "<td>0.0109179</td>\n",
              "<td>0.9365854</td>\n",
              "<td>0.9585406</td>\n",
              "<td>0.9357143</td>\n",
              "<td>0.9263502</td>\n",
              "<td>0.9265906</td>\n",
              "<td>0.9284627</td>\n",
              "<td>0.9461664</td>\n",
              "<td>0.9317852</td>\n",
              "<td>0.9223455</td>\n",
              "<td>0.9286847</td></tr>\n",
              "<tr><td>f2</td>\n",
              "<td>0.9398823</td>\n",
              "<td>0.0123253</td>\n",
              "<td>0.9393346</td>\n",
              "<td>0.9594954</td>\n",
              "<td>0.9377237</td>\n",
              "<td>0.9496644</td>\n",
              "<td>0.9329829</td>\n",
              "<td>0.9483831</td>\n",
              "<td>0.9397278</td>\n",
              "<td>0.9474616</td>\n",
              "<td>0.9162468</td>\n",
              "<td>0.9278024</td></tr>\n",
              "<tr><td>lift_top_group</td>\n",
              "<td>2.6042056</td>\n",
              "<td>0.1324018</td>\n",
              "<td>2.6143792</td>\n",
              "<td>2.6578074</td>\n",
              "<td>2.8673835</td>\n",
              "<td>2.7303755</td>\n",
              "<td>2.640264</td>\n",
              "<td>2.5236592</td>\n",
              "<td>2.580645</td>\n",
              "<td>2.3880596</td>\n",
              "<td>2.507837</td>\n",
              "<td>2.5316455</td></tr>\n",
              "<tr><td>logloss</td>\n",
              "<td>0.1411213</td>\n",
              "<td>0.0190486</td>\n",
              "<td>0.1321801</td>\n",
              "<td>0.1128110</td>\n",
              "<td>0.1316768</td>\n",
              "<td>0.1458569</td>\n",
              "<td>0.1425228</td>\n",
              "<td>0.1434189</td>\n",
              "<td>0.1283116</td>\n",
              "<td>0.1416261</td>\n",
              "<td>0.1461246</td>\n",
              "<td>0.1866843</td></tr>\n",
              "<tr><td>max_per_class_error</td>\n",
              "<td>0.0659869</td>\n",
              "<td>0.0123332</td>\n",
              "<td>0.0588235</td>\n",
              "<td>0.0398671</td>\n",
              "<td>0.0609319</td>\n",
              "<td>0.0690335</td>\n",
              "<td>0.0627063</td>\n",
              "<td>0.0724638</td>\n",
              "<td>0.0645161</td>\n",
              "<td>0.0709677</td>\n",
              "<td>0.0877743</td>\n",
              "<td>0.0727848</td></tr>\n",
              "<tr><td>mcc</td>\n",
              "<td>0.8924317</td>\n",
              "<td>0.0188935</td>\n",
              "<td>0.8970212</td>\n",
              "<td>0.9334688</td>\n",
              "<td>0.9011132</td>\n",
              "<td>0.8829053</td>\n",
              "<td>0.8811584</td>\n",
              "<td>0.8802769</td>\n",
              "<td>0.9128952</td>\n",
              "<td>0.8812954</td>\n",
              "<td>0.8719344</td>\n",
              "<td>0.8822482</td></tr>\n",
              "<tr><td>mean_per_class_accuracy</td>\n",
              "<td>0.9476683</td>\n",
              "<td>0.0089106</td>\n",
              "<td>0.9493332</td>\n",
              "<td>0.9670404</td>\n",
              "<td>0.9512999</td>\n",
              "<td>0.9484184</td>\n",
              "<td>0.9424899</td>\n",
              "<td>0.9448407</td>\n",
              "<td>0.9544767</td>\n",
              "<td>0.9436206</td>\n",
              "<td>0.9342833</td>\n",
              "<td>0.9408803</td></tr>\n",
              "<tr><td>mean_per_class_error</td>\n",
              "<td>0.0523317</td>\n",
              "<td>0.0089106</td>\n",
              "<td>0.0506668</td>\n",
              "<td>0.0329596</td>\n",
              "<td>0.0487001</td>\n",
              "<td>0.0515816</td>\n",
              "<td>0.0575101</td>\n",
              "<td>0.0551593</td>\n",
              "<td>0.0455234</td>\n",
              "<td>0.0563794</td>\n",
              "<td>0.0657167</td>\n",
              "<td>0.0591197</td></tr>\n",
              "<tr><td>mse</td>\n",
              "<td>0.0410048</td>\n",
              "<td>0.0044137</td>\n",
              "<td>0.0389478</td>\n",
              "<td>0.0313437</td>\n",
              "<td>0.0385018</td>\n",
              "<td>0.0451063</td>\n",
              "<td>0.0434138</td>\n",
              "<td>0.0434346</td>\n",
              "<td>0.0373019</td>\n",
              "<td>0.0427476</td>\n",
              "<td>0.04465</td>\n",
              "<td>0.0446002</td></tr>\n",
              "<tr><td>pr_auc</td>\n",
              "<td>0.9844196</td>\n",
              "<td>0.0034229</td>\n",
              "<td>0.9845253</td>\n",
              "<td>0.9909664</td>\n",
              "<td>0.986631</td>\n",
              "<td>0.9791239</td>\n",
              "<td>0.9819524</td>\n",
              "<td>0.9828061</td>\n",
              "<td>0.9875858</td>\n",
              "<td>0.9858642</td>\n",
              "<td>0.9828396</td>\n",
              "<td>0.981901</td></tr>\n",
              "<tr><td>precision</td>\n",
              "<td>0.9251228</td>\n",
              "<td>0.0227588</td>\n",
              "<td>0.9320388</td>\n",
              "<td>0.9569536</td>\n",
              "<td>0.9323843</td>\n",
              "<td>0.8899371</td>\n",
              "<td>0.9161291</td>\n",
              "<td>0.8970588</td>\n",
              "<td>0.9570957</td>\n",
              "<td>0.9067797</td>\n",
              "<td>0.9326923</td>\n",
              "<td>0.9301587</td></tr>\n",
              "<tr><td>r2</td>\n",
              "<td>0.8265975</td>\n",
              "<td>0.0179854</td>\n",
              "<td>0.8351024</td>\n",
              "<td>0.866444</td>\n",
              "<td>0.8304807</td>\n",
              "<td>0.8056693</td>\n",
              "<td>0.8154945</td>\n",
              "<td>0.8184445</td>\n",
              "<td>0.8428361</td>\n",
              "<td>0.8243719</td>\n",
              "<td>0.8137631</td>\n",
              "<td>0.8133687</td></tr>\n",
              "<tr><td>recall</td>\n",
              "<td>0.9438821</td>\n",
              "<td>0.0173548</td>\n",
              "<td>0.9411765</td>\n",
              "<td>0.9601329</td>\n",
              "<td>0.9390681</td>\n",
              "<td>0.9658703</td>\n",
              "<td>0.9372937</td>\n",
              "<td>0.9621451</td>\n",
              "<td>0.9354839</td>\n",
              "<td>0.958209</td>\n",
              "<td>0.9122257</td>\n",
              "<td>0.9272152</td></tr>\n",
              "<tr><td>rmse</td>\n",
              "<td>0.2022149</td>\n",
              "<td>0.0112496</td>\n",
              "<td>0.1973519</td>\n",
              "<td>0.1770416</td>\n",
              "<td>0.1962188</td>\n",
              "<td>0.2123824</td>\n",
              "<td>0.2083599</td>\n",
              "<td>0.2084097</td>\n",
              "<td>0.1931369</td>\n",
              "<td>0.2067550</td>\n",
              "<td>0.2113055</td>\n",
              "<td>0.2111877</td></tr>\n",
              "<tr><td>specificity</td>\n",
              "<td>0.9514546</td>\n",
              "<td>0.0173690</td>\n",
              "<td>0.9574899</td>\n",
              "<td>0.9739479</td>\n",
              "<td>0.9635317</td>\n",
              "<td>0.9309665</td>\n",
              "<td>0.9476861</td>\n",
              "<td>0.9275362</td>\n",
              "<td>0.9734694</td>\n",
              "<td>0.9290323</td>\n",
              "<td>0.9563410</td>\n",
              "<td>0.9545454</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-13.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-13 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-13 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-13 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-13 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-13 .h2o-table th,\n",
              "#h2o-table-13 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-13 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-13\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Scoring History: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>timestamp</th>\n",
              "<th>duration</th>\n",
              "<th>number_of_trees</th>\n",
              "<th>training_rmse</th>\n",
              "<th>training_logloss</th>\n",
              "<th>training_auc</th>\n",
              "<th>training_pr_auc</th>\n",
              "<th>training_lift</th>\n",
              "<th>training_classification_error</th>\n",
              "<th>validation_rmse</th>\n",
              "<th>validation_logloss</th>\n",
              "<th>validation_auc</th>\n",
              "<th>validation_pr_auc</th>\n",
              "<th>validation_lift</th>\n",
              "<th>validation_classification_error</th></tr></thead>\n",
              "    <tbody><tr><td></td>\n",
              "<td>2023-07-04 11:22:41</td>\n",
              "<td>25.527 sec</td>\n",
              "<td>0.0</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-07-04 11:22:41</td>\n",
              "<td>25.759 sec</td>\n",
              "<td>5.0</td>\n",
              "<td>0.2767544</td>\n",
              "<td>1.9967730</td>\n",
              "<td>0.9308393</td>\n",
              "<td>0.8925009</td>\n",
              "<td>2.4093223</td>\n",
              "<td>0.0920443</td>\n",
              "<td>0.2190890</td>\n",
              "<td>0.3669400</td>\n",
              "<td>0.9789388</td>\n",
              "<td>0.9678027</td>\n",
              "<td>2.6238260</td>\n",
              "<td>0.063</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-07-04 11:22:42</td>\n",
              "<td>26.012 sec</td>\n",
              "<td>10.0</td>\n",
              "<td>0.2445273</td>\n",
              "<td>0.9663935</td>\n",
              "<td>0.9605493</td>\n",
              "<td>0.9364353</td>\n",
              "<td>2.4996767</td>\n",
              "<td>0.0761556</td>\n",
              "<td>0.2058033</td>\n",
              "<td>0.1665588</td>\n",
              "<td>0.9875954</td>\n",
              "<td>0.9801532</td>\n",
              "<td>2.6431199</td>\n",
              "<td>0.0595</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-07-04 11:22:42</td>\n",
              "<td>26.283 sec</td>\n",
              "<td>15.0</td>\n",
              "<td>0.2261966</td>\n",
              "<td>0.5028121</td>\n",
              "<td>0.9752431</td>\n",
              "<td>0.9599033</td>\n",
              "<td>2.5495443</td>\n",
              "<td>0.0665666</td>\n",
              "<td>0.1991817</td>\n",
              "<td>0.1460567</td>\n",
              "<td>0.9896636</td>\n",
              "<td>0.9846118</td>\n",
              "<td>2.6490066</td>\n",
              "<td>0.056</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-07-04 11:22:42</td>\n",
              "<td>26.497 sec</td>\n",
              "<td>20.0</td>\n",
              "<td>0.2187206</td>\n",
              "<td>0.3612843</td>\n",
              "<td>0.9803188</td>\n",
              "<td>0.9681426</td>\n",
              "<td>2.5660418</td>\n",
              "<td>0.0632579</td>\n",
              "<td>0.1965201</td>\n",
              "<td>0.1436989</td>\n",
              "<td>0.9905513</td>\n",
              "<td>0.9860533</td>\n",
              "<td>2.6490066</td>\n",
              "<td>0.0505</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-07-04 11:22:42</td>\n",
              "<td>26.704 sec</td>\n",
              "<td>25.0</td>\n",
              "<td>0.2139304</td>\n",
              "<td>0.2746755</td>\n",
              "<td>0.9829967</td>\n",
              "<td>0.9753618</td>\n",
              "<td>2.5860606</td>\n",
              "<td>0.060625</td>\n",
              "<td>0.1958920</td>\n",
              "<td>0.1438512</td>\n",
              "<td>0.9908077</td>\n",
              "<td>0.9863770</td>\n",
              "<td>2.6490066</td>\n",
              "<td>0.0495</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-07-04 11:22:43</td>\n",
              "<td>26.940 sec</td>\n",
              "<td>30.0</td>\n",
              "<td>0.2121942</td>\n",
              "<td>0.2425199</td>\n",
              "<td>0.9842336</td>\n",
              "<td>0.9769625</td>\n",
              "<td>2.5884415</td>\n",
              "<td>0.059</td>\n",
              "<td>0.1949704</td>\n",
              "<td>0.1433966</td>\n",
              "<td>0.9909694</td>\n",
              "<td>0.9865957</td>\n",
              "<td>2.6490066</td>\n",
              "<td>0.0475</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-07-04 11:22:43</td>\n",
              "<td>27.197 sec</td>\n",
              "<td>35.0</td>\n",
              "<td>0.2096984</td>\n",
              "<td>0.2207400</td>\n",
              "<td>0.9853191</td>\n",
              "<td>0.9787134</td>\n",
              "<td>2.5910047</td>\n",
              "<td>0.057</td>\n",
              "<td>0.1947836</td>\n",
              "<td>0.1430478</td>\n",
              "<td>0.9910710</td>\n",
              "<td>0.9867606</td>\n",
              "<td>2.6490066</td>\n",
              "<td>0.0485</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-07-04 11:22:43</td>\n",
              "<td>27.446 sec</td>\n",
              "<td>40.0</td>\n",
              "<td>0.2089029</td>\n",
              "<td>0.2166056</td>\n",
              "<td>0.9855383</td>\n",
              "<td>0.9793254</td>\n",
              "<td>2.5923310</td>\n",
              "<td>0.056125</td>\n",
              "<td>0.1931846</td>\n",
              "<td>0.1417876</td>\n",
              "<td>0.9913833</td>\n",
              "<td>0.9872003</td>\n",
              "<td>2.6490066</td>\n",
              "<td>0.046</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-07-04 11:22:43</td>\n",
              "<td>27.675 sec</td>\n",
              "<td>45.0</td>\n",
              "<td>0.2079904</td>\n",
              "<td>0.2041993</td>\n",
              "<td>0.9860597</td>\n",
              "<td>0.9801217</td>\n",
              "<td>2.5937064</td>\n",
              "<td>0.056625</td>\n",
              "<td>0.1926063</td>\n",
              "<td>0.1412901</td>\n",
              "<td>0.9914631</td>\n",
              "<td>0.9872754</td>\n",
              "<td>2.6490066</td>\n",
              "<td>0.0455</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-07-04 11:22:43</td>\n",
              "<td>27.749 sec</td>\n",
              "<td>46.0</td>\n",
              "<td>0.2080096</td>\n",
              "<td>0.2042815</td>\n",
              "<td>0.9860385</td>\n",
              "<td>0.9800860</td>\n",
              "<td>2.5936825</td>\n",
              "<td>0.056625</td>\n",
              "<td>0.1921907</td>\n",
              "<td>0.1407921</td>\n",
              "<td>0.9915375</td>\n",
              "<td>0.9873978</td>\n",
              "<td>2.6490066</td>\n",
              "<td>0.047</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-14.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-14 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-14 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-14 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-14 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-14 .h2o-table th,\n",
              "#h2o-table-14 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-14 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-14\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Variable Importances: </caption>\n",
              "    <thead><tr><th>variable</th>\n",
              "<th>relative_importance</th>\n",
              "<th>scaled_importance</th>\n",
              "<th>percentage</th></tr></thead>\n",
              "    <tbody><tr><td>concave points_mean</td>\n",
              "<td>12892.1552734</td>\n",
              "<td>1.0</td>\n",
              "<td>0.1843350</td></tr>\n",
              "<tr><td>perimeter_worst</td>\n",
              "<td>12409.1396484</td>\n",
              "<td>0.9625341</td>\n",
              "<td>0.1774287</td></tr>\n",
              "<tr><td>concave points_worst</td>\n",
              "<td>6141.6552734</td>\n",
              "<td>0.4763870</td>\n",
              "<td>0.0878148</td></tr>\n",
              "<tr><td>radius_worst</td>\n",
              "<td>5617.1918945</td>\n",
              "<td>0.4357062</td>\n",
              "<td>0.0803159</td></tr>\n",
              "<tr><td>radius_se</td>\n",
              "<td>4640.3554688</td>\n",
              "<td>0.3599364</td>\n",
              "<td>0.0663489</td></tr>\n",
              "<tr><td>perimeter_mean</td>\n",
              "<td>4096.8095703</td>\n",
              "<td>0.3177754</td>\n",
              "<td>0.0585771</td></tr>\n",
              "<tr><td>area_worst</td>\n",
              "<td>3825.3610840</td>\n",
              "<td>0.2967201</td>\n",
              "<td>0.0546959</td></tr>\n",
              "<tr><td>area_se</td>\n",
              "<td>3570.8486328</td>\n",
              "<td>0.2769784</td>\n",
              "<td>0.0510568</td></tr>\n",
              "<tr><td>concavity_mean</td>\n",
              "<td>3542.3181152</td>\n",
              "<td>0.2747654</td>\n",
              "<td>0.0506489</td></tr>\n",
              "<tr><td>area_mean</td>\n",
              "<td>1562.5438232</td>\n",
              "<td>0.1212011</td>\n",
              "<td>0.0223416</td></tr>\n",
              "<tr><td>---</td>\n",
              "<td>---</td>\n",
              "<td>---</td>\n",
              "<td>---</td></tr>\n",
              "<tr><td>symmetry_worst</td>\n",
              "<td>398.6156921</td>\n",
              "<td>0.0309192</td>\n",
              "<td>0.0056995</td></tr>\n",
              "<tr><td>smoothness_mean</td>\n",
              "<td>397.4166565</td>\n",
              "<td>0.0308262</td>\n",
              "<td>0.0056824</td></tr>\n",
              "<tr><td>texture_se</td>\n",
              "<td>372.9902344</td>\n",
              "<td>0.0289316</td>\n",
              "<td>0.0053331</td></tr>\n",
              "<tr><td>symmetry_mean</td>\n",
              "<td>357.3835449</td>\n",
              "<td>0.0277210</td>\n",
              "<td>0.0051100</td></tr>\n",
              "<tr><td>smoothness_se</td>\n",
              "<td>350.0584106</td>\n",
              "<td>0.0271528</td>\n",
              "<td>0.0050052</td></tr>\n",
              "<tr><td>fractal_dimension_worst</td>\n",
              "<td>340.3181763</td>\n",
              "<td>0.0263973</td>\n",
              "<td>0.0048659</td></tr>\n",
              "<tr><td>symmetry_se</td>\n",
              "<td>333.9683533</td>\n",
              "<td>0.0259048</td>\n",
              "<td>0.0047752</td></tr>\n",
              "<tr><td>concavity_se</td>\n",
              "<td>327.7789612</td>\n",
              "<td>0.0254247</td>\n",
              "<td>0.0046867</td></tr>\n",
              "<tr><td>concave points_se</td>\n",
              "<td>309.9120178</td>\n",
              "<td>0.0240388</td>\n",
              "<td>0.0044312</td></tr>\n",
              "<tr><td>fractal_dimension_se</td>\n",
              "<td>298.4029541</td>\n",
              "<td>0.0231461</td>\n",
              "<td>0.0042666</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "<pre style='font-size: smaller; margin-bottom: 1em;'>[30 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
              "\n",
              "[tips]\n",
              "Use `model.explain()` to inspect the model.\n",
              "--\n",
              "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.model_performance(train).accuracy()"
      ],
      "metadata": {
        "id": "G_PyYFNMs97_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4506b8a4-9651-4a2a-9aee-cfba41d694eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.5434782608695652, 1.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = aml.get_best_model()\n",
        "HATr  = best_model.model_performance(train)\n",
        "HATe  = best_model.model_performance(valid)"
      ],
      "metadata": {
        "id": "jKquKjVVJBL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_h2o = pd.DataFrame(h2o.as_list(best_model.predict(valid)))['predict']\n",
        "y_test_h2o = np.array(valid1['diagnosis']).copy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-caBWGPlp8P",
        "outputId": "245201e4-5804-4433-a276-573298f34f13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drf prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SFOLD DATA AUTOML\n",
        "#strain, svalid = shdf.split_frame(ratios=[.8], seed=123)\n",
        "shdf  = newdata.copy()\n",
        "#shdf['y_test'] = shdf['y_test'].replace(0,\"B\")\n",
        "#shdf['y_test'] = shdf['y_test'].replace(1,\"M\")\n",
        "shy = \"y_test\"\n",
        "shx = list(shdf.columns)\n",
        "shx.remove(shy)\n",
        "\n",
        "shdf.iloc[:,0:6] = StandardScaler().fit_transform(shdf.iloc[:,0:6])\n",
        "#shdf.iloc[:,-1] = LabelEncoder().fit_transform(shdf.iloc[:,-1])\n",
        "strain1, svalid1 = train_test_split(shdf, test_size=0.2,random_state=123)\n",
        "strain = h2o.H2OFrame(strain1)\n",
        "svalid = h2o.H2OFrame(svalid1)\n",
        "strain[\"y_test\"] = strain[\"y_test\"].asfactor()\n",
        "svalid[\"y_test\"] = svalid[\"y_test\"].asfactor()\n",
        "\n",
        "st = time.time()\n",
        "saml = H2OAutoML(max_models = 10, seed = 123, verbosity=\"info\", nfolds=10, sort_metric='accuracy')\n",
        "saml.train(x = shx, y = shy, training_frame = strain, validation_frame = svalid)\n",
        "sautoend = time.time() - st\n",
        "sbest_model = saml.get_best_model()\n",
        "sHATr  = sbest_model.model_performance(strain)\n",
        "sHATe  = sbest_model.model_performance(svalid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMDqylVK7svS",
        "outputId": "30e82476-494a-49cc-e7b9-e4b93f71b0fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
            "AutoML progress: |\n",
            "11:25:56.750: Project: AutoML_2_20230704_112556\n",
            "11:25:56.750: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n",
            "11:25:56.751: Setting stopping tolerance adaptively based on the training frame: 0.011180339887498949\n",
            "11:25:56.751: Build control seed: 123\n",
            "11:25:56.751: training frame: Frame key: AutoML_2_20230704_112556_training_py_11_sid_bee4    cols: 7    rows: 8000  chunks: 1    size: 98174  checksum: -2050260270905888720\n",
            "11:25:56.752: validation frame: Frame key: py_12_sid_bee4    cols: 7    rows: 2000  chunks: 1    size: 25420  checksum: 7415620342461106608\n",
            "11:25:56.752: leaderboard frame: NULL\n",
            "11:25:56.752: blending frame: NULL\n",
            "11:25:56.752: response column: y_test\n",
            "11:25:56.752: fold column: null\n",
            "11:25:56.752: weights column: null\n",
            "11:25:56.753: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (7g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (7g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (6g, 60w)]}, {StackedEnsemble : [monotonic (9g, 10w), best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
            "11:25:56.756: AutoML job created: 2023.07.04 11:25:56.750\n",
            "11:25:56.756: AutoML build started: 2023.07.04 11:25:56.756\n",
            "11:25:56.757: AutoML: starting XGBoost_1_AutoML_2_20230704_112556 model training\n",
            "\n",
            "██\n",
            "11:26:06.589: New leader: XGBoost_1_AutoML_2_20230704_112556, accuracy: 0.94925\n",
            "11:26:06.594: AutoML: starting GLM_1_AutoML_2_20230704_112556 model training\n",
            "\n",
            "\n",
            "11:26:11.630: AutoML: starting GBM_1_AutoML_2_20230704_112556 model training\n",
            "\n",
            "██\n",
            "11:26:18.515: AutoML: starting XGBoost_2_AutoML_2_20230704_112556 model training\n",
            "\n",
            "█\n",
            "11:26:24.140: AutoML: starting DRF_1_AutoML_2_20230704_112556 model training\n",
            "\n",
            "█\n",
            "11:26:29.422: AutoML: starting GBM_2_AutoML_2_20230704_112556 model training\n",
            "\n",
            "██\n",
            "11:26:36.900: AutoML: starting GBM_3_AutoML_2_20230704_112556 model training\n",
            "\n",
            "█\n",
            "11:26:43.319: AutoML: starting GBM_4_AutoML_2_20230704_112556 model training\n",
            "\n",
            "█\n",
            "11:26:50.260: AutoML: starting XGBoost_3_AutoML_2_20230704_112556 model training\n",
            "\n",
            "█\n",
            "11:26:54.476: AutoML: starting XRT_1_AutoML_2_20230704_112556 model training\n",
            "\n",
            "██\n",
            "11:27:00.921: No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'monotonic'.\n",
            "11:27:00.925: AutoML: starting StackedEnsemble_BestOfFamily_1_AutoML_2_20230704_112556 model training\n",
            "\n",
            "████\n",
            "11:27:12.976: AutoML: starting StackedEnsemble_AllModels_1_AutoML_2_20230704_112556 model training\n",
            "\n",
            "██████████████████████████████████████████████| (done) 100%\n",
            "\n",
            "11:27:28.51: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GLM : [def_1 (1g, 10w)]}, {GBM : [def_5 (1g, 10w)]}, {XGBoost : [def_1 (2g, 10w)]}, {DRF : [def_1 (2g, 10w)]}, {GBM : [def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w)]}, {XGBoost : [def_3 (3g, 10w)]}, {DRF : [XRT (3g, 10w)]}, {StackedEnsemble : [best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
            "11:27:28.51: AutoML build stopped: 2023.07.04 11:27:28.51\n",
            "11:27:28.51: AutoML build done: built 10 models\n",
            "11:27:28.51: AutoML duration:  1 min 31.295 sec\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_sh2o = pd.DataFrame(h2o.as_list(sbest_model.predict(svalid)))['predict']\n",
        "y_test_sh2o = np.array(svalid1['y_test']).copy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivMaaDNNmYY2",
        "outputId": "41e097df-9ae0-42cc-a96f-3f632d6ddbd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.bar(acc.index, acc['train'], color ='black',width = 0.4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "nJrcI3Gn8we2",
        "outputId": "ed2775b6-0df0-4706-ab46-7a1eb2c7ac0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 7 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = [ANNmodel, model, knn, lr, rf, svm, xgb, best_model]\n",
        "\n",
        "label = [\"ArtificialNeuralNetwork\", 'DeepNeuralNetwork',\n",
        "         'KNearestNeighborsClassifier', 'LogisticRegression',\n",
        "         'RandomForestClassifier', 'SupportVectorClassifier',\n",
        "         'XGBoost', type(best_model).__name__, type(sbest_model).__name__ ]\n",
        "\n",
        "acc = pd.DataFrame(\n",
        "    {\n",
        "    \"ANN\":[ATr,ATe],\n",
        "    \"DNN\":[DTr,DTe],\n",
        "    \"KNN\":[KTr,KTe],\n",
        "    \"LR\" :[LTr,LTe],\n",
        "    \"RF\" :[RTr,RTe],\n",
        "    \"SVM\":[STr,STe],\n",
        "    \"XGB\":[XTr,XTe],\n",
        "    \"H_OD\":[HATr.accuracy()[0][1],HATe.accuracy()[0][1]],\n",
        "    \"H_SOD\":[sHATr.accuracy()[0][1],sHATe.accuracy()[0][1]]\n",
        "    })\n",
        "acc.index = [\"train\", \"test\"]\n",
        "acc = acc.T\n",
        "acc['Model'] = label\n",
        "\n",
        "acc = acc[['Model', 'train', 'test']]\n",
        "acc['avg'] = round((acc['train'] + acc['test'])/2, 6)\n",
        "acc[acc[\"avg\"] == acc[\"avg\"].max()]\n",
        "acc['BestModel'] = 0\n",
        "for i in range(len(acc)):\n",
        "  if acc['avg'][i] >= 90 and acc['avg'][i] < acc['avg'].max():\n",
        "    acc.iloc[i,-1] = \"good\"\n",
        "  elif acc['avg'][i] == acc['avg'].max():\n",
        "    acc.iloc[i,-1] = \"best\"\n",
        "  else:\n",
        "    acc.iloc[i,-1] = \"not good\"\n",
        "\n",
        "acc[\"Precision\"] = np.zeros(len(acc))\n",
        "acc[\"Recall\"]    = np.zeros(len(acc))\n",
        "acc[\"F1_Score\"]  = np.zeros(len(acc))\n",
        "\n"
      ],
      "metadata": {
        "id": "Ba6kRO-eI60S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_ANNn = []\n",
        "y_pred_DNNn = []\n",
        "for i in range(len(y_pred_ANN)):\n",
        "  y_pred_ANNn.append(y_pred_ANN[i][0])\n",
        "  y_pred_DNNn.append(y_pred_DNN[i][0])"
      ],
      "metadata": {
        "id": "S7pf8G6ao4oF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = [np.array(y_pred_ANNn), np.array(y_pred_DNNn), y_pred_knn,\n",
        "        y_pred_lr, y_pred_rf,\n",
        "        y_pred_svm, y_pred_xgb, y_pred_h2o, y_pred_sh2o]\n",
        "\n",
        "tes  = [y_test_indi_ML, np.array(Dy_test), y_test_indi_ML, y_test_indi_ML,\n",
        "        y_test_indi_ML, y_test_indi_ML, y_test_indi_ML,\n",
        "        y_test_h2o.copy(), y_test_sh2o.copy()]"
      ],
      "metadata": {
        "id": "D2n2VnW1jKp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(y_pred_ANNn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1F7SoCqUI9px",
        "outputId": "8541b54a-c351-4eaf-8928-7a9fc04f1487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 0, 0, 0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(pred)):\n",
        "  p,r,f,_ = precision_recall_fscore_support(tes[i], pred[i],average='macro')\n",
        "  acc.iloc[i,5]= p\n",
        "  acc.iloc[i,6]= r\n",
        "  acc.iloc[i,7]= f\n",
        "  p = 0\n",
        "  r = 0\n",
        "  f = 0\n",
        "  print(i)\n",
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "2DlSQ29moN9T",
        "outputId": "1d84a100-6eb3-4c6e-c2b4-30e82bc11edd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             Model     train    test       avg BestModel  \\\n",
              "ANN        ArtificialNeuralNetwork  0.957625  0.9515  0.954562  not good   \n",
              "DNN              DeepNeuralNetwork  0.954750  0.9515  0.953125  not good   \n",
              "KNN    KNearestNeighborsClassifier  0.954875  0.9445  0.949688  not good   \n",
              "LR              LogisticRegression  0.950000  0.9500  0.950000  not good   \n",
              "RF          RandomForestClassifier  0.943875  0.9505  0.947188  not good   \n",
              "SVM        SupportVectorClassifier  0.950500  0.9500  0.950250  not good   \n",
              "XGB                        XGBoost  0.956875  0.9410  0.948938  not good   \n",
              "H_OD      H2ORandomForestEstimator  1.000000  0.9530  0.976500      best   \n",
              "H_SOD          H2OXGBoostEstimator  0.951000  0.9495  0.950250  not good   \n",
              "\n",
              "       Precision    Recall  F1_Score  \n",
              "ANN     0.950317  0.946187  0.948169  \n",
              "DNN     0.949153  0.947491  0.948308  \n",
              "KNN     0.945655  0.935873  0.940325  \n",
              "LR      0.946807  0.946807  0.946807  \n",
              "RF      0.949487  0.944863  0.947072  \n",
              "SVM     0.947226  0.946286  0.946751  \n",
              "XGB     0.938046  0.936190  0.937100  \n",
              "H_OD    0.947959  0.952866  0.950277  \n",
              "H_SOD   0.947239  0.945102  0.946148  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5d48ce41-ad50-4e3f-ad97-80b9f80187aa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "      <th>avg</th>\n",
              "      <th>BestModel</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ANN</th>\n",
              "      <td>ArtificialNeuralNetwork</td>\n",
              "      <td>0.957625</td>\n",
              "      <td>0.9515</td>\n",
              "      <td>0.954562</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.950317</td>\n",
              "      <td>0.946187</td>\n",
              "      <td>0.948169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DNN</th>\n",
              "      <td>DeepNeuralNetwork</td>\n",
              "      <td>0.954750</td>\n",
              "      <td>0.9515</td>\n",
              "      <td>0.953125</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.949153</td>\n",
              "      <td>0.947491</td>\n",
              "      <td>0.948308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>KNearestNeighborsClassifier</td>\n",
              "      <td>0.954875</td>\n",
              "      <td>0.9445</td>\n",
              "      <td>0.949688</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.945655</td>\n",
              "      <td>0.935873</td>\n",
              "      <td>0.940325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LR</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.9500</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.946807</td>\n",
              "      <td>0.946807</td>\n",
              "      <td>0.946807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.943875</td>\n",
              "      <td>0.9505</td>\n",
              "      <td>0.947188</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.949487</td>\n",
              "      <td>0.944863</td>\n",
              "      <td>0.947072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>SupportVectorClassifier</td>\n",
              "      <td>0.950500</td>\n",
              "      <td>0.9500</td>\n",
              "      <td>0.950250</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.947226</td>\n",
              "      <td>0.946286</td>\n",
              "      <td>0.946751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGB</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.956875</td>\n",
              "      <td>0.9410</td>\n",
              "      <td>0.948938</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.938046</td>\n",
              "      <td>0.936190</td>\n",
              "      <td>0.937100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H_OD</th>\n",
              "      <td>H2ORandomForestEstimator</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.9530</td>\n",
              "      <td>0.976500</td>\n",
              "      <td>best</td>\n",
              "      <td>0.947959</td>\n",
              "      <td>0.952866</td>\n",
              "      <td>0.950277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H_SOD</th>\n",
              "      <td>H2OXGBoostEstimator</td>\n",
              "      <td>0.951000</td>\n",
              "      <td>0.9495</td>\n",
              "      <td>0.950250</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.947239</td>\n",
              "      <td>0.945102</td>\n",
              "      <td>0.946148</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d48ce41-ad50-4e3f-ad97-80b9f80187aa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5d48ce41-ad50-4e3f-ad97-80b9f80187aa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5d48ce41-ad50-4e3f-ad97-80b9f80187aa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.bar(acc.index, acc['train'], color ='black',width = 0.4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "ru4oH6-YzGPw",
        "outputId": "753ce941-f384-4eff-9e87-49787505d21b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 9 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve"
      ],
      "metadata": {
        "id": "Qma6hWrmDBvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = [ANNmodel, model, knn, lr, rf, svm, xgb, best_model]"
      ],
      "metadata": {
        "id": "03rwpiYpoAGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(df['diagnosis']).copy()\n",
        "X = df.drop(columns=['diagnosis']).copy()\n",
        "X = StandardScaler().fit_transform(X).copy()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=123)\n",
        "y_test_indi_ML = y_test.copy()"
      ],
      "metadata": {
        "id": "x5wrzn-qPaXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "C80ESe__xB5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(1)\n",
        "plt.rcParams[\"figure.figsize\"] = [10, 5]\n",
        "\n",
        "y_pred = ANNmodel.predict(X_test).ravel()\n",
        "y_test = y_test_indi_ML\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[0]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = model.predict(DX_test).ravel()\n",
        "y_test = Dy_test.copy()\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[1]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = knn.predict_proba(X_test)[:, 1]\n",
        "y_test = y_test_indi_ML\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[2]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = lr.predict_proba(X_test)[:, 1]\n",
        "y_test = y_test_indi_ML\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[3]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = rf.predict_proba(X_test)[:, 1]\n",
        "y_test = y_test_indi_ML\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[4]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = svm.predict_proba(X_test)[:, 1]\n",
        "y_test = y_test_indi_ML\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[5]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = xgb.predict_proba(X_test)[:, 1]\n",
        "y_test = y_test_indi_ML\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[6]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = pd.DataFrame(h2o.as_list(best_model.predict(valid)))\n",
        "y_test = h2o.as_list(valid['diagnosis'])\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred[\"p1\"])\n",
        "auc = metrics.roc_auc_score(y_test, y_pred[\"p1\"])\n",
        "plt.plot(fpr, tpr,label=type(best_model).__name__ + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = pd.DataFrame(h2o.as_list(sbest_model.predict(svalid)))\n",
        "y_test = h2o.as_list(svalid['y_test'])\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred[\"p1\"])\n",
        "auc = metrics.roc_auc_score(y_test, y_pred[\"p1\"])\n",
        "plt.plot(fpr, tpr,label=type(sbest_model).__name__ + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('AUC ROC curve')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "4Bi4CMUJm6yH",
        "outputId": "83ca9369-c8a7-4f5c-dc9a-94c83b278eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 4ms/step\n",
            "63/63 [==============================] - 0s 3ms/step\n",
            "drf prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
            "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tm = [aend,dend,kend,lend,rend,send,xend,autoend,sautoend]"
      ],
      "metadata": {
        "id": "6vUubKKMxLIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc['time'] = 0#tm\n",
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "_1wKoAe9wIPn",
        "outputId": "b4a35927-3774-4745-e103-4bb5e71972c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             Model     train    test       avg BestModel  \\\n",
              "ANN        ArtificialNeuralNetwork  0.957625  0.9515  0.954562  not good   \n",
              "DNN              DeepNeuralNetwork  0.954750  0.9515  0.953125  not good   \n",
              "KNN    KNearestNeighborsClassifier  0.954875  0.9445  0.949688  not good   \n",
              "LR              LogisticRegression  0.950000  0.9500  0.950000  not good   \n",
              "RF          RandomForestClassifier  0.943875  0.9505  0.947188  not good   \n",
              "SVM        SupportVectorClassifier  0.950500  0.9500  0.950250  not good   \n",
              "XGB                        XGBoost  0.956875  0.9410  0.948938  not good   \n",
              "H_OD      H2ORandomForestEstimator  1.000000  0.9530  0.976500      best   \n",
              "H_SOD          H2OXGBoostEstimator  0.951000  0.9495  0.950250  not good   \n",
              "\n",
              "       Precision    Recall  F1_Score  time  \n",
              "ANN     0.950317  0.946187  0.948169     0  \n",
              "DNN     0.949153  0.947491  0.948308     0  \n",
              "KNN     0.945655  0.935873  0.940325     0  \n",
              "LR      0.946807  0.946807  0.946807     0  \n",
              "RF      0.949487  0.944863  0.947072     0  \n",
              "SVM     0.947226  0.946286  0.946751     0  \n",
              "XGB     0.938046  0.936190  0.937100     0  \n",
              "H_OD    0.947959  0.952866  0.950277     0  \n",
              "H_SOD   0.947239  0.945102  0.946148     0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-acd9e1c1-1030-4131-81d2-dcc806731acf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "      <th>avg</th>\n",
              "      <th>BestModel</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1_Score</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ANN</th>\n",
              "      <td>ArtificialNeuralNetwork</td>\n",
              "      <td>0.957625</td>\n",
              "      <td>0.9515</td>\n",
              "      <td>0.954562</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.950317</td>\n",
              "      <td>0.946187</td>\n",
              "      <td>0.948169</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DNN</th>\n",
              "      <td>DeepNeuralNetwork</td>\n",
              "      <td>0.954750</td>\n",
              "      <td>0.9515</td>\n",
              "      <td>0.953125</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.949153</td>\n",
              "      <td>0.947491</td>\n",
              "      <td>0.948308</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>KNearestNeighborsClassifier</td>\n",
              "      <td>0.954875</td>\n",
              "      <td>0.9445</td>\n",
              "      <td>0.949688</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.945655</td>\n",
              "      <td>0.935873</td>\n",
              "      <td>0.940325</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LR</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.9500</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.946807</td>\n",
              "      <td>0.946807</td>\n",
              "      <td>0.946807</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.943875</td>\n",
              "      <td>0.9505</td>\n",
              "      <td>0.947188</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.949487</td>\n",
              "      <td>0.944863</td>\n",
              "      <td>0.947072</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>SupportVectorClassifier</td>\n",
              "      <td>0.950500</td>\n",
              "      <td>0.9500</td>\n",
              "      <td>0.950250</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.947226</td>\n",
              "      <td>0.946286</td>\n",
              "      <td>0.946751</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGB</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.956875</td>\n",
              "      <td>0.9410</td>\n",
              "      <td>0.948938</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.938046</td>\n",
              "      <td>0.936190</td>\n",
              "      <td>0.937100</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H_OD</th>\n",
              "      <td>H2ORandomForestEstimator</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.9530</td>\n",
              "      <td>0.976500</td>\n",
              "      <td>best</td>\n",
              "      <td>0.947959</td>\n",
              "      <td>0.952866</td>\n",
              "      <td>0.950277</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H_SOD</th>\n",
              "      <td>H2OXGBoostEstimator</td>\n",
              "      <td>0.951000</td>\n",
              "      <td>0.9495</td>\n",
              "      <td>0.950250</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.947239</td>\n",
              "      <td>0.945102</td>\n",
              "      <td>0.946148</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-acd9e1c1-1030-4131-81d2-dcc806731acf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-acd9e1c1-1030-4131-81d2-dcc806731acf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-acd9e1c1-1030-4131-81d2-dcc806731acf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc['time'] = tm"
      ],
      "metadata": {
        "id": "P-K86caJxhvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "H9pBjIrPQ3nu",
        "outputId": "de4629c6-bee4-439b-d190-f139bf0053ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             Model     train    test       avg BestModel  \\\n",
              "ANN        ArtificialNeuralNetwork  0.957625  0.9515  0.954562  not good   \n",
              "DNN              DeepNeuralNetwork  0.954750  0.9515  0.953125  not good   \n",
              "KNN    KNearestNeighborsClassifier  0.954875  0.9445  0.949688  not good   \n",
              "LR              LogisticRegression  0.950000  0.9500  0.950000  not good   \n",
              "RF          RandomForestClassifier  0.943875  0.9505  0.947188  not good   \n",
              "SVM        SupportVectorClassifier  0.950500  0.9500  0.950250  not good   \n",
              "XGB                        XGBoost  0.956875  0.9410  0.948938  not good   \n",
              "H_OD      H2ORandomForestEstimator  1.000000  0.9530  0.976500      best   \n",
              "H_SOD          H2OXGBoostEstimator  0.951000  0.9495  0.950250  not good   \n",
              "\n",
              "       Precision    Recall  F1_Score        time  \n",
              "ANN     0.950317  0.946187  0.948169    6.243280  \n",
              "DNN     0.949153  0.947491  0.948308  203.734524  \n",
              "KNN     0.945655  0.935873  0.940325    0.002470  \n",
              "LR      0.946807  0.946807  0.946807    0.054387  \n",
              "RF      0.949487  0.944863  0.947072    1.240527  \n",
              "SVM     0.947226  0.946286  0.946751    7.244547  \n",
              "XGB     0.938046  0.936190  0.937100   13.642071  \n",
              "H_OD    0.947959  0.952866  0.950277  343.929040  \n",
              "H_SOD   0.947239  0.945102  0.946148   93.816365  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-22e8fc86-ff34-43b0-a392-a9dd0acd3330\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "      <th>avg</th>\n",
              "      <th>BestModel</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1_Score</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ANN</th>\n",
              "      <td>ArtificialNeuralNetwork</td>\n",
              "      <td>0.957625</td>\n",
              "      <td>0.9515</td>\n",
              "      <td>0.954562</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.950317</td>\n",
              "      <td>0.946187</td>\n",
              "      <td>0.948169</td>\n",
              "      <td>6.243280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DNN</th>\n",
              "      <td>DeepNeuralNetwork</td>\n",
              "      <td>0.954750</td>\n",
              "      <td>0.9515</td>\n",
              "      <td>0.953125</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.949153</td>\n",
              "      <td>0.947491</td>\n",
              "      <td>0.948308</td>\n",
              "      <td>203.734524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>KNearestNeighborsClassifier</td>\n",
              "      <td>0.954875</td>\n",
              "      <td>0.9445</td>\n",
              "      <td>0.949688</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.945655</td>\n",
              "      <td>0.935873</td>\n",
              "      <td>0.940325</td>\n",
              "      <td>0.002470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LR</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.9500</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.946807</td>\n",
              "      <td>0.946807</td>\n",
              "      <td>0.946807</td>\n",
              "      <td>0.054387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.943875</td>\n",
              "      <td>0.9505</td>\n",
              "      <td>0.947188</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.949487</td>\n",
              "      <td>0.944863</td>\n",
              "      <td>0.947072</td>\n",
              "      <td>1.240527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>SupportVectorClassifier</td>\n",
              "      <td>0.950500</td>\n",
              "      <td>0.9500</td>\n",
              "      <td>0.950250</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.947226</td>\n",
              "      <td>0.946286</td>\n",
              "      <td>0.946751</td>\n",
              "      <td>7.244547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGB</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.956875</td>\n",
              "      <td>0.9410</td>\n",
              "      <td>0.948938</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.938046</td>\n",
              "      <td>0.936190</td>\n",
              "      <td>0.937100</td>\n",
              "      <td>13.642071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H_OD</th>\n",
              "      <td>H2ORandomForestEstimator</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.9530</td>\n",
              "      <td>0.976500</td>\n",
              "      <td>best</td>\n",
              "      <td>0.947959</td>\n",
              "      <td>0.952866</td>\n",
              "      <td>0.950277</td>\n",
              "      <td>343.929040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H_SOD</th>\n",
              "      <td>H2OXGBoostEstimator</td>\n",
              "      <td>0.951000</td>\n",
              "      <td>0.9495</td>\n",
              "      <td>0.950250</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.947239</td>\n",
              "      <td>0.945102</td>\n",
              "      <td>0.946148</td>\n",
              "      <td>93.816365</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22e8fc86-ff34-43b0-a392-a9dd0acd3330')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-22e8fc86-ff34-43b0-a392-a9dd0acd3330 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-22e8fc86-ff34-43b0-a392-a9dd0acd3330');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UXbDp_CjQ4Xc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}