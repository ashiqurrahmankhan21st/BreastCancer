{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashiqurrahmankhan21st/BreastCancer/blob/main/Breast_Cancer_V3_TVAE_DATA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUMYU_d6_J-X"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "#import keras_metrics\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from sklearn.inspection import PartialDependenceDisplay\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#original data\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/ashiqurrahmankhan21st/BreastCancer/main/tvae_SDV_BreastCancer.csv\")\n",
        "del df['Unnamed: 0']\n",
        "df"
      ],
      "metadata": {
        "id": "Ntdqq4T_aGXN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "outputId": "8c6b249c-f8ce-49ec-bd47-ea8470882197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     diagnosis  radius_mean  texture_mean  perimeter_mean   area_mean  \\\n",
              "0            B     9.866787     14.637137       63.409325  283.713730   \n",
              "1            B    12.885053     21.506004       79.229176  336.364127   \n",
              "2            B    11.165762     15.516346       84.076405  356.413321   \n",
              "3            B    12.271667     19.807824       68.534578  428.143496   \n",
              "4            B     7.454015     12.357933       51.167853  202.087605   \n",
              "...        ...          ...           ...             ...         ...   \n",
              "9995         B    11.653797     19.591590       66.871153  347.640448   \n",
              "9996         B    12.779385     13.799951       71.689730  568.975097   \n",
              "9997         B    12.144682     17.091324       72.648862  363.638743   \n",
              "9998         B    11.440653     14.876270       83.906545  447.719512   \n",
              "9999         B    12.327089     21.793296       90.006683  585.450805   \n",
              "\n",
              "      smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0            0.084223          0.046159        0.016544             0.020951   \n",
              "1            0.081238          0.061742        0.030052             0.025329   \n",
              "2            0.112075          0.064143        0.012986             0.000000   \n",
              "3            0.088438          0.031222        0.028840             0.018988   \n",
              "4            0.088588          0.052791        0.051511             0.013281   \n",
              "...               ...               ...             ...                  ...   \n",
              "9995         0.114469          0.153040        0.098849             0.020412   \n",
              "9996         0.102959          0.126075        0.107483             0.026956   \n",
              "9997         0.115953          0.122028        0.112376             0.031809   \n",
              "9998         0.101748          0.135110        0.069284             0.093306   \n",
              "9999         0.097919          0.170219        0.093106             0.028075   \n",
              "\n",
              "      symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
              "0          0.170999  ...     13.174990      18.064878        79.308249   \n",
              "1          0.169469  ...     15.764673      27.487070        81.358017   \n",
              "2          0.159183  ...     12.177383      34.227039        87.682893   \n",
              "3          0.144926  ...     14.332578      18.433072        68.255508   \n",
              "4          0.174599  ...     10.671485      18.960872        60.949763   \n",
              "...             ...  ...           ...            ...              ...   \n",
              "9995       0.171224  ...     13.364227      31.212963        75.105110   \n",
              "9996       0.176738  ...     14.636441      25.387452        81.755763   \n",
              "9997       0.145315  ...     12.978866      21.222782        88.692189   \n",
              "9998       0.198483  ...     14.864455      19.688309       104.210820   \n",
              "9999       0.185964  ...     12.195219      29.697275        77.443915   \n",
              "\n",
              "      area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
              "0     368.916148          0.152767           0.166851         0.158809   \n",
              "1     726.979378          0.112737           0.137944         0.120542   \n",
              "2     644.261133          0.125459           0.256056         0.112901   \n",
              "3     505.092414          0.092259           0.116755         0.059426   \n",
              "4     340.397278          0.127406           0.107711         0.110993   \n",
              "...          ...               ...                ...              ...   \n",
              "9995  309.445867          0.150710           0.268134         0.244718   \n",
              "9996  675.860482          0.160312           0.562150         0.291571   \n",
              "9997  534.210501          0.185600           0.492610         0.452870   \n",
              "9998  711.314226          0.158937           0.555026         0.211123   \n",
              "9999  449.710078          0.147902           0.498236         0.346742   \n",
              "\n",
              "      concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
              "0                 0.035439        0.288579                 0.073689  \n",
              "1                 0.071356        0.271750                 0.068861  \n",
              "2                 0.045699        0.301039                 0.055040  \n",
              "3                 0.044334        0.235016                 0.079151  \n",
              "4                 0.000000        0.299682                 0.069818  \n",
              "...                    ...             ...                      ...  \n",
              "9995              0.056089        0.251965                 0.088369  \n",
              "9996              0.173512        0.298970                 0.102903  \n",
              "9997              0.090011        0.243860                 0.143752  \n",
              "9998              0.186335        0.263381                 0.072269  \n",
              "9999              0.067868        0.252371                 0.084630  \n",
              "\n",
              "[10000 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d6b7be1c-a67b-48e6-81cb-52025f5c493f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B</td>\n",
              "      <td>9.866787</td>\n",
              "      <td>14.637137</td>\n",
              "      <td>63.409325</td>\n",
              "      <td>283.713730</td>\n",
              "      <td>0.084223</td>\n",
              "      <td>0.046159</td>\n",
              "      <td>0.016544</td>\n",
              "      <td>0.020951</td>\n",
              "      <td>0.170999</td>\n",
              "      <td>...</td>\n",
              "      <td>13.174990</td>\n",
              "      <td>18.064878</td>\n",
              "      <td>79.308249</td>\n",
              "      <td>368.916148</td>\n",
              "      <td>0.152767</td>\n",
              "      <td>0.166851</td>\n",
              "      <td>0.158809</td>\n",
              "      <td>0.035439</td>\n",
              "      <td>0.288579</td>\n",
              "      <td>0.073689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B</td>\n",
              "      <td>12.885053</td>\n",
              "      <td>21.506004</td>\n",
              "      <td>79.229176</td>\n",
              "      <td>336.364127</td>\n",
              "      <td>0.081238</td>\n",
              "      <td>0.061742</td>\n",
              "      <td>0.030052</td>\n",
              "      <td>0.025329</td>\n",
              "      <td>0.169469</td>\n",
              "      <td>...</td>\n",
              "      <td>15.764673</td>\n",
              "      <td>27.487070</td>\n",
              "      <td>81.358017</td>\n",
              "      <td>726.979378</td>\n",
              "      <td>0.112737</td>\n",
              "      <td>0.137944</td>\n",
              "      <td>0.120542</td>\n",
              "      <td>0.071356</td>\n",
              "      <td>0.271750</td>\n",
              "      <td>0.068861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B</td>\n",
              "      <td>11.165762</td>\n",
              "      <td>15.516346</td>\n",
              "      <td>84.076405</td>\n",
              "      <td>356.413321</td>\n",
              "      <td>0.112075</td>\n",
              "      <td>0.064143</td>\n",
              "      <td>0.012986</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.159183</td>\n",
              "      <td>...</td>\n",
              "      <td>12.177383</td>\n",
              "      <td>34.227039</td>\n",
              "      <td>87.682893</td>\n",
              "      <td>644.261133</td>\n",
              "      <td>0.125459</td>\n",
              "      <td>0.256056</td>\n",
              "      <td>0.112901</td>\n",
              "      <td>0.045699</td>\n",
              "      <td>0.301039</td>\n",
              "      <td>0.055040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B</td>\n",
              "      <td>12.271667</td>\n",
              "      <td>19.807824</td>\n",
              "      <td>68.534578</td>\n",
              "      <td>428.143496</td>\n",
              "      <td>0.088438</td>\n",
              "      <td>0.031222</td>\n",
              "      <td>0.028840</td>\n",
              "      <td>0.018988</td>\n",
              "      <td>0.144926</td>\n",
              "      <td>...</td>\n",
              "      <td>14.332578</td>\n",
              "      <td>18.433072</td>\n",
              "      <td>68.255508</td>\n",
              "      <td>505.092414</td>\n",
              "      <td>0.092259</td>\n",
              "      <td>0.116755</td>\n",
              "      <td>0.059426</td>\n",
              "      <td>0.044334</td>\n",
              "      <td>0.235016</td>\n",
              "      <td>0.079151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B</td>\n",
              "      <td>7.454015</td>\n",
              "      <td>12.357933</td>\n",
              "      <td>51.167853</td>\n",
              "      <td>202.087605</td>\n",
              "      <td>0.088588</td>\n",
              "      <td>0.052791</td>\n",
              "      <td>0.051511</td>\n",
              "      <td>0.013281</td>\n",
              "      <td>0.174599</td>\n",
              "      <td>...</td>\n",
              "      <td>10.671485</td>\n",
              "      <td>18.960872</td>\n",
              "      <td>60.949763</td>\n",
              "      <td>340.397278</td>\n",
              "      <td>0.127406</td>\n",
              "      <td>0.107711</td>\n",
              "      <td>0.110993</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.299682</td>\n",
              "      <td>0.069818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>B</td>\n",
              "      <td>11.653797</td>\n",
              "      <td>19.591590</td>\n",
              "      <td>66.871153</td>\n",
              "      <td>347.640448</td>\n",
              "      <td>0.114469</td>\n",
              "      <td>0.153040</td>\n",
              "      <td>0.098849</td>\n",
              "      <td>0.020412</td>\n",
              "      <td>0.171224</td>\n",
              "      <td>...</td>\n",
              "      <td>13.364227</td>\n",
              "      <td>31.212963</td>\n",
              "      <td>75.105110</td>\n",
              "      <td>309.445867</td>\n",
              "      <td>0.150710</td>\n",
              "      <td>0.268134</td>\n",
              "      <td>0.244718</td>\n",
              "      <td>0.056089</td>\n",
              "      <td>0.251965</td>\n",
              "      <td>0.088369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>B</td>\n",
              "      <td>12.779385</td>\n",
              "      <td>13.799951</td>\n",
              "      <td>71.689730</td>\n",
              "      <td>568.975097</td>\n",
              "      <td>0.102959</td>\n",
              "      <td>0.126075</td>\n",
              "      <td>0.107483</td>\n",
              "      <td>0.026956</td>\n",
              "      <td>0.176738</td>\n",
              "      <td>...</td>\n",
              "      <td>14.636441</td>\n",
              "      <td>25.387452</td>\n",
              "      <td>81.755763</td>\n",
              "      <td>675.860482</td>\n",
              "      <td>0.160312</td>\n",
              "      <td>0.562150</td>\n",
              "      <td>0.291571</td>\n",
              "      <td>0.173512</td>\n",
              "      <td>0.298970</td>\n",
              "      <td>0.102903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>B</td>\n",
              "      <td>12.144682</td>\n",
              "      <td>17.091324</td>\n",
              "      <td>72.648862</td>\n",
              "      <td>363.638743</td>\n",
              "      <td>0.115953</td>\n",
              "      <td>0.122028</td>\n",
              "      <td>0.112376</td>\n",
              "      <td>0.031809</td>\n",
              "      <td>0.145315</td>\n",
              "      <td>...</td>\n",
              "      <td>12.978866</td>\n",
              "      <td>21.222782</td>\n",
              "      <td>88.692189</td>\n",
              "      <td>534.210501</td>\n",
              "      <td>0.185600</td>\n",
              "      <td>0.492610</td>\n",
              "      <td>0.452870</td>\n",
              "      <td>0.090011</td>\n",
              "      <td>0.243860</td>\n",
              "      <td>0.143752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>B</td>\n",
              "      <td>11.440653</td>\n",
              "      <td>14.876270</td>\n",
              "      <td>83.906545</td>\n",
              "      <td>447.719512</td>\n",
              "      <td>0.101748</td>\n",
              "      <td>0.135110</td>\n",
              "      <td>0.069284</td>\n",
              "      <td>0.093306</td>\n",
              "      <td>0.198483</td>\n",
              "      <td>...</td>\n",
              "      <td>14.864455</td>\n",
              "      <td>19.688309</td>\n",
              "      <td>104.210820</td>\n",
              "      <td>711.314226</td>\n",
              "      <td>0.158937</td>\n",
              "      <td>0.555026</td>\n",
              "      <td>0.211123</td>\n",
              "      <td>0.186335</td>\n",
              "      <td>0.263381</td>\n",
              "      <td>0.072269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>B</td>\n",
              "      <td>12.327089</td>\n",
              "      <td>21.793296</td>\n",
              "      <td>90.006683</td>\n",
              "      <td>585.450805</td>\n",
              "      <td>0.097919</td>\n",
              "      <td>0.170219</td>\n",
              "      <td>0.093106</td>\n",
              "      <td>0.028075</td>\n",
              "      <td>0.185964</td>\n",
              "      <td>...</td>\n",
              "      <td>12.195219</td>\n",
              "      <td>29.697275</td>\n",
              "      <td>77.443915</td>\n",
              "      <td>449.710078</td>\n",
              "      <td>0.147902</td>\n",
              "      <td>0.498236</td>\n",
              "      <td>0.346742</td>\n",
              "      <td>0.067868</td>\n",
              "      <td>0.252371</td>\n",
              "      <td>0.084630</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6b7be1c-a67b-48e6-81cb-52025f5c493f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d6b7be1c-a67b-48e6-81cb-52025f5c493f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d6b7be1c-a67b-48e6-81cb-52025f5c493f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(df['diagnosis']).copy()\n",
        "X = df.drop(columns=['diagnosis']).copy()\n",
        "X = StandardScaler().fit_transform(X).copy()"
      ],
      "metadata": {
        "id": "4cimS259ti6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['diagnosis'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bv9sG-P8M1Fe",
        "outputId": "f789df22-1f3d-4be4-8ba5-314613a67507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "B    6166\n",
              "M    3834\n",
              "Name: diagnosis, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(df['diagnosis']).copy()\n",
        "X = df.drop(columns=['diagnosis']).copy()\n",
        "X = StandardScaler().fit_transform(X).copy()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "#X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=123)\n",
        "y_test_indi_ML = y_test.copy()\n",
        "print(\"Original data : \",df.shape)\n",
        "print(\"tarin         : \",X_train.shape)\n",
        "print(\"test          : \",X_test.shape[0])\n",
        "#print(\"validation    : \",X_val.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpyVwv13CTut",
        "outputId": "05352400-eb9e-4865-96e9-ee2abdf96e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original data :  (10000, 31)\n",
            "tarin         :  (8000, 30)\n",
            "test          :  2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM\n",
        "svm = SVC(C=0.1, gamma='auto', kernel = 'rbf',probability=True)\n",
        "svm.fit(X_train, y_train)\n",
        "STr = svm.score(X_train, y_train)\n",
        "STe = svm.score(X_test, y_test)\n",
        "y_pred_svm = svm.predict(X_test)"
      ],
      "metadata": {
        "id": "wnRYFOkyEEZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ANN\n",
        "tf.random.set_seed(123)\n",
        "ANNmodel = Sequential()\n",
        "ANNmodel.add(Dense(30, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "ANNmodel.add(Dense(10, activation='relu'))\n",
        "ANNmodel.add(Dense(1, activation='sigmoid'))\n",
        "ANNmodel.compile(loss='BinaryCrossentropy', optimizer='adam', metrics=['accuracy']) #tf.keras.metrics.Precision(), tf.keras.metrics.Recall()\n",
        "ANNmodel.fit(X_train,y_train, batch_size = 128, epochs = 20, validation_split = 0.1)\n",
        "ATr = ANNmodel.evaluate(X_train,y_train,verbose=0)[1]\n",
        "ATe = ANNmodel.evaluate(X_test,y_test,verbose=0)[1]\n",
        "y_pred_ANN = (ANNmodel.predict(X_test) > 0.5).astype(\"int32\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZX7DbN-OIyu",
        "outputId": "e0ea008e-1bb8-4d81-a9f4-b330e1b10da6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "57/57 [==============================] - 2s 13ms/step - loss: 0.4435 - accuracy: 0.8051 - val_loss: 0.2634 - val_accuracy: 0.9250\n",
            "Epoch 2/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1864 - accuracy: 0.9331 - val_loss: 0.1506 - val_accuracy: 0.9362\n",
            "Epoch 3/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1371 - accuracy: 0.9417 - val_loss: 0.1329 - val_accuracy: 0.9362\n",
            "Epoch 4/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1256 - accuracy: 0.9472 - val_loss: 0.1267 - val_accuracy: 0.9413\n",
            "Epoch 5/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1201 - accuracy: 0.9506 - val_loss: 0.1237 - val_accuracy: 0.9438\n",
            "Epoch 6/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1172 - accuracy: 0.9490 - val_loss: 0.1213 - val_accuracy: 0.9450\n",
            "Epoch 7/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1147 - accuracy: 0.9515 - val_loss: 0.1185 - val_accuracy: 0.9513\n",
            "Epoch 8/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1128 - accuracy: 0.9528 - val_loss: 0.1186 - val_accuracy: 0.9463\n",
            "Epoch 9/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1110 - accuracy: 0.9525 - val_loss: 0.1172 - val_accuracy: 0.9488\n",
            "Epoch 10/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1093 - accuracy: 0.9533 - val_loss: 0.1158 - val_accuracy: 0.9475\n",
            "Epoch 11/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1083 - accuracy: 0.9539 - val_loss: 0.1169 - val_accuracy: 0.9500\n",
            "Epoch 12/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1071 - accuracy: 0.9546 - val_loss: 0.1148 - val_accuracy: 0.9450\n",
            "Epoch 13/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1052 - accuracy: 0.9556 - val_loss: 0.1150 - val_accuracy: 0.9500\n",
            "Epoch 14/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1042 - accuracy: 0.9564 - val_loss: 0.1152 - val_accuracy: 0.9488\n",
            "Epoch 15/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1029 - accuracy: 0.9561 - val_loss: 0.1160 - val_accuracy: 0.9488\n",
            "Epoch 16/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1016 - accuracy: 0.9567 - val_loss: 0.1149 - val_accuracy: 0.9475\n",
            "Epoch 17/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1009 - accuracy: 0.9578 - val_loss: 0.1157 - val_accuracy: 0.9450\n",
            "Epoch 18/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.0999 - accuracy: 0.9575 - val_loss: 0.1140 - val_accuracy: 0.9475\n",
            "Epoch 19/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.0987 - accuracy: 0.9592 - val_loss: 0.1146 - val_accuracy: 0.9488\n",
            "Epoch 20/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.0977 - accuracy: 0.9593 - val_loss: 0.1150 - val_accuracy: 0.9538\n",
            "63/63 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XGBoost\n",
        "params = {\n",
        "            'objective':'binary:logistic',\n",
        "            'max_depth': 7,\n",
        "            'alpha': 10,\n",
        "            'learning_rate': 1,\n",
        "            'n_estimators':100\n",
        "        }\n",
        "xgb = XGBClassifier(objective='binary:logistic',max_depth= 7,alpha= 10,learning_rate= 1,n_estimators=100)\n",
        "xgb.fit(X_train, y_train)\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "XTr = accuracy_score(y_train, xgb.predict(X_train))\n",
        "XTe = accuracy_score(y_test, xgb.predict(X_test))\n",
        "XTr,XTe"
      ],
      "metadata": {
        "id": "PCP82YZ9RjgJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d557203-9a90-481a-95ce-dc8aa3a759d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.98825, 0.9455)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#KNN\n",
        "# Define the range of n_neighbors values to test\n",
        "n_neighbors_values = [1,3, 5, 7, 9, 11]\n",
        "\n",
        "best_accuracy = 0.0\n",
        "best_n_neighbors = None\n",
        "\n",
        "for n_neighbors in n_neighbors_values:\n",
        "    print(\"Number of Neighbors:\", n_neighbors)\n",
        "\n",
        "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    y_pred_knn = knn.predict(X_test)\n",
        "\n",
        "    train_accuracy = accuracy_score(y_train, knn.predict(X_train))\n",
        "    test_accuracy = accuracy_score(y_test, knn.predict(X_test))\n",
        "\n",
        "    print('KNN model train accuracy score: {0:0.4f}'.format(train_accuracy))\n",
        "    print('KNN model test accuracy score: {0:0.4f}'.format(test_accuracy))\n",
        "    print()\n",
        "\n",
        "    # Check if the current test accuracy is better than the previous best\n",
        "    if test_accuracy > best_accuracy:\n",
        "        best_accuracy = test_accuracy\n",
        "        best_n_neighbors = n_neighbors\n",
        "print(\"best neighbours: \", best_n_neighbors)\n",
        "knn = KNeighborsClassifier(n_neighbors=best_n_neighbors)\n",
        "knn.fit(X_train, y_train)\n",
        "KTr = accuracy_score(y_train, knn.predict(X_train))\n",
        "KTe = accuracy_score(y_test, knn.predict(X_test))\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "KTr,KTe\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Y_6b33A1imy",
        "outputId": "1d2cdf2f-f72b-4c3c-beca-bd0892b14f06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Neighbors: 1\n",
            "KNN model train accuracy score: 1.0000\n",
            "KNN model test accuracy score: 0.9180\n",
            "\n",
            "Number of Neighbors: 3\n",
            "KNN model train accuracy score: 0.9629\n",
            "KNN model test accuracy score: 0.9340\n",
            "\n",
            "Number of Neighbors: 5\n",
            "KNN model train accuracy score: 0.9549\n",
            "KNN model test accuracy score: 0.9445\n",
            "\n",
            "Number of Neighbors: 7\n",
            "KNN model train accuracy score: 0.9537\n",
            "KNN model test accuracy score: 0.9440\n",
            "\n",
            "Number of Neighbors: 9\n",
            "KNN model train accuracy score: 0.9523\n",
            "KNN model test accuracy score: 0.9445\n",
            "\n",
            "Number of Neighbors: 11\n",
            "KNN model train accuracy score: 0.9499\n",
            "KNN model test accuracy score: 0.9410\n",
            "\n",
            "best neighbours:  5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.954875, 0.9445)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RF\n",
        "rf = RandomForestClassifier(n_estimators= 500,max_features = 'sqrt', max_samples = 100, random_state=123)\n",
        "rf.fit(X_train, y_train)\n",
        "RTr = accuracy_score(y_train, rf.predict(X_train))\n",
        "RTe = accuracy_score(y_test, rf.predict(X_test))\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "RTr,RTe"
      ],
      "metadata": {
        "id": "k_kyk_E92bSX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56673b29-dcd4-4087-a5cf-09cf03e43ce6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.943875, 0.9505)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LR\n",
        "lr = LogisticRegression(C= 0.1 , penalty='l1', solver='liblinear', max_iter = 1000, random_state=123)\n",
        "lr.fit(X_train, y_train)\n",
        "LTr = accuracy_score(y_train, lr.predict(X_train))\n",
        "LTe = accuracy_score(y_test, lr.predict(X_test))\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "LTr,LTe"
      ],
      "metadata": {
        "id": "OWkZmwL23Fm_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27c00459-2fc3-434e-c02b-66a4e8adbb78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.95, 0.95)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E9_l6r5f0w5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CVal(ML):\n",
        "\n",
        "  df = pd.read_csv(\"https://raw.githubusercontent.com/ashiqurrahmankhan21st/BreastCancer/main/tvae_SDV_BreastCancer.csv\")\n",
        "  del df['Unnamed: 0']\n",
        "\n",
        "  s = 0\n",
        "  e = round(df.shape[0]*.2)\n",
        "\n",
        "  y_pred = []\n",
        "  y_original = []\n",
        "\n",
        "  for i in range(5):\n",
        "\n",
        "    test_set  = df.iloc[s:e,:]\n",
        "    train_set = df.drop(test_set.index)\n",
        "\n",
        "    X_train = StandardScaler().fit_transform(train_set.drop(columns=['diagnosis'])).copy()\n",
        "    y_train = encoder.fit_transform(train_set['diagnosis']).copy()\n",
        "    X_test = StandardScaler().fit_transform(test_set.drop(columns=['diagnosis'])).copy()\n",
        "    y_test = encoder.fit_transform(test_set['diagnosis']).copy()\n",
        "\n",
        "    #svm = SVC(C=0.1, gamma='auto', kernel = 'rbf')\n",
        "    ML.fit(X_train, y_train)\n",
        "    y_pred_ML = ML.predict(X_test)\n",
        "\n",
        "\n",
        "    y_pred.append(y_pred_ML)\n",
        "    y_original.append(y_test)\n",
        "\n",
        "    s = e\n",
        "    e = e + round(df.shape[0]*.2)\n",
        "    if e-s < round(df.shape[0]*.2):\n",
        "      e = df.shape[0]+1\n",
        "\n",
        "  y_pred_final = []\n",
        "  y_original_final = []\n",
        "\n",
        "  try:\n",
        "    for i in range(5):\n",
        "      for j in range(round(df.shape[0]*.2)):\n",
        "        y_pred_final.append(y_pred[i][j])\n",
        "        y_original_final.append(y_original[i][j])\n",
        "  except:\n",
        "    pass\n",
        "  return y_pred_final"
      ],
      "metadata": {
        "id": "XqaJZ1Mb0xAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CValANN():\n",
        "\n",
        "  df = pd.read_csv(\"https://raw.githubusercontent.com/ashiqurrahmankhan21st/BreastCancer/main/tvae_SDV_BreastCancer.csv\")\n",
        "  del df['Unnamed: 0']\n",
        "\n",
        "  s = 0\n",
        "  e = round(df.shape[0]*.2)\n",
        "\n",
        "  y_pred = []\n",
        "  y_original = []\n",
        "\n",
        "  for i in range(5):\n",
        "\n",
        "    test_set  = df.iloc[s:e,:]\n",
        "    train_set = df.drop(test_set.index)\n",
        "\n",
        "    X_train = StandardScaler().fit_transform(train_set.drop(columns=['diagnosis'])).copy()\n",
        "    y_train = encoder.fit_transform(train_set['diagnosis']).copy()\n",
        "    X_test = StandardScaler().fit_transform(test_set.drop(columns=['diagnosis'])).copy()\n",
        "    y_test = encoder.fit_transform(test_set['diagnosis']).copy()\n",
        "\n",
        "    #svm = SVC(C=0.1, gamma='auto', kernel = 'rbf')\n",
        "    tf.random.set_seed(123)\n",
        "    ANNmodel = Sequential()\n",
        "    ANNmodel.add(Dense(30, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "    ANNmodel.add(Dense(10, activation='relu'))\n",
        "    ANNmodel.add(Dense(1, activation='sigmoid'))\n",
        "    ANNmodel.compile(loss='BinaryCrossentropy', optimizer='adam', metrics=['accuracy']) #tf.keras.metrics.Precision(), tf.keras.metrics.Recall()\n",
        "    ANNmodel.fit(X_train,y_train, batch_size = 128, epochs = 20, validation_split = 0.1)\n",
        "    y_pred_ANN = (ANNmodel.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "\n",
        "    y_pred.append(y_pred_ANN)\n",
        "    y_original.append(y_test)\n",
        "\n",
        "    s = e\n",
        "    e = e + round(df.shape[0]*.2)\n",
        "    if e-s < round(df.shape[0]*.2):\n",
        "      e = df.shape[0]\n",
        "\n",
        "  y_pred_fina = []\n",
        "  y_original_final = []\n",
        "\n",
        "  try:\n",
        "    for i in range(5):\n",
        "      for j in range(round(df.shape[0]*.2)):\n",
        "        y_pred_fina.append(y_pred[i][j])\n",
        "        y_original_final.append(y_original[i][j])\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  y_pred_final = []\n",
        "\n",
        "  for i in range(len(y_pred_fina)):\n",
        "    y_pred_final.append(y_pred_fina[i][0])\n",
        "\n",
        "  return y_pred_final"
      ],
      "metadata": {
        "id": "jRa_a7EY0y6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newdata = pd.DataFrame({\n",
        "    \"SVM\": CVal(SVC(C=0.1, gamma='auto', kernel = 'rbf'))\n",
        "})\n",
        "newdata[\"KNN\"] = CVal(KNeighborsClassifier(n_neighbors=3))\n",
        "newdata[\"RF\"]  = CVal(RandomForestClassifier(n_estimators= 500,max_features = 'sqrt', max_samples = 100, random_state=123))\n",
        "newdata['LR']  = CVal(LogisticRegression(C= 0.1 , penalty='l1', solver='liblinear', max_iter = 1000, random_state=123))\n",
        "newdata[\"ANN\"] = CValANN()\n",
        "newdata[\"XGB\"] = CVal(XGBClassifier(objective='binary:logistic',max_depth= 7,alpha= 10,learning_rate= 1,n_estimators=100))\n",
        "newdata['y_test'] = encoder.fit_transform(df['diagnosis']).copy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CGgdO1V0zA9",
        "outputId": "e51270be-ffa5-4608-95c3-e25dd8cb8500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "57/57 [==============================] - 1s 5ms/step - loss: 0.4555 - accuracy: 0.8206 - val_loss: 0.2911 - val_accuracy: 0.9125\n",
            "Epoch 2/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.2136 - accuracy: 0.9290 - val_loss: 0.1829 - val_accuracy: 0.9400\n",
            "Epoch 3/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1568 - accuracy: 0.9385 - val_loss: 0.1500 - val_accuracy: 0.9450\n",
            "Epoch 4/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1383 - accuracy: 0.9464 - val_loss: 0.1383 - val_accuracy: 0.9438\n",
            "Epoch 5/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1298 - accuracy: 0.9472 - val_loss: 0.1326 - val_accuracy: 0.9450\n",
            "Epoch 6/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1253 - accuracy: 0.9483 - val_loss: 0.1290 - val_accuracy: 0.9475\n",
            "Epoch 7/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1222 - accuracy: 0.9499 - val_loss: 0.1270 - val_accuracy: 0.9525\n",
            "Epoch 8/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1197 - accuracy: 0.9503 - val_loss: 0.1239 - val_accuracy: 0.9463\n",
            "Epoch 9/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1173 - accuracy: 0.9518 - val_loss: 0.1234 - val_accuracy: 0.9513\n",
            "Epoch 10/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1155 - accuracy: 0.9519 - val_loss: 0.1220 - val_accuracy: 0.9513\n",
            "Epoch 11/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1135 - accuracy: 0.9529 - val_loss: 0.1218 - val_accuracy: 0.9525\n",
            "Epoch 12/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1122 - accuracy: 0.9531 - val_loss: 0.1201 - val_accuracy: 0.9525\n",
            "Epoch 13/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1113 - accuracy: 0.9536 - val_loss: 0.1187 - val_accuracy: 0.9500\n",
            "Epoch 14/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1093 - accuracy: 0.9542 - val_loss: 0.1184 - val_accuracy: 0.9513\n",
            "Epoch 15/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1078 - accuracy: 0.9561 - val_loss: 0.1182 - val_accuracy: 0.9563\n",
            "Epoch 16/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1066 - accuracy: 0.9560 - val_loss: 0.1179 - val_accuracy: 0.9513\n",
            "Epoch 17/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1056 - accuracy: 0.9551 - val_loss: 0.1178 - val_accuracy: 0.9525\n",
            "Epoch 18/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1043 - accuracy: 0.9551 - val_loss: 0.1170 - val_accuracy: 0.9500\n",
            "Epoch 19/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1031 - accuracy: 0.9560 - val_loss: 0.1165 - val_accuracy: 0.9500\n",
            "Epoch 20/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1023 - accuracy: 0.9563 - val_loss: 0.1168 - val_accuracy: 0.9525\n",
            "63/63 [==============================] - 0s 1ms/step\n",
            "Epoch 1/20\n",
            "57/57 [==============================] - 1s 5ms/step - loss: 0.4497 - accuracy: 0.7706 - val_loss: 0.3020 - val_accuracy: 0.8938\n",
            "Epoch 2/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.2369 - accuracy: 0.9117 - val_loss: 0.1914 - val_accuracy: 0.9325\n",
            "Epoch 3/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1693 - accuracy: 0.9337 - val_loss: 0.1488 - val_accuracy: 0.9475\n",
            "Epoch 4/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1433 - accuracy: 0.9413 - val_loss: 0.1322 - val_accuracy: 0.9488\n",
            "Epoch 5/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1312 - accuracy: 0.9440 - val_loss: 0.1251 - val_accuracy: 0.9488\n",
            "Epoch 6/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1247 - accuracy: 0.9460 - val_loss: 0.1209 - val_accuracy: 0.9538\n",
            "Epoch 7/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1206 - accuracy: 0.9474 - val_loss: 0.1195 - val_accuracy: 0.9550\n",
            "Epoch 8/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1176 - accuracy: 0.9472 - val_loss: 0.1172 - val_accuracy: 0.9525\n",
            "Epoch 9/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1150 - accuracy: 0.9497 - val_loss: 0.1162 - val_accuracy: 0.9538\n",
            "Epoch 10/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1134 - accuracy: 0.9503 - val_loss: 0.1160 - val_accuracy: 0.9563\n",
            "Epoch 11/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1118 - accuracy: 0.9511 - val_loss: 0.1167 - val_accuracy: 0.9550\n",
            "Epoch 12/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1107 - accuracy: 0.9501 - val_loss: 0.1158 - val_accuracy: 0.9575\n",
            "Epoch 13/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1090 - accuracy: 0.9517 - val_loss: 0.1142 - val_accuracy: 0.9538\n",
            "Epoch 14/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1076 - accuracy: 0.9522 - val_loss: 0.1145 - val_accuracy: 0.9550\n",
            "Epoch 15/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1063 - accuracy: 0.9531 - val_loss: 0.1155 - val_accuracy: 0.9563\n",
            "Epoch 16/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1052 - accuracy: 0.9547 - val_loss: 0.1142 - val_accuracy: 0.9538\n",
            "Epoch 17/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1037 - accuracy: 0.9542 - val_loss: 0.1147 - val_accuracy: 0.9563\n",
            "Epoch 18/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1029 - accuracy: 0.9549 - val_loss: 0.1152 - val_accuracy: 0.9563\n",
            "Epoch 19/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1016 - accuracy: 0.9551 - val_loss: 0.1146 - val_accuracy: 0.9588\n",
            "Epoch 20/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1013 - accuracy: 0.9558 - val_loss: 0.1153 - val_accuracy: 0.9563\n",
            "63/63 [==============================] - 0s 1ms/step\n",
            "Epoch 1/20\n",
            "57/57 [==============================] - 1s 5ms/step - loss: 0.4223 - accuracy: 0.8625 - val_loss: 0.2665 - val_accuracy: 0.9162\n",
            "Epoch 2/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1918 - accuracy: 0.9340 - val_loss: 0.1629 - val_accuracy: 0.9375\n",
            "Epoch 3/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1411 - accuracy: 0.9447 - val_loss: 0.1358 - val_accuracy: 0.9475\n",
            "Epoch 4/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1267 - accuracy: 0.9469 - val_loss: 0.1274 - val_accuracy: 0.9475\n",
            "Epoch 5/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1206 - accuracy: 0.9488 - val_loss: 0.1240 - val_accuracy: 0.9513\n",
            "Epoch 6/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1173 - accuracy: 0.9503 - val_loss: 0.1224 - val_accuracy: 0.9513\n",
            "Epoch 7/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1140 - accuracy: 0.9522 - val_loss: 0.1213 - val_accuracy: 0.9525\n",
            "Epoch 8/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1124 - accuracy: 0.9525 - val_loss: 0.1198 - val_accuracy: 0.9538\n",
            "Epoch 9/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1102 - accuracy: 0.9544 - val_loss: 0.1192 - val_accuracy: 0.9538\n",
            "Epoch 10/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1088 - accuracy: 0.9533 - val_loss: 0.1185 - val_accuracy: 0.9563\n",
            "Epoch 11/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1074 - accuracy: 0.9542 - val_loss: 0.1188 - val_accuracy: 0.9550\n",
            "Epoch 12/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1063 - accuracy: 0.9551 - val_loss: 0.1187 - val_accuracy: 0.9563\n",
            "Epoch 13/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1052 - accuracy: 0.9556 - val_loss: 0.1172 - val_accuracy: 0.9563\n",
            "Epoch 14/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1040 - accuracy: 0.9568 - val_loss: 0.1175 - val_accuracy: 0.9563\n",
            "Epoch 15/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1031 - accuracy: 0.9556 - val_loss: 0.1177 - val_accuracy: 0.9563\n",
            "Epoch 16/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1016 - accuracy: 0.9579 - val_loss: 0.1167 - val_accuracy: 0.9563\n",
            "Epoch 17/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1007 - accuracy: 0.9585 - val_loss: 0.1167 - val_accuracy: 0.9550\n",
            "Epoch 18/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1003 - accuracy: 0.9583 - val_loss: 0.1167 - val_accuracy: 0.9550\n",
            "Epoch 19/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0990 - accuracy: 0.9574 - val_loss: 0.1164 - val_accuracy: 0.9563\n",
            "Epoch 20/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.0991 - accuracy: 0.9578 - val_loss: 0.1174 - val_accuracy: 0.9550\n",
            "63/63 [==============================] - 0s 1ms/step\n",
            "Epoch 1/20\n",
            "57/57 [==============================] - 1s 5ms/step - loss: 0.4499 - accuracy: 0.7976 - val_loss: 0.2612 - val_accuracy: 0.9050\n",
            "Epoch 2/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1958 - accuracy: 0.9265 - val_loss: 0.1684 - val_accuracy: 0.9388\n",
            "Epoch 3/20\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1485 - accuracy: 0.9382 - val_loss: 0.1409 - val_accuracy: 0.9438\n",
            "Epoch 4/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1316 - accuracy: 0.9444 - val_loss: 0.1311 - val_accuracy: 0.9475\n",
            "Epoch 5/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1243 - accuracy: 0.9486 - val_loss: 0.1262 - val_accuracy: 0.9463\n",
            "Epoch 6/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1201 - accuracy: 0.9499 - val_loss: 0.1238 - val_accuracy: 0.9500\n",
            "Epoch 7/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1170 - accuracy: 0.9511 - val_loss: 0.1227 - val_accuracy: 0.9500\n",
            "Epoch 8/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1150 - accuracy: 0.9513 - val_loss: 0.1213 - val_accuracy: 0.9500\n",
            "Epoch 9/20\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1121 - accuracy: 0.9531 - val_loss: 0.1212 - val_accuracy: 0.9500\n",
            "Epoch 10/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1108 - accuracy: 0.9528 - val_loss: 0.1199 - val_accuracy: 0.9500\n",
            "Epoch 11/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1093 - accuracy: 0.9529 - val_loss: 0.1198 - val_accuracy: 0.9513\n",
            "Epoch 12/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1078 - accuracy: 0.9546 - val_loss: 0.1197 - val_accuracy: 0.9525\n",
            "Epoch 13/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1064 - accuracy: 0.9544 - val_loss: 0.1191 - val_accuracy: 0.9525\n",
            "Epoch 14/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1052 - accuracy: 0.9540 - val_loss: 0.1186 - val_accuracy: 0.9550\n",
            "Epoch 15/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1039 - accuracy: 0.9549 - val_loss: 0.1190 - val_accuracy: 0.9525\n",
            "Epoch 16/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1025 - accuracy: 0.9568 - val_loss: 0.1183 - val_accuracy: 0.9538\n",
            "Epoch 17/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1012 - accuracy: 0.9572 - val_loss: 0.1181 - val_accuracy: 0.9550\n",
            "Epoch 18/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.0999 - accuracy: 0.9569 - val_loss: 0.1183 - val_accuracy: 0.9563\n",
            "Epoch 19/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0988 - accuracy: 0.9579 - val_loss: 0.1179 - val_accuracy: 0.9538\n",
            "Epoch 20/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.0979 - accuracy: 0.9579 - val_loss: 0.1183 - val_accuracy: 0.9575\n",
            "63/63 [==============================] - 0s 1ms/step\n",
            "Epoch 1/20\n",
            "57/57 [==============================] - 1s 5ms/step - loss: 0.5381 - accuracy: 0.7386 - val_loss: 0.2998 - val_accuracy: 0.9112\n",
            "Epoch 2/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.2246 - accuracy: 0.9242 - val_loss: 0.1674 - val_accuracy: 0.9362\n",
            "Epoch 3/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1507 - accuracy: 0.9408 - val_loss: 0.1362 - val_accuracy: 0.9400\n",
            "Epoch 4/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1304 - accuracy: 0.9464 - val_loss: 0.1267 - val_accuracy: 0.9450\n",
            "Epoch 5/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1229 - accuracy: 0.9493 - val_loss: 0.1217 - val_accuracy: 0.9450\n",
            "Epoch 6/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1183 - accuracy: 0.9511 - val_loss: 0.1197 - val_accuracy: 0.9475\n",
            "Epoch 7/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1148 - accuracy: 0.9521 - val_loss: 0.1187 - val_accuracy: 0.9463\n",
            "Epoch 8/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1131 - accuracy: 0.9526 - val_loss: 0.1173 - val_accuracy: 0.9475\n",
            "Epoch 9/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1105 - accuracy: 0.9539 - val_loss: 0.1151 - val_accuracy: 0.9463\n",
            "Epoch 10/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1092 - accuracy: 0.9535 - val_loss: 0.1151 - val_accuracy: 0.9450\n",
            "Epoch 11/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1076 - accuracy: 0.9542 - val_loss: 0.1150 - val_accuracy: 0.9488\n",
            "Epoch 12/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1060 - accuracy: 0.9550 - val_loss: 0.1157 - val_accuracy: 0.9450\n",
            "Epoch 13/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1046 - accuracy: 0.9547 - val_loss: 0.1147 - val_accuracy: 0.9488\n",
            "Epoch 14/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.1035 - accuracy: 0.9550 - val_loss: 0.1152 - val_accuracy: 0.9500\n",
            "Epoch 15/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1026 - accuracy: 0.9568 - val_loss: 0.1133 - val_accuracy: 0.9475\n",
            "Epoch 16/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1012 - accuracy: 0.9575 - val_loss: 0.1161 - val_accuracy: 0.9513\n",
            "Epoch 17/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1004 - accuracy: 0.9569 - val_loss: 0.1160 - val_accuracy: 0.9525\n",
            "Epoch 18/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0992 - accuracy: 0.9571 - val_loss: 0.1168 - val_accuracy: 0.9525\n",
            "Epoch 19/20\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.0982 - accuracy: 0.9579 - val_loss: 0.1158 - val_accuracy: 0.9500\n",
            "Epoch 20/20\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0970 - accuracy: 0.9589 - val_loss: 0.1159 - val_accuracy: 0.9525\n",
            "63/63 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newdata.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "05ryfvyLzFVK",
        "outputId": "6822554f-3fa4-4c40-ebb6-bd50148cf93e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   SVM  KNN  RF  LR  ANN  XGB  y_test\n",
              "0    0    0   0   0    0    0       0\n",
              "1    0    0   0   0    0    0       0\n",
              "2    0    0   0   0    0    0       0\n",
              "3    0    0   0   0    0    0       0\n",
              "4    0    0   0   0    0    0       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-04bed4b8-bf6f-438d-9586-4676024b9c25\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SVM</th>\n",
              "      <th>KNN</th>\n",
              "      <th>RF</th>\n",
              "      <th>LR</th>\n",
              "      <th>ANN</th>\n",
              "      <th>XGB</th>\n",
              "      <th>y_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04bed4b8-bf6f-438d-9586-4676024b9c25')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-04bed4b8-bf6f-438d-9586-4676024b9c25 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-04bed4b8-bf6f-438d-9586-4676024b9c25');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the DNN model\n",
        "DNNX = newdata.drop(columns=['y_test']).copy()\n",
        "DNNY = newdata.y_test.copy()\n",
        "DX_train, DX_test, Dy_train, Dy_test = train_test_split(\n",
        "    DNNX, DNNY, test_size=0.2, random_state=123)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(30, activation='relu', input_shape=DNNX.shape[1:]),\n",
        "    tf.keras.layers.Dense(25, activation='relu'),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dense(15, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(DX_train, Dy_train, epochs=500, batch_size=64, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4kf97a3yX15",
        "outputId": "c22dc6dd-2f86-49af-c665-bedcd4415eaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "100/100 [==============================] - 2s 4ms/step - loss: 0.6285 - accuracy: 0.6195 - val_loss: 0.4857 - val_accuracy: 0.5975\n",
            "Epoch 2/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.3668 - accuracy: 0.7708 - val_loss: 0.3476 - val_accuracy: 0.9463\n",
            "Epoch 3/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.9438 - val_loss: 0.3301 - val_accuracy: 0.9450\n",
            "Epoch 4/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.3146 - accuracy: 0.9434 - val_loss: 0.3150 - val_accuracy: 0.9488\n",
            "Epoch 5/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3001 - accuracy: 0.9497 - val_loss: 0.3004 - val_accuracy: 0.9488\n",
            "Epoch 6/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2864 - accuracy: 0.9505 - val_loss: 0.2872 - val_accuracy: 0.9481\n",
            "Epoch 7/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2761 - accuracy: 0.9503 - val_loss: 0.2770 - val_accuracy: 0.9488\n",
            "Epoch 8/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2654 - accuracy: 0.9500 - val_loss: 0.2666 - val_accuracy: 0.9475\n",
            "Epoch 9/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2564 - accuracy: 0.9511 - val_loss: 0.2582 - val_accuracy: 0.9475\n",
            "Epoch 10/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2483 - accuracy: 0.9508 - val_loss: 0.2492 - val_accuracy: 0.9488\n",
            "Epoch 11/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2405 - accuracy: 0.9513 - val_loss: 0.2423 - val_accuracy: 0.9500\n",
            "Epoch 12/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2341 - accuracy: 0.9514 - val_loss: 0.2343 - val_accuracy: 0.9500\n",
            "Epoch 13/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2275 - accuracy: 0.9523 - val_loss: 0.2288 - val_accuracy: 0.9488\n",
            "Epoch 14/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2223 - accuracy: 0.9508 - val_loss: 0.2230 - val_accuracy: 0.9469\n",
            "Epoch 15/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2171 - accuracy: 0.9520 - val_loss: 0.2173 - val_accuracy: 0.9488\n",
            "Epoch 16/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2123 - accuracy: 0.9527 - val_loss: 0.2108 - val_accuracy: 0.9494\n",
            "Epoch 17/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2072 - accuracy: 0.9522 - val_loss: 0.2064 - val_accuracy: 0.9469\n",
            "Epoch 18/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.2033 - accuracy: 0.9525 - val_loss: 0.2020 - val_accuracy: 0.9494\n",
            "Epoch 19/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1997 - accuracy: 0.9520 - val_loss: 0.1992 - val_accuracy: 0.9481\n",
            "Epoch 20/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1959 - accuracy: 0.9520 - val_loss: 0.1948 - val_accuracy: 0.9494\n",
            "Epoch 21/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1923 - accuracy: 0.9516 - val_loss: 0.1907 - val_accuracy: 0.9506\n",
            "Epoch 22/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1896 - accuracy: 0.9514 - val_loss: 0.1890 - val_accuracy: 0.9519\n",
            "Epoch 23/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1875 - accuracy: 0.9523 - val_loss: 0.1841 - val_accuracy: 0.9469\n",
            "Epoch 24/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1842 - accuracy: 0.9527 - val_loss: 0.1813 - val_accuracy: 0.9481\n",
            "Epoch 25/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1821 - accuracy: 0.9523 - val_loss: 0.1796 - val_accuracy: 0.9469\n",
            "Epoch 26/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.9525 - val_loss: 0.1762 - val_accuracy: 0.9494\n",
            "Epoch 27/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1770 - accuracy: 0.9531 - val_loss: 0.1747 - val_accuracy: 0.9481\n",
            "Epoch 28/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1755 - accuracy: 0.9516 - val_loss: 0.1723 - val_accuracy: 0.9494\n",
            "Epoch 29/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1741 - accuracy: 0.9523 - val_loss: 0.1700 - val_accuracy: 0.9488\n",
            "Epoch 30/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1714 - accuracy: 0.9531 - val_loss: 0.1674 - val_accuracy: 0.9494\n",
            "Epoch 31/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1704 - accuracy: 0.9522 - val_loss: 0.1697 - val_accuracy: 0.9513\n",
            "Epoch 32/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1691 - accuracy: 0.9528 - val_loss: 0.1659 - val_accuracy: 0.9481\n",
            "Epoch 33/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1675 - accuracy: 0.9523 - val_loss: 0.1637 - val_accuracy: 0.9494\n",
            "Epoch 34/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1652 - accuracy: 0.9528 - val_loss: 0.1612 - val_accuracy: 0.9488\n",
            "Epoch 35/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1649 - accuracy: 0.9531 - val_loss: 0.1616 - val_accuracy: 0.9500\n",
            "Epoch 36/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1630 - accuracy: 0.9525 - val_loss: 0.1598 - val_accuracy: 0.9513\n",
            "Epoch 37/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1627 - accuracy: 0.9528 - val_loss: 0.1561 - val_accuracy: 0.9494\n",
            "Epoch 38/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1604 - accuracy: 0.9538 - val_loss: 0.1565 - val_accuracy: 0.9488\n",
            "Epoch 39/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1592 - accuracy: 0.9542 - val_loss: 0.1580 - val_accuracy: 0.9500\n",
            "Epoch 40/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1587 - accuracy: 0.9536 - val_loss: 0.1574 - val_accuracy: 0.9494\n",
            "Epoch 41/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1579 - accuracy: 0.9531 - val_loss: 0.1563 - val_accuracy: 0.9494\n",
            "Epoch 42/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1574 - accuracy: 0.9534 - val_loss: 0.1552 - val_accuracy: 0.9513\n",
            "Epoch 43/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1564 - accuracy: 0.9542 - val_loss: 0.1542 - val_accuracy: 0.9494\n",
            "Epoch 44/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1561 - accuracy: 0.9538 - val_loss: 0.1525 - val_accuracy: 0.9494\n",
            "Epoch 45/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1544 - accuracy: 0.9539 - val_loss: 0.1528 - val_accuracy: 0.9500\n",
            "Epoch 46/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1540 - accuracy: 0.9544 - val_loss: 0.1517 - val_accuracy: 0.9494\n",
            "Epoch 47/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1534 - accuracy: 0.9544 - val_loss: 0.1501 - val_accuracy: 0.9506\n",
            "Epoch 48/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1527 - accuracy: 0.9552 - val_loss: 0.1537 - val_accuracy: 0.9488\n",
            "Epoch 49/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1524 - accuracy: 0.9541 - val_loss: 0.1508 - val_accuracy: 0.9494\n",
            "Epoch 50/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1522 - accuracy: 0.9542 - val_loss: 0.1507 - val_accuracy: 0.9494\n",
            "Epoch 51/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1522 - accuracy: 0.9538 - val_loss: 0.1477 - val_accuracy: 0.9488\n",
            "Epoch 52/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1511 - accuracy: 0.9552 - val_loss: 0.1487 - val_accuracy: 0.9506\n",
            "Epoch 53/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1516 - accuracy: 0.9547 - val_loss: 0.1495 - val_accuracy: 0.9538\n",
            "Epoch 54/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1510 - accuracy: 0.9545 - val_loss: 0.1476 - val_accuracy: 0.9494\n",
            "Epoch 55/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1500 - accuracy: 0.9544 - val_loss: 0.1459 - val_accuracy: 0.9500\n",
            "Epoch 56/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1498 - accuracy: 0.9550 - val_loss: 0.1465 - val_accuracy: 0.9506\n",
            "Epoch 57/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1499 - accuracy: 0.9545 - val_loss: 0.1476 - val_accuracy: 0.9481\n",
            "Epoch 58/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1492 - accuracy: 0.9539 - val_loss: 0.1468 - val_accuracy: 0.9494\n",
            "Epoch 59/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1492 - accuracy: 0.9544 - val_loss: 0.1484 - val_accuracy: 0.9494\n",
            "Epoch 60/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1500 - accuracy: 0.9545 - val_loss: 0.1497 - val_accuracy: 0.9494\n",
            "Epoch 61/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1492 - accuracy: 0.9536 - val_loss: 0.1485 - val_accuracy: 0.9481\n",
            "Epoch 62/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9545 - val_loss: 0.1454 - val_accuracy: 0.9506\n",
            "Epoch 63/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9545 - val_loss: 0.1460 - val_accuracy: 0.9506\n",
            "Epoch 64/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1495 - accuracy: 0.9544 - val_loss: 0.1445 - val_accuracy: 0.9494\n",
            "Epoch 65/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1490 - accuracy: 0.9545 - val_loss: 0.1467 - val_accuracy: 0.9506\n",
            "Epoch 66/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1483 - accuracy: 0.9539 - val_loss: 0.1450 - val_accuracy: 0.9506\n",
            "Epoch 67/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9552 - val_loss: 0.1447 - val_accuracy: 0.9506\n",
            "Epoch 68/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9541 - val_loss: 0.1459 - val_accuracy: 0.9506\n",
            "Epoch 69/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1471 - accuracy: 0.9541 - val_loss: 0.1466 - val_accuracy: 0.9506\n",
            "Epoch 70/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9553 - val_loss: 0.1460 - val_accuracy: 0.9481\n",
            "Epoch 71/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1484 - accuracy: 0.9552 - val_loss: 0.1462 - val_accuracy: 0.9481\n",
            "Epoch 72/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9541 - val_loss: 0.1519 - val_accuracy: 0.9494\n",
            "Epoch 73/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9547 - val_loss: 0.1484 - val_accuracy: 0.9513\n",
            "Epoch 74/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1469 - accuracy: 0.9550 - val_loss: 0.1452 - val_accuracy: 0.9513\n",
            "Epoch 75/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1473 - accuracy: 0.9547 - val_loss: 0.1468 - val_accuracy: 0.9506\n",
            "Epoch 76/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9547 - val_loss: 0.1439 - val_accuracy: 0.9500\n",
            "Epoch 77/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1466 - accuracy: 0.9548 - val_loss: 0.1452 - val_accuracy: 0.9506\n",
            "Epoch 78/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1466 - accuracy: 0.9548 - val_loss: 0.1456 - val_accuracy: 0.9506\n",
            "Epoch 79/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1472 - accuracy: 0.9538 - val_loss: 0.1452 - val_accuracy: 0.9488\n",
            "Epoch 80/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1464 - accuracy: 0.9555 - val_loss: 0.1454 - val_accuracy: 0.9513\n",
            "Epoch 81/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1460 - accuracy: 0.9553 - val_loss: 0.1452 - val_accuracy: 0.9506\n",
            "Epoch 82/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1478 - accuracy: 0.9544 - val_loss: 0.1442 - val_accuracy: 0.9506\n",
            "Epoch 83/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1466 - accuracy: 0.9550 - val_loss: 0.1441 - val_accuracy: 0.9513\n",
            "Epoch 84/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9547 - val_loss: 0.1444 - val_accuracy: 0.9506\n",
            "Epoch 85/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1470 - accuracy: 0.9541 - val_loss: 0.1438 - val_accuracy: 0.9506\n",
            "Epoch 86/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1473 - accuracy: 0.9553 - val_loss: 0.1436 - val_accuracy: 0.9513\n",
            "Epoch 87/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1461 - accuracy: 0.9555 - val_loss: 0.1431 - val_accuracy: 0.9494\n",
            "Epoch 88/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1471 - accuracy: 0.9541 - val_loss: 0.1448 - val_accuracy: 0.9513\n",
            "Epoch 89/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1465 - accuracy: 0.9547 - val_loss: 0.1445 - val_accuracy: 0.9513\n",
            "Epoch 90/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1463 - accuracy: 0.9547 - val_loss: 0.1441 - val_accuracy: 0.9506\n",
            "Epoch 91/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1461 - accuracy: 0.9553 - val_loss: 0.1459 - val_accuracy: 0.9506\n",
            "Epoch 92/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1466 - accuracy: 0.9541 - val_loss: 0.1451 - val_accuracy: 0.9506\n",
            "Epoch 93/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9561 - val_loss: 0.1447 - val_accuracy: 0.9525\n",
            "Epoch 94/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9558 - val_loss: 0.1441 - val_accuracy: 0.9513\n",
            "Epoch 95/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1464 - accuracy: 0.9553 - val_loss: 0.1439 - val_accuracy: 0.9506\n",
            "Epoch 96/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1460 - accuracy: 0.9559 - val_loss: 0.1445 - val_accuracy: 0.9506\n",
            "Epoch 97/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1464 - accuracy: 0.9552 - val_loss: 0.1434 - val_accuracy: 0.9506\n",
            "Epoch 98/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1456 - accuracy: 0.9548 - val_loss: 0.1450 - val_accuracy: 0.9525\n",
            "Epoch 99/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1460 - accuracy: 0.9545 - val_loss: 0.1442 - val_accuracy: 0.9506\n",
            "Epoch 100/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1460 - accuracy: 0.9547 - val_loss: 0.1446 - val_accuracy: 0.9494\n",
            "Epoch 101/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1462 - accuracy: 0.9550 - val_loss: 0.1431 - val_accuracy: 0.9525\n",
            "Epoch 102/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1464 - accuracy: 0.9553 - val_loss: 0.1451 - val_accuracy: 0.9531\n",
            "Epoch 103/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1462 - accuracy: 0.9550 - val_loss: 0.1477 - val_accuracy: 0.9513\n",
            "Epoch 104/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1465 - accuracy: 0.9547 - val_loss: 0.1439 - val_accuracy: 0.9506\n",
            "Epoch 105/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1459 - accuracy: 0.9544 - val_loss: 0.1434 - val_accuracy: 0.9525\n",
            "Epoch 106/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1464 - accuracy: 0.9553 - val_loss: 0.1437 - val_accuracy: 0.9506\n",
            "Epoch 107/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1461 - accuracy: 0.9548 - val_loss: 0.1434 - val_accuracy: 0.9506\n",
            "Epoch 108/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1457 - accuracy: 0.9552 - val_loss: 0.1433 - val_accuracy: 0.9513\n",
            "Epoch 109/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1462 - accuracy: 0.9534 - val_loss: 0.1427 - val_accuracy: 0.9506\n",
            "Epoch 110/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9547 - val_loss: 0.1427 - val_accuracy: 0.9506\n",
            "Epoch 111/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1458 - accuracy: 0.9553 - val_loss: 0.1425 - val_accuracy: 0.9513\n",
            "Epoch 112/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9552 - val_loss: 0.1431 - val_accuracy: 0.9513\n",
            "Epoch 113/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9556 - val_loss: 0.1443 - val_accuracy: 0.9506\n",
            "Epoch 114/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1454 - accuracy: 0.9552 - val_loss: 0.1442 - val_accuracy: 0.9544\n",
            "Epoch 115/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1462 - accuracy: 0.9538 - val_loss: 0.1436 - val_accuracy: 0.9513\n",
            "Epoch 116/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1460 - accuracy: 0.9545 - val_loss: 0.1445 - val_accuracy: 0.9506\n",
            "Epoch 117/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1466 - accuracy: 0.9545 - val_loss: 0.1434 - val_accuracy: 0.9506\n",
            "Epoch 118/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9547 - val_loss: 0.1433 - val_accuracy: 0.9506\n",
            "Epoch 119/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1461 - accuracy: 0.9550 - val_loss: 0.1440 - val_accuracy: 0.9506\n",
            "Epoch 120/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9548 - val_loss: 0.1425 - val_accuracy: 0.9506\n",
            "Epoch 121/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1459 - accuracy: 0.9552 - val_loss: 0.1433 - val_accuracy: 0.9525\n",
            "Epoch 122/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1461 - accuracy: 0.9552 - val_loss: 0.1430 - val_accuracy: 0.9506\n",
            "Epoch 123/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9547 - val_loss: 0.1429 - val_accuracy: 0.9500\n",
            "Epoch 124/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9552 - val_loss: 0.1432 - val_accuracy: 0.9500\n",
            "Epoch 125/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1460 - accuracy: 0.9552 - val_loss: 0.1435 - val_accuracy: 0.9513\n",
            "Epoch 126/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9552 - val_loss: 0.1436 - val_accuracy: 0.9513\n",
            "Epoch 127/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9550 - val_loss: 0.1441 - val_accuracy: 0.9513\n",
            "Epoch 128/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9548 - val_loss: 0.1451 - val_accuracy: 0.9531\n",
            "Epoch 129/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1463 - accuracy: 0.9545 - val_loss: 0.1432 - val_accuracy: 0.9513\n",
            "Epoch 130/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9544 - val_loss: 0.1440 - val_accuracy: 0.9506\n",
            "Epoch 131/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9553 - val_loss: 0.1433 - val_accuracy: 0.9513\n",
            "Epoch 132/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1458 - accuracy: 0.9548 - val_loss: 0.1435 - val_accuracy: 0.9531\n",
            "Epoch 133/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9548 - val_loss: 0.1438 - val_accuracy: 0.9506\n",
            "Epoch 134/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9553 - val_loss: 0.1461 - val_accuracy: 0.9506\n",
            "Epoch 135/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1455 - accuracy: 0.9547 - val_loss: 0.1439 - val_accuracy: 0.9513\n",
            "Epoch 136/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1456 - accuracy: 0.9553 - val_loss: 0.1432 - val_accuracy: 0.9525\n",
            "Epoch 137/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1460 - accuracy: 0.9552 - val_loss: 0.1432 - val_accuracy: 0.9506\n",
            "Epoch 138/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1456 - accuracy: 0.9553 - val_loss: 0.1485 - val_accuracy: 0.9513\n",
            "Epoch 139/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1459 - accuracy: 0.9544 - val_loss: 0.1431 - val_accuracy: 0.9513\n",
            "Epoch 140/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9548 - val_loss: 0.1450 - val_accuracy: 0.9531\n",
            "Epoch 141/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9553 - val_loss: 0.1428 - val_accuracy: 0.9506\n",
            "Epoch 142/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9548 - val_loss: 0.1449 - val_accuracy: 0.9513\n",
            "Epoch 143/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9548 - val_loss: 0.1449 - val_accuracy: 0.9544\n",
            "Epoch 144/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9552 - val_loss: 0.1436 - val_accuracy: 0.9513\n",
            "Epoch 145/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9552 - val_loss: 0.1433 - val_accuracy: 0.9506\n",
            "Epoch 146/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9545 - val_loss: 0.1434 - val_accuracy: 0.9506\n",
            "Epoch 147/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9544 - val_loss: 0.1467 - val_accuracy: 0.9513\n",
            "Epoch 148/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1460 - accuracy: 0.9545 - val_loss: 0.1422 - val_accuracy: 0.9506\n",
            "Epoch 149/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1459 - accuracy: 0.9550 - val_loss: 0.1440 - val_accuracy: 0.9506\n",
            "Epoch 150/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9548 - val_loss: 0.1461 - val_accuracy: 0.9513\n",
            "Epoch 151/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9553 - val_loss: 0.1437 - val_accuracy: 0.9513\n",
            "Epoch 152/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9558 - val_loss: 0.1439 - val_accuracy: 0.9506\n",
            "Epoch 153/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1463 - accuracy: 0.9550 - val_loss: 0.1433 - val_accuracy: 0.9513\n",
            "Epoch 154/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1460 - accuracy: 0.9541 - val_loss: 0.1435 - val_accuracy: 0.9513\n",
            "Epoch 155/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9538 - val_loss: 0.1447 - val_accuracy: 0.9525\n",
            "Epoch 156/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9548 - val_loss: 0.1443 - val_accuracy: 0.9506\n",
            "Epoch 157/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1460 - accuracy: 0.9544 - val_loss: 0.1439 - val_accuracy: 0.9494\n",
            "Epoch 158/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9542 - val_loss: 0.1463 - val_accuracy: 0.9513\n",
            "Epoch 159/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1462 - accuracy: 0.9552 - val_loss: 0.1439 - val_accuracy: 0.9513\n",
            "Epoch 160/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9547 - val_loss: 0.1436 - val_accuracy: 0.9506\n",
            "Epoch 161/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9555 - val_loss: 0.1434 - val_accuracy: 0.9506\n",
            "Epoch 162/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9553 - val_loss: 0.1440 - val_accuracy: 0.9513\n",
            "Epoch 163/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9541 - val_loss: 0.1440 - val_accuracy: 0.9513\n",
            "Epoch 164/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9553 - val_loss: 0.1445 - val_accuracy: 0.9506\n",
            "Epoch 165/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9550 - val_loss: 0.1443 - val_accuracy: 0.9506\n",
            "Epoch 166/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9555 - val_loss: 0.1440 - val_accuracy: 0.9506\n",
            "Epoch 167/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9553 - val_loss: 0.1435 - val_accuracy: 0.9506\n",
            "Epoch 168/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1462 - accuracy: 0.9544 - val_loss: 0.1431 - val_accuracy: 0.9506\n",
            "Epoch 169/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9556 - val_loss: 0.1424 - val_accuracy: 0.9506\n",
            "Epoch 170/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1459 - accuracy: 0.9545 - val_loss: 0.1451 - val_accuracy: 0.9506\n",
            "Epoch 171/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9552 - val_loss: 0.1451 - val_accuracy: 0.9506\n",
            "Epoch 172/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1460 - accuracy: 0.9558 - val_loss: 0.1443 - val_accuracy: 0.9506\n",
            "Epoch 173/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9553 - val_loss: 0.1448 - val_accuracy: 0.9506\n",
            "Epoch 174/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9553 - val_loss: 0.1443 - val_accuracy: 0.9506\n",
            "Epoch 175/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1451 - accuracy: 0.9542 - val_loss: 0.1436 - val_accuracy: 0.9506\n",
            "Epoch 176/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1442 - accuracy: 0.9559 - val_loss: 0.1461 - val_accuracy: 0.9513\n",
            "Epoch 177/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1467 - accuracy: 0.9541 - val_loss: 0.1436 - val_accuracy: 0.9506\n",
            "Epoch 178/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1453 - accuracy: 0.9556 - val_loss: 0.1444 - val_accuracy: 0.9506\n",
            "Epoch 179/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1461 - accuracy: 0.9553 - val_loss: 0.1436 - val_accuracy: 0.9506\n",
            "Epoch 180/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1459 - accuracy: 0.9548 - val_loss: 0.1440 - val_accuracy: 0.9500\n",
            "Epoch 181/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9555 - val_loss: 0.1442 - val_accuracy: 0.9506\n",
            "Epoch 182/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9553 - val_loss: 0.1459 - val_accuracy: 0.9525\n",
            "Epoch 183/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1462 - accuracy: 0.9542 - val_loss: 0.1450 - val_accuracy: 0.9506\n",
            "Epoch 184/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9550 - val_loss: 0.1443 - val_accuracy: 0.9506\n",
            "Epoch 185/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9555 - val_loss: 0.1447 - val_accuracy: 0.9506\n",
            "Epoch 186/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9542 - val_loss: 0.1450 - val_accuracy: 0.9500\n",
            "Epoch 187/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9544 - val_loss: 0.1449 - val_accuracy: 0.9506\n",
            "Epoch 188/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9548 - val_loss: 0.1441 - val_accuracy: 0.9506\n",
            "Epoch 189/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9552 - val_loss: 0.1455 - val_accuracy: 0.9513\n",
            "Epoch 190/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9552 - val_loss: 0.1459 - val_accuracy: 0.9525\n",
            "Epoch 191/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9545 - val_loss: 0.1440 - val_accuracy: 0.9506\n",
            "Epoch 192/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9547 - val_loss: 0.1450 - val_accuracy: 0.9506\n",
            "Epoch 193/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9552 - val_loss: 0.1438 - val_accuracy: 0.9506\n",
            "Epoch 194/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9542 - val_loss: 0.1444 - val_accuracy: 0.9506\n",
            "Epoch 195/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9559 - val_loss: 0.1450 - val_accuracy: 0.9506\n",
            "Epoch 196/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9555 - val_loss: 0.1444 - val_accuracy: 0.9500\n",
            "Epoch 197/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9552 - val_loss: 0.1440 - val_accuracy: 0.9506\n",
            "Epoch 198/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9553 - val_loss: 0.1432 - val_accuracy: 0.9506\n",
            "Epoch 199/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9559 - val_loss: 0.1439 - val_accuracy: 0.9506\n",
            "Epoch 200/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1459 - accuracy: 0.9547 - val_loss: 0.1434 - val_accuracy: 0.9506\n",
            "Epoch 201/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9553 - val_loss: 0.1440 - val_accuracy: 0.9506\n",
            "Epoch 202/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9553 - val_loss: 0.1440 - val_accuracy: 0.9506\n",
            "Epoch 203/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9553 - val_loss: 0.1448 - val_accuracy: 0.9513\n",
            "Epoch 204/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9548 - val_loss: 0.1442 - val_accuracy: 0.9506\n",
            "Epoch 205/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9550 - val_loss: 0.1454 - val_accuracy: 0.9494\n",
            "Epoch 206/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9553 - val_loss: 0.1447 - val_accuracy: 0.9506\n",
            "Epoch 207/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9541 - val_loss: 0.1440 - val_accuracy: 0.9506\n",
            "Epoch 208/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9556 - val_loss: 0.1442 - val_accuracy: 0.9506\n",
            "Epoch 209/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9552 - val_loss: 0.1432 - val_accuracy: 0.9500\n",
            "Epoch 210/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9553 - val_loss: 0.1437 - val_accuracy: 0.9506\n",
            "Epoch 211/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9547 - val_loss: 0.1450 - val_accuracy: 0.9506\n",
            "Epoch 212/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9547 - val_loss: 0.1464 - val_accuracy: 0.9525\n",
            "Epoch 213/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9547 - val_loss: 0.1439 - val_accuracy: 0.9494\n",
            "Epoch 214/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1452 - accuracy: 0.9548 - val_loss: 0.1443 - val_accuracy: 0.9506\n",
            "Epoch 215/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1452 - accuracy: 0.9548 - val_loss: 0.1438 - val_accuracy: 0.9506\n",
            "Epoch 216/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1448 - accuracy: 0.9555 - val_loss: 0.1451 - val_accuracy: 0.9525\n",
            "Epoch 217/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1457 - accuracy: 0.9542 - val_loss: 0.1443 - val_accuracy: 0.9506\n",
            "Epoch 218/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1456 - accuracy: 0.9548 - val_loss: 0.1440 - val_accuracy: 0.9506\n",
            "Epoch 219/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9556 - val_loss: 0.1448 - val_accuracy: 0.9506\n",
            "Epoch 220/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9550 - val_loss: 0.1447 - val_accuracy: 0.9525\n",
            "Epoch 221/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9550 - val_loss: 0.1451 - val_accuracy: 0.9500\n",
            "Epoch 222/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9552 - val_loss: 0.1445 - val_accuracy: 0.9506\n",
            "Epoch 223/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9555 - val_loss: 0.1466 - val_accuracy: 0.9513\n",
            "Epoch 224/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9553 - val_loss: 0.1474 - val_accuracy: 0.9513\n",
            "Epoch 225/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9552 - val_loss: 0.1451 - val_accuracy: 0.9525\n",
            "Epoch 226/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9553 - val_loss: 0.1455 - val_accuracy: 0.9506\n",
            "Epoch 227/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9555 - val_loss: 0.1448 - val_accuracy: 0.9513\n",
            "Epoch 228/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9550 - val_loss: 0.1446 - val_accuracy: 0.9525\n",
            "Epoch 229/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9547 - val_loss: 0.1457 - val_accuracy: 0.9506\n",
            "Epoch 230/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9553 - val_loss: 0.1448 - val_accuracy: 0.9506\n",
            "Epoch 231/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9550 - val_loss: 0.1447 - val_accuracy: 0.9506\n",
            "Epoch 232/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9552 - val_loss: 0.1445 - val_accuracy: 0.9506\n",
            "Epoch 233/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9548 - val_loss: 0.1446 - val_accuracy: 0.9506\n",
            "Epoch 234/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9558 - val_loss: 0.1460 - val_accuracy: 0.9525\n",
            "Epoch 235/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9544 - val_loss: 0.1448 - val_accuracy: 0.9506\n",
            "Epoch 236/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9556 - val_loss: 0.1446 - val_accuracy: 0.9506\n",
            "Epoch 237/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9556 - val_loss: 0.1442 - val_accuracy: 0.9506\n",
            "Epoch 238/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9561 - val_loss: 0.1451 - val_accuracy: 0.9525\n",
            "Epoch 239/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9550 - val_loss: 0.1447 - val_accuracy: 0.9513\n",
            "Epoch 240/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9555 - val_loss: 0.1442 - val_accuracy: 0.9506\n",
            "Epoch 241/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9556 - val_loss: 0.1440 - val_accuracy: 0.9506\n",
            "Epoch 242/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9555 - val_loss: 0.1456 - val_accuracy: 0.9506\n",
            "Epoch 243/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9547 - val_loss: 0.1444 - val_accuracy: 0.9506\n",
            "Epoch 244/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9556 - val_loss: 0.1498 - val_accuracy: 0.9500\n",
            "Epoch 245/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9552 - val_loss: 0.1451 - val_accuracy: 0.9506\n",
            "Epoch 246/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9559 - val_loss: 0.1457 - val_accuracy: 0.9500\n",
            "Epoch 247/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9555 - val_loss: 0.1449 - val_accuracy: 0.9500\n",
            "Epoch 248/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9552 - val_loss: 0.1471 - val_accuracy: 0.9513\n",
            "Epoch 249/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9558 - val_loss: 0.1442 - val_accuracy: 0.9506\n",
            "Epoch 250/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9553 - val_loss: 0.1469 - val_accuracy: 0.9500\n",
            "Epoch 251/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1459 - accuracy: 0.9555 - val_loss: 0.1449 - val_accuracy: 0.9525\n",
            "Epoch 252/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9555 - val_loss: 0.1457 - val_accuracy: 0.9506\n",
            "Epoch 253/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9547 - val_loss: 0.1459 - val_accuracy: 0.9525\n",
            "Epoch 254/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1452 - accuracy: 0.9556 - val_loss: 0.1459 - val_accuracy: 0.9506\n",
            "Epoch 255/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1450 - accuracy: 0.9545 - val_loss: 0.1443 - val_accuracy: 0.9500\n",
            "Epoch 256/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1451 - accuracy: 0.9555 - val_loss: 0.1452 - val_accuracy: 0.9506\n",
            "Epoch 257/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1451 - accuracy: 0.9548 - val_loss: 0.1454 - val_accuracy: 0.9506\n",
            "Epoch 258/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1451 - accuracy: 0.9548 - val_loss: 0.1458 - val_accuracy: 0.9513\n",
            "Epoch 259/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9548 - val_loss: 0.1462 - val_accuracy: 0.9506\n",
            "Epoch 260/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9556 - val_loss: 0.1451 - val_accuracy: 0.9500\n",
            "Epoch 261/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9553 - val_loss: 0.1451 - val_accuracy: 0.9500\n",
            "Epoch 262/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9547 - val_loss: 0.1455 - val_accuracy: 0.9525\n",
            "Epoch 263/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9552 - val_loss: 0.1451 - val_accuracy: 0.9525\n",
            "Epoch 264/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9553 - val_loss: 0.1454 - val_accuracy: 0.9506\n",
            "Epoch 265/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9556 - val_loss: 0.1451 - val_accuracy: 0.9506\n",
            "Epoch 266/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9553 - val_loss: 0.1451 - val_accuracy: 0.9500\n",
            "Epoch 267/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1453 - accuracy: 0.9550 - val_loss: 0.1453 - val_accuracy: 0.9500\n",
            "Epoch 268/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9553 - val_loss: 0.1446 - val_accuracy: 0.9500\n",
            "Epoch 269/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9550 - val_loss: 0.1459 - val_accuracy: 0.9500\n",
            "Epoch 270/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1442 - accuracy: 0.9558 - val_loss: 0.1463 - val_accuracy: 0.9500\n",
            "Epoch 271/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9553 - val_loss: 0.1457 - val_accuracy: 0.9506\n",
            "Epoch 272/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1450 - accuracy: 0.9553 - val_loss: 0.1457 - val_accuracy: 0.9500\n",
            "Epoch 273/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9555 - val_loss: 0.1456 - val_accuracy: 0.9500\n",
            "Epoch 274/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9547 - val_loss: 0.1449 - val_accuracy: 0.9500\n",
            "Epoch 275/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9553 - val_loss: 0.1454 - val_accuracy: 0.9506\n",
            "Epoch 276/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9555 - val_loss: 0.1457 - val_accuracy: 0.9525\n",
            "Epoch 277/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9553 - val_loss: 0.1450 - val_accuracy: 0.9506\n",
            "Epoch 278/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9548 - val_loss: 0.1457 - val_accuracy: 0.9525\n",
            "Epoch 279/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9555 - val_loss: 0.1469 - val_accuracy: 0.9506\n",
            "Epoch 280/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9553 - val_loss: 0.1453 - val_accuracy: 0.9500\n",
            "Epoch 281/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9550 - val_loss: 0.1468 - val_accuracy: 0.9519\n",
            "Epoch 282/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9561 - val_loss: 0.1462 - val_accuracy: 0.9506\n",
            "Epoch 283/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9552 - val_loss: 0.1465 - val_accuracy: 0.9506\n",
            "Epoch 284/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9553 - val_loss: 0.1459 - val_accuracy: 0.9525\n",
            "Epoch 285/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9552 - val_loss: 0.1452 - val_accuracy: 0.9500\n",
            "Epoch 286/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9550 - val_loss: 0.1454 - val_accuracy: 0.9500\n",
            "Epoch 287/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9552 - val_loss: 0.1460 - val_accuracy: 0.9506\n",
            "Epoch 288/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9556 - val_loss: 0.1456 - val_accuracy: 0.9500\n",
            "Epoch 289/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9556 - val_loss: 0.1448 - val_accuracy: 0.9500\n",
            "Epoch 290/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9556 - val_loss: 0.1454 - val_accuracy: 0.9500\n",
            "Epoch 291/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9552 - val_loss: 0.1475 - val_accuracy: 0.9506\n",
            "Epoch 292/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9555 - val_loss: 0.1451 - val_accuracy: 0.9500\n",
            "Epoch 293/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1446 - accuracy: 0.9553 - val_loss: 0.1457 - val_accuracy: 0.9506\n",
            "Epoch 294/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1449 - accuracy: 0.9550 - val_loss: 0.1461 - val_accuracy: 0.9500\n",
            "Epoch 295/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1449 - accuracy: 0.9553 - val_loss: 0.1468 - val_accuracy: 0.9506\n",
            "Epoch 296/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1455 - accuracy: 0.9555 - val_loss: 0.1458 - val_accuracy: 0.9506\n",
            "Epoch 297/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9556 - val_loss: 0.1463 - val_accuracy: 0.9506\n",
            "Epoch 298/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9545 - val_loss: 0.1460 - val_accuracy: 0.9506\n",
            "Epoch 299/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9550 - val_loss: 0.1457 - val_accuracy: 0.9506\n",
            "Epoch 300/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9538 - val_loss: 0.1459 - val_accuracy: 0.9506\n",
            "Epoch 301/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9548 - val_loss: 0.1465 - val_accuracy: 0.9506\n",
            "Epoch 302/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9547 - val_loss: 0.1451 - val_accuracy: 0.9500\n",
            "Epoch 303/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9556 - val_loss: 0.1460 - val_accuracy: 0.9506\n",
            "Epoch 304/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9553 - val_loss: 0.1466 - val_accuracy: 0.9525\n",
            "Epoch 305/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9559 - val_loss: 0.1464 - val_accuracy: 0.9506\n",
            "Epoch 306/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9542 - val_loss: 0.1465 - val_accuracy: 0.9506\n",
            "Epoch 307/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9550 - val_loss: 0.1462 - val_accuracy: 0.9500\n",
            "Epoch 308/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9555 - val_loss: 0.1460 - val_accuracy: 0.9506\n",
            "Epoch 309/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9555 - val_loss: 0.1460 - val_accuracy: 0.9506\n",
            "Epoch 310/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9555 - val_loss: 0.1462 - val_accuracy: 0.9506\n",
            "Epoch 311/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9553 - val_loss: 0.1464 - val_accuracy: 0.9506\n",
            "Epoch 312/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9555 - val_loss: 0.1465 - val_accuracy: 0.9500\n",
            "Epoch 313/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9547 - val_loss: 0.1462 - val_accuracy: 0.9506\n",
            "Epoch 314/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9555 - val_loss: 0.1457 - val_accuracy: 0.9500\n",
            "Epoch 315/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1444 - accuracy: 0.9553 - val_loss: 0.1461 - val_accuracy: 0.9513\n",
            "Epoch 316/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9552 - val_loss: 0.1481 - val_accuracy: 0.9513\n",
            "Epoch 317/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9552 - val_loss: 0.1443 - val_accuracy: 0.9506\n",
            "Epoch 318/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9555 - val_loss: 0.1466 - val_accuracy: 0.9506\n",
            "Epoch 319/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9553 - val_loss: 0.1463 - val_accuracy: 0.9506\n",
            "Epoch 320/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9550 - val_loss: 0.1457 - val_accuracy: 0.9506\n",
            "Epoch 321/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9550 - val_loss: 0.1461 - val_accuracy: 0.9506\n",
            "Epoch 322/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9555 - val_loss: 0.1467 - val_accuracy: 0.9506\n",
            "Epoch 323/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9548 - val_loss: 0.1469 - val_accuracy: 0.9525\n",
            "Epoch 324/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9558 - val_loss: 0.1472 - val_accuracy: 0.9506\n",
            "Epoch 325/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9545 - val_loss: 0.1466 - val_accuracy: 0.9525\n",
            "Epoch 326/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9556 - val_loss: 0.1466 - val_accuracy: 0.9500\n",
            "Epoch 327/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9555 - val_loss: 0.1478 - val_accuracy: 0.9506\n",
            "Epoch 328/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9558 - val_loss: 0.1473 - val_accuracy: 0.9506\n",
            "Epoch 329/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9553 - val_loss: 0.1463 - val_accuracy: 0.9500\n",
            "Epoch 330/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9556 - val_loss: 0.1466 - val_accuracy: 0.9500\n",
            "Epoch 331/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1443 - accuracy: 0.9552 - val_loss: 0.1464 - val_accuracy: 0.9500\n",
            "Epoch 332/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1448 - accuracy: 0.9550 - val_loss: 0.1464 - val_accuracy: 0.9506\n",
            "Epoch 333/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1454 - accuracy: 0.9550 - val_loss: 0.1468 - val_accuracy: 0.9506\n",
            "Epoch 334/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1449 - accuracy: 0.9552 - val_loss: 0.1469 - val_accuracy: 0.9500\n",
            "Epoch 335/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1446 - accuracy: 0.9555 - val_loss: 0.1475 - val_accuracy: 0.9525\n",
            "Epoch 336/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9553 - val_loss: 0.1484 - val_accuracy: 0.9525\n",
            "Epoch 337/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9550 - val_loss: 0.1457 - val_accuracy: 0.9506\n",
            "Epoch 338/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9553 - val_loss: 0.1465 - val_accuracy: 0.9506\n",
            "Epoch 339/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9556 - val_loss: 0.1466 - val_accuracy: 0.9513\n",
            "Epoch 340/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1444 - accuracy: 0.9558 - val_loss: 0.1471 - val_accuracy: 0.9525\n",
            "Epoch 341/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9550 - val_loss: 0.1454 - val_accuracy: 0.9506\n",
            "Epoch 342/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9559 - val_loss: 0.1464 - val_accuracy: 0.9506\n",
            "Epoch 343/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9550 - val_loss: 0.1474 - val_accuracy: 0.9506\n",
            "Epoch 344/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9548 - val_loss: 0.1466 - val_accuracy: 0.9506\n",
            "Epoch 345/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9553 - val_loss: 0.1468 - val_accuracy: 0.9525\n",
            "Epoch 346/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9552 - val_loss: 0.1468 - val_accuracy: 0.9506\n",
            "Epoch 347/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9552 - val_loss: 0.1488 - val_accuracy: 0.9525\n",
            "Epoch 348/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9547 - val_loss: 0.1454 - val_accuracy: 0.9500\n",
            "Epoch 349/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9550 - val_loss: 0.1464 - val_accuracy: 0.9513\n",
            "Epoch 350/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1442 - accuracy: 0.9553 - val_loss: 0.1462 - val_accuracy: 0.9506\n",
            "Epoch 351/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9556 - val_loss: 0.1455 - val_accuracy: 0.9506\n",
            "Epoch 352/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9558 - val_loss: 0.1461 - val_accuracy: 0.9500\n",
            "Epoch 353/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9558 - val_loss: 0.1467 - val_accuracy: 0.9506\n",
            "Epoch 354/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1443 - accuracy: 0.9552 - val_loss: 0.1489 - val_accuracy: 0.9525\n",
            "Epoch 355/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9555 - val_loss: 0.1468 - val_accuracy: 0.9506\n",
            "Epoch 356/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9545 - val_loss: 0.1462 - val_accuracy: 0.9513\n",
            "Epoch 357/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9552 - val_loss: 0.1479 - val_accuracy: 0.9506\n",
            "Epoch 358/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9547 - val_loss: 0.1456 - val_accuracy: 0.9500\n",
            "Epoch 359/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9553 - val_loss: 0.1471 - val_accuracy: 0.9506\n",
            "Epoch 360/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1444 - accuracy: 0.9555 - val_loss: 0.1466 - val_accuracy: 0.9506\n",
            "Epoch 361/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9556 - val_loss: 0.1477 - val_accuracy: 0.9506\n",
            "Epoch 362/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9550 - val_loss: 0.1468 - val_accuracy: 0.9506\n",
            "Epoch 363/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9550 - val_loss: 0.1467 - val_accuracy: 0.9506\n",
            "Epoch 364/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9552 - val_loss: 0.1463 - val_accuracy: 0.9506\n",
            "Epoch 365/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1444 - accuracy: 0.9550 - val_loss: 0.1470 - val_accuracy: 0.9506\n",
            "Epoch 366/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9556 - val_loss: 0.1468 - val_accuracy: 0.9506\n",
            "Epoch 367/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9556 - val_loss: 0.1470 - val_accuracy: 0.9506\n",
            "Epoch 368/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9553 - val_loss: 0.1474 - val_accuracy: 0.9506\n",
            "Epoch 369/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1446 - accuracy: 0.9559 - val_loss: 0.1477 - val_accuracy: 0.9506\n",
            "Epoch 370/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1443 - accuracy: 0.9547 - val_loss: 0.1474 - val_accuracy: 0.9506\n",
            "Epoch 371/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1442 - accuracy: 0.9550 - val_loss: 0.1461 - val_accuracy: 0.9506\n",
            "Epoch 372/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1448 - accuracy: 0.9552 - val_loss: 0.1458 - val_accuracy: 0.9500\n",
            "Epoch 373/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1450 - accuracy: 0.9553 - val_loss: 0.1465 - val_accuracy: 0.9500\n",
            "Epoch 374/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1441 - accuracy: 0.9552 - val_loss: 0.1475 - val_accuracy: 0.9525\n",
            "Epoch 375/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9556 - val_loss: 0.1468 - val_accuracy: 0.9506\n",
            "Epoch 376/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1444 - accuracy: 0.9555 - val_loss: 0.1469 - val_accuracy: 0.9500\n",
            "Epoch 377/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1444 - accuracy: 0.9550 - val_loss: 0.1467 - val_accuracy: 0.9506\n",
            "Epoch 378/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9556 - val_loss: 0.1474 - val_accuracy: 0.9506\n",
            "Epoch 379/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9552 - val_loss: 0.1467 - val_accuracy: 0.9506\n",
            "Epoch 380/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9547 - val_loss: 0.1468 - val_accuracy: 0.9506\n",
            "Epoch 381/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1443 - accuracy: 0.9555 - val_loss: 0.1468 - val_accuracy: 0.9506\n",
            "Epoch 382/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9548 - val_loss: 0.1453 - val_accuracy: 0.9506\n",
            "Epoch 383/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1444 - accuracy: 0.9552 - val_loss: 0.1480 - val_accuracy: 0.9506\n",
            "Epoch 384/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1444 - accuracy: 0.9553 - val_loss: 0.1468 - val_accuracy: 0.9506\n",
            "Epoch 385/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9552 - val_loss: 0.1470 - val_accuracy: 0.9506\n",
            "Epoch 386/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1444 - accuracy: 0.9558 - val_loss: 0.1470 - val_accuracy: 0.9500\n",
            "Epoch 387/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1455 - accuracy: 0.9559 - val_loss: 0.1469 - val_accuracy: 0.9513\n",
            "Epoch 388/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1444 - accuracy: 0.9552 - val_loss: 0.1466 - val_accuracy: 0.9506\n",
            "Epoch 389/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1448 - accuracy: 0.9558 - val_loss: 0.1473 - val_accuracy: 0.9506\n",
            "Epoch 390/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1445 - accuracy: 0.9550 - val_loss: 0.1470 - val_accuracy: 0.9506\n",
            "Epoch 391/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1447 - accuracy: 0.9553 - val_loss: 0.1469 - val_accuracy: 0.9506\n",
            "Epoch 392/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9556 - val_loss: 0.1469 - val_accuracy: 0.9506\n",
            "Epoch 393/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1444 - accuracy: 0.9548 - val_loss: 0.1472 - val_accuracy: 0.9506\n",
            "Epoch 394/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9548 - val_loss: 0.1482 - val_accuracy: 0.9525\n",
            "Epoch 395/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9544 - val_loss: 0.1469 - val_accuracy: 0.9506\n",
            "Epoch 396/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1443 - accuracy: 0.9558 - val_loss: 0.1480 - val_accuracy: 0.9506\n",
            "Epoch 397/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1453 - accuracy: 0.9558 - val_loss: 0.1471 - val_accuracy: 0.9506\n",
            "Epoch 398/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9555 - val_loss: 0.1476 - val_accuracy: 0.9506\n",
            "Epoch 399/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9553 - val_loss: 0.1463 - val_accuracy: 0.9506\n",
            "Epoch 400/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9552 - val_loss: 0.1462 - val_accuracy: 0.9506\n",
            "Epoch 401/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9552 - val_loss: 0.1469 - val_accuracy: 0.9500\n",
            "Epoch 402/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9553 - val_loss: 0.1466 - val_accuracy: 0.9506\n",
            "Epoch 403/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9545 - val_loss: 0.1464 - val_accuracy: 0.9513\n",
            "Epoch 404/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9555 - val_loss: 0.1472 - val_accuracy: 0.9525\n",
            "Epoch 405/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1451 - accuracy: 0.9550 - val_loss: 0.1470 - val_accuracy: 0.9506\n",
            "Epoch 406/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1442 - accuracy: 0.9550 - val_loss: 0.1476 - val_accuracy: 0.9525\n",
            "Epoch 407/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1446 - accuracy: 0.9548 - val_loss: 0.1471 - val_accuracy: 0.9506\n",
            "Epoch 408/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1445 - accuracy: 0.9555 - val_loss: 0.1468 - val_accuracy: 0.9506\n",
            "Epoch 409/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1445 - accuracy: 0.9556 - val_loss: 0.1472 - val_accuracy: 0.9506\n",
            "Epoch 410/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1447 - accuracy: 0.9555 - val_loss: 0.1475 - val_accuracy: 0.9506\n",
            "Epoch 411/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9556 - val_loss: 0.1471 - val_accuracy: 0.9500\n",
            "Epoch 412/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9552 - val_loss: 0.1470 - val_accuracy: 0.9506\n",
            "Epoch 413/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1440 - accuracy: 0.9552 - val_loss: 0.1479 - val_accuracy: 0.9506\n",
            "Epoch 414/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9553 - val_loss: 0.1481 - val_accuracy: 0.9500\n",
            "Epoch 415/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9552 - val_loss: 0.1467 - val_accuracy: 0.9506\n",
            "Epoch 416/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1442 - accuracy: 0.9555 - val_loss: 0.1469 - val_accuracy: 0.9506\n",
            "Epoch 417/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9559 - val_loss: 0.1472 - val_accuracy: 0.9506\n",
            "Epoch 418/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1442 - accuracy: 0.9555 - val_loss: 0.1468 - val_accuracy: 0.9513\n",
            "Epoch 419/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9555 - val_loss: 0.1470 - val_accuracy: 0.9506\n",
            "Epoch 420/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1443 - accuracy: 0.9559 - val_loss: 0.1474 - val_accuracy: 0.9506\n",
            "Epoch 421/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1444 - accuracy: 0.9558 - val_loss: 0.1483 - val_accuracy: 0.9500\n",
            "Epoch 422/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9556 - val_loss: 0.1480 - val_accuracy: 0.9506\n",
            "Epoch 423/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9545 - val_loss: 0.1481 - val_accuracy: 0.9506\n",
            "Epoch 424/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9555 - val_loss: 0.1469 - val_accuracy: 0.9500\n",
            "Epoch 425/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9548 - val_loss: 0.1472 - val_accuracy: 0.9506\n",
            "Epoch 426/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9550 - val_loss: 0.1466 - val_accuracy: 0.9506\n",
            "Epoch 427/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9556 - val_loss: 0.1463 - val_accuracy: 0.9513\n",
            "Epoch 428/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9558 - val_loss: 0.1475 - val_accuracy: 0.9525\n",
            "Epoch 429/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9553 - val_loss: 0.1470 - val_accuracy: 0.9506\n",
            "Epoch 430/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1444 - accuracy: 0.9552 - val_loss: 0.1468 - val_accuracy: 0.9500\n",
            "Epoch 431/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9558 - val_loss: 0.1475 - val_accuracy: 0.9506\n",
            "Epoch 432/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1443 - accuracy: 0.9550 - val_loss: 0.1467 - val_accuracy: 0.9513\n",
            "Epoch 433/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1441 - accuracy: 0.9556 - val_loss: 0.1472 - val_accuracy: 0.9506\n",
            "Epoch 434/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1443 - accuracy: 0.9550 - val_loss: 0.1468 - val_accuracy: 0.9506\n",
            "Epoch 435/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1441 - accuracy: 0.9556 - val_loss: 0.1471 - val_accuracy: 0.9506\n",
            "Epoch 436/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9547 - val_loss: 0.1468 - val_accuracy: 0.9506\n",
            "Epoch 437/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9553 - val_loss: 0.1469 - val_accuracy: 0.9500\n",
            "Epoch 438/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1442 - accuracy: 0.9553 - val_loss: 0.1475 - val_accuracy: 0.9506\n",
            "Epoch 439/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9553 - val_loss: 0.1469 - val_accuracy: 0.9506\n",
            "Epoch 440/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1441 - accuracy: 0.9559 - val_loss: 0.1470 - val_accuracy: 0.9506\n",
            "Epoch 441/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1444 - accuracy: 0.9558 - val_loss: 0.1472 - val_accuracy: 0.9506\n",
            "Epoch 442/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1444 - accuracy: 0.9548 - val_loss: 0.1467 - val_accuracy: 0.9500\n",
            "Epoch 443/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9548 - val_loss: 0.1481 - val_accuracy: 0.9506\n",
            "Epoch 444/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1448 - accuracy: 0.9555 - val_loss: 0.1466 - val_accuracy: 0.9506\n",
            "Epoch 445/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1441 - accuracy: 0.9555 - val_loss: 0.1475 - val_accuracy: 0.9506\n",
            "Epoch 446/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1453 - accuracy: 0.9548 - val_loss: 0.1488 - val_accuracy: 0.9506\n",
            "Epoch 447/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1442 - accuracy: 0.9555 - val_loss: 0.1477 - val_accuracy: 0.9506\n",
            "Epoch 448/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1444 - accuracy: 0.9555 - val_loss: 0.1471 - val_accuracy: 0.9506\n",
            "Epoch 449/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1441 - accuracy: 0.9553 - val_loss: 0.1470 - val_accuracy: 0.9506\n",
            "Epoch 450/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1443 - accuracy: 0.9552 - val_loss: 0.1478 - val_accuracy: 0.9506\n",
            "Epoch 451/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1443 - accuracy: 0.9553 - val_loss: 0.1475 - val_accuracy: 0.9506\n",
            "Epoch 452/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1441 - accuracy: 0.9558 - val_loss: 0.1476 - val_accuracy: 0.9506\n",
            "Epoch 453/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9553 - val_loss: 0.1475 - val_accuracy: 0.9513\n",
            "Epoch 454/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9555 - val_loss: 0.1461 - val_accuracy: 0.9506\n",
            "Epoch 455/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9561 - val_loss: 0.1470 - val_accuracy: 0.9500\n",
            "Epoch 456/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9550 - val_loss: 0.1469 - val_accuracy: 0.9506\n",
            "Epoch 457/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1443 - accuracy: 0.9552 - val_loss: 0.1470 - val_accuracy: 0.9506\n",
            "Epoch 458/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9552 - val_loss: 0.1471 - val_accuracy: 0.9506\n",
            "Epoch 459/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9552 - val_loss: 0.1474 - val_accuracy: 0.9506\n",
            "Epoch 460/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1442 - accuracy: 0.9555 - val_loss: 0.1471 - val_accuracy: 0.9506\n",
            "Epoch 461/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9552 - val_loss: 0.1474 - val_accuracy: 0.9506\n",
            "Epoch 462/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9553 - val_loss: 0.1469 - val_accuracy: 0.9506\n",
            "Epoch 463/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1440 - accuracy: 0.9555 - val_loss: 0.1475 - val_accuracy: 0.9506\n",
            "Epoch 464/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1444 - accuracy: 0.9553 - val_loss: 0.1481 - val_accuracy: 0.9506\n",
            "Epoch 465/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1443 - accuracy: 0.9556 - val_loss: 0.1477 - val_accuracy: 0.9506\n",
            "Epoch 466/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1441 - accuracy: 0.9553 - val_loss: 0.1474 - val_accuracy: 0.9500\n",
            "Epoch 467/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1441 - accuracy: 0.9547 - val_loss: 0.1482 - val_accuracy: 0.9506\n",
            "Epoch 468/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9555 - val_loss: 0.1472 - val_accuracy: 0.9506\n",
            "Epoch 469/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1444 - accuracy: 0.9550 - val_loss: 0.1480 - val_accuracy: 0.9506\n",
            "Epoch 470/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1440 - accuracy: 0.9555 - val_loss: 0.1477 - val_accuracy: 0.9506\n",
            "Epoch 471/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1442 - accuracy: 0.9556 - val_loss: 0.1472 - val_accuracy: 0.9500\n",
            "Epoch 472/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1443 - accuracy: 0.9555 - val_loss: 0.1474 - val_accuracy: 0.9506\n",
            "Epoch 473/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9552 - val_loss: 0.1476 - val_accuracy: 0.9506\n",
            "Epoch 474/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1444 - accuracy: 0.9556 - val_loss: 0.1478 - val_accuracy: 0.9506\n",
            "Epoch 475/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9556 - val_loss: 0.1477 - val_accuracy: 0.9500\n",
            "Epoch 476/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1441 - accuracy: 0.9558 - val_loss: 0.1474 - val_accuracy: 0.9506\n",
            "Epoch 477/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9553 - val_loss: 0.1474 - val_accuracy: 0.9506\n",
            "Epoch 478/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9558 - val_loss: 0.1473 - val_accuracy: 0.9506\n",
            "Epoch 479/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1443 - accuracy: 0.9550 - val_loss: 0.1476 - val_accuracy: 0.9506\n",
            "Epoch 480/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9547 - val_loss: 0.1471 - val_accuracy: 0.9506\n",
            "Epoch 481/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1439 - accuracy: 0.9553 - val_loss: 0.1477 - val_accuracy: 0.9506\n",
            "Epoch 482/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1444 - accuracy: 0.9555 - val_loss: 0.1474 - val_accuracy: 0.9506\n",
            "Epoch 483/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1440 - accuracy: 0.9553 - val_loss: 0.1480 - val_accuracy: 0.9500\n",
            "Epoch 484/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1446 - accuracy: 0.9555 - val_loss: 0.1475 - val_accuracy: 0.9506\n",
            "Epoch 485/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1443 - accuracy: 0.9556 - val_loss: 0.1486 - val_accuracy: 0.9500\n",
            "Epoch 486/500\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.1443 - accuracy: 0.9552 - val_loss: 0.1473 - val_accuracy: 0.9506\n",
            "Epoch 487/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1442 - accuracy: 0.9553 - val_loss: 0.1477 - val_accuracy: 0.9506\n",
            "Epoch 488/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1442 - accuracy: 0.9555 - val_loss: 0.1486 - val_accuracy: 0.9506\n",
            "Epoch 489/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1443 - accuracy: 0.9555 - val_loss: 0.1476 - val_accuracy: 0.9506\n",
            "Epoch 490/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1443 - accuracy: 0.9552 - val_loss: 0.1473 - val_accuracy: 0.9500\n",
            "Epoch 491/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9552 - val_loss: 0.1475 - val_accuracy: 0.9500\n",
            "Epoch 492/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9555 - val_loss: 0.1471 - val_accuracy: 0.9506\n",
            "Epoch 493/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9558 - val_loss: 0.1482 - val_accuracy: 0.9506\n",
            "Epoch 494/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9555 - val_loss: 0.1479 - val_accuracy: 0.9500\n",
            "Epoch 495/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1444 - accuracy: 0.9548 - val_loss: 0.1474 - val_accuracy: 0.9506\n",
            "Epoch 496/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1441 - accuracy: 0.9555 - val_loss: 0.1477 - val_accuracy: 0.9506\n",
            "Epoch 497/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1440 - accuracy: 0.9555 - val_loss: 0.1507 - val_accuracy: 0.9506\n",
            "Epoch 498/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9552 - val_loss: 0.1472 - val_accuracy: 0.9500\n",
            "Epoch 499/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9556 - val_loss: 0.1482 - val_accuracy: 0.9506\n",
            "Epoch 500/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9541 - val_loss: 0.1473 - val_accuracy: 0.9500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f681920a6b0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#y_pred_DNN = (model.predict(DNNX) > 0.5).astype(\"int32\")\n",
        "DTr = model.evaluate(DX_train, Dy_train,verbose=0)[1]\n",
        "DTe = model.evaluate(DX_test, Dy_test,verbose=0)[1]\n",
        "DTr,DTe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhG0YCbhASH9",
        "outputId": "01114816-2e83-4138-ddac-d0780afa6fc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9545000195503235, 0.9455000162124634)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_DNN = (model.predict(DX_test) > 0.5).astype(\"int32\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKbxrS57kOBE",
        "outputId": "18893ece-2bb3-4295-f17a-3f5e5a9b7986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = pd.DataFrame(\n",
        "    {\n",
        "    \"SVM\":[STr,STe],\n",
        "    \"KNN\":[KTr,KTe],\n",
        "    \"RF\" :[RTr,RTe],\n",
        "    \"LR\" :[LTr,LTe],\n",
        "    \"ANN\":[ATr,ATe],\n",
        "    \"XGB\":[XTr,XTe],\n",
        "    \"DNN\":[DTr,DTe]})\n",
        "acc.index = [\"train\", \"test\"]\n",
        "acc = acc.T\n",
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "v_YjlCdOO1JY",
        "outputId": "b397c6d7-8a68-4484-a3da-a6b207eea7a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        train    test\n",
              "SVM  0.950500  0.9500\n",
              "KNN  0.954875  0.9445\n",
              "RF   0.943875  0.9505\n",
              "LR   0.950000  0.9500\n",
              "ANN  0.959375  0.9520\n",
              "XGB  0.988250  0.9455\n",
              "DNN  0.954500  0.9455"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-da91ba55-921c-434b-aac4-cb27907958c4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>0.950500</td>\n",
              "      <td>0.9500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>0.954875</td>\n",
              "      <td>0.9445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>0.943875</td>\n",
              "      <td>0.9505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LR</th>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.9500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ANN</th>\n",
              "      <td>0.959375</td>\n",
              "      <td>0.9520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGB</th>\n",
              "      <td>0.988250</td>\n",
              "      <td>0.9455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DNN</th>\n",
              "      <td>0.954500</td>\n",
              "      <td>0.9455</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da91ba55-921c-434b-aac4-cb27907958c4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-da91ba55-921c-434b-aac4-cb27907958c4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-da91ba55-921c-434b-aac4-cb27907958c4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **AutoML Individual and AutoML DNN**"
      ],
      "metadata": {
        "id": "nJaAMLDKKfKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#H2O AutoML"
      ],
      "metadata": {
        "id": "EhNt_UkjDKcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h2o\n",
        "import h2o\n",
        "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
        "h2o.init()\n",
        "from h2o.model.segment_models import H2OFrame\n",
        "from h2o.automl import H2OAutoML\n",
        "print(\"All Library Loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 908
        },
        "id": "iwMF9ROeDOzF",
        "outputId": "7b14cf7f-c13e-44e0-ea07-e86d0dab645b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting h2o\n",
            "  Downloading h2o-3.40.0.4.tar.gz (177.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from h2o) (2.27.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from h2o) (0.8.10)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from h2o) (0.18.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (3.4)\n",
            "Building wheels for collected packages: h2o\n",
            "  Building wheel for h2o (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for h2o: filename=h2o-3.40.0.4-py2.py3-none-any.whl size=177697886 sha256=616a5d0a8a63b5134b64478e032bc91f1a0017780554e572a56cd7f82414ddfd\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/f2/b0/5bb4d702a0467e82d77c45088db3eef25114c26b0eec8e7f6a\n",
            "Successfully built h2o\n",
            "Installing collected packages: h2o\n",
            "Successfully installed h2o-3.40.0.4\n",
            "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
            "Attempting to start a local H2O server...\n",
            "  Java Version: openjdk version \"11.0.19\" 2023-04-18; OpenJDK Runtime Environment (build 11.0.19+7-post-Ubuntu-0ubuntu120.04.1); OpenJDK 64-Bit Server VM (build 11.0.19+7-post-Ubuntu-0ubuntu120.04.1, mixed mode, sharing)\n",
            "  Starting server from /usr/local/lib/python3.10/dist-packages/h2o/backend/bin/h2o.jar\n",
            "  Ice root: /tmp/tmp778sf13d\n",
            "  JVM stdout: /tmp/tmp778sf13d/h2o_unknownUser_started_from_python.out\n",
            "  JVM stderr: /tmp/tmp778sf13d/h2o_unknownUser_started_from_python.err\n",
            "  Server is running at http://127.0.0.1:54321\n",
            "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "--------------------------  -----------------------------------------------------------------------------------------\n",
              "H2O_cluster_uptime:         02 secs\n",
              "H2O_cluster_timezone:       Etc/UTC\n",
              "H2O_data_parsing_timezone:  UTC\n",
              "H2O_cluster_version:        3.40.0.4\n",
              "H2O_cluster_version_age:    1 month and 25 days\n",
              "H2O_cluster_name:           H2O_from_python_unknownUser_a9rn03\n",
              "H2O_cluster_total_nodes:    1\n",
              "H2O_cluster_free_memory:    3.170 Gb\n",
              "H2O_cluster_total_cores:    2\n",
              "H2O_cluster_allowed_cores:  2\n",
              "H2O_cluster_status:         locked, healthy\n",
              "H2O_connection_url:         http://127.0.0.1:54321\n",
              "H2O_connection_proxy:       {\"http\": null, \"https\": null, \"colab_language_server\": \"/usr/colab/bin/language_service\"}\n",
              "H2O_internal_security:      False\n",
              "Python_version:             3.10.12 final\n",
              "--------------------------  -----------------------------------------------------------------------------------------"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "#h2o-table-1.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-1 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-1 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-1 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-1 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-1 .h2o-table th,\n",
              "#h2o-table-1 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption></caption>\n",
              "    <thead></thead>\n",
              "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
              "<td>02 secs</td></tr>\n",
              "<tr><td>H2O_cluster_timezone:</td>\n",
              "<td>Etc/UTC</td></tr>\n",
              "<tr><td>H2O_data_parsing_timezone:</td>\n",
              "<td>UTC</td></tr>\n",
              "<tr><td>H2O_cluster_version:</td>\n",
              "<td>3.40.0.4</td></tr>\n",
              "<tr><td>H2O_cluster_version_age:</td>\n",
              "<td>1 month and 25 days</td></tr>\n",
              "<tr><td>H2O_cluster_name:</td>\n",
              "<td>H2O_from_python_unknownUser_a9rn03</td></tr>\n",
              "<tr><td>H2O_cluster_total_nodes:</td>\n",
              "<td>1</td></tr>\n",
              "<tr><td>H2O_cluster_free_memory:</td>\n",
              "<td>3.170 Gb</td></tr>\n",
              "<tr><td>H2O_cluster_total_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_allowed_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_status:</td>\n",
              "<td>locked, healthy</td></tr>\n",
              "<tr><td>H2O_connection_url:</td>\n",
              "<td>http://127.0.0.1:54321</td></tr>\n",
              "<tr><td>H2O_connection_proxy:</td>\n",
              "<td>{\"http\": null, \"https\": null, \"colab_language_server\": \"/usr/colab/bin/language_service\"}</td></tr>\n",
              "<tr><td>H2O_internal_security:</td>\n",
              "<td>False</td></tr>\n",
              "<tr><td>Python_version:</td>\n",
              "<td>3.10.12 final</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Library Loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train, valid = hdf.split_frame(ratios=[.8], seed=123)\n",
        "#hdf = h2o.H2OFrame(df)\n",
        "#hdf[\"diagnosis\"] = hdf[\"diagnosis\"].asfactor()\n",
        "hy = \"diagnosis\"\n",
        "hx = list(df.columns)\n",
        "hx.remove(hy)\n",
        "hdf  = df.copy()\n",
        "hdf.iloc[:,1:] = StandardScaler().fit_transform(hdf.iloc[:,1:])\n",
        "hdf.iloc[:,0] = LabelEncoder().fit_transform(hdf.iloc[:,0])\n",
        "hdf.iloc[:,0] = hdf.iloc[:,0].astype('category')\n",
        "train1, valid1 = train_test_split(hdf, test_size=0.2,random_state=123)\n",
        "train = h2o.H2OFrame(train1)\n",
        "valid = h2o.H2OFrame(valid1)\n",
        "train[\"diagnosis\"] = train[\"diagnosis\"].asfactor()\n",
        "valid[\"diagnosis\"] = valid[\"diagnosis\"].asfactor()"
      ],
      "metadata": {
        "id": "NVoFNbYCGxGh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbfcf700-6c6a-4dba-d8e9-40e3789bc43b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-460708a37676>:9: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  hdf.iloc[:,0] = LabelEncoder().fit_transform(hdf.iloc[:,0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aml = H2OAutoML(max_models = 10, seed = 123, verbosity=\"info\",\n",
        "                nfolds=10, sort_metric='accuracy')"
      ],
      "metadata": {
        "id": "7JNO6XnVHH5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aml.train(x = hx, y = hy, training_frame = train,\n",
        "          validation_frame = valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Lbo606kFH4Zc",
        "outputId": "1fa7ef4d-bde7-4935-8c55-206fbe1a766b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoML progress: |\n",
            "20:41:29.108: Project: AutoML_1_20230622_204129\n",
            "20:41:29.109: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n",
            "20:41:29.116: Setting stopping tolerance adaptively based on the training frame: 0.011180339887498949\n",
            "20:41:29.116: Build control seed: 123\n",
            "20:41:29.117: training frame: Frame key: AutoML_1_20230622_204129_training_py_1_sid_88c4    cols: 31    rows: 8000  chunks: 2    size: 1926168  checksum: -5600652261642703400\n",
            "20:41:29.122: validation frame: Frame key: py_2_sid_88c4    cols: 31    rows: 2000  chunks: 1    size: 482912  checksum: -8629894929602001568\n",
            "20:41:29.122: leaderboard frame: NULL\n",
            "20:41:29.122: blending frame: NULL\n",
            "20:41:29.122: response column: diagnosis\n",
            "20:41:29.123: fold column: null\n",
            "20:41:29.123: weights column: null\n",
            "20:41:29.153: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (7g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (7g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (6g, 60w)]}, {StackedEnsemble : [monotonic (9g, 10w), best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
            "20:41:29.189: AutoML job created: 2023.06.22 20:41:29.65\n",
            "20:41:29.190: AutoML build started: 2023.06.22 20:41:29.190\n",
            "20:41:29.226: AutoML: starting XGBoost_1_AutoML_1_20230622_204129 model training\n",
            "\n",
            "██\n",
            "20:41:57.637: New leader: XGBoost_1_AutoML_1_20230622_204129, accuracy: 0.94825\n",
            "20:41:57.642: AutoML: starting GLM_1_AutoML_1_20230622_204129 model training\n",
            "\n",
            "███\n",
            "20:42:16.680: AutoML: starting GBM_1_AutoML_1_20230622_204129 model training\n",
            "\n",
            "█\n",
            "20:43:11.583: AutoML: starting XGBoost_2_AutoML_1_20230622_204129 model training\n",
            "\n",
            "█\n",
            "20:43:31.823: AutoML: starting DRF_1_AutoML_1_20230622_204129 model training\n",
            "\n",
            "███\n",
            "20:43:57.270: New leader: DRF_1_AutoML_1_20230622_204129, accuracy: 0.945125\n",
            "20:43:57.273: AutoML: starting GBM_2_AutoML_1_20230622_204129 model training\n",
            "\n",
            "█\n",
            "20:44:29.555: AutoML: starting GBM_3_AutoML_1_20230622_204129 model training\n",
            "\n",
            "█\n",
            "20:45:00.158: AutoML: starting GBM_4_AutoML_1_20230622_204129 model training\n",
            "\n",
            "█\n",
            "20:45:33.373: AutoML: starting XGBoost_3_AutoML_1_20230622_204129 model training\n",
            "\n",
            "█\n",
            "20:45:52.281: AutoML: starting XRT_1_AutoML_1_20230622_204129 model training\n",
            "\n",
            "███\n",
            "20:46:22.261: No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'monotonic'.\n",
            "20:46:22.277: AutoML: starting StackedEnsemble_BestOfFamily_1_AutoML_1_20230622_204129 model training\n",
            "\n",
            "██\n",
            "20:46:34.897: AutoML: starting StackedEnsemble_AllModels_1_AutoML_1_20230622_204129 model training\n",
            "\n",
            "████████████████████████████████████████████| (done) 100%\n",
            "\n",
            "20:46:51.845: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GLM : [def_1 (1g, 10w)]}, {GBM : [def_5 (1g, 10w)]}, {XGBoost : [def_1 (2g, 10w)]}, {DRF : [def_1 (2g, 10w)]}, {GBM : [def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w)]}, {XGBoost : [def_3 (3g, 10w)]}, {DRF : [XRT (3g, 10w)]}, {StackedEnsemble : [best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
            "20:46:51.845: AutoML build stopped: 2023.06.22 20:46:51.845\n",
            "20:46:51.845: AutoML build done: built 10 models\n",
            "20:46:51.845: AutoML duration:  5 min 22.655 sec\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model Details\n",
              "=============\n",
              "H2ORandomForestEstimator : Distributed Random Forest\n",
              "Model Key: DRF_1_AutoML_1_20230622_204129\n",
              "\n",
              "\n",
              "Model Summary: \n",
              "    number_of_trees    number_of_internal_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n",
              "--  -----------------  --------------------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n",
              "    46                 46                          199283                 15           20           18.2174       311           369           340\n",
              "\n",
              "ModelMetricsBinomial: drf\n",
              "** Reported on train data. **\n",
              "\n",
              "MSE: 0.04326800279168445\n",
              "RMSE: 0.2080096218728462\n",
              "LogLoss: 0.20428151575245082\n",
              "Mean Per-Class Error: 0.057211674235314855\n",
              "AUC: 0.9860384526971423\n",
              "AUCPR: 0.9800859943345126\n",
              "Gini: 0.9720769053942846\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4666666666666667\n",
              "       0     1     Error    Rate\n",
              "-----  ----  ----  -------  --------------\n",
              "0      4652  269   0.0547   (269.0/4921.0)\n",
              "1      184   2895  0.0598   (184.0/3079.0)\n",
              "Total  4836  3164  0.0566   (453.0/8000.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.466667     0.927439  105\n",
              "max f2                       0.294118     0.945237  140\n",
              "max f0point5                 0.647059     0.94207   70\n",
              "max accuracy                 0.5          0.94375   100\n",
              "max precision                0.956522     0.998262  4\n",
              "max recall                   0            1         197\n",
              "max specificity              1            0.99939   0\n",
              "max absolute_mcc             0.5          0.881501  100\n",
              "max min_per_class_accuracy   0.454545     0.942839  108\n",
              "max mean_per_class_accuracy  0.45         0.943213  109\n",
              "max tns                      1            4918      0\n",
              "max fns                      1            1374      0\n",
              "max fps                      0            4921      197\n",
              "max tps                      0            3079      197\n",
              "max tnr                      1            0.99939   0\n",
              "max fnr                      1            0.446249  0\n",
              "max fpr                      0            1         197\n",
              "max tpr                      0            1         197\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 38.49 %, avg score: 38.54 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.2135                      1                  2.59368    2.59368            0.998244         1          0.998244                    1                   0.553751        0.553751                   159.368   159.368            0.553142\n",
              "2        0.30125                     0.789474           2.47611    2.55943            0.952991         0.893171   0.985062                    0.968882            0.217278        0.77103                    147.611   155.943            0.763714\n",
              "3        0.40025                     0.444444           1.75841    2.3613             0.676768         0.62211    0.908807                    0.88311             0.174082        0.945112                   75.8409   136.13             0.885775\n",
              "4        0.504                       0.117647           0.438258   1.96544            0.168675         0.255875   0.756448                    0.753991            0.0454693       0.990581                   -56.1742  96.5439            0.791028\n",
              "5        1                           0                  0.0189892  1                  0.00730847       0.0108765  0.384875                    0.385406            0.00941864      1                          -98.1011  0                  0\n",
              "\n",
              "ModelMetricsBinomial: drf\n",
              "** Reported on validation data. **\n",
              "\n",
              "MSE: 0.036937276832765605\n",
              "RMSE: 0.19219073035077838\n",
              "LogLoss: 0.14079214212429528\n",
              "Mean Per-Class Error: 0.04713423229341206\n",
              "AUC: 0.9915375408920449\n",
              "AUCPR: 0.9873978367714009\n",
              "Gini: 0.9830750817840899\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4565217391304348\n",
              "       0     1    Error    Rate\n",
              "-----  ----  ---  -------  -------------\n",
              "0      1187  58   0.0466   (58.0/1245.0)\n",
              "1      36    719  0.0477   (36.0/755.0)\n",
              "Total  1223  777  0.047    (94.0/2000.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.456522     0.938642  27\n",
              "max f2                       0.304348     0.956846  34\n",
              "max f0point5                 0.652174     0.952449  17\n",
              "max accuracy                 0.492754     0.953     25\n",
              "max precision                1            1         0\n",
              "max recall                   0            1         48\n",
              "max specificity              1            1         0\n",
              "max absolute_mcc             0.456522     0.900811  27\n",
              "max min_per_class_accuracy   0.456522     0.952318  27\n",
              "max mean_per_class_accuracy  0.434783     0.953084  28\n",
              "max tns                      1            1245      0\n",
              "max fns                      1            445       0\n",
              "max fps                      0            1245      48\n",
              "max tps                      0            755       48\n",
              "max tnr                      1            1         0\n",
              "max fnr                      1            0.589404  0\n",
              "max fpr                      0            1         48\n",
              "max tpr                      0            1         48\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 37.75 %, avg score: 37.82 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.155                       1                  2.64901     2.64901            1                1          1                           1                   0.410596        0.410596                   164.901   164.901            0.410596\n",
              "2        0.2005                      0.978261           2.64901     2.64901            1                0.978261   1                           0.995067            0.12053         0.531126                   164.901   164.901            0.531126\n",
              "3        0.3025                      0.782609           2.55811     2.61836            0.965686         0.890239   0.98843                     0.95972             0.260927        0.792053                   155.811   161.836            0.78643\n",
              "4        0.401                       0.413043           1.73463     2.40128            0.654822         0.59229    0.906484                    0.869466            0.170861        0.962914                   73.4629   140.128            0.902673\n",
              "5        0.5015                      0.108696           0.342658    1.98874            0.129353         0.241834   0.750748                    0.743689            0.0344371       0.997351                   -65.7342  98.8736            0.796548\n",
              "6        0.6315                      0.0217391          0.0101885   1.58143            0.00384615       0.0399666  0.596991                    0.598822            0.0013245       0.998675                   -98.9812  58.1434            0.58984\n",
              "7        1                           0                  0.00359431  1                  0.00135685       0          0.3775                      0.378156            0.0013245       1                          -99.6406  0                  0\n",
              "\n",
              "ModelMetricsBinomial: drf\n",
              "** Reported on cross-validation data. **\n",
              "\n",
              "MSE: 0.04109426250888458\n",
              "RMSE: 0.20271719835496094\n",
              "LogLoss: 0.14109268080346257\n",
              "Mean Per-Class Error: 0.05639704934588783\n",
              "AUC: 0.9891767351896238\n",
              "AUCPR: 0.984216068014286\n",
              "Gini: 0.9783534703792476\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.48\n",
              "       0     1     Error    Rate\n",
              "-----  ----  ----  -------  --------------\n",
              "0      4676  245   0.0498   (245.0/4921.0)\n",
              "1      194   2885  0.063    (194.0/3079.0)\n",
              "Total  4870  3130  0.0549   (439.0/8000.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.48         0.929296  54\n",
              "max f2                       0.32         0.949712  76\n",
              "max f0point5                 0.68         0.947539  29\n",
              "max accuracy                 0.52         0.945125  51\n",
              "max precision                1            1         0\n",
              "max recall                   0            1         135\n",
              "max specificity              1            1         0\n",
              "max absolute_mcc             0.48         0.884544  54\n",
              "max min_per_class_accuracy   0.44         0.940459  59\n",
              "max mean_per_class_accuracy  0.48         0.943603  54\n",
              "max tns                      1            4921      0\n",
              "max fns                      1            1720      0\n",
              "max fps                      0            4921      135\n",
              "max tps                      0            3079      135\n",
              "max tnr                      1            1         0\n",
              "max fnr                      1            0.558623  0\n",
              "max fpr                      0            1         135\n",
              "max tpr                      0            1         135\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 38.49 %, avg score: 38.55 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift         cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  -----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.169875                    1                  2.59825      2.59825            1                1            1                           1                   0.441377        0.441377                   159.825   159.825            0.441377\n",
              "2        0.20075                     0.98               2.58773      2.59663            0.995951         0.98         0.999377                    0.996924            0.0798961       0.521273                   158.773   159.663            0.52107\n",
              "3        0.3025                      0.8                2.52483      2.57248            0.971744         0.89986      0.990083                    0.964275            0.256902        0.778175                   152.483   157.248            0.773298\n",
              "4        0.4005                      0.44               1.70676      2.36064            0.656888         0.621349     0.908552                    0.880363            0.167262        0.945437                   70.6756   136.064            0.885896\n",
              "5        0.50625                     0.12               0.45454      1.96248            0.174941         0.253057     0.755309                    0.749326            0.0480676       0.993504                   -54.546   96.2478            0.792123\n",
              "6        0.647375                    0.02               0.043726     1.5442             0.0168291        0.0437432    0.594323                    0.595512            0.00617083      0.999675                   -95.6274  54.4198            0.572729\n",
              "7        1                           0                  0.000921037  1                  0.000354484      1.41147e-06  0.384875                    0.38552             0.000324781     1                          -99.9079  0                  0\n",
              "\n",
              "Cross-Validation Metrics Summary: \n",
              "                         mean       sd          cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid    cv_6_valid    cv_7_valid    cv_8_valid    cv_9_valid    cv_10_valid\n",
              "-----------------------  ---------  ----------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  -------------\n",
              "accuracy                 0.948625   0.00961859  0.95125       0.96875       0.955         0.94375       0.94375       0.94125       0.95875       0.94125       0.93875       0.94375\n",
              "auc                      0.989321   0.0026153   0.98965       0.994138      0.992543      0.987122      0.987971      0.987636      0.991501      0.989148      0.9872        0.986305\n",
              "err                      0.051375   0.00961859  0.04875       0.03125       0.045         0.05625       0.05625       0.05875       0.04125       0.05875       0.06125       0.05625\n",
              "err_count                41.1       7.69488     39            25            36            45            45            47            33            47            49            45\n",
              "f0point5                 0.928636   0.0171784   0.933852      0.957588      0.933713      0.904153      0.920285      0.909362      0.952694      0.916619      0.928526      0.929569\n",
              "f1                       0.934123   0.0109179   0.936585      0.958541      0.935714      0.92635       0.926591      0.928463      0.946166      0.931785      0.922345      0.928685\n",
              "f2                       0.939882   0.0123253   0.939335      0.959495      0.937724      0.949664      0.932983      0.948383      0.939728      0.947462      0.916247      0.927802\n",
              "lift_top_group           2.60421    0.132402    2.61438       2.65781       2.86738       2.73038       2.64026       2.52366       2.58065       2.38806       2.50784       2.53165\n",
              "logloss                  0.141121   0.0190486   0.13218       0.112811      0.131677      0.145857      0.142523      0.143419      0.128312      0.141626      0.146125      0.186684\n",
              "max_per_class_error      0.0659869  0.0123332   0.0588235     0.0398671     0.0609319     0.0690335     0.0627063     0.0724638     0.0645161     0.0709677     0.0877743     0.0727848\n",
              "mcc                      0.892432   0.0188935   0.897021      0.933469      0.901113      0.882905      0.881158      0.880277      0.912895      0.881295      0.871934      0.882248\n",
              "mean_per_class_accuracy  0.947668   0.00891056  0.949333      0.96704       0.9513        0.948418      0.94249       0.944841      0.954477      0.943621      0.934283      0.94088\n",
              "mean_per_class_error     0.0523317  0.00891056  0.0506668     0.0329596     0.0487001     0.0515816     0.0575101     0.0551593     0.0455234     0.0563794     0.0657167     0.0591197\n",
              "mse                      0.0410048  0.00441369  0.0389478     0.0313437     0.0385018     0.0451063     0.0434138     0.0434346     0.0373019     0.0427476     0.04465       0.0446002\n",
              "pr_auc                   0.98442    0.00342295  0.984525      0.990966      0.986631      0.979124      0.981952      0.982806      0.987586      0.985864      0.98284       0.981901\n",
              "precision                0.925123   0.0227588   0.932039      0.956954      0.932384      0.889937      0.916129      0.897059      0.957096      0.90678       0.932692      0.930159\n",
              "r2                       0.826597   0.0179854   0.835102      0.866444      0.830481      0.805669      0.815495      0.818445      0.842836      0.824372      0.813763      0.813369\n",
              "recall                   0.943882   0.0173548   0.941176      0.960133      0.939068      0.96587       0.937294      0.962145      0.935484      0.958209      0.912226      0.927215\n",
              "rmse                     0.202215   0.0112496   0.197352      0.177042      0.196219      0.212382      0.20836       0.20841       0.193137      0.206755      0.211305      0.211188\n",
              "specificity              0.951455   0.017369    0.95749       0.973948      0.963532      0.930967      0.947686      0.927536      0.973469      0.929032      0.956341      0.954545\n",
              "\n",
              "Scoring History: \n",
              "    timestamp            duration    number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
              "--  -------------------  ----------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ----------------  -------------------  -----------------  ---------------------------------\n",
              "    2023-06-22 20:43:55  23.403 sec  0                  nan              nan                 nan             nan                nan              nan                              nan                nan                   nan               nan                  nan                nan\n",
              "    2023-06-22 20:43:55  23.600 sec  5                  0.276754         1.99677             0.930839        0.892501           2.40932          0.0920443                        0.219089           0.36694               0.978939          0.967803             2.62383            0.063\n",
              "    2023-06-22 20:43:55  23.851 sec  10                 0.244527         0.966394            0.960549        0.936435           2.49968          0.0761556                        0.205803           0.166559              0.987595          0.980153             2.64312            0.0595\n",
              "    2023-06-22 20:43:55  24.079 sec  15                 0.226197         0.502812            0.975243        0.959903           2.54954          0.0665666                        0.199182           0.146057              0.989664          0.984612             2.64901            0.056\n",
              "    2023-06-22 20:43:56  24.262 sec  20                 0.218721         0.361284            0.980319        0.968143           2.56604          0.0632579                        0.19652            0.143699              0.990551          0.986053             2.64901            0.0505\n",
              "    2023-06-22 20:43:56  24.451 sec  25                 0.21393          0.274676            0.982997        0.975362           2.58606          0.060625                         0.195892           0.143851              0.990808          0.986377             2.64901            0.0495\n",
              "    2023-06-22 20:43:56  24.647 sec  30                 0.212194         0.24252             0.984234        0.976963           2.58844          0.059                            0.19497            0.143397              0.990969          0.986596             2.64901            0.0475\n",
              "    2023-06-22 20:43:56  24.846 sec  35                 0.209698         0.22074             0.985319        0.978713           2.591            0.057                            0.194784           0.143048              0.991071          0.986761             2.64901            0.0485\n",
              "    2023-06-22 20:43:56  25.088 sec  40                 0.208903         0.216606            0.985538        0.979325           2.59233          0.056125                         0.193185           0.141788              0.991383          0.9872               2.64901            0.046\n",
              "    2023-06-22 20:43:57  25.289 sec  45                 0.20799          0.204199            0.98606         0.980122           2.59371          0.056625                         0.192606           0.14129               0.991463          0.987275             2.64901            0.0455\n",
              "    2023-06-22 20:43:57  25.356 sec  46                 0.20801          0.204282            0.986038        0.980086           2.59368          0.056625                         0.192191           0.140792              0.991538          0.987398             2.64901            0.047\n",
              "\n",
              "Variable Importances: \n",
              "variable                 relative_importance    scaled_importance     percentage\n",
              "-----------------------  ---------------------  --------------------  ---------------------\n",
              "concave points_mean      12892.1552734375       1.0                   0.18433499477221202\n",
              "perimeter_worst          12409.1396484375       0.9625341446208621    0.17742872651676217\n",
              "concave points_worst     6141.6552734375        0.4763870076938594    0.0878147965727973\n",
              "radius_worst             5617.19189453125       0.4357061930602632    0.08031589881998402\n",
              "radius_se                4640.35546875          0.35993636210004465   0.06634886742604074\n",
              "perimeter_mean           4096.8095703125        0.3177753822709077    0.058577123429645446\n",
              "area_worst               3825.361083984375      0.29672005982320127   0.05469589067632025\n",
              "area_se                  3570.8486328125        0.27697840718454103   0.05105681324037799\n",
              "concavity_mean           3542.318115234375      0.2747653933809524    0.050648877352462644\n",
              "area_mean                1562.5438232421875     0.12120113278976655   0.02234161017918779\n",
              "---                      ---                    ---                   ---\n",
              "symmetry_worst           398.6156921386719      0.03091924381022344   0.005699498646118286\n",
              "smoothness_mean          397.4166564941406      0.03082623875256627   0.005682354559301263\n",
              "texture_se               372.990234375          0.028931565472492773  0.005333099970123865\n",
              "symmetry_mean            357.383544921875       0.027721008422712242  0.0051099519426811065\n",
              "smoothness_se            350.05841064453125     0.02715282303229609   0.005005215491709098\n",
              "fractal_dimension_worst  340.31817626953125     0.02639730666064112   0.004865947385289758\n",
              "symmetry_se              333.9683532714844      0.025904772800834933  0.0047751561588172476\n",
              "concavity_se             327.7789611816406      0.025424683013008986  0.004686658810288159\n",
              "concave points_se        309.9120178222656      0.02403880586675809   0.004431193153779072\n",
              "fractal_dimension_se     298.4029541015625      0.023146087506127115  0.0042666339194391036\n",
              "[30 rows x 4 columns]\n",
              "\n",
              "\n",
              "[tips]\n",
              "Use `model.explain()` to inspect the model.\n",
              "--\n",
              "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
            ],
            "text/html": [
              "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
              "=============\n",
              "H2ORandomForestEstimator : Distributed Random Forest\n",
              "Model Key: DRF_1_AutoML_1_20230622_204129\n",
              "</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-2.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-2 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-2 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-2 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-2 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-2 .h2o-table th,\n",
              "#h2o-table-2 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Model Summary: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>number_of_trees</th>\n",
              "<th>number_of_internal_trees</th>\n",
              "<th>model_size_in_bytes</th>\n",
              "<th>min_depth</th>\n",
              "<th>max_depth</th>\n",
              "<th>mean_depth</th>\n",
              "<th>min_leaves</th>\n",
              "<th>max_leaves</th>\n",
              "<th>mean_leaves</th></tr></thead>\n",
              "    <tbody><tr><td></td>\n",
              "<td>46.0</td>\n",
              "<td>46.0</td>\n",
              "<td>199283.0</td>\n",
              "<td>15.0</td>\n",
              "<td>20.0</td>\n",
              "<td>18.217392</td>\n",
              "<td>311.0</td>\n",
              "<td>369.0</td>\n",
              "<td>340.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: drf\n",
              "** Reported on train data. **\n",
              "\n",
              "MSE: 0.04326800279168445\n",
              "RMSE: 0.2080096218728462\n",
              "LogLoss: 0.20428151575245082\n",
              "Mean Per-Class Error: 0.057211674235314855\n",
              "AUC: 0.9860384526971423\n",
              "AUCPR: 0.9800859943345126\n",
              "Gini: 0.9720769053942846</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-3.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-3 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-3 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-3 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-3 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-3 .h2o-table th,\n",
              "#h2o-table-3 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-3 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-3\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4666666666666667</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>0</th>\n",
              "<th>1</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>0</td>\n",
              "<td>4652.0</td>\n",
              "<td>269.0</td>\n",
              "<td>0.0547</td>\n",
              "<td> (269.0/4921.0)</td></tr>\n",
              "<tr><td>1</td>\n",
              "<td>184.0</td>\n",
              "<td>2895.0</td>\n",
              "<td>0.0598</td>\n",
              "<td> (184.0/3079.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>4836.0</td>\n",
              "<td>3164.0</td>\n",
              "<td>0.0566</td>\n",
              "<td> (453.0/8000.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-4.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-4 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-4 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-4 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-4 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-4 .h2o-table th,\n",
              "#h2o-table-4 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-4 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-4\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.4666667</td>\n",
              "<td>0.9274387</td>\n",
              "<td>105.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.2941176</td>\n",
              "<td>0.9452375</td>\n",
              "<td>140.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.6470588</td>\n",
              "<td>0.9420699</td>\n",
              "<td>70.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.5</td>\n",
              "<td>0.94375</td>\n",
              "<td>100.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>0.9565217</td>\n",
              "<td>0.9982619</td>\n",
              "<td>4.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>197.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9993904</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.5</td>\n",
              "<td>0.8815009</td>\n",
              "<td>100.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.4545455</td>\n",
              "<td>0.9428386</td>\n",
              "<td>108.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.4500000</td>\n",
              "<td>0.9432129</td>\n",
              "<td>109.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>1.0</td>\n",
              "<td>4918.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>1.0</td>\n",
              "<td>1374.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0</td>\n",
              "<td>4921.0</td>\n",
              "<td>197.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0</td>\n",
              "<td>3079.0</td>\n",
              "<td>197.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9993904</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>1.0</td>\n",
              "<td>0.4462488</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>197.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>197.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-5.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-5 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-5 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-5 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-5 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-5 .h2o-table th,\n",
              "#h2o-table-5 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-5 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-5\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 38.49 %, avg score: 38.54 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.2135</td>\n",
              "<td>1.0</td>\n",
              "<td>2.5936825</td>\n",
              "<td>2.5936825</td>\n",
              "<td>0.9982436</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9982436</td>\n",
              "<td>1.0</td>\n",
              "<td>0.5537512</td>\n",
              "<td>0.5537512</td>\n",
              "<td>159.3682520</td>\n",
              "<td>159.3682520</td>\n",
              "<td>0.5531416</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.30125</td>\n",
              "<td>0.7894737</td>\n",
              "<td>2.4761064</td>\n",
              "<td>2.5594342</td>\n",
              "<td>0.9529915</td>\n",
              "<td>0.8931708</td>\n",
              "<td>0.9850622</td>\n",
              "<td>0.9688821</td>\n",
              "<td>0.2172783</td>\n",
              "<td>0.7710296</td>\n",
              "<td>147.6106406</td>\n",
              "<td>155.9434208</td>\n",
              "<td>0.7637140</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.40025</td>\n",
              "<td>0.4444444</td>\n",
              "<td>1.7584090</td>\n",
              "<td>2.3613043</td>\n",
              "<td>0.6767677</td>\n",
              "<td>0.6221101</td>\n",
              "<td>0.9088070</td>\n",
              "<td>0.8831097</td>\n",
              "<td>0.1740825</td>\n",
              "<td>0.9451120</td>\n",
              "<td>75.8409033</td>\n",
              "<td>136.1304308</td>\n",
              "<td>0.8857745</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.504</td>\n",
              "<td>0.1176471</td>\n",
              "<td>0.4382584</td>\n",
              "<td>1.9654392</td>\n",
              "<td>0.1686747</td>\n",
              "<td>0.2558749</td>\n",
              "<td>0.7564484</td>\n",
              "<td>0.7539914</td>\n",
              "<td>0.0454693</td>\n",
              "<td>0.9905814</td>\n",
              "<td>-56.1741608</td>\n",
              "<td>96.5439202</td>\n",
              "<td>0.7910284</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0189892</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0073085</td>\n",
              "<td>0.0108765</td>\n",
              "<td>0.384875</td>\n",
              "<td>0.3854064</td>\n",
              "<td>0.0094186</td>\n",
              "<td>1.0</td>\n",
              "<td>-98.1010802</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: drf\n",
              "** Reported on validation data. **\n",
              "\n",
              "MSE: 0.036937276832765605\n",
              "RMSE: 0.19219073035077838\n",
              "LogLoss: 0.14079214212429528\n",
              "Mean Per-Class Error: 0.04713423229341206\n",
              "AUC: 0.9915375408920449\n",
              "AUCPR: 0.9873978367714009\n",
              "Gini: 0.9830750817840899</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-6.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-6 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-6 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-6 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-6 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-6 .h2o-table th,\n",
              "#h2o-table-6 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-6 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-6\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4565217391304348</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>0</th>\n",
              "<th>1</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>0</td>\n",
              "<td>1187.0</td>\n",
              "<td>58.0</td>\n",
              "<td>0.0466</td>\n",
              "<td> (58.0/1245.0)</td></tr>\n",
              "<tr><td>1</td>\n",
              "<td>36.0</td>\n",
              "<td>719.0</td>\n",
              "<td>0.0477</td>\n",
              "<td> (36.0/755.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>1223.0</td>\n",
              "<td>777.0</td>\n",
              "<td>0.047</td>\n",
              "<td> (94.0/2000.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-7.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-7 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-7 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-7 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-7 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-7 .h2o-table th,\n",
              "#h2o-table-7 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-7 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-7\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.4565217</td>\n",
              "<td>0.9386423</td>\n",
              "<td>27.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.3043478</td>\n",
              "<td>0.9568456</td>\n",
              "<td>34.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.6521739</td>\n",
              "<td>0.9524492</td>\n",
              "<td>17.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.4927536</td>\n",
              "<td>0.953</td>\n",
              "<td>25.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>48.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.4565217</td>\n",
              "<td>0.9008115</td>\n",
              "<td>27.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.4565217</td>\n",
              "<td>0.9523179</td>\n",
              "<td>27.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.4347826</td>\n",
              "<td>0.9530839</td>\n",
              "<td>28.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>1.0</td>\n",
              "<td>1245.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>1.0</td>\n",
              "<td>445.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0</td>\n",
              "<td>1245.0</td>\n",
              "<td>48.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0</td>\n",
              "<td>755.0</td>\n",
              "<td>48.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>1.0</td>\n",
              "<td>0.5894040</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>48.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>48.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-8.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-8 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-8 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-8 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-8 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-8 .h2o-table th,\n",
              "#h2o-table-8 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-8 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-8\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 37.75 %, avg score: 37.82 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.155</td>\n",
              "<td>1.0</td>\n",
              "<td>2.6490066</td>\n",
              "<td>2.6490066</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.4105960</td>\n",
              "<td>0.4105960</td>\n",
              "<td>164.9006623</td>\n",
              "<td>164.9006623</td>\n",
              "<td>0.4105960</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.2005</td>\n",
              "<td>0.9782609</td>\n",
              "<td>2.6490066</td>\n",
              "<td>2.6490066</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9782609</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9950667</td>\n",
              "<td>0.1205298</td>\n",
              "<td>0.5311258</td>\n",
              "<td>164.9006623</td>\n",
              "<td>164.9006623</td>\n",
              "<td>0.5311258</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.3025</td>\n",
              "<td>0.7826087</td>\n",
              "<td>2.5581093</td>\n",
              "<td>2.6183570</td>\n",
              "<td>0.9656863</td>\n",
              "<td>0.8902387</td>\n",
              "<td>0.9884298</td>\n",
              "<td>0.9597197</td>\n",
              "<td>0.2609272</td>\n",
              "<td>0.7920530</td>\n",
              "<td>155.8109336</td>\n",
              "<td>161.8356959</td>\n",
              "<td>0.7864305</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.401</td>\n",
              "<td>0.4130435</td>\n",
              "<td>1.7346287</td>\n",
              "<td>2.4012816</td>\n",
              "<td>0.6548223</td>\n",
              "<td>0.5922901</td>\n",
              "<td>0.9064838</td>\n",
              "<td>0.8694658</td>\n",
              "<td>0.1708609</td>\n",
              "<td>0.9629139</td>\n",
              "<td>73.4628702</td>\n",
              "<td>140.1281564</td>\n",
              "<td>0.9026729</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.5015</td>\n",
              "<td>0.1086957</td>\n",
              "<td>0.3426576</td>\n",
              "<td>1.9887358</td>\n",
              "<td>0.1293532</td>\n",
              "<td>0.2418343</td>\n",
              "<td>0.7507478</td>\n",
              "<td>0.7436892</td>\n",
              "<td>0.0344371</td>\n",
              "<td>0.9973510</td>\n",
              "<td>-65.7342427</td>\n",
              "<td>98.8735779</td>\n",
              "<td>0.7965478</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.6315</td>\n",
              "<td>0.0217391</td>\n",
              "<td>0.0101885</td>\n",
              "<td>1.5814339</td>\n",
              "<td>0.0038462</td>\n",
              "<td>0.0399666</td>\n",
              "<td>0.5969913</td>\n",
              "<td>0.5988215</td>\n",
              "<td>0.0013245</td>\n",
              "<td>0.9986755</td>\n",
              "<td>-98.9811513</td>\n",
              "<td>58.1433882</td>\n",
              "<td>0.5898402</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0035943</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0013569</td>\n",
              "<td>0.0</td>\n",
              "<td>0.3775</td>\n",
              "<td>0.3781558</td>\n",
              "<td>0.0013245</td>\n",
              "<td>1.0</td>\n",
              "<td>-99.6405690</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: drf\n",
              "** Reported on cross-validation data. **\n",
              "\n",
              "MSE: 0.04109426250888458\n",
              "RMSE: 0.20271719835496094\n",
              "LogLoss: 0.14109268080346257\n",
              "Mean Per-Class Error: 0.05639704934588783\n",
              "AUC: 0.9891767351896238\n",
              "AUCPR: 0.984216068014286\n",
              "Gini: 0.9783534703792476</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-9.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-9 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-9 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-9 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-9 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-9 .h2o-table th,\n",
              "#h2o-table-9 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-9 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-9\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.48</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>0</th>\n",
              "<th>1</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>0</td>\n",
              "<td>4676.0</td>\n",
              "<td>245.0</td>\n",
              "<td>0.0498</td>\n",
              "<td> (245.0/4921.0)</td></tr>\n",
              "<tr><td>1</td>\n",
              "<td>194.0</td>\n",
              "<td>2885.0</td>\n",
              "<td>0.063</td>\n",
              "<td> (194.0/3079.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>4870.0</td>\n",
              "<td>3130.0</td>\n",
              "<td>0.0549</td>\n",
              "<td> (439.0/8000.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-10.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-10 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-10 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-10 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-10 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-10 .h2o-table th,\n",
              "#h2o-table-10 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-10 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-10\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.48</td>\n",
              "<td>0.9292962</td>\n",
              "<td>54.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.3200000</td>\n",
              "<td>0.9497118</td>\n",
              "<td>76.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.6800000</td>\n",
              "<td>0.9475386</td>\n",
              "<td>29.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.52</td>\n",
              "<td>0.945125</td>\n",
              "<td>51.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>135.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.48</td>\n",
              "<td>0.8845437</td>\n",
              "<td>54.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.4400000</td>\n",
              "<td>0.9404593</td>\n",
              "<td>59.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.48</td>\n",
              "<td>0.9436030</td>\n",
              "<td>54.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>1.0</td>\n",
              "<td>4921.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>1.0</td>\n",
              "<td>1720.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0</td>\n",
              "<td>4921.0</td>\n",
              "<td>135.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0</td>\n",
              "<td>3079.0</td>\n",
              "<td>135.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>1.0</td>\n",
              "<td>0.5586229</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>135.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>135.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-11.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-11 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-11 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-11 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-11 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-11 .h2o-table th,\n",
              "#h2o-table-11 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-11 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-11\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 38.49 %, avg score: 38.55 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.169875</td>\n",
              "<td>1.0</td>\n",
              "<td>2.5982462</td>\n",
              "<td>2.5982462</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.4413771</td>\n",
              "<td>0.4413771</td>\n",
              "<td>159.8246184</td>\n",
              "<td>159.8246184</td>\n",
              "<td>0.4413771</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.20075</td>\n",
              "<td>0.98</td>\n",
              "<td>2.5877270</td>\n",
              "<td>2.5966283</td>\n",
              "<td>0.9959514</td>\n",
              "<td>0.9800000</td>\n",
              "<td>0.9993773</td>\n",
              "<td>0.9969240</td>\n",
              "<td>0.0798961</td>\n",
              "<td>0.5212731</td>\n",
              "<td>158.7726969</td>\n",
              "<td>159.6628347</td>\n",
              "<td>0.5210699</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.3025</td>\n",
              "<td>0.8</td>\n",
              "<td>2.5248314</td>\n",
              "<td>2.5724785</td>\n",
              "<td>0.9717445</td>\n",
              "<td>0.8998605</td>\n",
              "<td>0.9900826</td>\n",
              "<td>0.9642754</td>\n",
              "<td>0.2569016</td>\n",
              "<td>0.7781747</td>\n",
              "<td>152.4831365</td>\n",
              "<td>157.2478453</td>\n",
              "<td>0.7732977</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.4005</td>\n",
              "<td>0.44</td>\n",
              "<td>1.7067561</td>\n",
              "<td>2.3606413</td>\n",
              "<td>0.6568878</td>\n",
              "<td>0.6213488</td>\n",
              "<td>0.9085518</td>\n",
              "<td>0.8803633</td>\n",
              "<td>0.1672621</td>\n",
              "<td>0.9454368</td>\n",
              "<td>70.6756103</td>\n",
              "<td>136.0641274</td>\n",
              "<td>0.8858961</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.50625</td>\n",
              "<td>0.12</td>\n",
              "<td>0.4545395</td>\n",
              "<td>1.9624778</td>\n",
              "<td>0.1749409</td>\n",
              "<td>0.2530573</td>\n",
              "<td>0.7553086</td>\n",
              "<td>0.7493260</td>\n",
              "<td>0.0480676</td>\n",
              "<td>0.9935044</td>\n",
              "<td>-54.5460478</td>\n",
              "<td>96.2477797</td>\n",
              "<td>0.7921226</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.647375</td>\n",
              "<td>0.02</td>\n",
              "<td>0.0437260</td>\n",
              "<td>1.5441981</td>\n",
              "<td>0.0168291</td>\n",
              "<td>0.0437432</td>\n",
              "<td>0.5943232</td>\n",
              "<td>0.5955120</td>\n",
              "<td>0.0061708</td>\n",
              "<td>0.9996752</td>\n",
              "<td>-95.6273979</td>\n",
              "<td>54.4198060</td>\n",
              "<td>0.5727295</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0009210</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0003545</td>\n",
              "<td>0.0000014</td>\n",
              "<td>0.384875</td>\n",
              "<td>0.3855201</td>\n",
              "<td>0.0003248</td>\n",
              "<td>1.0</td>\n",
              "<td>-99.9078963</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-12.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-12 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-12 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-12 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-12 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-12 .h2o-table th,\n",
              "#h2o-table-12 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-12 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-12\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Cross-Validation Metrics Summary: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>mean</th>\n",
              "<th>sd</th>\n",
              "<th>cv_1_valid</th>\n",
              "<th>cv_2_valid</th>\n",
              "<th>cv_3_valid</th>\n",
              "<th>cv_4_valid</th>\n",
              "<th>cv_5_valid</th>\n",
              "<th>cv_6_valid</th>\n",
              "<th>cv_7_valid</th>\n",
              "<th>cv_8_valid</th>\n",
              "<th>cv_9_valid</th>\n",
              "<th>cv_10_valid</th></tr></thead>\n",
              "    <tbody><tr><td>accuracy</td>\n",
              "<td>0.948625</td>\n",
              "<td>0.0096186</td>\n",
              "<td>0.95125</td>\n",
              "<td>0.96875</td>\n",
              "<td>0.955</td>\n",
              "<td>0.94375</td>\n",
              "<td>0.94375</td>\n",
              "<td>0.94125</td>\n",
              "<td>0.95875</td>\n",
              "<td>0.94125</td>\n",
              "<td>0.93875</td>\n",
              "<td>0.94375</td></tr>\n",
              "<tr><td>auc</td>\n",
              "<td>0.9893215</td>\n",
              "<td>0.0026153</td>\n",
              "<td>0.9896503</td>\n",
              "<td>0.9941378</td>\n",
              "<td>0.9925426</td>\n",
              "<td>0.9871223</td>\n",
              "<td>0.9879707</td>\n",
              "<td>0.9876364</td>\n",
              "<td>0.991501</td>\n",
              "<td>0.9891478</td>\n",
              "<td>0.9872001</td>\n",
              "<td>0.9863054</td></tr>\n",
              "<tr><td>err</td>\n",
              "<td>0.051375</td>\n",
              "<td>0.0096186</td>\n",
              "<td>0.04875</td>\n",
              "<td>0.03125</td>\n",
              "<td>0.045</td>\n",
              "<td>0.05625</td>\n",
              "<td>0.05625</td>\n",
              "<td>0.05875</td>\n",
              "<td>0.04125</td>\n",
              "<td>0.05875</td>\n",
              "<td>0.06125</td>\n",
              "<td>0.05625</td></tr>\n",
              "<tr><td>err_count</td>\n",
              "<td>41.1</td>\n",
              "<td>7.6948757</td>\n",
              "<td>39.0</td>\n",
              "<td>25.0</td>\n",
              "<td>36.0</td>\n",
              "<td>45.0</td>\n",
              "<td>45.0</td>\n",
              "<td>47.0</td>\n",
              "<td>33.0</td>\n",
              "<td>47.0</td>\n",
              "<td>49.0</td>\n",
              "<td>45.0</td></tr>\n",
              "<tr><td>f0point5</td>\n",
              "<td>0.9286361</td>\n",
              "<td>0.0171784</td>\n",
              "<td>0.9338521</td>\n",
              "<td>0.9575878</td>\n",
              "<td>0.9337135</td>\n",
              "<td>0.9041533</td>\n",
              "<td>0.9202852</td>\n",
              "<td>0.9093620</td>\n",
              "<td>0.9526938</td>\n",
              "<td>0.9166191</td>\n",
              "<td>0.9285259</td>\n",
              "<td>0.9295685</td></tr>\n",
              "<tr><td>f1</td>\n",
              "<td>0.9341226</td>\n",
              "<td>0.0109179</td>\n",
              "<td>0.9365854</td>\n",
              "<td>0.9585406</td>\n",
              "<td>0.9357143</td>\n",
              "<td>0.9263502</td>\n",
              "<td>0.9265906</td>\n",
              "<td>0.9284627</td>\n",
              "<td>0.9461664</td>\n",
              "<td>0.9317852</td>\n",
              "<td>0.9223455</td>\n",
              "<td>0.9286847</td></tr>\n",
              "<tr><td>f2</td>\n",
              "<td>0.9398823</td>\n",
              "<td>0.0123253</td>\n",
              "<td>0.9393346</td>\n",
              "<td>0.9594954</td>\n",
              "<td>0.9377237</td>\n",
              "<td>0.9496644</td>\n",
              "<td>0.9329829</td>\n",
              "<td>0.9483831</td>\n",
              "<td>0.9397278</td>\n",
              "<td>0.9474616</td>\n",
              "<td>0.9162468</td>\n",
              "<td>0.9278024</td></tr>\n",
              "<tr><td>lift_top_group</td>\n",
              "<td>2.6042056</td>\n",
              "<td>0.1324018</td>\n",
              "<td>2.6143792</td>\n",
              "<td>2.6578074</td>\n",
              "<td>2.8673835</td>\n",
              "<td>2.7303755</td>\n",
              "<td>2.640264</td>\n",
              "<td>2.5236592</td>\n",
              "<td>2.580645</td>\n",
              "<td>2.3880596</td>\n",
              "<td>2.507837</td>\n",
              "<td>2.5316455</td></tr>\n",
              "<tr><td>logloss</td>\n",
              "<td>0.1411213</td>\n",
              "<td>0.0190486</td>\n",
              "<td>0.1321801</td>\n",
              "<td>0.1128110</td>\n",
              "<td>0.1316768</td>\n",
              "<td>0.1458569</td>\n",
              "<td>0.1425228</td>\n",
              "<td>0.1434189</td>\n",
              "<td>0.1283116</td>\n",
              "<td>0.1416261</td>\n",
              "<td>0.1461246</td>\n",
              "<td>0.1866843</td></tr>\n",
              "<tr><td>max_per_class_error</td>\n",
              "<td>0.0659869</td>\n",
              "<td>0.0123332</td>\n",
              "<td>0.0588235</td>\n",
              "<td>0.0398671</td>\n",
              "<td>0.0609319</td>\n",
              "<td>0.0690335</td>\n",
              "<td>0.0627063</td>\n",
              "<td>0.0724638</td>\n",
              "<td>0.0645161</td>\n",
              "<td>0.0709677</td>\n",
              "<td>0.0877743</td>\n",
              "<td>0.0727848</td></tr>\n",
              "<tr><td>mcc</td>\n",
              "<td>0.8924317</td>\n",
              "<td>0.0188935</td>\n",
              "<td>0.8970212</td>\n",
              "<td>0.9334688</td>\n",
              "<td>0.9011132</td>\n",
              "<td>0.8829053</td>\n",
              "<td>0.8811584</td>\n",
              "<td>0.8802769</td>\n",
              "<td>0.9128952</td>\n",
              "<td>0.8812954</td>\n",
              "<td>0.8719344</td>\n",
              "<td>0.8822482</td></tr>\n",
              "<tr><td>mean_per_class_accuracy</td>\n",
              "<td>0.9476683</td>\n",
              "<td>0.0089106</td>\n",
              "<td>0.9493332</td>\n",
              "<td>0.9670404</td>\n",
              "<td>0.9512999</td>\n",
              "<td>0.9484184</td>\n",
              "<td>0.9424899</td>\n",
              "<td>0.9448407</td>\n",
              "<td>0.9544767</td>\n",
              "<td>0.9436206</td>\n",
              "<td>0.9342833</td>\n",
              "<td>0.9408803</td></tr>\n",
              "<tr><td>mean_per_class_error</td>\n",
              "<td>0.0523317</td>\n",
              "<td>0.0089106</td>\n",
              "<td>0.0506668</td>\n",
              "<td>0.0329596</td>\n",
              "<td>0.0487001</td>\n",
              "<td>0.0515816</td>\n",
              "<td>0.0575101</td>\n",
              "<td>0.0551593</td>\n",
              "<td>0.0455234</td>\n",
              "<td>0.0563794</td>\n",
              "<td>0.0657167</td>\n",
              "<td>0.0591197</td></tr>\n",
              "<tr><td>mse</td>\n",
              "<td>0.0410048</td>\n",
              "<td>0.0044137</td>\n",
              "<td>0.0389478</td>\n",
              "<td>0.0313437</td>\n",
              "<td>0.0385018</td>\n",
              "<td>0.0451063</td>\n",
              "<td>0.0434138</td>\n",
              "<td>0.0434346</td>\n",
              "<td>0.0373019</td>\n",
              "<td>0.0427476</td>\n",
              "<td>0.04465</td>\n",
              "<td>0.0446002</td></tr>\n",
              "<tr><td>pr_auc</td>\n",
              "<td>0.9844196</td>\n",
              "<td>0.0034229</td>\n",
              "<td>0.9845253</td>\n",
              "<td>0.9909664</td>\n",
              "<td>0.986631</td>\n",
              "<td>0.9791239</td>\n",
              "<td>0.9819524</td>\n",
              "<td>0.9828061</td>\n",
              "<td>0.9875858</td>\n",
              "<td>0.9858642</td>\n",
              "<td>0.9828396</td>\n",
              "<td>0.981901</td></tr>\n",
              "<tr><td>precision</td>\n",
              "<td>0.9251228</td>\n",
              "<td>0.0227588</td>\n",
              "<td>0.9320388</td>\n",
              "<td>0.9569536</td>\n",
              "<td>0.9323843</td>\n",
              "<td>0.8899371</td>\n",
              "<td>0.9161291</td>\n",
              "<td>0.8970588</td>\n",
              "<td>0.9570957</td>\n",
              "<td>0.9067797</td>\n",
              "<td>0.9326923</td>\n",
              "<td>0.9301587</td></tr>\n",
              "<tr><td>r2</td>\n",
              "<td>0.8265975</td>\n",
              "<td>0.0179854</td>\n",
              "<td>0.8351024</td>\n",
              "<td>0.866444</td>\n",
              "<td>0.8304807</td>\n",
              "<td>0.8056693</td>\n",
              "<td>0.8154945</td>\n",
              "<td>0.8184445</td>\n",
              "<td>0.8428361</td>\n",
              "<td>0.8243719</td>\n",
              "<td>0.8137631</td>\n",
              "<td>0.8133687</td></tr>\n",
              "<tr><td>recall</td>\n",
              "<td>0.9438821</td>\n",
              "<td>0.0173548</td>\n",
              "<td>0.9411765</td>\n",
              "<td>0.9601329</td>\n",
              "<td>0.9390681</td>\n",
              "<td>0.9658703</td>\n",
              "<td>0.9372937</td>\n",
              "<td>0.9621451</td>\n",
              "<td>0.9354839</td>\n",
              "<td>0.958209</td>\n",
              "<td>0.9122257</td>\n",
              "<td>0.9272152</td></tr>\n",
              "<tr><td>rmse</td>\n",
              "<td>0.2022149</td>\n",
              "<td>0.0112496</td>\n",
              "<td>0.1973519</td>\n",
              "<td>0.1770416</td>\n",
              "<td>0.1962188</td>\n",
              "<td>0.2123824</td>\n",
              "<td>0.2083599</td>\n",
              "<td>0.2084097</td>\n",
              "<td>0.1931369</td>\n",
              "<td>0.2067550</td>\n",
              "<td>0.2113055</td>\n",
              "<td>0.2111877</td></tr>\n",
              "<tr><td>specificity</td>\n",
              "<td>0.9514546</td>\n",
              "<td>0.0173690</td>\n",
              "<td>0.9574899</td>\n",
              "<td>0.9739479</td>\n",
              "<td>0.9635317</td>\n",
              "<td>0.9309665</td>\n",
              "<td>0.9476861</td>\n",
              "<td>0.9275362</td>\n",
              "<td>0.9734694</td>\n",
              "<td>0.9290323</td>\n",
              "<td>0.9563410</td>\n",
              "<td>0.9545454</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-13.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-13 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-13 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-13 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-13 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-13 .h2o-table th,\n",
              "#h2o-table-13 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-13 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-13\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Scoring History: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>timestamp</th>\n",
              "<th>duration</th>\n",
              "<th>number_of_trees</th>\n",
              "<th>training_rmse</th>\n",
              "<th>training_logloss</th>\n",
              "<th>training_auc</th>\n",
              "<th>training_pr_auc</th>\n",
              "<th>training_lift</th>\n",
              "<th>training_classification_error</th>\n",
              "<th>validation_rmse</th>\n",
              "<th>validation_logloss</th>\n",
              "<th>validation_auc</th>\n",
              "<th>validation_pr_auc</th>\n",
              "<th>validation_lift</th>\n",
              "<th>validation_classification_error</th></tr></thead>\n",
              "    <tbody><tr><td></td>\n",
              "<td>2023-06-22 20:43:55</td>\n",
              "<td>23.403 sec</td>\n",
              "<td>0.0</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-22 20:43:55</td>\n",
              "<td>23.600 sec</td>\n",
              "<td>5.0</td>\n",
              "<td>0.2767544</td>\n",
              "<td>1.9967730</td>\n",
              "<td>0.9308393</td>\n",
              "<td>0.8925009</td>\n",
              "<td>2.4093223</td>\n",
              "<td>0.0920443</td>\n",
              "<td>0.2190890</td>\n",
              "<td>0.3669400</td>\n",
              "<td>0.9789388</td>\n",
              "<td>0.9678027</td>\n",
              "<td>2.6238260</td>\n",
              "<td>0.063</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-22 20:43:55</td>\n",
              "<td>23.851 sec</td>\n",
              "<td>10.0</td>\n",
              "<td>0.2445273</td>\n",
              "<td>0.9663935</td>\n",
              "<td>0.9605493</td>\n",
              "<td>0.9364353</td>\n",
              "<td>2.4996767</td>\n",
              "<td>0.0761556</td>\n",
              "<td>0.2058033</td>\n",
              "<td>0.1665588</td>\n",
              "<td>0.9875954</td>\n",
              "<td>0.9801532</td>\n",
              "<td>2.6431199</td>\n",
              "<td>0.0595</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-22 20:43:55</td>\n",
              "<td>24.079 sec</td>\n",
              "<td>15.0</td>\n",
              "<td>0.2261966</td>\n",
              "<td>0.5028121</td>\n",
              "<td>0.9752431</td>\n",
              "<td>0.9599033</td>\n",
              "<td>2.5495443</td>\n",
              "<td>0.0665666</td>\n",
              "<td>0.1991817</td>\n",
              "<td>0.1460567</td>\n",
              "<td>0.9896636</td>\n",
              "<td>0.9846118</td>\n",
              "<td>2.6490066</td>\n",
              "<td>0.056</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-22 20:43:56</td>\n",
              "<td>24.262 sec</td>\n",
              "<td>20.0</td>\n",
              "<td>0.2187206</td>\n",
              "<td>0.3612843</td>\n",
              "<td>0.9803188</td>\n",
              "<td>0.9681426</td>\n",
              "<td>2.5660418</td>\n",
              "<td>0.0632579</td>\n",
              "<td>0.1965201</td>\n",
              "<td>0.1436989</td>\n",
              "<td>0.9905513</td>\n",
              "<td>0.9860533</td>\n",
              "<td>2.6490066</td>\n",
              "<td>0.0505</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-22 20:43:56</td>\n",
              "<td>24.451 sec</td>\n",
              "<td>25.0</td>\n",
              "<td>0.2139304</td>\n",
              "<td>0.2746755</td>\n",
              "<td>0.9829967</td>\n",
              "<td>0.9753618</td>\n",
              "<td>2.5860606</td>\n",
              "<td>0.060625</td>\n",
              "<td>0.1958920</td>\n",
              "<td>0.1438512</td>\n",
              "<td>0.9908077</td>\n",
              "<td>0.9863770</td>\n",
              "<td>2.6490066</td>\n",
              "<td>0.0495</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-22 20:43:56</td>\n",
              "<td>24.647 sec</td>\n",
              "<td>30.0</td>\n",
              "<td>0.2121942</td>\n",
              "<td>0.2425199</td>\n",
              "<td>0.9842336</td>\n",
              "<td>0.9769625</td>\n",
              "<td>2.5884415</td>\n",
              "<td>0.059</td>\n",
              "<td>0.1949704</td>\n",
              "<td>0.1433966</td>\n",
              "<td>0.9909694</td>\n",
              "<td>0.9865957</td>\n",
              "<td>2.6490066</td>\n",
              "<td>0.0475</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-22 20:43:56</td>\n",
              "<td>24.846 sec</td>\n",
              "<td>35.0</td>\n",
              "<td>0.2096984</td>\n",
              "<td>0.2207400</td>\n",
              "<td>0.9853191</td>\n",
              "<td>0.9787134</td>\n",
              "<td>2.5910047</td>\n",
              "<td>0.057</td>\n",
              "<td>0.1947836</td>\n",
              "<td>0.1430478</td>\n",
              "<td>0.9910710</td>\n",
              "<td>0.9867606</td>\n",
              "<td>2.6490066</td>\n",
              "<td>0.0485</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-22 20:43:56</td>\n",
              "<td>25.088 sec</td>\n",
              "<td>40.0</td>\n",
              "<td>0.2089029</td>\n",
              "<td>0.2166056</td>\n",
              "<td>0.9855383</td>\n",
              "<td>0.9793254</td>\n",
              "<td>2.5923310</td>\n",
              "<td>0.056125</td>\n",
              "<td>0.1931846</td>\n",
              "<td>0.1417876</td>\n",
              "<td>0.9913833</td>\n",
              "<td>0.9872003</td>\n",
              "<td>2.6490066</td>\n",
              "<td>0.046</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-22 20:43:57</td>\n",
              "<td>25.289 sec</td>\n",
              "<td>45.0</td>\n",
              "<td>0.2079904</td>\n",
              "<td>0.2041993</td>\n",
              "<td>0.9860597</td>\n",
              "<td>0.9801217</td>\n",
              "<td>2.5937064</td>\n",
              "<td>0.056625</td>\n",
              "<td>0.1926063</td>\n",
              "<td>0.1412901</td>\n",
              "<td>0.9914631</td>\n",
              "<td>0.9872754</td>\n",
              "<td>2.6490066</td>\n",
              "<td>0.0455</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-22 20:43:57</td>\n",
              "<td>25.356 sec</td>\n",
              "<td>46.0</td>\n",
              "<td>0.2080096</td>\n",
              "<td>0.2042815</td>\n",
              "<td>0.9860385</td>\n",
              "<td>0.9800860</td>\n",
              "<td>2.5936825</td>\n",
              "<td>0.056625</td>\n",
              "<td>0.1921907</td>\n",
              "<td>0.1407921</td>\n",
              "<td>0.9915375</td>\n",
              "<td>0.9873978</td>\n",
              "<td>2.6490066</td>\n",
              "<td>0.047</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-14.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-14 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-14 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-14 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-14 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-14 .h2o-table th,\n",
              "#h2o-table-14 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-14 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-14\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Variable Importances: </caption>\n",
              "    <thead><tr><th>variable</th>\n",
              "<th>relative_importance</th>\n",
              "<th>scaled_importance</th>\n",
              "<th>percentage</th></tr></thead>\n",
              "    <tbody><tr><td>concave points_mean</td>\n",
              "<td>12892.1552734</td>\n",
              "<td>1.0</td>\n",
              "<td>0.1843350</td></tr>\n",
              "<tr><td>perimeter_worst</td>\n",
              "<td>12409.1396484</td>\n",
              "<td>0.9625341</td>\n",
              "<td>0.1774287</td></tr>\n",
              "<tr><td>concave points_worst</td>\n",
              "<td>6141.6552734</td>\n",
              "<td>0.4763870</td>\n",
              "<td>0.0878148</td></tr>\n",
              "<tr><td>radius_worst</td>\n",
              "<td>5617.1918945</td>\n",
              "<td>0.4357062</td>\n",
              "<td>0.0803159</td></tr>\n",
              "<tr><td>radius_se</td>\n",
              "<td>4640.3554688</td>\n",
              "<td>0.3599364</td>\n",
              "<td>0.0663489</td></tr>\n",
              "<tr><td>perimeter_mean</td>\n",
              "<td>4096.8095703</td>\n",
              "<td>0.3177754</td>\n",
              "<td>0.0585771</td></tr>\n",
              "<tr><td>area_worst</td>\n",
              "<td>3825.3610840</td>\n",
              "<td>0.2967201</td>\n",
              "<td>0.0546959</td></tr>\n",
              "<tr><td>area_se</td>\n",
              "<td>3570.8486328</td>\n",
              "<td>0.2769784</td>\n",
              "<td>0.0510568</td></tr>\n",
              "<tr><td>concavity_mean</td>\n",
              "<td>3542.3181152</td>\n",
              "<td>0.2747654</td>\n",
              "<td>0.0506489</td></tr>\n",
              "<tr><td>area_mean</td>\n",
              "<td>1562.5438232</td>\n",
              "<td>0.1212011</td>\n",
              "<td>0.0223416</td></tr>\n",
              "<tr><td>---</td>\n",
              "<td>---</td>\n",
              "<td>---</td>\n",
              "<td>---</td></tr>\n",
              "<tr><td>symmetry_worst</td>\n",
              "<td>398.6156921</td>\n",
              "<td>0.0309192</td>\n",
              "<td>0.0056995</td></tr>\n",
              "<tr><td>smoothness_mean</td>\n",
              "<td>397.4166565</td>\n",
              "<td>0.0308262</td>\n",
              "<td>0.0056824</td></tr>\n",
              "<tr><td>texture_se</td>\n",
              "<td>372.9902344</td>\n",
              "<td>0.0289316</td>\n",
              "<td>0.0053331</td></tr>\n",
              "<tr><td>symmetry_mean</td>\n",
              "<td>357.3835449</td>\n",
              "<td>0.0277210</td>\n",
              "<td>0.0051100</td></tr>\n",
              "<tr><td>smoothness_se</td>\n",
              "<td>350.0584106</td>\n",
              "<td>0.0271528</td>\n",
              "<td>0.0050052</td></tr>\n",
              "<tr><td>fractal_dimension_worst</td>\n",
              "<td>340.3181763</td>\n",
              "<td>0.0263973</td>\n",
              "<td>0.0048659</td></tr>\n",
              "<tr><td>symmetry_se</td>\n",
              "<td>333.9683533</td>\n",
              "<td>0.0259048</td>\n",
              "<td>0.0047752</td></tr>\n",
              "<tr><td>concavity_se</td>\n",
              "<td>327.7789612</td>\n",
              "<td>0.0254247</td>\n",
              "<td>0.0046867</td></tr>\n",
              "<tr><td>concave points_se</td>\n",
              "<td>309.9120178</td>\n",
              "<td>0.0240388</td>\n",
              "<td>0.0044312</td></tr>\n",
              "<tr><td>fractal_dimension_se</td>\n",
              "<td>298.4029541</td>\n",
              "<td>0.0231461</td>\n",
              "<td>0.0042666</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "<pre style='font-size: smaller; margin-bottom: 1em;'>[30 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
              "\n",
              "[tips]\n",
              "Use `model.explain()` to inspect the model.\n",
              "--\n",
              "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lb = aml.leaderboard\n",
        "lb.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "gmCXw_D_4y1D",
        "outputId": "1253fde7-d66e-4dea-ce4c-3c4ea28cdce4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model_id                              accuracy       auc    logloss     aucpr    mean_per_class_error      rmse        mse\n",
              "----------------------------------  ----------  --------  ---------  --------  ----------------------  --------  ---------\n",
              "DRF_1_AutoML_1_20230622_204129        0.945125  0.989177   0.141093  0.984216               0.056397   0.202717  0.0410943\n",
              "XRT_1_AutoML_1_20230622_204129        0.945625  0.989034   0.15255   0.984006               0.0589083  0.202303  0.0409264\n",
              "XGBoost_3_AutoML_1_20230622_204129    0.948     0.990641   0.125343  0.986013               0.0535747  0.196101  0.0384557\n",
              "XGBoost_1_AutoML_1_20230622_204129    0.94825   0.990807   0.12301   0.986256               0.0542833  0.194461  0.037815\n",
              "GBM_2_AutoML_1_20230622_204129        0.949125  0.990889   0.122321  0.986528               0.055881   0.193309  0.0373683\n",
              "GBM_4_AutoML_1_20230622_204129        0.949125  0.990796   0.12375   0.986334               0.0527628  0.193394  0.0374012\n",
              "GBM_3_AutoML_1_20230622_204129        0.949375  0.991048   0.122135  0.986551               0.0517268  0.19245   0.037037\n",
              "XGBoost_2_AutoML_1_20230622_204129    0.9495    0.990286   0.129042  0.985682               0.0508957  0.196218  0.0385014\n",
              "GLM_1_AutoML_1_20230622_204129        0.949625  0.990625   0.120152  0.986297               0.0545628  0.192167  0.0369281\n",
              "GBM_1_AutoML_1_20230622_204129        0.94975   0.991147   0.117772  0.986794               0.051422   0.190749  0.0363851\n",
              "[10 rows x 8 columns]\n"
            ],
            "text/html": [
              "<table class='dataframe'>\n",
              "<thead>\n",
              "<tr><th>model_id                          </th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">      mse</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DRF_1_AutoML_1_20230622_204129    </td><td style=\"text-align: right;\">  0.945125</td><td style=\"text-align: right;\">0.989177</td><td style=\"text-align: right;\"> 0.141093</td><td style=\"text-align: right;\">0.984216</td><td style=\"text-align: right;\">             0.056397 </td><td style=\"text-align: right;\">0.202717</td><td style=\"text-align: right;\">0.0410943</td></tr>\n",
              "<tr><td>XRT_1_AutoML_1_20230622_204129    </td><td style=\"text-align: right;\">  0.945625</td><td style=\"text-align: right;\">0.989034</td><td style=\"text-align: right;\"> 0.15255 </td><td style=\"text-align: right;\">0.984006</td><td style=\"text-align: right;\">             0.0589083</td><td style=\"text-align: right;\">0.202303</td><td style=\"text-align: right;\">0.0409264</td></tr>\n",
              "<tr><td>XGBoost_3_AutoML_1_20230622_204129</td><td style=\"text-align: right;\">  0.948   </td><td style=\"text-align: right;\">0.990641</td><td style=\"text-align: right;\"> 0.125343</td><td style=\"text-align: right;\">0.986013</td><td style=\"text-align: right;\">             0.0535747</td><td style=\"text-align: right;\">0.196101</td><td style=\"text-align: right;\">0.0384557</td></tr>\n",
              "<tr><td>XGBoost_1_AutoML_1_20230622_204129</td><td style=\"text-align: right;\">  0.94825 </td><td style=\"text-align: right;\">0.990807</td><td style=\"text-align: right;\"> 0.12301 </td><td style=\"text-align: right;\">0.986256</td><td style=\"text-align: right;\">             0.0542833</td><td style=\"text-align: right;\">0.194461</td><td style=\"text-align: right;\">0.037815 </td></tr>\n",
              "<tr><td>GBM_2_AutoML_1_20230622_204129    </td><td style=\"text-align: right;\">  0.949125</td><td style=\"text-align: right;\">0.990889</td><td style=\"text-align: right;\"> 0.122321</td><td style=\"text-align: right;\">0.986528</td><td style=\"text-align: right;\">             0.055881 </td><td style=\"text-align: right;\">0.193309</td><td style=\"text-align: right;\">0.0373683</td></tr>\n",
              "<tr><td>GBM_4_AutoML_1_20230622_204129    </td><td style=\"text-align: right;\">  0.949125</td><td style=\"text-align: right;\">0.990796</td><td style=\"text-align: right;\"> 0.12375 </td><td style=\"text-align: right;\">0.986334</td><td style=\"text-align: right;\">             0.0527628</td><td style=\"text-align: right;\">0.193394</td><td style=\"text-align: right;\">0.0374012</td></tr>\n",
              "<tr><td>GBM_3_AutoML_1_20230622_204129    </td><td style=\"text-align: right;\">  0.949375</td><td style=\"text-align: right;\">0.991048</td><td style=\"text-align: right;\"> 0.122135</td><td style=\"text-align: right;\">0.986551</td><td style=\"text-align: right;\">             0.0517268</td><td style=\"text-align: right;\">0.19245 </td><td style=\"text-align: right;\">0.037037 </td></tr>\n",
              "<tr><td>XGBoost_2_AutoML_1_20230622_204129</td><td style=\"text-align: right;\">  0.9495  </td><td style=\"text-align: right;\">0.990286</td><td style=\"text-align: right;\"> 0.129042</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">             0.0508957</td><td style=\"text-align: right;\">0.196218</td><td style=\"text-align: right;\">0.0385014</td></tr>\n",
              "<tr><td>GLM_1_AutoML_1_20230622_204129    </td><td style=\"text-align: right;\">  0.949625</td><td style=\"text-align: right;\">0.990625</td><td style=\"text-align: right;\"> 0.120152</td><td style=\"text-align: right;\">0.986297</td><td style=\"text-align: right;\">             0.0545628</td><td style=\"text-align: right;\">0.192167</td><td style=\"text-align: right;\">0.0369281</td></tr>\n",
              "<tr><td>GBM_1_AutoML_1_20230622_204129    </td><td style=\"text-align: right;\">  0.94975 </td><td style=\"text-align: right;\">0.991147</td><td style=\"text-align: right;\"> 0.117772</td><td style=\"text-align: right;\">0.986794</td><td style=\"text-align: right;\">             0.051422 </td><td style=\"text-align: right;\">0.190749</td><td style=\"text-align: right;\">0.0363851</td></tr>\n",
              "</tbody>\n",
              "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[10 rows x 8 columns]</pre>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = aml.get_best_model()\n",
        "best_model"
      ],
      "metadata": {
        "id": "vlH8zwtisQU1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "62f57db1-b18e-4911-eaa9-2a7114d3d805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model Details\n",
              "=============\n",
              "H2ORandomForestEstimator : Distributed Random Forest\n",
              "Model Key: DRF_1_AutoML_1_20230622_204129\n",
              "\n",
              "\n",
              "Model Summary: \n",
              "    number_of_trees    number_of_internal_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n",
              "--  -----------------  --------------------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n",
              "    46                 46                          199283                 15           20           18.2174       311           369           340\n",
              "\n",
              "ModelMetricsBinomial: drf\n",
              "** Reported on train data. **\n",
              "\n",
              "MSE: 0.04326800279168445\n",
              "RMSE: 0.2080096218728462\n",
              "LogLoss: 0.20428151575245082\n",
              "Mean Per-Class Error: 0.057211674235314855\n",
              "AUC: 0.9860384526971423\n",
              "AUCPR: 0.9800859943345126\n",
              "Gini: 0.9720769053942846\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4666666666666667\n",
              "       0     1     Error    Rate\n",
              "-----  ----  ----  -------  --------------\n",
              "0      4652  269   0.0547   (269.0/4921.0)\n",
              "1      184   2895  0.0598   (184.0/3079.0)\n",
              "Total  4836  3164  0.0566   (453.0/8000.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.466667     0.927439  105\n",
              "max f2                       0.294118     0.945237  140\n",
              "max f0point5                 0.647059     0.94207   70\n",
              "max accuracy                 0.5          0.94375   100\n",
              "max precision                0.956522     0.998262  4\n",
              "max recall                   0            1         197\n",
              "max specificity              1            0.99939   0\n",
              "max absolute_mcc             0.5          0.881501  100\n",
              "max min_per_class_accuracy   0.454545     0.942839  108\n",
              "max mean_per_class_accuracy  0.45         0.943213  109\n",
              "max tns                      1            4918      0\n",
              "max fns                      1            1374      0\n",
              "max fps                      0            4921      197\n",
              "max tps                      0            3079      197\n",
              "max tnr                      1            0.99939   0\n",
              "max fnr                      1            0.446249  0\n",
              "max fpr                      0            1         197\n",
              "max tpr                      0            1         197\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 38.49 %, avg score: 38.54 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.2135                      1                  2.59368    2.59368            0.998244         1          0.998244                    1                   0.553751        0.553751                   159.368   159.368            0.553142\n",
              "2        0.30125                     0.789474           2.47611    2.55943            0.952991         0.893171   0.985062                    0.968882            0.217278        0.77103                    147.611   155.943            0.763714\n",
              "3        0.40025                     0.444444           1.75841    2.3613             0.676768         0.62211    0.908807                    0.88311             0.174082        0.945112                   75.8409   136.13             0.885775\n",
              "4        0.504                       0.117647           0.438258   1.96544            0.168675         0.255875   0.756448                    0.753991            0.0454693       0.990581                   -56.1742  96.5439            0.791028\n",
              "5        1                           0                  0.0189892  1                  0.00730847       0.0108765  0.384875                    0.385406            0.00941864      1                          -98.1011  0                  0\n",
              "\n",
              "ModelMetricsBinomial: drf\n",
              "** Reported on validation data. **\n",
              "\n",
              "MSE: 0.036937276832765605\n",
              "RMSE: 0.19219073035077838\n",
              "LogLoss: 0.14079214212429528\n",
              "Mean Per-Class Error: 0.04713423229341206\n",
              "AUC: 0.9915375408920449\n",
              "AUCPR: 0.9873978367714009\n",
              "Gini: 0.9830750817840899\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4565217391304348\n",
              "       0     1    Error    Rate\n",
              "-----  ----  ---  -------  -------------\n",
              "0      1187  58   0.0466   (58.0/1245.0)\n",
              "1      36    719  0.0477   (36.0/755.0)\n",
              "Total  1223  777  0.047    (94.0/2000.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.456522     0.938642  27\n",
              "max f2                       0.304348     0.956846  34\n",
              "max f0point5                 0.652174     0.952449  17\n",
              "max accuracy                 0.492754     0.953     25\n",
              "max precision                1            1         0\n",
              "max recall                   0            1         48\n",
              "max specificity              1            1         0\n",
              "max absolute_mcc             0.456522     0.900811  27\n",
              "max min_per_class_accuracy   0.456522     0.952318  27\n",
              "max mean_per_class_accuracy  0.434783     0.953084  28\n",
              "max tns                      1            1245      0\n",
              "max fns                      1            445       0\n",
              "max fps                      0            1245      48\n",
              "max tps                      0            755       48\n",
              "max tnr                      1            1         0\n",
              "max fnr                      1            0.589404  0\n",
              "max fpr                      0            1         48\n",
              "max tpr                      0            1         48\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 37.75 %, avg score: 37.82 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.155                       1                  2.64901     2.64901            1                1          1                           1                   0.410596        0.410596                   164.901   164.901            0.410596\n",
              "2        0.2005                      0.978261           2.64901     2.64901            1                0.978261   1                           0.995067            0.12053         0.531126                   164.901   164.901            0.531126\n",
              "3        0.3025                      0.782609           2.55811     2.61836            0.965686         0.890239   0.98843                     0.95972             0.260927        0.792053                   155.811   161.836            0.78643\n",
              "4        0.401                       0.413043           1.73463     2.40128            0.654822         0.59229    0.906484                    0.869466            0.170861        0.962914                   73.4629   140.128            0.902673\n",
              "5        0.5015                      0.108696           0.342658    1.98874            0.129353         0.241834   0.750748                    0.743689            0.0344371       0.997351                   -65.7342  98.8736            0.796548\n",
              "6        0.6315                      0.0217391          0.0101885   1.58143            0.00384615       0.0399666  0.596991                    0.598822            0.0013245       0.998675                   -98.9812  58.1434            0.58984\n",
              "7        1                           0                  0.00359431  1                  0.00135685       0          0.3775                      0.378156            0.0013245       1                          -99.6406  0                  0\n",
              "\n",
              "ModelMetricsBinomial: drf\n",
              "** Reported on cross-validation data. **\n",
              "\n",
              "MSE: 0.04109426250888458\n",
              "RMSE: 0.20271719835496094\n",
              "LogLoss: 0.14109268080346257\n",
              "Mean Per-Class Error: 0.05639704934588783\n",
              "AUC: 0.9891767351896238\n",
              "AUCPR: 0.984216068014286\n",
              "Gini: 0.9783534703792476\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.48\n",
              "       0     1     Error    Rate\n",
              "-----  ----  ----  -------  --------------\n",
              "0      4676  245   0.0498   (245.0/4921.0)\n",
              "1      194   2885  0.063    (194.0/3079.0)\n",
              "Total  4870  3130  0.0549   (439.0/8000.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.48         0.929296  54\n",
              "max f2                       0.32         0.949712  76\n",
              "max f0point5                 0.68         0.947539  29\n",
              "max accuracy                 0.52         0.945125  51\n",
              "max precision                1            1         0\n",
              "max recall                   0            1         135\n",
              "max specificity              1            1         0\n",
              "max absolute_mcc             0.48         0.884544  54\n",
              "max min_per_class_accuracy   0.44         0.940459  59\n",
              "max mean_per_class_accuracy  0.48         0.943603  54\n",
              "max tns                      1            4921      0\n",
              "max fns                      1            1720      0\n",
              "max fps                      0            4921      135\n",
              "max tps                      0            3079      135\n",
              "max tnr                      1            1         0\n",
              "max fnr                      1            0.558623  0\n",
              "max fpr                      0            1         135\n",
              "max tpr                      0            1         135\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 38.49 %, avg score: 38.55 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift         cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  -----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.169875                    1                  2.59825      2.59825            1                1            1                           1                   0.441377        0.441377                   159.825   159.825            0.441377\n",
              "2        0.20075                     0.98               2.58773      2.59663            0.995951         0.98         0.999377                    0.996924            0.0798961       0.521273                   158.773   159.663            0.52107\n",
              "3        0.3025                      0.8                2.52483      2.57248            0.971744         0.89986      0.990083                    0.964275            0.256902        0.778175                   152.483   157.248            0.773298\n",
              "4        0.4005                      0.44               1.70676      2.36064            0.656888         0.621349     0.908552                    0.880363            0.167262        0.945437                   70.6756   136.064            0.885896\n",
              "5        0.50625                     0.12               0.45454      1.96248            0.174941         0.253057     0.755309                    0.749326            0.0480676       0.993504                   -54.546   96.2478            0.792123\n",
              "6        0.647375                    0.02               0.043726     1.5442             0.0168291        0.0437432    0.594323                    0.595512            0.00617083      0.999675                   -95.6274  54.4198            0.572729\n",
              "7        1                           0                  0.000921037  1                  0.000354484      1.41147e-06  0.384875                    0.38552             0.000324781     1                          -99.9079  0                  0\n",
              "\n",
              "Cross-Validation Metrics Summary: \n",
              "                         mean       sd          cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid    cv_6_valid    cv_7_valid    cv_8_valid    cv_9_valid    cv_10_valid\n",
              "-----------------------  ---------  ----------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  -------------\n",
              "accuracy                 0.948625   0.00961859  0.95125       0.96875       0.955         0.94375       0.94375       0.94125       0.95875       0.94125       0.93875       0.94375\n",
              "auc                      0.989321   0.0026153   0.98965       0.994138      0.992543      0.987122      0.987971      0.987636      0.991501      0.989148      0.9872        0.986305\n",
              "err                      0.051375   0.00961859  0.04875       0.03125       0.045         0.05625       0.05625       0.05875       0.04125       0.05875       0.06125       0.05625\n",
              "err_count                41.1       7.69488     39            25            36            45            45            47            33            47            49            45\n",
              "f0point5                 0.928636   0.0171784   0.933852      0.957588      0.933713      0.904153      0.920285      0.909362      0.952694      0.916619      0.928526      0.929569\n",
              "f1                       0.934123   0.0109179   0.936585      0.958541      0.935714      0.92635       0.926591      0.928463      0.946166      0.931785      0.922345      0.928685\n",
              "f2                       0.939882   0.0123253   0.939335      0.959495      0.937724      0.949664      0.932983      0.948383      0.939728      0.947462      0.916247      0.927802\n",
              "lift_top_group           2.60421    0.132402    2.61438       2.65781       2.86738       2.73038       2.64026       2.52366       2.58065       2.38806       2.50784       2.53165\n",
              "logloss                  0.141121   0.0190486   0.13218       0.112811      0.131677      0.145857      0.142523      0.143419      0.128312      0.141626      0.146125      0.186684\n",
              "max_per_class_error      0.0659869  0.0123332   0.0588235     0.0398671     0.0609319     0.0690335     0.0627063     0.0724638     0.0645161     0.0709677     0.0877743     0.0727848\n",
              "mcc                      0.892432   0.0188935   0.897021      0.933469      0.901113      0.882905      0.881158      0.880277      0.912895      0.881295      0.871934      0.882248\n",
              "mean_per_class_accuracy  0.947668   0.00891056  0.949333      0.96704       0.9513        0.948418      0.94249       0.944841      0.954477      0.943621      0.934283      0.94088\n",
              "mean_per_class_error     0.0523317  0.00891056  0.0506668     0.0329596     0.0487001     0.0515816     0.0575101     0.0551593     0.0455234     0.0563794     0.0657167     0.0591197\n",
              "mse                      0.0410048  0.00441369  0.0389478     0.0313437     0.0385018     0.0451063     0.0434138     0.0434346     0.0373019     0.0427476     0.04465       0.0446002\n",
              "pr_auc                   0.98442    0.00342295  0.984525      0.990966      0.986631      0.979124      0.981952      0.982806      0.987586      0.985864      0.98284       0.981901\n",
              "precision                0.925123   0.0227588   0.932039      0.956954      0.932384      0.889937      0.916129      0.897059      0.957096      0.90678       0.932692      0.930159\n",
              "r2                       0.826597   0.0179854   0.835102      0.866444      0.830481      0.805669      0.815495      0.818445      0.842836      0.824372      0.813763      0.813369\n",
              "recall                   0.943882   0.0173548   0.941176      0.960133      0.939068      0.96587       0.937294      0.962145      0.935484      0.958209      0.912226      0.927215\n",
              "rmse                     0.202215   0.0112496   0.197352      0.177042      0.196219      0.212382      0.20836       0.20841       0.193137      0.206755      0.211305      0.211188\n",
              "specificity              0.951455   0.017369    0.95749       0.973948      0.963532      0.930967      0.947686      0.927536      0.973469      0.929032      0.956341      0.954545\n",
              "\n",
              "Scoring History: \n",
              "    timestamp            duration    number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
              "--  -------------------  ----------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ----------------  -------------------  -----------------  ---------------------------------\n",
              "    2023-06-22 20:43:55  23.403 sec  0                  nan              nan                 nan             nan                nan              nan                              nan                nan                   nan               nan                  nan                nan\n",
              "    2023-06-22 20:43:55  23.600 sec  5                  0.276754         1.99677             0.930839        0.892501           2.40932          0.0920443                        0.219089           0.36694               0.978939          0.967803             2.62383            0.063\n",
              "    2023-06-22 20:43:55  23.851 sec  10                 0.244527         0.966394            0.960549        0.936435           2.49968          0.0761556                        0.205803           0.166559              0.987595          0.980153             2.64312            0.0595\n",
              "    2023-06-22 20:43:55  24.079 sec  15                 0.226197         0.502812            0.975243        0.959903           2.54954          0.0665666                        0.199182           0.146057              0.989664          0.984612             2.64901            0.056\n",
              "    2023-06-22 20:43:56  24.262 sec  20                 0.218721         0.361284            0.980319        0.968143           2.56604          0.0632579                        0.19652            0.143699              0.990551          0.986053             2.64901            0.0505\n",
              "    2023-06-22 20:43:56  24.451 sec  25                 0.21393          0.274676            0.982997        0.975362           2.58606          0.060625                         0.195892           0.143851              0.990808          0.986377             2.64901            0.0495\n",
              "    2023-06-22 20:43:56  24.647 sec  30                 0.212194         0.24252             0.984234        0.976963           2.58844          0.059                            0.19497            0.143397              0.990969          0.986596             2.64901            0.0475\n",
              "    2023-06-22 20:43:56  24.846 sec  35                 0.209698         0.22074             0.985319        0.978713           2.591            0.057                            0.194784           0.143048              0.991071          0.986761             2.64901            0.0485\n",
              "    2023-06-22 20:43:56  25.088 sec  40                 0.208903         0.216606            0.985538        0.979325           2.59233          0.056125                         0.193185           0.141788              0.991383          0.9872               2.64901            0.046\n",
              "    2023-06-22 20:43:57  25.289 sec  45                 0.20799          0.204199            0.98606         0.980122           2.59371          0.056625                         0.192606           0.14129               0.991463          0.987275             2.64901            0.0455\n",
              "    2023-06-22 20:43:57  25.356 sec  46                 0.20801          0.204282            0.986038        0.980086           2.59368          0.056625                         0.192191           0.140792              0.991538          0.987398             2.64901            0.047\n",
              "\n",
              "Variable Importances: \n",
              "variable                 relative_importance    scaled_importance     percentage\n",
              "-----------------------  ---------------------  --------------------  ---------------------\n",
              "concave points_mean      12892.1552734375       1.0                   0.18433499477221202\n",
              "perimeter_worst          12409.1396484375       0.9625341446208621    0.17742872651676217\n",
              "concave points_worst     6141.6552734375        0.4763870076938594    0.0878147965727973\n",
              "radius_worst             5617.19189453125       0.4357061930602632    0.08031589881998402\n",
              "radius_se                4640.35546875          0.35993636210004465   0.06634886742604074\n",
              "perimeter_mean           4096.8095703125        0.3177753822709077    0.058577123429645446\n",
              "area_worst               3825.361083984375      0.29672005982320127   0.05469589067632025\n",
              "area_se                  3570.8486328125        0.27697840718454103   0.05105681324037799\n",
              "concavity_mean           3542.318115234375      0.2747653933809524    0.050648877352462644\n",
              "area_mean                1562.5438232421875     0.12120113278976655   0.02234161017918779\n",
              "---                      ---                    ---                   ---\n",
              "symmetry_worst           398.6156921386719      0.03091924381022344   0.005699498646118286\n",
              "smoothness_mean          397.4166564941406      0.03082623875256627   0.005682354559301263\n",
              "texture_se               372.990234375          0.028931565472492773  0.005333099970123865\n",
              "symmetry_mean            357.383544921875       0.027721008422712242  0.0051099519426811065\n",
              "smoothness_se            350.05841064453125     0.02715282303229609   0.005005215491709098\n",
              "fractal_dimension_worst  340.31817626953125     0.02639730666064112   0.004865947385289758\n",
              "symmetry_se              333.9683532714844      0.025904772800834933  0.0047751561588172476\n",
              "concavity_se             327.7789611816406      0.025424683013008986  0.004686658810288159\n",
              "concave points_se        309.9120178222656      0.02403880586675809   0.004431193153779072\n",
              "fractal_dimension_se     298.4029541015625      0.023146087506127115  0.0042666339194391036\n",
              "[30 rows x 4 columns]\n",
              "\n",
              "\n",
              "[tips]\n",
              "Use `model.explain()` to inspect the model.\n",
              "--\n",
              "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
            ],
            "text/html": [
              "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
              "=============\n",
              "H2ORandomForestEstimator : Distributed Random Forest\n",
              "Model Key: DRF_1_AutoML_1_20230622_204129\n",
              "</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-15.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-15 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-15 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-15 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-15 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-15 .h2o-table th,\n",
              "#h2o-table-15 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-15 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-15\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Model Summary: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>number_of_trees</th>\n",
              "<th>number_of_internal_trees</th>\n",
              "<th>model_size_in_bytes</th>\n",
              "<th>min_depth</th>\n",
              "<th>max_depth</th>\n",
              "<th>mean_depth</th>\n",
              "<th>min_leaves</th>\n",
              "<th>max_leaves</th>\n",
              "<th>mean_leaves</th></tr></thead>\n",
              "    <tbody><tr><td></td>\n",
              "<td>46.0</td>\n",
              "<td>46.0</td>\n",
              "<td>199283.0</td>\n",
              "<td>15.0</td>\n",
              "<td>20.0</td>\n",
              "<td>18.217392</td>\n",
              "<td>311.0</td>\n",
              "<td>369.0</td>\n",
              "<td>340.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: drf\n",
              "** Reported on train data. **\n",
              "\n",
              "MSE: 0.04326800279168445\n",
              "RMSE: 0.2080096218728462\n",
              "LogLoss: 0.20428151575245082\n",
              "Mean Per-Class Error: 0.057211674235314855\n",
              "AUC: 0.9860384526971423\n",
              "AUCPR: 0.9800859943345126\n",
              "Gini: 0.9720769053942846</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-16.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-16 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-16 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-16 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-16 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-16 .h2o-table th,\n",
              "#h2o-table-16 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-16 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-16\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4666666666666667</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>0</th>\n",
              "<th>1</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>0</td>\n",
              "<td>4652.0</td>\n",
              "<td>269.0</td>\n",
              "<td>0.0547</td>\n",
              "<td> (269.0/4921.0)</td></tr>\n",
              "<tr><td>1</td>\n",
              "<td>184.0</td>\n",
              "<td>2895.0</td>\n",
              "<td>0.0598</td>\n",
              "<td> (184.0/3079.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>4836.0</td>\n",
              "<td>3164.0</td>\n",
              "<td>0.0566</td>\n",
              "<td> (453.0/8000.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-17.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-17 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-17 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-17 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-17 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-17 .h2o-table th,\n",
              "#h2o-table-17 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-17 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-17\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.4666667</td>\n",
              "<td>0.9274387</td>\n",
              "<td>105.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.2941176</td>\n",
              "<td>0.9452375</td>\n",
              "<td>140.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.6470588</td>\n",
              "<td>0.9420699</td>\n",
              "<td>70.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.5</td>\n",
              "<td>0.94375</td>\n",
              "<td>100.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>0.9565217</td>\n",
              "<td>0.9982619</td>\n",
              "<td>4.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>197.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9993904</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.5</td>\n",
              "<td>0.8815009</td>\n",
              "<td>100.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.4545455</td>\n",
              "<td>0.9428386</td>\n",
              "<td>108.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.4500000</td>\n",
              "<td>0.9432129</td>\n",
              "<td>109.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>1.0</td>\n",
              "<td>4918.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>1.0</td>\n",
              "<td>1374.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0</td>\n",
              "<td>4921.0</td>\n",
              "<td>197.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0</td>\n",
              "<td>3079.0</td>\n",
              "<td>197.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9993904</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>1.0</td>\n",
              "<td>0.4462488</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>197.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>197.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-18.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-18 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-18 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-18 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-18 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-18 .h2o-table th,\n",
              "#h2o-table-18 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-18 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-18\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 38.49 %, avg score: 38.54 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.2135</td>\n",
              "<td>1.0</td>\n",
              "<td>2.5936825</td>\n",
              "<td>2.5936825</td>\n",
              "<td>0.9982436</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9982436</td>\n",
              "<td>1.0</td>\n",
              "<td>0.5537512</td>\n",
              "<td>0.5537512</td>\n",
              "<td>159.3682520</td>\n",
              "<td>159.3682520</td>\n",
              "<td>0.5531416</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.30125</td>\n",
              "<td>0.7894737</td>\n",
              "<td>2.4761064</td>\n",
              "<td>2.5594342</td>\n",
              "<td>0.9529915</td>\n",
              "<td>0.8931708</td>\n",
              "<td>0.9850622</td>\n",
              "<td>0.9688821</td>\n",
              "<td>0.2172783</td>\n",
              "<td>0.7710296</td>\n",
              "<td>147.6106406</td>\n",
              "<td>155.9434208</td>\n",
              "<td>0.7637140</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.40025</td>\n",
              "<td>0.4444444</td>\n",
              "<td>1.7584090</td>\n",
              "<td>2.3613043</td>\n",
              "<td>0.6767677</td>\n",
              "<td>0.6221101</td>\n",
              "<td>0.9088070</td>\n",
              "<td>0.8831097</td>\n",
              "<td>0.1740825</td>\n",
              "<td>0.9451120</td>\n",
              "<td>75.8409033</td>\n",
              "<td>136.1304308</td>\n",
              "<td>0.8857745</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.504</td>\n",
              "<td>0.1176471</td>\n",
              "<td>0.4382584</td>\n",
              "<td>1.9654392</td>\n",
              "<td>0.1686747</td>\n",
              "<td>0.2558749</td>\n",
              "<td>0.7564484</td>\n",
              "<td>0.7539914</td>\n",
              "<td>0.0454693</td>\n",
              "<td>0.9905814</td>\n",
              "<td>-56.1741608</td>\n",
              "<td>96.5439202</td>\n",
              "<td>0.7910284</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0189892</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0073085</td>\n",
              "<td>0.0108765</td>\n",
              "<td>0.384875</td>\n",
              "<td>0.3854064</td>\n",
              "<td>0.0094186</td>\n",
              "<td>1.0</td>\n",
              "<td>-98.1010802</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: drf\n",
              "** Reported on validation data. **\n",
              "\n",
              "MSE: 0.036937276832765605\n",
              "RMSE: 0.19219073035077838\n",
              "LogLoss: 0.14079214212429528\n",
              "Mean Per-Class Error: 0.04713423229341206\n",
              "AUC: 0.9915375408920449\n",
              "AUCPR: 0.9873978367714009\n",
              "Gini: 0.9830750817840899</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-19.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-19 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-19 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-19 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-19 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-19 .h2o-table th,\n",
              "#h2o-table-19 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-19 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-19\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4565217391304348</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>0</th>\n",
              "<th>1</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>0</td>\n",
              "<td>1187.0</td>\n",
              "<td>58.0</td>\n",
              "<td>0.0466</td>\n",
              "<td> (58.0/1245.0)</td></tr>\n",
              "<tr><td>1</td>\n",
              "<td>36.0</td>\n",
              "<td>719.0</td>\n",
              "<td>0.0477</td>\n",
              "<td> (36.0/755.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>1223.0</td>\n",
              "<td>777.0</td>\n",
              "<td>0.047</td>\n",
              "<td> (94.0/2000.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-20.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-20 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-20 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-20 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-20 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-20 .h2o-table th,\n",
              "#h2o-table-20 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-20 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-20\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.4565217</td>\n",
              "<td>0.9386423</td>\n",
              "<td>27.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.3043478</td>\n",
              "<td>0.9568456</td>\n",
              "<td>34.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.6521739</td>\n",
              "<td>0.9524492</td>\n",
              "<td>17.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.4927536</td>\n",
              "<td>0.953</td>\n",
              "<td>25.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>48.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.4565217</td>\n",
              "<td>0.9008115</td>\n",
              "<td>27.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.4565217</td>\n",
              "<td>0.9523179</td>\n",
              "<td>27.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.4347826</td>\n",
              "<td>0.9530839</td>\n",
              "<td>28.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>1.0</td>\n",
              "<td>1245.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>1.0</td>\n",
              "<td>445.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0</td>\n",
              "<td>1245.0</td>\n",
              "<td>48.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0</td>\n",
              "<td>755.0</td>\n",
              "<td>48.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>1.0</td>\n",
              "<td>0.5894040</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>48.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>48.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-21.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-21 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-21 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-21 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-21 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-21 .h2o-table th,\n",
              "#h2o-table-21 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-21 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-21\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 37.75 %, avg score: 37.82 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.155</td>\n",
              "<td>1.0</td>\n",
              "<td>2.6490066</td>\n",
              "<td>2.6490066</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.4105960</td>\n",
              "<td>0.4105960</td>\n",
              "<td>164.9006623</td>\n",
              "<td>164.9006623</td>\n",
              "<td>0.4105960</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.2005</td>\n",
              "<td>0.9782609</td>\n",
              "<td>2.6490066</td>\n",
              "<td>2.6490066</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9782609</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9950667</td>\n",
              "<td>0.1205298</td>\n",
              "<td>0.5311258</td>\n",
              "<td>164.9006623</td>\n",
              "<td>164.9006623</td>\n",
              "<td>0.5311258</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.3025</td>\n",
              "<td>0.7826087</td>\n",
              "<td>2.5581093</td>\n",
              "<td>2.6183570</td>\n",
              "<td>0.9656863</td>\n",
              "<td>0.8902387</td>\n",
              "<td>0.9884298</td>\n",
              "<td>0.9597197</td>\n",
              "<td>0.2609272</td>\n",
              "<td>0.7920530</td>\n",
              "<td>155.8109336</td>\n",
              "<td>161.8356959</td>\n",
              "<td>0.7864305</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.401</td>\n",
              "<td>0.4130435</td>\n",
              "<td>1.7346287</td>\n",
              "<td>2.4012816</td>\n",
              "<td>0.6548223</td>\n",
              "<td>0.5922901</td>\n",
              "<td>0.9064838</td>\n",
              "<td>0.8694658</td>\n",
              "<td>0.1708609</td>\n",
              "<td>0.9629139</td>\n",
              "<td>73.4628702</td>\n",
              "<td>140.1281564</td>\n",
              "<td>0.9026729</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.5015</td>\n",
              "<td>0.1086957</td>\n",
              "<td>0.3426576</td>\n",
              "<td>1.9887358</td>\n",
              "<td>0.1293532</td>\n",
              "<td>0.2418343</td>\n",
              "<td>0.7507478</td>\n",
              "<td>0.7436892</td>\n",
              "<td>0.0344371</td>\n",
              "<td>0.9973510</td>\n",
              "<td>-65.7342427</td>\n",
              "<td>98.8735779</td>\n",
              "<td>0.7965478</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.6315</td>\n",
              "<td>0.0217391</td>\n",
              "<td>0.0101885</td>\n",
              "<td>1.5814339</td>\n",
              "<td>0.0038462</td>\n",
              "<td>0.0399666</td>\n",
              "<td>0.5969913</td>\n",
              "<td>0.5988215</td>\n",
              "<td>0.0013245</td>\n",
              "<td>0.9986755</td>\n",
              "<td>-98.9811513</td>\n",
              "<td>58.1433882</td>\n",
              "<td>0.5898402</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0035943</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0013569</td>\n",
              "<td>0.0</td>\n",
              "<td>0.3775</td>\n",
              "<td>0.3781558</td>\n",
              "<td>0.0013245</td>\n",
              "<td>1.0</td>\n",
              "<td>-99.6405690</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: drf\n",
              "** Reported on cross-validation data. **\n",
              "\n",
              "MSE: 0.04109426250888458\n",
              "RMSE: 0.20271719835496094\n",
              "LogLoss: 0.14109268080346257\n",
              "Mean Per-Class Error: 0.05639704934588783\n",
              "AUC: 0.9891767351896238\n",
              "AUCPR: 0.984216068014286\n",
              "Gini: 0.9783534703792476</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-22.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-22 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-22 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-22 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-22 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-22 .h2o-table th,\n",
              "#h2o-table-22 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-22 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-22\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.48</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>0</th>\n",
              "<th>1</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>0</td>\n",
              "<td>4676.0</td>\n",
              "<td>245.0</td>\n",
              "<td>0.0498</td>\n",
              "<td> (245.0/4921.0)</td></tr>\n",
              "<tr><td>1</td>\n",
              "<td>194.0</td>\n",
              "<td>2885.0</td>\n",
              "<td>0.063</td>\n",
              "<td> (194.0/3079.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>4870.0</td>\n",
              "<td>3130.0</td>\n",
              "<td>0.0549</td>\n",
              "<td> (439.0/8000.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-23.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-23 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-23 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-23 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-23 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-23 .h2o-table th,\n",
              "#h2o-table-23 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-23 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-23\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.48</td>\n",
              "<td>0.9292962</td>\n",
              "<td>54.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.3200000</td>\n",
              "<td>0.9497118</td>\n",
              "<td>76.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.6800000</td>\n",
              "<td>0.9475386</td>\n",
              "<td>29.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.52</td>\n",
              "<td>0.945125</td>\n",
              "<td>51.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>135.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.48</td>\n",
              "<td>0.8845437</td>\n",
              "<td>54.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.4400000</td>\n",
              "<td>0.9404593</td>\n",
              "<td>59.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.48</td>\n",
              "<td>0.9436030</td>\n",
              "<td>54.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>1.0</td>\n",
              "<td>4921.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>1.0</td>\n",
              "<td>1720.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0</td>\n",
              "<td>4921.0</td>\n",
              "<td>135.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0</td>\n",
              "<td>3079.0</td>\n",
              "<td>135.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>1.0</td>\n",
              "<td>0.5586229</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>135.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>135.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-24.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-24 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-24 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-24 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-24 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-24 .h2o-table th,\n",
              "#h2o-table-24 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-24 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-24\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 38.49 %, avg score: 38.55 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.169875</td>\n",
              "<td>1.0</td>\n",
              "<td>2.5982462</td>\n",
              "<td>2.5982462</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.4413771</td>\n",
              "<td>0.4413771</td>\n",
              "<td>159.8246184</td>\n",
              "<td>159.8246184</td>\n",
              "<td>0.4413771</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.20075</td>\n",
              "<td>0.98</td>\n",
              "<td>2.5877270</td>\n",
              "<td>2.5966283</td>\n",
              "<td>0.9959514</td>\n",
              "<td>0.9800000</td>\n",
              "<td>0.9993773</td>\n",
              "<td>0.9969240</td>\n",
              "<td>0.0798961</td>\n",
              "<td>0.5212731</td>\n",
              "<td>158.7726969</td>\n",
              "<td>159.6628347</td>\n",
              "<td>0.5210699</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.3025</td>\n",
              "<td>0.8</td>\n",
              "<td>2.5248314</td>\n",
              "<td>2.5724785</td>\n",
              "<td>0.9717445</td>\n",
              "<td>0.8998605</td>\n",
              "<td>0.9900826</td>\n",
              "<td>0.9642754</td>\n",
              "<td>0.2569016</td>\n",
              "<td>0.7781747</td>\n",
              "<td>152.4831365</td>\n",
              "<td>157.2478453</td>\n",
              "<td>0.7732977</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.4005</td>\n",
              "<td>0.44</td>\n",
              "<td>1.7067561</td>\n",
              "<td>2.3606413</td>\n",
              "<td>0.6568878</td>\n",
              "<td>0.6213488</td>\n",
              "<td>0.9085518</td>\n",
              "<td>0.8803633</td>\n",
              "<td>0.1672621</td>\n",
              "<td>0.9454368</td>\n",
              "<td>70.6756103</td>\n",
              "<td>136.0641274</td>\n",
              "<td>0.8858961</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.50625</td>\n",
              "<td>0.12</td>\n",
              "<td>0.4545395</td>\n",
              "<td>1.9624778</td>\n",
              "<td>0.1749409</td>\n",
              "<td>0.2530573</td>\n",
              "<td>0.7553086</td>\n",
              "<td>0.7493260</td>\n",
              "<td>0.0480676</td>\n",
              "<td>0.9935044</td>\n",
              "<td>-54.5460478</td>\n",
              "<td>96.2477797</td>\n",
              "<td>0.7921226</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.647375</td>\n",
              "<td>0.02</td>\n",
              "<td>0.0437260</td>\n",
              "<td>1.5441981</td>\n",
              "<td>0.0168291</td>\n",
              "<td>0.0437432</td>\n",
              "<td>0.5943232</td>\n",
              "<td>0.5955120</td>\n",
              "<td>0.0061708</td>\n",
              "<td>0.9996752</td>\n",
              "<td>-95.6273979</td>\n",
              "<td>54.4198060</td>\n",
              "<td>0.5727295</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0009210</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0003545</td>\n",
              "<td>0.0000014</td>\n",
              "<td>0.384875</td>\n",
              "<td>0.3855201</td>\n",
              "<td>0.0003248</td>\n",
              "<td>1.0</td>\n",
              "<td>-99.9078963</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-25.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-25 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-25 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-25 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-25 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-25 .h2o-table th,\n",
              "#h2o-table-25 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-25 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-25\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Cross-Validation Metrics Summary: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>mean</th>\n",
              "<th>sd</th>\n",
              "<th>cv_1_valid</th>\n",
              "<th>cv_2_valid</th>\n",
              "<th>cv_3_valid</th>\n",
              "<th>cv_4_valid</th>\n",
              "<th>cv_5_valid</th>\n",
              "<th>cv_6_valid</th>\n",
              "<th>cv_7_valid</th>\n",
              "<th>cv_8_valid</th>\n",
              "<th>cv_9_valid</th>\n",
              "<th>cv_10_valid</th></tr></thead>\n",
              "    <tbody><tr><td>accuracy</td>\n",
              "<td>0.948625</td>\n",
              "<td>0.0096186</td>\n",
              "<td>0.95125</td>\n",
              "<td>0.96875</td>\n",
              "<td>0.955</td>\n",
              "<td>0.94375</td>\n",
              "<td>0.94375</td>\n",
              "<td>0.94125</td>\n",
              "<td>0.95875</td>\n",
              "<td>0.94125</td>\n",
              "<td>0.93875</td>\n",
              "<td>0.94375</td></tr>\n",
              "<tr><td>auc</td>\n",
              "<td>0.9893215</td>\n",
              "<td>0.0026153</td>\n",
              "<td>0.9896503</td>\n",
              "<td>0.9941378</td>\n",
              "<td>0.9925426</td>\n",
              "<td>0.9871223</td>\n",
              "<td>0.9879707</td>\n",
              "<td>0.9876364</td>\n",
              "<td>0.991501</td>\n",
              "<td>0.9891478</td>\n",
              "<td>0.9872001</td>\n",
              "<td>0.9863054</td></tr>\n",
              "<tr><td>err</td>\n",
              "<td>0.051375</td>\n",
              "<td>0.0096186</td>\n",
              "<td>0.04875</td>\n",
              "<td>0.03125</td>\n",
              "<td>0.045</td>\n",
              "<td>0.05625</td>\n",
              "<td>0.05625</td>\n",
              "<td>0.05875</td>\n",
              "<td>0.04125</td>\n",
              "<td>0.05875</td>\n",
              "<td>0.06125</td>\n",
              "<td>0.05625</td></tr>\n",
              "<tr><td>err_count</td>\n",
              "<td>41.1</td>\n",
              "<td>7.6948757</td>\n",
              "<td>39.0</td>\n",
              "<td>25.0</td>\n",
              "<td>36.0</td>\n",
              "<td>45.0</td>\n",
              "<td>45.0</td>\n",
              "<td>47.0</td>\n",
              "<td>33.0</td>\n",
              "<td>47.0</td>\n",
              "<td>49.0</td>\n",
              "<td>45.0</td></tr>\n",
              "<tr><td>f0point5</td>\n",
              "<td>0.9286361</td>\n",
              "<td>0.0171784</td>\n",
              "<td>0.9338521</td>\n",
              "<td>0.9575878</td>\n",
              "<td>0.9337135</td>\n",
              "<td>0.9041533</td>\n",
              "<td>0.9202852</td>\n",
              "<td>0.9093620</td>\n",
              "<td>0.9526938</td>\n",
              "<td>0.9166191</td>\n",
              "<td>0.9285259</td>\n",
              "<td>0.9295685</td></tr>\n",
              "<tr><td>f1</td>\n",
              "<td>0.9341226</td>\n",
              "<td>0.0109179</td>\n",
              "<td>0.9365854</td>\n",
              "<td>0.9585406</td>\n",
              "<td>0.9357143</td>\n",
              "<td>0.9263502</td>\n",
              "<td>0.9265906</td>\n",
              "<td>0.9284627</td>\n",
              "<td>0.9461664</td>\n",
              "<td>0.9317852</td>\n",
              "<td>0.9223455</td>\n",
              "<td>0.9286847</td></tr>\n",
              "<tr><td>f2</td>\n",
              "<td>0.9398823</td>\n",
              "<td>0.0123253</td>\n",
              "<td>0.9393346</td>\n",
              "<td>0.9594954</td>\n",
              "<td>0.9377237</td>\n",
              "<td>0.9496644</td>\n",
              "<td>0.9329829</td>\n",
              "<td>0.9483831</td>\n",
              "<td>0.9397278</td>\n",
              "<td>0.9474616</td>\n",
              "<td>0.9162468</td>\n",
              "<td>0.9278024</td></tr>\n",
              "<tr><td>lift_top_group</td>\n",
              "<td>2.6042056</td>\n",
              "<td>0.1324018</td>\n",
              "<td>2.6143792</td>\n",
              "<td>2.6578074</td>\n",
              "<td>2.8673835</td>\n",
              "<td>2.7303755</td>\n",
              "<td>2.640264</td>\n",
              "<td>2.5236592</td>\n",
              "<td>2.580645</td>\n",
              "<td>2.3880596</td>\n",
              "<td>2.507837</td>\n",
              "<td>2.5316455</td></tr>\n",
              "<tr><td>logloss</td>\n",
              "<td>0.1411213</td>\n",
              "<td>0.0190486</td>\n",
              "<td>0.1321801</td>\n",
              "<td>0.1128110</td>\n",
              "<td>0.1316768</td>\n",
              "<td>0.1458569</td>\n",
              "<td>0.1425228</td>\n",
              "<td>0.1434189</td>\n",
              "<td>0.1283116</td>\n",
              "<td>0.1416261</td>\n",
              "<td>0.1461246</td>\n",
              "<td>0.1866843</td></tr>\n",
              "<tr><td>max_per_class_error</td>\n",
              "<td>0.0659869</td>\n",
              "<td>0.0123332</td>\n",
              "<td>0.0588235</td>\n",
              "<td>0.0398671</td>\n",
              "<td>0.0609319</td>\n",
              "<td>0.0690335</td>\n",
              "<td>0.0627063</td>\n",
              "<td>0.0724638</td>\n",
              "<td>0.0645161</td>\n",
              "<td>0.0709677</td>\n",
              "<td>0.0877743</td>\n",
              "<td>0.0727848</td></tr>\n",
              "<tr><td>mcc</td>\n",
              "<td>0.8924317</td>\n",
              "<td>0.0188935</td>\n",
              "<td>0.8970212</td>\n",
              "<td>0.9334688</td>\n",
              "<td>0.9011132</td>\n",
              "<td>0.8829053</td>\n",
              "<td>0.8811584</td>\n",
              "<td>0.8802769</td>\n",
              "<td>0.9128952</td>\n",
              "<td>0.8812954</td>\n",
              "<td>0.8719344</td>\n",
              "<td>0.8822482</td></tr>\n",
              "<tr><td>mean_per_class_accuracy</td>\n",
              "<td>0.9476683</td>\n",
              "<td>0.0089106</td>\n",
              "<td>0.9493332</td>\n",
              "<td>0.9670404</td>\n",
              "<td>0.9512999</td>\n",
              "<td>0.9484184</td>\n",
              "<td>0.9424899</td>\n",
              "<td>0.9448407</td>\n",
              "<td>0.9544767</td>\n",
              "<td>0.9436206</td>\n",
              "<td>0.9342833</td>\n",
              "<td>0.9408803</td></tr>\n",
              "<tr><td>mean_per_class_error</td>\n",
              "<td>0.0523317</td>\n",
              "<td>0.0089106</td>\n",
              "<td>0.0506668</td>\n",
              "<td>0.0329596</td>\n",
              "<td>0.0487001</td>\n",
              "<td>0.0515816</td>\n",
              "<td>0.0575101</td>\n",
              "<td>0.0551593</td>\n",
              "<td>0.0455234</td>\n",
              "<td>0.0563794</td>\n",
              "<td>0.0657167</td>\n",
              "<td>0.0591197</td></tr>\n",
              "<tr><td>mse</td>\n",
              "<td>0.0410048</td>\n",
              "<td>0.0044137</td>\n",
              "<td>0.0389478</td>\n",
              "<td>0.0313437</td>\n",
              "<td>0.0385018</td>\n",
              "<td>0.0451063</td>\n",
              "<td>0.0434138</td>\n",
              "<td>0.0434346</td>\n",
              "<td>0.0373019</td>\n",
              "<td>0.0427476</td>\n",
              "<td>0.04465</td>\n",
              "<td>0.0446002</td></tr>\n",
              "<tr><td>pr_auc</td>\n",
              "<td>0.9844196</td>\n",
              "<td>0.0034229</td>\n",
              "<td>0.9845253</td>\n",
              "<td>0.9909664</td>\n",
              "<td>0.986631</td>\n",
              "<td>0.9791239</td>\n",
              "<td>0.9819524</td>\n",
              "<td>0.9828061</td>\n",
              "<td>0.9875858</td>\n",
              "<td>0.9858642</td>\n",
              "<td>0.9828396</td>\n",
              "<td>0.981901</td></tr>\n",
              "<tr><td>precision</td>\n",
              "<td>0.9251228</td>\n",
              "<td>0.0227588</td>\n",
              "<td>0.9320388</td>\n",
              "<td>0.9569536</td>\n",
              "<td>0.9323843</td>\n",
              "<td>0.8899371</td>\n",
              "<td>0.9161291</td>\n",
              "<td>0.8970588</td>\n",
              "<td>0.9570957</td>\n",
              "<td>0.9067797</td>\n",
              "<td>0.9326923</td>\n",
              "<td>0.9301587</td></tr>\n",
              "<tr><td>r2</td>\n",
              "<td>0.8265975</td>\n",
              "<td>0.0179854</td>\n",
              "<td>0.8351024</td>\n",
              "<td>0.866444</td>\n",
              "<td>0.8304807</td>\n",
              "<td>0.8056693</td>\n",
              "<td>0.8154945</td>\n",
              "<td>0.8184445</td>\n",
              "<td>0.8428361</td>\n",
              "<td>0.8243719</td>\n",
              "<td>0.8137631</td>\n",
              "<td>0.8133687</td></tr>\n",
              "<tr><td>recall</td>\n",
              "<td>0.9438821</td>\n",
              "<td>0.0173548</td>\n",
              "<td>0.9411765</td>\n",
              "<td>0.9601329</td>\n",
              "<td>0.9390681</td>\n",
              "<td>0.9658703</td>\n",
              "<td>0.9372937</td>\n",
              "<td>0.9621451</td>\n",
              "<td>0.9354839</td>\n",
              "<td>0.958209</td>\n",
              "<td>0.9122257</td>\n",
              "<td>0.9272152</td></tr>\n",
              "<tr><td>rmse</td>\n",
              "<td>0.2022149</td>\n",
              "<td>0.0112496</td>\n",
              "<td>0.1973519</td>\n",
              "<td>0.1770416</td>\n",
              "<td>0.1962188</td>\n",
              "<td>0.2123824</td>\n",
              "<td>0.2083599</td>\n",
              "<td>0.2084097</td>\n",
              "<td>0.1931369</td>\n",
              "<td>0.2067550</td>\n",
              "<td>0.2113055</td>\n",
              "<td>0.2111877</td></tr>\n",
              "<tr><td>specificity</td>\n",
              "<td>0.9514546</td>\n",
              "<td>0.0173690</td>\n",
              "<td>0.9574899</td>\n",
              "<td>0.9739479</td>\n",
              "<td>0.9635317</td>\n",
              "<td>0.9309665</td>\n",
              "<td>0.9476861</td>\n",
              "<td>0.9275362</td>\n",
              "<td>0.9734694</td>\n",
              "<td>0.9290323</td>\n",
              "<td>0.9563410</td>\n",
              "<td>0.9545454</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-26.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-26 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-26 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-26 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-26 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-26 .h2o-table th,\n",
              "#h2o-table-26 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-26 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-26\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Scoring History: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>timestamp</th>\n",
              "<th>duration</th>\n",
              "<th>number_of_trees</th>\n",
              "<th>training_rmse</th>\n",
              "<th>training_logloss</th>\n",
              "<th>training_auc</th>\n",
              "<th>training_pr_auc</th>\n",
              "<th>training_lift</th>\n",
              "<th>training_classification_error</th>\n",
              "<th>validation_rmse</th>\n",
              "<th>validation_logloss</th>\n",
              "<th>validation_auc</th>\n",
              "<th>validation_pr_auc</th>\n",
              "<th>validation_lift</th>\n",
              "<th>validation_classification_error</th></tr></thead>\n",
              "    <tbody><tr><td></td>\n",
              "<td>2023-06-22 20:43:55</td>\n",
              "<td>23.403 sec</td>\n",
              "<td>0.0</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-22 20:43:55</td>\n",
              "<td>23.600 sec</td>\n",
              "<td>5.0</td>\n",
              "<td>0.2767544</td>\n",
              "<td>1.9967730</td>\n",
              "<td>0.9308393</td>\n",
              "<td>0.8925009</td>\n",
              "<td>2.4093223</td>\n",
              "<td>0.0920443</td>\n",
              "<td>0.2190890</td>\n",
              "<td>0.3669400</td>\n",
              "<td>0.9789388</td>\n",
              "<td>0.9678027</td>\n",
              "<td>2.6238260</td>\n",
              "<td>0.063</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-22 20:43:55</td>\n",
              "<td>23.851 sec</td>\n",
              "<td>10.0</td>\n",
              "<td>0.2445273</td>\n",
              "<td>0.9663935</td>\n",
              "<td>0.9605493</td>\n",
              "<td>0.9364353</td>\n",
              "<td>2.4996767</td>\n",
              "<td>0.0761556</td>\n",
              "<td>0.2058033</td>\n",
              "<td>0.1665588</td>\n",
              "<td>0.9875954</td>\n",
              "<td>0.9801532</td>\n",
              "<td>2.6431199</td>\n",
              "<td>0.0595</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-22 20:43:55</td>\n",
              "<td>24.079 sec</td>\n",
              "<td>15.0</td>\n",
              "<td>0.2261966</td>\n",
              "<td>0.5028121</td>\n",
              "<td>0.9752431</td>\n",
              "<td>0.9599033</td>\n",
              "<td>2.5495443</td>\n",
              "<td>0.0665666</td>\n",
              "<td>0.1991817</td>\n",
              "<td>0.1460567</td>\n",
              "<td>0.9896636</td>\n",
              "<td>0.9846118</td>\n",
              "<td>2.6490066</td>\n",
              "<td>0.056</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-22 20:43:56</td>\n",
              "<td>24.262 sec</td>\n",
              "<td>20.0</td>\n",
              "<td>0.2187206</td>\n",
              "<td>0.3612843</td>\n",
              "<td>0.9803188</td>\n",
              "<td>0.9681426</td>\n",
              "<td>2.5660418</td>\n",
              "<td>0.0632579</td>\n",
              "<td>0.1965201</td>\n",
              "<td>0.1436989</td>\n",
              "<td>0.9905513</td>\n",
              "<td>0.9860533</td>\n",
              "<td>2.6490066</td>\n",
              "<td>0.0505</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-22 20:43:56</td>\n",
              "<td>24.451 sec</td>\n",
              "<td>25.0</td>\n",
              "<td>0.2139304</td>\n",
              "<td>0.2746755</td>\n",
              "<td>0.9829967</td>\n",
              "<td>0.9753618</td>\n",
              "<td>2.5860606</td>\n",
              "<td>0.060625</td>\n",
              "<td>0.1958920</td>\n",
              "<td>0.1438512</td>\n",
              "<td>0.9908077</td>\n",
              "<td>0.9863770</td>\n",
              "<td>2.6490066</td>\n",
              "<td>0.0495</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-22 20:43:56</td>\n",
              "<td>24.647 sec</td>\n",
              "<td>30.0</td>\n",
              "<td>0.2121942</td>\n",
              "<td>0.2425199</td>\n",
              "<td>0.9842336</td>\n",
              "<td>0.9769625</td>\n",
              "<td>2.5884415</td>\n",
              "<td>0.059</td>\n",
              "<td>0.1949704</td>\n",
              "<td>0.1433966</td>\n",
              "<td>0.9909694</td>\n",
              "<td>0.9865957</td>\n",
              "<td>2.6490066</td>\n",
              "<td>0.0475</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-22 20:43:56</td>\n",
              "<td>24.846 sec</td>\n",
              "<td>35.0</td>\n",
              "<td>0.2096984</td>\n",
              "<td>0.2207400</td>\n",
              "<td>0.9853191</td>\n",
              "<td>0.9787134</td>\n",
              "<td>2.5910047</td>\n",
              "<td>0.057</td>\n",
              "<td>0.1947836</td>\n",
              "<td>0.1430478</td>\n",
              "<td>0.9910710</td>\n",
              "<td>0.9867606</td>\n",
              "<td>2.6490066</td>\n",
              "<td>0.0485</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-22 20:43:56</td>\n",
              "<td>25.088 sec</td>\n",
              "<td>40.0</td>\n",
              "<td>0.2089029</td>\n",
              "<td>0.2166056</td>\n",
              "<td>0.9855383</td>\n",
              "<td>0.9793254</td>\n",
              "<td>2.5923310</td>\n",
              "<td>0.056125</td>\n",
              "<td>0.1931846</td>\n",
              "<td>0.1417876</td>\n",
              "<td>0.9913833</td>\n",
              "<td>0.9872003</td>\n",
              "<td>2.6490066</td>\n",
              "<td>0.046</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-22 20:43:57</td>\n",
              "<td>25.289 sec</td>\n",
              "<td>45.0</td>\n",
              "<td>0.2079904</td>\n",
              "<td>0.2041993</td>\n",
              "<td>0.9860597</td>\n",
              "<td>0.9801217</td>\n",
              "<td>2.5937064</td>\n",
              "<td>0.056625</td>\n",
              "<td>0.1926063</td>\n",
              "<td>0.1412901</td>\n",
              "<td>0.9914631</td>\n",
              "<td>0.9872754</td>\n",
              "<td>2.6490066</td>\n",
              "<td>0.0455</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-22 20:43:57</td>\n",
              "<td>25.356 sec</td>\n",
              "<td>46.0</td>\n",
              "<td>0.2080096</td>\n",
              "<td>0.2042815</td>\n",
              "<td>0.9860385</td>\n",
              "<td>0.9800860</td>\n",
              "<td>2.5936825</td>\n",
              "<td>0.056625</td>\n",
              "<td>0.1921907</td>\n",
              "<td>0.1407921</td>\n",
              "<td>0.9915375</td>\n",
              "<td>0.9873978</td>\n",
              "<td>2.6490066</td>\n",
              "<td>0.047</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-27.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-27 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-27 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-27 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-27 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-27 .h2o-table th,\n",
              "#h2o-table-27 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-27 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-27\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Variable Importances: </caption>\n",
              "    <thead><tr><th>variable</th>\n",
              "<th>relative_importance</th>\n",
              "<th>scaled_importance</th>\n",
              "<th>percentage</th></tr></thead>\n",
              "    <tbody><tr><td>concave points_mean</td>\n",
              "<td>12892.1552734</td>\n",
              "<td>1.0</td>\n",
              "<td>0.1843350</td></tr>\n",
              "<tr><td>perimeter_worst</td>\n",
              "<td>12409.1396484</td>\n",
              "<td>0.9625341</td>\n",
              "<td>0.1774287</td></tr>\n",
              "<tr><td>concave points_worst</td>\n",
              "<td>6141.6552734</td>\n",
              "<td>0.4763870</td>\n",
              "<td>0.0878148</td></tr>\n",
              "<tr><td>radius_worst</td>\n",
              "<td>5617.1918945</td>\n",
              "<td>0.4357062</td>\n",
              "<td>0.0803159</td></tr>\n",
              "<tr><td>radius_se</td>\n",
              "<td>4640.3554688</td>\n",
              "<td>0.3599364</td>\n",
              "<td>0.0663489</td></tr>\n",
              "<tr><td>perimeter_mean</td>\n",
              "<td>4096.8095703</td>\n",
              "<td>0.3177754</td>\n",
              "<td>0.0585771</td></tr>\n",
              "<tr><td>area_worst</td>\n",
              "<td>3825.3610840</td>\n",
              "<td>0.2967201</td>\n",
              "<td>0.0546959</td></tr>\n",
              "<tr><td>area_se</td>\n",
              "<td>3570.8486328</td>\n",
              "<td>0.2769784</td>\n",
              "<td>0.0510568</td></tr>\n",
              "<tr><td>concavity_mean</td>\n",
              "<td>3542.3181152</td>\n",
              "<td>0.2747654</td>\n",
              "<td>0.0506489</td></tr>\n",
              "<tr><td>area_mean</td>\n",
              "<td>1562.5438232</td>\n",
              "<td>0.1212011</td>\n",
              "<td>0.0223416</td></tr>\n",
              "<tr><td>---</td>\n",
              "<td>---</td>\n",
              "<td>---</td>\n",
              "<td>---</td></tr>\n",
              "<tr><td>symmetry_worst</td>\n",
              "<td>398.6156921</td>\n",
              "<td>0.0309192</td>\n",
              "<td>0.0056995</td></tr>\n",
              "<tr><td>smoothness_mean</td>\n",
              "<td>397.4166565</td>\n",
              "<td>0.0308262</td>\n",
              "<td>0.0056824</td></tr>\n",
              "<tr><td>texture_se</td>\n",
              "<td>372.9902344</td>\n",
              "<td>0.0289316</td>\n",
              "<td>0.0053331</td></tr>\n",
              "<tr><td>symmetry_mean</td>\n",
              "<td>357.3835449</td>\n",
              "<td>0.0277210</td>\n",
              "<td>0.0051100</td></tr>\n",
              "<tr><td>smoothness_se</td>\n",
              "<td>350.0584106</td>\n",
              "<td>0.0271528</td>\n",
              "<td>0.0050052</td></tr>\n",
              "<tr><td>fractal_dimension_worst</td>\n",
              "<td>340.3181763</td>\n",
              "<td>0.0263973</td>\n",
              "<td>0.0048659</td></tr>\n",
              "<tr><td>symmetry_se</td>\n",
              "<td>333.9683533</td>\n",
              "<td>0.0259048</td>\n",
              "<td>0.0047752</td></tr>\n",
              "<tr><td>concavity_se</td>\n",
              "<td>327.7789612</td>\n",
              "<td>0.0254247</td>\n",
              "<td>0.0046867</td></tr>\n",
              "<tr><td>concave points_se</td>\n",
              "<td>309.9120178</td>\n",
              "<td>0.0240388</td>\n",
              "<td>0.0044312</td></tr>\n",
              "<tr><td>fractal_dimension_se</td>\n",
              "<td>298.4029541</td>\n",
              "<td>0.0231461</td>\n",
              "<td>0.0042666</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "<pre style='font-size: smaller; margin-bottom: 1em;'>[30 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
              "\n",
              "[tips]\n",
              "Use `model.explain()` to inspect the model.\n",
              "--\n",
              "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.model_performance(train).accuracy()"
      ],
      "metadata": {
        "id": "G_PyYFNMs97_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1e82a97-a6e9-41f7-87ce-318562bc3c30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.5434782608695652, 1.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = aml.get_best_model()\n",
        "HATr  = best_model.model_performance(train)\n",
        "HATe  = best_model.model_performance(valid)"
      ],
      "metadata": {
        "id": "jKquKjVVJBL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_h2o = pd.DataFrame(h2o.as_list(best_model.predict(valid)))['predict']\n",
        "y_test_h2o = np.array(valid1['diagnosis']).copy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-caBWGPlp8P",
        "outputId": "bfbbaa94-6245-4949-ec1f-6377d020c35c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drf prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SFOLD DATA AUTOML\n",
        "#strain, svalid = shdf.split_frame(ratios=[.8], seed=123)\n",
        "shdf  = newdata.copy()\n",
        "#shdf['y_test'] = shdf['y_test'].replace(0,\"B\")\n",
        "#shdf['y_test'] = shdf['y_test'].replace(1,\"M\")\n",
        "shy = \"y_test\"\n",
        "shx = list(shdf.columns)\n",
        "shx.remove(shy)\n",
        "\n",
        "shdf.iloc[:,0:6] = StandardScaler().fit_transform(shdf.iloc[:,0:6])\n",
        "#shdf.iloc[:,-1] = LabelEncoder().fit_transform(shdf.iloc[:,-1])\n",
        "strain1, svalid1 = train_test_split(shdf, test_size=0.2,random_state=123)\n",
        "strain = h2o.H2OFrame(strain1)\n",
        "svalid = h2o.H2OFrame(svalid1)\n",
        "strain[\"y_test\"] = strain[\"y_test\"].asfactor()\n",
        "svalid[\"y_test\"] = svalid[\"y_test\"].asfactor()\n",
        "\n",
        "\n",
        "saml = H2OAutoML(max_models = 10, seed = 123, verbosity=\"info\", nfolds=10, sort_metric='accuracy')\n",
        "saml.train(x = shx, y = shy, training_frame = strain, validation_frame = svalid)\n",
        "sbest_model = saml.get_best_model()\n",
        "sHATr  = sbest_model.model_performance(strain)\n",
        "sHATe  = sbest_model.model_performance(svalid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMDqylVK7svS",
        "outputId": "d29f53fc-43b6-42ec-9fa0-7286ada7eae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
            "AutoML progress: |\n",
            "20:46:57.361: Project: AutoML_2_20230622_204657\n",
            "20:46:57.362: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n",
            "20:46:57.362: Setting stopping tolerance adaptively based on the training frame: 0.011180339887498949\n",
            "20:46:57.362: Build control seed: 123\n",
            "20:46:57.363: training frame: Frame key: AutoML_2_20230622_204657_training_py_11_sid_88c4    cols: 7    rows: 8000  chunks: 1    size: 98174  checksum: -2683389049080009696\n",
            "20:46:57.363: validation frame: Frame key: py_12_sid_88c4    cols: 7    rows: 2000  chunks: 1    size: 25424  checksum: 5900120306796139776\n",
            "20:46:57.363: leaderboard frame: NULL\n",
            "20:46:57.363: blending frame: NULL\n",
            "20:46:57.363: response column: y_test\n",
            "20:46:57.363: fold column: null\n",
            "20:46:57.363: weights column: null\n",
            "20:46:57.363: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (7g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (7g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (6g, 60w)]}, {StackedEnsemble : [monotonic (9g, 10w), best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
            "20:46:57.365: AutoML job created: 2023.06.22 20:46:57.361\n",
            "20:46:57.365: AutoML build started: 2023.06.22 20:46:57.365\n",
            "20:46:57.366: AutoML: starting XGBoost_1_AutoML_2_20230622_204657 model training\n",
            "\n",
            "█\n",
            "20:47:03.676: New leader: XGBoost_1_AutoML_2_20230622_204657, accuracy: 0.950875\n",
            "20:47:03.676: AutoML: starting GLM_1_AutoML_2_20230622_204657 model training\n",
            "\n",
            "█\n",
            "20:47:07.63: New leader: GLM_1_AutoML_2_20230622_204657, accuracy: 0.949875\n",
            "20:47:07.65: AutoML: starting GBM_1_AutoML_2_20230622_204657 model training\n",
            "\n",
            "██\n",
            "20:47:12.749: AutoML: starting XGBoost_2_AutoML_2_20230622_204657 model training\n",
            "\n",
            "█\n",
            "20:47:18.53: AutoML: starting DRF_1_AutoML_2_20230622_204657 model training\n",
            "\n",
            "██\n",
            "20:47:23.177: AutoML: starting GBM_2_AutoML_2_20230622_204657 model training\n",
            "\n",
            "█\n",
            "20:47:30.832: AutoML: starting GBM_3_AutoML_2_20230622_204657 model training\n",
            "\n",
            "██\n",
            "20:47:38.695: AutoML: starting GBM_4_AutoML_2_20230622_204657 model training\n",
            "\n",
            "█\n",
            "20:47:44.961: AutoML: starting XGBoost_3_AutoML_2_20230622_204657 model training\n",
            "\n",
            "█\n",
            "20:47:49.167: AutoML: starting XRT_1_AutoML_2_20230622_204657 model training\n",
            "\n",
            "█\n",
            "20:47:55.625: No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'monotonic'.\n",
            "20:47:55.627: AutoML: starting StackedEnsemble_BestOfFamily_1_AutoML_2_20230622_204657 model training\n",
            "\n",
            "████\n",
            "20:48:06.423: AutoML: starting StackedEnsemble_AllModels_1_AutoML_2_20230622_204657 model training\n",
            "\n",
            "██████████████████████████████████████████████| (done) 100%\n",
            "\n",
            "20:48:20.925: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GLM : [def_1 (1g, 10w)]}, {GBM : [def_5 (1g, 10w)]}, {XGBoost : [def_1 (2g, 10w)]}, {DRF : [def_1 (2g, 10w)]}, {GBM : [def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w)]}, {XGBoost : [def_3 (3g, 10w)]}, {DRF : [XRT (3g, 10w)]}, {StackedEnsemble : [best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
            "20:48:20.925: AutoML build stopped: 2023.06.22 20:48:20.925\n",
            "20:48:20.926: AutoML build done: built 10 models\n",
            "20:48:20.926: AutoML duration:  1 min 23.560 sec\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_sh2o = pd.DataFrame(h2o.as_list(sbest_model.predict(svalid)))['predict']\n",
        "y_test_sh2o = np.array(svalid1['y_test']).copy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivMaaDNNmYY2",
        "outputId": "2d3da12a-8af8-47dc-9a8a-1f50fe573d7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.bar(acc.index, acc['train'], color ='black',width = 0.4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "nJrcI3Gn8we2",
        "outputId": "ab2067e3-4e77-4dfe-a89f-af12baacd55a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 7 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = [ANNmodel, model, knn, lr, rf, svm, xgb, best_model]\n",
        "\n",
        "label = [\"ArtificialNeuralNetwork\", 'DeepNeuralNetwork',\n",
        "         'KNearestNeighborsClassifier', 'LogisticRegression',\n",
        "         'RandomForestClassifier', 'SupportVectorClassifier',\n",
        "         'XGBoost', type(best_model).__name__, type(sbest_model).__name__ ]\n",
        "\n",
        "acc = pd.DataFrame(\n",
        "    {\n",
        "    \"ANN\":[ATr,ATe],\n",
        "    \"DNN\":[DTr,DTe],\n",
        "    \"KNN\":[KTr,KTe],\n",
        "    \"LR\" :[LTr,LTe],\n",
        "    \"RF\" :[RTr,RTe],\n",
        "    \"SVM\":[STr,STe],\n",
        "    \"XGB\":[XTr,XTe],\n",
        "    \"H_OD\":[HATr.accuracy()[0][1],HATe.accuracy()[0][1]],\n",
        "    \"H_SOD\":[sHATr.accuracy()[0][1],sHATe.accuracy()[0][1]]\n",
        "    })\n",
        "acc.index = [\"train\", \"test\"]\n",
        "acc = acc.T\n",
        "acc['Model'] = label\n",
        "\n",
        "acc = acc[['Model', 'train', 'test']]\n",
        "acc['avg'] = round((acc['train'] + acc['test'])/2, 6)\n",
        "acc[acc[\"avg\"] == acc[\"avg\"].max()]\n",
        "acc['BestModel'] = 0\n",
        "for i in range(len(acc)):\n",
        "  if acc['avg'][i] >= 90 and acc['avg'][i] < acc['avg'].max():\n",
        "    acc.iloc[i,-1] = \"good\"\n",
        "  elif acc['avg'][i] == acc['avg'].max():\n",
        "    acc.iloc[i,-1] = \"best\"\n",
        "  else:\n",
        "    acc.iloc[i,-1] = \"not good\"\n",
        "\n",
        "acc[\"Precision\"] = np.zeros(len(acc))\n",
        "acc[\"Recall\"]    = np.zeros(len(acc))\n",
        "acc[\"F1_Score\"]  = np.zeros(len(acc))\n",
        "\n"
      ],
      "metadata": {
        "id": "Ba6kRO-eI60S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_ANNn = []\n",
        "y_pred_DNNn = []\n",
        "for i in range(len(y_pred_ANN)):\n",
        "  y_pred_ANNn.append(y_pred_ANN[i][0])\n",
        "  y_pred_DNNn.append(y_pred_DNN[i][0])"
      ],
      "metadata": {
        "id": "S7pf8G6ao4oF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = [np.array(y_pred_ANNn), np.array(y_pred_DNNn), y_pred_knn,\n",
        "        y_pred_lr, y_pred_rf,\n",
        "        y_pred_svm, y_pred_xgb, y_pred_h2o, y_pred_sh2o]\n",
        "\n",
        "tes  = [y_test_indi_ML, np.array(Dy_test), y_test_indi_ML, y_test_indi_ML,\n",
        "        y_test_indi_ML, y_test_indi_ML, y_test_indi_ML,\n",
        "        y_test_h2o.copy(), y_test_sh2o.copy()]"
      ],
      "metadata": {
        "id": "D2n2VnW1jKp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(pred)):\n",
        "  p,r,f,_ = precision_recall_fscore_support(tes[i], pred[i],\n",
        "                                            average='macro')\n",
        "  acc.iloc[i,5]= p\n",
        "  acc.iloc[i,6]= r\n",
        "  acc.iloc[i,7]= f\n",
        "  p = 0\n",
        "  r = 0\n",
        "  f = 0\n",
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "2DlSQ29moN9T",
        "outputId": "b5dfea65-a9b1-405d-a8a3-8e57aa2b3f4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               Model     train    test       avg BestModel  \\\n",
              "ANN          ArtificialNeuralNetwork  0.959375  0.9520  0.955688  not good   \n",
              "DNN                DeepNeuralNetwork  0.954500  0.9455  0.950000  not good   \n",
              "KNN      KNearestNeighborsClassifier  0.954875  0.9445  0.949688  not good   \n",
              "LR                LogisticRegression  0.950000  0.9500  0.950000  not good   \n",
              "RF            RandomForestClassifier  0.943875  0.9505  0.947188  not good   \n",
              "SVM          SupportVectorClassifier  0.950500  0.9500  0.950250  not good   \n",
              "XGB                          XGBoost  0.988250  0.9455  0.966875  not good   \n",
              "H_OD        H2ORandomForestEstimator  1.000000  0.9530  0.976500      best   \n",
              "H_SOD  H2OGeneralizedLinearEstimator  0.950500  0.9530  0.951750  not good   \n",
              "\n",
              "       Precision    Recall  F1_Score  \n",
              "ANN     0.951225  0.946328  0.948662  \n",
              "DNN     0.942746  0.941107  0.941913  \n",
              "KNN     0.945655  0.935873  0.940325  \n",
              "LR      0.946807  0.946807  0.946807  \n",
              "RF      0.949487  0.944863  0.947072  \n",
              "SVM     0.947226  0.946286  0.946751  \n",
              "XGB     0.942533  0.941368  0.941944  \n",
              "H_OD    0.947959  0.952866  0.950277  \n",
              "H_SOD   0.951148  0.947512  0.949265  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2bea383f-3571-41a7-b69b-3e9c2296e129\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "      <th>avg</th>\n",
              "      <th>BestModel</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ANN</th>\n",
              "      <td>ArtificialNeuralNetwork</td>\n",
              "      <td>0.959375</td>\n",
              "      <td>0.9520</td>\n",
              "      <td>0.955688</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.951225</td>\n",
              "      <td>0.946328</td>\n",
              "      <td>0.948662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DNN</th>\n",
              "      <td>DeepNeuralNetwork</td>\n",
              "      <td>0.954500</td>\n",
              "      <td>0.9455</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.942746</td>\n",
              "      <td>0.941107</td>\n",
              "      <td>0.941913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>KNearestNeighborsClassifier</td>\n",
              "      <td>0.954875</td>\n",
              "      <td>0.9445</td>\n",
              "      <td>0.949688</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.945655</td>\n",
              "      <td>0.935873</td>\n",
              "      <td>0.940325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LR</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.9500</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.946807</td>\n",
              "      <td>0.946807</td>\n",
              "      <td>0.946807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.943875</td>\n",
              "      <td>0.9505</td>\n",
              "      <td>0.947188</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.949487</td>\n",
              "      <td>0.944863</td>\n",
              "      <td>0.947072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>SupportVectorClassifier</td>\n",
              "      <td>0.950500</td>\n",
              "      <td>0.9500</td>\n",
              "      <td>0.950250</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.947226</td>\n",
              "      <td>0.946286</td>\n",
              "      <td>0.946751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGB</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.988250</td>\n",
              "      <td>0.9455</td>\n",
              "      <td>0.966875</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.942533</td>\n",
              "      <td>0.941368</td>\n",
              "      <td>0.941944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H_OD</th>\n",
              "      <td>H2ORandomForestEstimator</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.9530</td>\n",
              "      <td>0.976500</td>\n",
              "      <td>best</td>\n",
              "      <td>0.947959</td>\n",
              "      <td>0.952866</td>\n",
              "      <td>0.950277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H_SOD</th>\n",
              "      <td>H2OGeneralizedLinearEstimator</td>\n",
              "      <td>0.950500</td>\n",
              "      <td>0.9530</td>\n",
              "      <td>0.951750</td>\n",
              "      <td>not good</td>\n",
              "      <td>0.951148</td>\n",
              "      <td>0.947512</td>\n",
              "      <td>0.949265</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2bea383f-3571-41a7-b69b-3e9c2296e129')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2bea383f-3571-41a7-b69b-3e9c2296e129 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2bea383f-3571-41a7-b69b-3e9c2296e129');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.bar(acc.index, acc['train'], color ='black',width = 0.4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "ru4oH6-YzGPw",
        "outputId": "1487ac76-b7ad-4197-95c8-3fb9e3c0fda4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 9 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "Qma6hWrmDBvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = [ANNmodel, model, knn, lr, rf, svm, xgb, best_model]"
      ],
      "metadata": {
        "id": "03rwpiYpoAGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#encoder = LabelEncoder()\n",
        "#y = encoder.fit_transform(df['diagnosis']).copy()\n",
        "#X = df.drop(columns=['diagnosis']).copy()\n",
        "#X = StandardScaler().fit_transform(X).copy()\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "#X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=123)\n",
        "#y_test_indi_ML = y_test.copy()"
      ],
      "metadata": {
        "id": "x5wrzn-qPaXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(1)\n",
        "plt.rcParams[\"figure.figsize\"] = [10, 5]\n",
        "\n",
        "y_pred = ANNmodel.predict(X_test).ravel()\n",
        "y_test = y_test_indi_ML\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[0]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = model.predict(DX_test).ravel()\n",
        "y_test = Dy_test.copy()\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[1]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = knn.predict_proba(X_test)[:, 1]\n",
        "y_test = y_test_indi_ML\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[2]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = lr.predict_proba(X_test)[:, 1]\n",
        "y_test = y_test_indi_ML\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[3]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = rf.predict_proba(X_test)[:, 1]\n",
        "y_test = y_test_indi_ML\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[4]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = svm.predict_proba(X_test)[:, 1]\n",
        "y_test = y_test_indi_ML\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[5]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = xgb.predict_proba(X_test)[:, 1]\n",
        "y_test = y_test_indi_ML\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[6]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = pd.DataFrame(h2o.as_list(best_model.predict(valid)))\n",
        "y_test = h2o.as_list(valid['diagnosis'])\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred[\"p1\"])\n",
        "auc = metrics.roc_auc_score(y_test, y_pred[\"p1\"])\n",
        "plt.plot(fpr, tpr,label=type(best_model).__name__ + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = pd.DataFrame(h2o.as_list(sbest_model.predict(svalid)))\n",
        "y_test = h2o.as_list(svalid['y_test'])\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred[\"p1\"])\n",
        "auc = metrics.roc_auc_score(y_test, y_pred[\"p1\"])\n",
        "plt.plot(fpr, tpr,label=type(sbest_model).__name__ + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('AUC ROC curve')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "4Bi4CMUJm6yH",
        "outputId": "b0e62487-0239-452f-bffc-94ba7bb1bd88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 1ms/step\n",
            "63/63 [==============================] - 0s 1ms/step\n",
            "drf prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
            "glm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nw9mlNqV7hgv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}