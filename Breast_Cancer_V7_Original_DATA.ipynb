{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashiqurrahmankhan21st/BreastCancer/blob/main/Breast_Cancer_V7_Original_DATA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {
        "id": "EUMYU_d6_J-X"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "#import keras_metrics\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers import Dense, Input\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from sklearn.inspection import PartialDependenceDisplay\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "Ntdqq4T_aGXN",
        "outputId": "4b50b079-c450-4acf-9e35-a467fdc5f287"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0           M        17.99         10.38          122.80     1001.0   \n",
              "1           M        20.57         17.77          132.90     1326.0   \n",
              "2           M        19.69         21.25          130.00     1203.0   \n",
              "3           M        11.42         20.38           77.58      386.1   \n",
              "4           M        20.29         14.34          135.10     1297.0   \n",
              "..        ...          ...           ...             ...        ...   \n",
              "564         M        21.56         22.39          142.00     1479.0   \n",
              "565         M        20.13         28.25          131.20     1261.0   \n",
              "566         M        16.60         28.08          108.30      858.1   \n",
              "567         M        20.60         29.33          140.10     1265.0   \n",
              "568         B         7.76         24.54           47.92      181.0   \n",
              "\n",
              "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0            0.11840           0.27760         0.30010              0.14710   \n",
              "1            0.08474           0.07864         0.08690              0.07017   \n",
              "2            0.10960           0.15990         0.19740              0.12790   \n",
              "3            0.14250           0.28390         0.24140              0.10520   \n",
              "4            0.10030           0.13280         0.19800              0.10430   \n",
              "..               ...               ...             ...                  ...   \n",
              "564          0.11100           0.11590         0.24390              0.13890   \n",
              "565          0.09780           0.10340         0.14400              0.09791   \n",
              "566          0.08455           0.10230         0.09251              0.05302   \n",
              "567          0.11780           0.27700         0.35140              0.15200   \n",
              "568          0.05263           0.04362         0.00000              0.00000   \n",
              "\n",
              "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
              "0           0.2419  ...        25.380          17.33           184.60   \n",
              "1           0.1812  ...        24.990          23.41           158.80   \n",
              "2           0.2069  ...        23.570          25.53           152.50   \n",
              "3           0.2597  ...        14.910          26.50            98.87   \n",
              "4           0.1809  ...        22.540          16.67           152.20   \n",
              "..             ...  ...           ...            ...              ...   \n",
              "564         0.1726  ...        25.450          26.40           166.10   \n",
              "565         0.1752  ...        23.690          38.25           155.00   \n",
              "566         0.1590  ...        18.980          34.12           126.70   \n",
              "567         0.2397  ...        25.740          39.42           184.60   \n",
              "568         0.1587  ...         9.456          30.37            59.16   \n",
              "\n",
              "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
              "0        2019.0           0.16220            0.66560           0.7119   \n",
              "1        1956.0           0.12380            0.18660           0.2416   \n",
              "2        1709.0           0.14440            0.42450           0.4504   \n",
              "3         567.7           0.20980            0.86630           0.6869   \n",
              "4        1575.0           0.13740            0.20500           0.4000   \n",
              "..          ...               ...                ...              ...   \n",
              "564      2027.0           0.14100            0.21130           0.4107   \n",
              "565      1731.0           0.11660            0.19220           0.3215   \n",
              "566      1124.0           0.11390            0.30940           0.3403   \n",
              "567      1821.0           0.16500            0.86810           0.9387   \n",
              "568       268.6           0.08996            0.06444           0.0000   \n",
              "\n",
              "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
              "0                  0.2654          0.4601                  0.11890  \n",
              "1                  0.1860          0.2750                  0.08902  \n",
              "2                  0.2430          0.3613                  0.08758  \n",
              "3                  0.2575          0.6638                  0.17300  \n",
              "4                  0.1625          0.2364                  0.07678  \n",
              "..                    ...             ...                      ...  \n",
              "564                0.2216          0.2060                  0.07115  \n",
              "565                0.1628          0.2572                  0.06637  \n",
              "566                0.1418          0.2218                  0.07820  \n",
              "567                0.2650          0.4087                  0.12400  \n",
              "568                0.0000          0.2871                  0.07039  \n",
              "\n",
              "[569 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f046ce1-ad32-4449-81ba-6bd781b2252d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>...</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>...</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>...</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>...</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>...</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>M</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>...</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>M</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>...</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>M</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>...</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>M</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>...</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>B</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>...</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows Ã— 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f046ce1-ad32-4449-81ba-6bd781b2252d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9f046ce1-ad32-4449-81ba-6bd781b2252d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9f046ce1-ad32-4449-81ba-6bd781b2252d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b94f345f-4b30-4171-8855-c3b043f5e8ba\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b94f345f-4b30-4171-8855-c3b043f5e8ba')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b94f345f-4b30-4171-8855-c3b043f5e8ba button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_76e6f7fe-fda7-4f3b-a561-0ac6f8880e25\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_76e6f7fe-fda7-4f3b-a561-0ac6f8880e25 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 276
        }
      ],
      "source": [
        "#original data\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/ashiqurrahmankhan21st/BreastCancer/main/data.csv\")\n",
        "del df['id']\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {
        "id": "4cimS259ti6F"
      },
      "outputs": [],
      "source": [
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(df['diagnosis']).copy()\n",
        "X = df.drop(columns=['diagnosis']).copy()\n",
        "X = StandardScaler().fit_transform(X).copy()\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "Bv9sG-P8M1Fe",
        "outputId": "97b781ff-b13a-4e39-b8ae-627d608f0da3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "diagnosis\n",
              "B    357\n",
              "M    212\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>diagnosis</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>B</th>\n",
              "      <td>357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>M</th>\n",
              "      <td>212</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 278
        }
      ],
      "source": [
        "df['diagnosis'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpyVwv13CTut",
        "outputId": "66a0afc9-9bc2-4aca-f42f-5b23ceaf6cad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original data :  (569, 31)\n",
            "tarin         :  (455, 30)\n",
            "test          :  114\n"
          ]
        }
      ],
      "source": [
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(df['diagnosis']).copy()\n",
        "X = df.drop(columns=['diagnosis']).copy()\n",
        "X = StandardScaler().fit_transform(X).copy()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123,stratify=y)\n",
        "#X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=123)\n",
        "y_test_indi_ML = y_test.copy()\n",
        "print(\"Original data : \",df.shape)\n",
        "print(\"tarin         : \",X_train.shape)\n",
        "print(\"test          : \",X_test.shape[0])\n",
        "#print(\"validation    : \",X_val.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xr0tAwYbEKzc"
      },
      "source": [
        "# SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnRYFOkyEEZ9",
        "outputId": "7518f214-0870-46d5-e16c-abd45ca2c3c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9538461538461539, 0.9473684210526315, 114)"
            ]
          },
          "metadata": {},
          "execution_count": 280
        }
      ],
      "source": [
        "# SVM\n",
        "st = time.time()\n",
        "svm = SVC(C=0.1, gamma='auto', kernel = 'rbf',probability=True)\n",
        "svm.fit(X_train, y_train)\n",
        "send = time.time() - st\n",
        "STr = svm.score(X_train, y_train)\n",
        "STe = svm.score(X_test, y_test)\n",
        "y_pred_svm = svm.predict(X_test)\n",
        "(STr,STe, len(y_pred_svm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 281,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ui8MNV6yEBoe",
        "outputId": "eddce9ea-5267-41a6-e231-2b6ede377ec4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1\n",
            "Training Accuracy : 0.9582\n",
            "Testing Accuracy  : 0.9298\n",
            "Training Time     : 0.04 seconds\n",
            "\n",
            "Fold 2\n",
            "Training Accuracy : 0.9560\n",
            "Testing Accuracy  : 0.9386\n",
            "Training Time     : 0.04 seconds\n",
            "\n",
            "Fold 3\n",
            "Training Accuracy : 0.9538\n",
            "Testing Accuracy  : 0.9474\n",
            "Training Time     : 0.04 seconds\n",
            "\n",
            "Fold 4\n",
            "Training Accuracy : 0.9473\n",
            "Testing Accuracy  : 0.9737\n",
            "Training Time     : 0.03 seconds\n",
            "\n",
            "Fold 5\n",
            "Training Accuracy : 0.9474\n",
            "Testing Accuracy  : 0.9735\n",
            "Training Time     : 0.04 seconds\n",
            "\n",
            "=== Cross-validation Summary ===\n",
            "Avg Train Accuracy : 0.9526\n",
            "Avg Test Accuracy  : 0.9526\n",
            "Avg Time per Fold  : 0.04 seconds\n"
          ]
        }
      ],
      "source": [
        "# Track metrics\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "times = []\n",
        "\n",
        "# Stratified 5-fold cross-validation loop\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
        "    SVCX_train, SVCX_test = X[train_index], X[test_index]\n",
        "    SVCy_train, SVCy_test = y[train_index], y[test_index]\n",
        "\n",
        "    print(f\"\\nFold {fold+1}\")\n",
        "\n",
        "    # Train SVM\n",
        "    st = time.time()\n",
        "    SCVsvm = SVC(C=0.1, gamma='auto', kernel='rbf', probability=True)\n",
        "    SCVsvm.fit(X_train, y_train)\n",
        "    elapsed = time.time() - st\n",
        "\n",
        "    # Scores\n",
        "    SCVSTr = SCVsvm.score(SVCX_train, SVCy_train)\n",
        "    SCVSTe = SCVsvm.score(SVCX_test, SVCy_test)\n",
        "\n",
        "    # Store metrics\n",
        "    train_scores.append(SCVSTr)\n",
        "    test_scores.append(SCVSTe)\n",
        "    times.append(elapsed)\n",
        "\n",
        "    # Display results\n",
        "    print(f\"Training Accuracy : {SCVSTr:.4f}\")\n",
        "    print(f\"Testing Accuracy  : {SCVSTe:.4f}\")\n",
        "    print(f\"Training Time     : {elapsed:.2f} seconds\")\n",
        "\n",
        "SCVSTr = np.mean(train_scores)\n",
        "SCVSTe = np.mean(test_scores)\n",
        "SCVsend = np.mean(times)\n",
        "# Summary\n",
        "print(\"\\n=== Cross-validation Summary ===\")\n",
        "print(f\"Avg Train Accuracy : {np.mean(train_scores):.4f}\")\n",
        "print(f\"Avg Test Accuracy  : {np.mean(test_scores):.4f}\")\n",
        "print(f\"Avg Time per Fold  : {np.mean(times):.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYLYyh58EPkj"
      },
      "source": [
        "#ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 282,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZX7DbN-OIyu",
        "outputId": "1f7dd78e-e5fe-4f86-e1a8-85f09174a8c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9648351669311523, 0.9298245906829834, 114)"
            ]
          },
          "metadata": {},
          "execution_count": 282
        }
      ],
      "source": [
        "tf.random.set_seed(123)\n",
        "st = time.time()\n",
        "\n",
        "ANNmodel = Sequential()\n",
        "ANNmodel.add(Input(shape=(X_train.shape[1],)))\n",
        "ANNmodel.add(Dense(30, activation='relu'))\n",
        "ANNmodel.add(Dense(15, activation='relu'))\n",
        "ANNmodel.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "ANNmodel.compile(loss='BinaryCrossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "ANNmodel.fit(X_train, y_train, batch_size=128, epochs=20, validation_split=0.1, verbose=0)\n",
        "\n",
        "aend = time.time() - st\n",
        "\n",
        "ATr = ANNmodel.evaluate(X_train, y_train, verbose=0)[1]\n",
        "ATe = ANNmodel.evaluate(X_test, y_test, verbose=0)[1]\n",
        "y_pred_ANN = (ANNmodel.predict(X_test, verbose=0) > 0.5).astype(\"int32\")\n",
        "ATr,ATe, len(y_pred_ANN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 283,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NW03GzkSHrm9",
        "outputId": "777278fe-f4ad-4aee-9365-016befd405af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1\n",
            "Training Accuracy : 0.9451\n",
            "Testing Accuracy  : 0.9561\n",
            "Training Time     : 4.01 seconds\n",
            "\n",
            "Fold 2\n",
            "Training Accuracy : 0.9538\n",
            "Testing Accuracy  : 0.9035\n",
            "Training Time     : 4.11 seconds\n",
            "\n",
            "Fold 3\n",
            "Training Accuracy : 0.9429\n",
            "Testing Accuracy  : 0.9649\n",
            "Training Time     : 5.07 seconds\n",
            "\n",
            "Fold 4\n",
            "Training Accuracy : 0.9495\n",
            "Testing Accuracy  : 0.9737\n",
            "Training Time     : 3.88 seconds\n",
            "\n",
            "Fold 5\n",
            "Training Accuracy : 0.9627\n",
            "Testing Accuracy  : 0.9735\n",
            "Training Time     : 4.14 seconds\n",
            "\n",
            "=== Cross-validation Summary ===\n",
            "Avg Train Accuracy : 0.9508\n",
            "Avg Test Accuracy  : 0.9543\n",
            "Avg Time per Fold  : 4.24 seconds\n"
          ]
        }
      ],
      "source": [
        "# Track metrics\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "times = []\n",
        "\n",
        "# Stratified 5-fold cross-validation loop\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
        "    SVCX_train, SVCX_test = X[train_index], X[test_index]\n",
        "    SVCy_train, SVCy_test = y[train_index], y[test_index]\n",
        "\n",
        "    print(f\"\\nFold {fold+1}\")\n",
        "\n",
        "    # Build and train ANN\n",
        "    tf.random.set_seed(123)\n",
        "    st = time.time()\n",
        "\n",
        "    SCVANNmodel = Sequential()\n",
        "    SCVANNmodel.add(Input(shape=(X_train.shape[1],)))\n",
        "    SCVANNmodel.add(Dense(30, activation='relu'))\n",
        "    SCVANNmodel.add(Dense(15, activation='relu'))\n",
        "    SCVANNmodel.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    SCVANNmodel.compile(loss='BinaryCrossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    SCVANNmodel.fit(X_train, y_train, batch_size=128, epochs=20, validation_split=0.1, verbose=0)\n",
        "\n",
        "    elapsed = time.time() - st\n",
        "\n",
        "    SCVATr = SCVANNmodel.evaluate(SVCX_train, SVCy_train, verbose=0)[1]\n",
        "    SCVATe = SCVANNmodel.evaluate(SVCX_test, SVCy_test, verbose=0)[1]\n",
        "\n",
        "    # Store metrics\n",
        "    train_scores.append(SCVATr)\n",
        "    test_scores.append(SCVATe)\n",
        "    times.append(elapsed)\n",
        "\n",
        "    # Display results\n",
        "    print(f\"Training Accuracy : {SCVATr:.4f}\")\n",
        "    print(f\"Testing Accuracy  : {SCVATe:.4f}\")\n",
        "    print(f\"Training Time     : {elapsed:.2f} seconds\")\n",
        "\n",
        "SCVATr = np.mean(train_scores)\n",
        "SCVATe = np.mean(test_scores)\n",
        "SCVaend = np.mean(times)\n",
        "# Summary\n",
        "print(\"\\n=== Cross-validation Summary ===\")\n",
        "print(f\"Avg Train Accuracy : {np.mean(train_scores):.4f}\")\n",
        "print(f\"Avg Test Accuracy  : {np.mean(test_scores):.4f}\")\n",
        "print(f\"Avg Time per Fold  : {np.mean(times):.2f} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 284,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCP82YZ9RjgJ",
        "outputId": "cd4682a9-7adf-4b71-ae09-6c78839e6436"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9912087912087912, 0.9473684210526315, 114)"
            ]
          },
          "metadata": {},
          "execution_count": 284
        }
      ],
      "source": [
        "#XGBoost\n",
        "st = time.time()\n",
        "xgb = XGBClassifier(objective='binary:logistic',max_depth= 6,alpha= 10,learning_rate= 0.03,n_estimators=250)\n",
        "xgb.fit(X_train, y_train)\n",
        "xend = time.time() - st\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "XTr = accuracy_score(y_train, xgb.predict(X_train))\n",
        "XTe = accuracy_score(y_test, xgb.predict(X_test))\n",
        "XTr,XTe, len(y_pred_xgb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHQABriUxjoy",
        "outputId": "77670caa-7d1c-431c-cf2a-f9593d7bf62a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1\n",
            "Training Accuracy : 0.9912\n",
            "Testing Accuracy  : 0.9211\n",
            "Training Time     : 0.77 seconds\n",
            "\n",
            "Fold 2\n",
            "Training Accuracy : 0.9868\n",
            "Testing Accuracy  : 0.9386\n",
            "Training Time     : 0.61 seconds\n",
            "\n",
            "Fold 3\n",
            "Training Accuracy : 0.9846\n",
            "Testing Accuracy  : 0.9474\n",
            "Training Time     : 1.48 seconds\n",
            "\n",
            "Fold 4\n",
            "Training Accuracy : 0.9890\n",
            "Testing Accuracy  : 0.9474\n",
            "Training Time     : 0.33 seconds\n",
            "\n",
            "Fold 5\n",
            "Training Accuracy : 0.9934\n",
            "Testing Accuracy  : 0.9912\n",
            "Training Time     : 0.35 seconds\n",
            "\n",
            "=== Cross-validation Summary ===\n",
            "Avg Train Accuracy : 0.9890\n",
            "Avg Test Accuracy  : 0.9491\n",
            "Avg Time per Fold  : 0.71 seconds\n"
          ]
        }
      ],
      "source": [
        "# Track metrics\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "times = []\n",
        "\n",
        "# Stratified 5-fold cross-validation loop\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
        "    SVCX_train, SVCX_test = X[train_index], X[test_index]\n",
        "    SVCy_train, SVCy_test = y[train_index], y[test_index]\n",
        "\n",
        "    print(f\"\\nFold {fold+1}\")\n",
        "\n",
        "    # Train XGBoost model\n",
        "    st = time.time()\n",
        "    SCVxgb = XGBClassifier(\n",
        "        objective='binary:logistic',\n",
        "        max_depth=6,\n",
        "        alpha=10,\n",
        "        learning_rate=0.03,\n",
        "        n_estimators=250,\n",
        "        eval_metric='logloss'\n",
        "    )\n",
        "    SCVxgb.fit(SVCX_train, SVCy_train)\n",
        "    elapsed = time.time() - st\n",
        "\n",
        "    # Predict\n",
        "    SVCy_pred_xgb = SCVxgb.predict(SVCX_test)\n",
        "\n",
        "    # Accuracy scores\n",
        "    SCVXTr = accuracy_score(SVCy_train, SCVxgb.predict(SVCX_train))\n",
        "    SCVXTe = accuracy_score(SVCy_test, SVCy_pred_xgb)\n",
        "\n",
        "    # Store metrics\n",
        "    train_scores.append(SCVXTr)\n",
        "    test_scores.append(SCVXTe)\n",
        "    times.append(elapsed)\n",
        "\n",
        "    # Display results\n",
        "    print(f\"Training Accuracy : {SCVXTr:.4f}\")\n",
        "    print(f\"Testing Accuracy  : {SCVXTe:.4f}\")\n",
        "    print(f\"Training Time     : {elapsed:.2f} seconds\")\n",
        "\n",
        "# Summary\n",
        "print(\"\\n=== Cross-validation Summary ===\")\n",
        "print(f\"Avg Train Accuracy : {np.mean(train_scores):.4f}\")\n",
        "print(f\"Avg Test Accuracy  : {np.mean(test_scores):.4f}\")\n",
        "print(f\"Avg Time per Fold  : {np.mean(times):.2f} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Y_6b33A1imy",
        "outputId": "30326ba3-2d94-4f97-d437-502a34f18f67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Neighbors: 1\n",
            "KNN model train accuracy score: 1.0000\n",
            "KNN model test accuracy score: 0.9298\n",
            "\n",
            "Number of Neighbors: 3\n",
            "KNN model train accuracy score: 0.9824\n",
            "KNN model test accuracy score: 0.9737\n",
            "\n",
            "Number of Neighbors: 5\n",
            "KNN model train accuracy score: 0.9780\n",
            "KNN model test accuracy score: 0.9649\n",
            "\n",
            "Number of Neighbors: 7\n",
            "KNN model train accuracy score: 0.9714\n",
            "KNN model test accuracy score: 0.9561\n",
            "\n",
            "Number of Neighbors: 9\n",
            "KNN model train accuracy score: 0.9714\n",
            "KNN model test accuracy score: 0.9474\n",
            "\n",
            "Number of Neighbors: 11\n",
            "KNN model train accuracy score: 0.9736\n",
            "KNN model test accuracy score: 0.9474\n",
            "\n",
            "best neighbours:  3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9824175824175824, 0.9736842105263158, 114)"
            ]
          },
          "metadata": {},
          "execution_count": 286
        }
      ],
      "source": [
        "#KNN\n",
        "# Define the range of n_neighbors values to test\n",
        "n_neighbors_values = [1,3, 5, 7, 9, 11]\n",
        "\n",
        "best_accuracy = 0.0\n",
        "best_n_neighbors = None\n",
        "\n",
        "for n_neighbors in n_neighbors_values:\n",
        "    print(\"Number of Neighbors:\", n_neighbors)\n",
        "\n",
        "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    y_pred_knn = knn.predict(X_test)\n",
        "\n",
        "    train_accuracy = accuracy_score(y_train, knn.predict(X_train))\n",
        "    test_accuracy = accuracy_score(y_test, knn.predict(X_test))\n",
        "\n",
        "    print('KNN model train accuracy score: {0:0.4f}'.format(train_accuracy))\n",
        "    print('KNN model test accuracy score: {0:0.4f}'.format(test_accuracy))\n",
        "    print()\n",
        "\n",
        "    # Check if the current test accuracy is better than the previous best\n",
        "    if test_accuracy > best_accuracy:\n",
        "        best_accuracy = test_accuracy\n",
        "        best_n_neighbors = n_neighbors\n",
        "print(\"best neighbours: \", best_n_neighbors)\n",
        "\n",
        "st = time.time()\n",
        "knn = KNeighborsClassifier(n_neighbors=best_n_neighbors)\n",
        "knn.fit(X_train, y_train)\n",
        "kend = time.time() - st\n",
        "KTr = accuracy_score(y_train, knn.predict(X_train))\n",
        "KTe = accuracy_score(y_test, knn.predict(X_test))\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "KTr,KTe, len(y_pred_knn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bU4IlhLhy3sg",
        "outputId": "dfda6714-0fa9-4f36-9f98-f6e944a20d28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1\n",
            "Training Accuracy : 0.9802\n",
            "Testing Accuracy  : 0.9474\n",
            "Training Time     : 0.00 seconds\n",
            "\n",
            "Fold 2\n",
            "Training Accuracy : 0.9824\n",
            "Testing Accuracy  : 0.9386\n",
            "Training Time     : 0.00 seconds\n",
            "\n",
            "Fold 3\n",
            "Training Accuracy : 0.9824\n",
            "Testing Accuracy  : 0.9649\n",
            "Training Time     : 0.00 seconds\n",
            "\n",
            "Fold 4\n",
            "Training Accuracy : 0.9802\n",
            "Testing Accuracy  : 1.0000\n",
            "Training Time     : 0.00 seconds\n",
            "\n",
            "Fold 5\n",
            "Training Accuracy : 0.9803\n",
            "Testing Accuracy  : 0.9823\n",
            "Training Time     : 0.00 seconds\n",
            "\n",
            "=== Cross-validation Summary ===\n",
            "Avg Train Accuracy : 0.9811\n",
            "Avg Test Accuracy  : 0.9666\n",
            "Avg Time per Fold  : 0.00 seconds\n"
          ]
        }
      ],
      "source": [
        "# Track metrics\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "times = []\n",
        "\n",
        "\n",
        "# Cross-validation loop\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
        "    SCVX_train, SCVX_test = X[train_index], X[test_index]\n",
        "    SCVy_train, SCVy_test = y[train_index], y[test_index]\n",
        "\n",
        "    print(f\"\\nFold {fold+1}\")\n",
        "\n",
        "    # Find the best n_neighbors for this fold\n",
        "\n",
        "\n",
        "    # Train with best n_neighbors\n",
        "    st = time.time()\n",
        "    SCVknn = KNeighborsClassifier(n_neighbors=3)\n",
        "    SCVknn.fit(SCVX_train, SCVy_train)\n",
        "    elapsed = time.time() - st\n",
        "\n",
        "    SCVKTr = accuracy_score(SCVy_train, SCVknn.predict(SCVX_train))\n",
        "    SCVKTe = accuracy_score(SCVy_test, SCVknn.predict(SCVX_test))\n",
        "\n",
        "    # Store metrics\n",
        "    train_scores.append(SCVKTr)\n",
        "    test_scores.append(SCVKTe)\n",
        "    times.append(elapsed)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Training Accuracy : {SCVKTr:.4f}\")\n",
        "    print(f\"Testing Accuracy  : {SCVKTe:.4f}\")\n",
        "    print(f\"Training Time     : {elapsed:.2f} seconds\")\n",
        "\n",
        "# Summary\n",
        "print(\"\\n=== Cross-validation Summary ===\")\n",
        "print(f\"Avg Train Accuracy : {np.mean(train_scores):.4f}\")\n",
        "print(f\"Avg Test Accuracy  : {np.mean(test_scores):.4f}\")\n",
        "print(f\"Avg Time per Fold  : {np.mean(times):.2f} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 288,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_kyk_E92bSX",
        "outputId": "5e025c21-d516-44cf-91ff-fd8a2bb0f781"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9758241758241758, 0.9473684210526315, 114)"
            ]
          },
          "metadata": {},
          "execution_count": 288
        }
      ],
      "source": [
        "#RF\n",
        "st = time.time()\n",
        "rf = RandomForestClassifier(n_estimators= 500,max_features = 'sqrt', max_samples = 100, random_state=123)\n",
        "rf.fit(X_train, y_train)\n",
        "rend = time.time() - st\n",
        "RTr = accuracy_score(y_train, rf.predict(X_train))\n",
        "RTe = accuracy_score(y_test, rf.predict(X_test))\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "RTr,RTe, len(y_pred_rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 289,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uO5FESNBzdZE",
        "outputId": "b518a62d-263e-460f-bfeb-14df6e9087a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1\n",
            "Training Accuracy : 0.9780\n",
            "Testing Accuracy  : 0.9298\n",
            "Training Time     : 0.87 seconds\n",
            "\n",
            "Fold 2\n",
            "Training Accuracy : 0.9846\n",
            "Testing Accuracy  : 0.9474\n",
            "Training Time     : 0.85 seconds\n",
            "\n",
            "Fold 3\n",
            "Training Accuracy : 0.9758\n",
            "Testing Accuracy  : 0.9649\n",
            "Training Time     : 0.89 seconds\n",
            "\n",
            "Fold 4\n",
            "Training Accuracy : 0.9714\n",
            "Testing Accuracy  : 0.9649\n",
            "Training Time     : 0.90 seconds\n",
            "\n",
            "Fold 5\n",
            "Training Accuracy : 0.9737\n",
            "Testing Accuracy  : 0.9646\n",
            "Training Time     : 0.87 seconds\n",
            "\n",
            "=== Cross-validation Summary ===\n",
            "Avg Train Accuracy : 0.9767\n",
            "Avg Test Accuracy  : 0.9543\n",
            "Avg Time per Fold  : 0.88 seconds\n"
          ]
        }
      ],
      "source": [
        "# Track metrics\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "times = []\n",
        "\n",
        "# Stratified 5-fold cross-validation loop\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
        "    SCVX_train, SCVX_test = X[train_index], X[test_index]\n",
        "    SCVy_train, SCVy_test = y[train_index], y[test_index]\n",
        "\n",
        "    print(f\"\\nFold {fold+1}\")\n",
        "\n",
        "    # Train Random Forest\n",
        "    st = time.time()\n",
        "    SCVrf = RandomForestClassifier(\n",
        "        n_estimators=500,\n",
        "        max_features='sqrt',\n",
        "        max_samples=100,\n",
        "        random_state=123\n",
        "    )\n",
        "    SCVrf.fit(SCVX_train, SCVy_train)\n",
        "    elapsed = time.time() - st\n",
        "\n",
        "    SCVRTr = accuracy_score(SCVy_train, SCVrf.predict(SCVX_train))\n",
        "    SCVRTe = accuracy_score(SCVy_test, SCVrf.predict(SCVX_test))\n",
        "\n",
        "    # Store metrics\n",
        "    train_scores.append(SCVRTr)\n",
        "    test_scores.append(SCVRTe)\n",
        "    times.append(elapsed)\n",
        "\n",
        "    # Print fold results\n",
        "    print(f\"Training Accuracy : {SCVRTr:.4f}\")\n",
        "    print(f\"Testing Accuracy  : {SCVRTe:.4f}\")\n",
        "    print(f\"Training Time     : {elapsed:.2f} seconds\")\n",
        "\n",
        "# Summary\n",
        "print(\"\\n=== Cross-validation Summary ===\")\n",
        "print(f\"Avg Train Accuracy : {np.mean(train_scores):.4f}\")\n",
        "print(f\"Avg Test Accuracy  : {np.mean(test_scores):.4f}\")\n",
        "print(f\"Avg Time per Fold  : {np.mean(times):.2f} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 290,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWkZmwL23Fm_",
        "outputId": "47602247-e09d-4a3f-bf2e-92f3f333e06d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9846153846153847, 0.9736842105263158, 114)"
            ]
          },
          "metadata": {},
          "execution_count": 290
        }
      ],
      "source": [
        "#LR\n",
        "st = time.time()\n",
        "lr = LogisticRegression(C= 0.1 , penalty='l1', solver='liblinear', max_iter = 1000, random_state=123)\n",
        "lr.fit(X_train, y_train)\n",
        "lend = time.time() - st\n",
        "LTr = accuracy_score(y_train, lr.predict(X_train))\n",
        "LTe = accuracy_score(y_test, lr.predict(X_test))\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "LTr,LTe, len(y_pred_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 291,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTBOggE5NVW-",
        "outputId": "fbcb5b3e-72bb-4d20-8b43-c6dbd2ad2719"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1\n",
            "Training Accuracy : 0.9802\n",
            "Testing Accuracy  : 0.9649\n",
            "Training Time     : 0.00 seconds\n",
            "\n",
            "Fold 2\n",
            "Training Accuracy : 0.9890\n",
            "Testing Accuracy  : 0.9386\n",
            "Training Time     : 0.00 seconds\n",
            "\n",
            "Fold 3\n",
            "Training Accuracy : 0.9802\n",
            "Testing Accuracy  : 0.9912\n",
            "Training Time     : 0.00 seconds\n",
            "\n",
            "Fold 4\n",
            "Training Accuracy : 0.9736\n",
            "Testing Accuracy  : 1.0000\n",
            "Training Time     : 0.00 seconds\n",
            "\n",
            "Fold 5\n",
            "Training Accuracy : 0.9803\n",
            "Testing Accuracy  : 0.9646\n",
            "Training Time     : 0.00 seconds\n",
            "\n",
            "=== Cross-validation Summary ===\n",
            "Avg Train Accuracy : 0.9807\n",
            "Avg Test Accuracy  : 0.9719\n",
            "Avg Time per Fold  : 0.00 seconds\n"
          ]
        }
      ],
      "source": [
        "# Track metrics\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "times = []\n",
        "\n",
        "# Stratified 5-fold CV loop\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
        "    SCVX_train, SCVX_test = X[train_index], X[test_index]\n",
        "    SCVy_train, SCVy_test = y[train_index], y[test_index]\n",
        "\n",
        "    print(f\"\\nFold {fold+1}\")\n",
        "\n",
        "    # Train Logistic Regression model\n",
        "    st = time.time()\n",
        "    SCVlr = LogisticRegression(\n",
        "        C=0.1,\n",
        "        penalty='l1',\n",
        "        solver='liblinear',\n",
        "        max_iter=1000,\n",
        "        random_state=123\n",
        "    )\n",
        "    SCVlr.fit( SCVX_train,  SCVy_train)\n",
        "    elapsed = time.time() - st\n",
        "\n",
        "    SCVLTr = accuracy_score( SCVy_train, SCVlr.predict( SCVX_train))\n",
        "    SCVLTe = accuracy_score( SCVy_test, SCVlr.predict( SCVX_test))\n",
        "\n",
        "\n",
        "    # Store metrics\n",
        "    train_scores.append(SCVLTr)\n",
        "    test_scores.append(SCVLTe)\n",
        "    times.append(elapsed)\n",
        "\n",
        "    # Print fold results\n",
        "    print(f\"Training Accuracy : {SCVLTr:.4f}\")\n",
        "    print(f\"Testing Accuracy  : {SCVLTe:.4f}\")\n",
        "    print(f\"Training Time     : {elapsed:.2f} seconds\")\n",
        "\n",
        "# Summary\n",
        "print(\"\\n=== Cross-validation Summary ===\")\n",
        "print(f\"Avg Train Accuracy : {np.mean(train_scores):.4f}\")\n",
        "print(f\"Avg Test Accuracy  : {np.mean(test_scores):.4f}\")\n",
        "print(f\"Avg Time per Fold  : {np.mean(times):.2f} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 291,
      "metadata": {
        "id": "E9_l6r5f0w5n"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 292,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "XqaJZ1Mb0xAe",
        "outputId": "e907793f-f6e7-4511-85aa-7df281a03983"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef CVal(ML):\\n\\n  df = pd.read_csv(\"https://raw.githubusercontent.com/ashiqurrahmankhan21st/BreastCancer/main/data.csv\")\\n  del df[\\'id\\']\\n\\n  s = 0\\n  e = round(df.shape[0]*.2)\\n\\n  y_pred = []\\n  y_original = []\\n\\n  for i in range(5):\\n\\n    test_set  = df.iloc[s:e,:]\\n    train_set = df.drop(test_set.index)\\n\\n    X_train = StandardScaler().fit_transform(train_set.drop(columns=[\\'diagnosis\\'])).copy()\\n    y_train = encoder.fit_transform(train_set[\\'diagnosis\\']).copy()\\n    X_test = StandardScaler().fit_transform(test_set.drop(columns=[\\'diagnosis\\'])).copy()\\n    y_test = encoder.fit_transform(test_set[\\'diagnosis\\']).copy()\\n\\n    #svm = SVC(C=0.1, gamma=\\'auto\\', kernel = \\'rbf\\')\\n\\n    ML.fit(X_train, y_train)\\n    y_pred_ML = ML.predict(X_test)\\n\\n\\n    y_pred.append(y_pred_ML)\\n    y_original.append(y_test)\\n\\n    s = e\\n    e = e + round(df.shape[0]*.2)\\n    if e-s < round(df.shape[0]*.2):\\n      e = df.shape[0]+1\\n\\n  y_pred_final = []\\n  y_original_final = []\\n\\n  try:\\n    for i in range(5):\\n      for j in range(round(df.shape[0]*.2)):\\n        y_pred_final.append(y_pred[i][j])\\n        y_original_final.append(y_original[i][j])\\n  except:\\n    pass\\n  return y_pred_final\\n  '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 292
        }
      ],
      "source": [
        "'''\n",
        "def CVal(ML):\n",
        "\n",
        "  df = pd.read_csv(\"https://raw.githubusercontent.com/ashiqurrahmankhan21st/BreastCancer/main/data.csv\")\n",
        "  del df['id']\n",
        "\n",
        "  s = 0\n",
        "  e = round(df.shape[0]*.2)\n",
        "\n",
        "  y_pred = []\n",
        "  y_original = []\n",
        "\n",
        "  for i in range(5):\n",
        "\n",
        "    test_set  = df.iloc[s:e,:]\n",
        "    train_set = df.drop(test_set.index)\n",
        "\n",
        "    X_train = StandardScaler().fit_transform(train_set.drop(columns=['diagnosis'])).copy()\n",
        "    y_train = encoder.fit_transform(train_set['diagnosis']).copy()\n",
        "    X_test = StandardScaler().fit_transform(test_set.drop(columns=['diagnosis'])).copy()\n",
        "    y_test = encoder.fit_transform(test_set['diagnosis']).copy()\n",
        "\n",
        "    #svm = SVC(C=0.1, gamma='auto', kernel = 'rbf')\n",
        "\n",
        "    ML.fit(X_train, y_train)\n",
        "    y_pred_ML = ML.predict(X_test)\n",
        "\n",
        "\n",
        "    y_pred.append(y_pred_ML)\n",
        "    y_original.append(y_test)\n",
        "\n",
        "    s = e\n",
        "    e = e + round(df.shape[0]*.2)\n",
        "    if e-s < round(df.shape[0]*.2):\n",
        "      e = df.shape[0]+1\n",
        "\n",
        "  y_pred_final = []\n",
        "  y_original_final = []\n",
        "\n",
        "  try:\n",
        "    for i in range(5):\n",
        "      for j in range(round(df.shape[0]*.2)):\n",
        "        y_pred_final.append(y_pred[i][j])\n",
        "        y_original_final.append(y_original[i][j])\n",
        "  except:\n",
        "    pass\n",
        "  return y_pred_final\n",
        "  '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 293,
      "metadata": {
        "id": "Pnzr2dnz0G5J"
      },
      "outputs": [],
      "source": [
        "def CVal(ML):\n",
        "    # Load and clean dataset\n",
        "    df = pd.read_csv(\"https://raw.githubusercontent.com/ashiqurrahmankhan21st/BreastCancer/main/data.csv\")\n",
        "    del df['id']\n",
        "\n",
        "    # Separate features and target\n",
        "    X = df.drop(columns=['diagnosis']).copy()\n",
        "    y = df['diagnosis'].copy()\n",
        "\n",
        "    # Encode labels\n",
        "    encoder = LabelEncoder()\n",
        "    y = encoder.fit_transform(y)\n",
        "\n",
        "    # Prepare StratifiedKFold\n",
        "\n",
        "    SCVy_pred = []\n",
        "    SCVy_original = []\n",
        "\n",
        "    for train_index, test_index in skf.split(X, y):\n",
        "        # Split data\n",
        "        SCVX_train, SCVX_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        SCVy_train, SCVy_test = y[train_index], y[test_index]\n",
        "\n",
        "        # Standardize\n",
        "        scaler = StandardScaler().fit(SCVX_train)\n",
        "        SCVX_train = scaler.transform(SCVX_train)\n",
        "        SCVX_test = scaler.transform(SCVX_test)\n",
        "\n",
        "        # Train model\n",
        "        ML.fit(SCVX_train, SCVy_train)\n",
        "        SCVy_pred_ML = ML.predict(SCVX_test)\n",
        "\n",
        "        # Collect predictions\n",
        "        SCVy_pred.append(SCVy_pred_ML)\n",
        "        SCVy_original.append(SCVy_test)\n",
        "\n",
        "    # Flatten predictions and true labels\n",
        "    SCVy_pred_final = []\n",
        "    SCVy_original_final = []\n",
        "\n",
        "    for i in range(5):\n",
        "        for j in range(len(SCVy_pred[i])):\n",
        "            SCVy_pred_final.append(SCVy_pred[i][j])\n",
        "            SCVy_original_final.append(SCVy_original[i][j])\n",
        "\n",
        "    return SCVy_pred_final\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 294,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "jRa_a7EY0y6B",
        "outputId": "ceb1346f-eb78-4222-e4fc-ca50929cd909"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef CValANN():\\n\\n  df = pd.read_csv(\"https://raw.githubusercontent.com/ashiqurrahmankhan21st/BreastCancer/main/data.csv\")\\n  del df[\\'id\\']\\n\\n  s = 0\\n  e = round(df.shape[0]*.2)\\n\\n  y_pred = []\\n  y_original = []\\n\\n  for i in range(5):\\n\\n    test_set  = df.iloc[s:e,:]\\n    train_set = df.drop(test_set.index)\\n\\n    X_train = StandardScaler().fit_transform(train_set.drop(columns=[\\'diagnosis\\'])).copy()\\n    y_train = encoder.fit_transform(train_set[\\'diagnosis\\']).copy()\\n    X_test = StandardScaler().fit_transform(test_set.drop(columns=[\\'diagnosis\\'])).copy()\\n    y_test = encoder.fit_transform(test_set[\\'diagnosis\\']).copy()\\n\\n    #svm = SVC(C=0.1, gamma=\\'auto\\', kernel = \\'rbf\\')\\n    tf.random.set_seed(123)\\n    ANNmodel = Sequential()\\n    ANNmodel.add(Dense(30, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    ANNmodel.add(Dense(15, activation=\\'relu\\'))\\n    ANNmodel.add(Dense(1, activation=\\'sigmoid\\'))\\n    ANNmodel.compile(loss=\\'BinaryCrossentropy\\', optimizer=\\'adam\\', metrics=[\\'accuracy\\']) #tf.keras.metrics.Precision(), tf.keras.metrics.Recall()\\n    ANNmodel.fit(X_train,y_train, batch_size = 128, epochs = 20, validation_split = 0.1)\\n    y_pred_ANN = (ANNmodel.predict(X_test) > 0.5).astype(\"int32\")\\n\\n\\n    y_pred.append(y_pred_ANN)\\n    y_original.append(y_test)\\n\\n    s = e\\n    e = e + round(df.shape[0]*.2)\\n    if e-s < round(df.shape[0]*.2):\\n      e = df.shape[0]\\n\\n  y_pred_fina = []\\n  y_original_final = []\\n\\n  try:\\n    for i in range(5):\\n      for j in range(round(df.shape[0]*.2)):\\n        y_pred_fina.append(y_pred[i][j])\\n        y_original_final.append(y_original[i][j])\\n  except:\\n    pass\\n\\n  y_pred_final = []\\n\\n  for i in range(len(y_pred_fina)):\\n    y_pred_final.append(y_pred_fina[i][0])\\n\\n  return y_pred_final\\n  '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 294
        }
      ],
      "source": [
        "'''\n",
        "def CValANN():\n",
        "\n",
        "  df = pd.read_csv(\"https://raw.githubusercontent.com/ashiqurrahmankhan21st/BreastCancer/main/data.csv\")\n",
        "  del df['id']\n",
        "\n",
        "  s = 0\n",
        "  e = round(df.shape[0]*.2)\n",
        "\n",
        "  y_pred = []\n",
        "  y_original = []\n",
        "\n",
        "  for i in range(5):\n",
        "\n",
        "    test_set  = df.iloc[s:e,:]\n",
        "    train_set = df.drop(test_set.index)\n",
        "\n",
        "    X_train = StandardScaler().fit_transform(train_set.drop(columns=['diagnosis'])).copy()\n",
        "    y_train = encoder.fit_transform(train_set['diagnosis']).copy()\n",
        "    X_test = StandardScaler().fit_transform(test_set.drop(columns=['diagnosis'])).copy()\n",
        "    y_test = encoder.fit_transform(test_set['diagnosis']).copy()\n",
        "\n",
        "    #svm = SVC(C=0.1, gamma='auto', kernel = 'rbf')\n",
        "    tf.random.set_seed(123)\n",
        "    ANNmodel = Sequential()\n",
        "    ANNmodel.add(Dense(30, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "    ANNmodel.add(Dense(15, activation='relu'))\n",
        "    ANNmodel.add(Dense(1, activation='sigmoid'))\n",
        "    ANNmodel.compile(loss='BinaryCrossentropy', optimizer='adam', metrics=['accuracy']) #tf.keras.metrics.Precision(), tf.keras.metrics.Recall()\n",
        "    ANNmodel.fit(X_train,y_train, batch_size = 128, epochs = 20, validation_split = 0.1)\n",
        "    y_pred_ANN = (ANNmodel.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "\n",
        "    y_pred.append(y_pred_ANN)\n",
        "    y_original.append(y_test)\n",
        "\n",
        "    s = e\n",
        "    e = e + round(df.shape[0]*.2)\n",
        "    if e-s < round(df.shape[0]*.2):\n",
        "      e = df.shape[0]\n",
        "\n",
        "  y_pred_fina = []\n",
        "  y_original_final = []\n",
        "\n",
        "  try:\n",
        "    for i in range(5):\n",
        "      for j in range(round(df.shape[0]*.2)):\n",
        "        y_pred_fina.append(y_pred[i][j])\n",
        "        y_original_final.append(y_original[i][j])\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  y_pred_final = []\n",
        "\n",
        "  for i in range(len(y_pred_fina)):\n",
        "    y_pred_final.append(y_pred_fina[i][0])\n",
        "\n",
        "  return y_pred_final\n",
        "  '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 295,
      "metadata": {
        "id": "GCS2ezed0mCD"
      },
      "outputs": [],
      "source": [
        "def CValANN():\n",
        "    # Load and preprocess dataset\n",
        "    df = pd.read_csv(\"https://raw.githubusercontent.com/ashiqurrahmankhan21st/BreastCancer/main/data.csv\")\n",
        "    del df['id']\n",
        "\n",
        "    X = df.drop(columns=['diagnosis']).copy()\n",
        "    y = df['diagnosis'].copy()\n",
        "\n",
        "    encoder = LabelEncoder()\n",
        "    y = encoder.fit_transform(y)\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
        "\n",
        "    SCVy_pred = []\n",
        "    SCVy_original = []\n",
        "\n",
        "    for train_index, test_index in skf.split(X, y):\n",
        "        SCVX_train, SCVX_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        SCVy_train, SCVy_test = y[train_index], y[test_index]\n",
        "\n",
        "        # Standardize\n",
        "        scaler = StandardScaler().fit(SCVX_train)\n",
        "        SCVX_train = scaler.transform(SCVX_train)\n",
        "        SCVX_test = scaler.transform(SCVX_test)\n",
        "\n",
        "        # ANN Model\n",
        "        tf.random.set_seed(123)\n",
        "        ANNmodel = Sequential()\n",
        "        ANNmodel.add(Input(shape=(X_train.shape[1],)))\n",
        "        ANNmodel.add(Dense(30, activation='relu'))\n",
        "        ANNmodel.add(Dense(15, activation='relu'))\n",
        "        ANNmodel.add(Dense(1, activation='sigmoid'))\n",
        "        ANNmodel.compile(loss='BinaryCrossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "        ANNmodel.fit(X_train, y_train, batch_size=128, epochs=20, validation_split=0.1, verbose=0)\n",
        "\n",
        "        SCVy_pred_ANN = (ANNmodel.predict(SCVX_test, verbose=0) > 0.5).astype(\"int32\")\n",
        "\n",
        "        SCVy_pred.append(SCVy_pred_ANN)\n",
        "        SCVy_original.append(SCVy_test)\n",
        "\n",
        "    SCVy_pred_fina = []\n",
        "    SCVy_original_final = []\n",
        "\n",
        "    try:\n",
        "        for i in range(5):\n",
        "            for j in range(len(SCVy_pred[i])):\n",
        "                SCVy_pred_fina.append(SCVy_pred[i][j])\n",
        "                SCVy_original_final.append(SCVy_original[i][j])\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    SCVy_pred_final = [val[0] for val in SCVy_pred_fina]\n",
        "\n",
        "    return SCVy_pred_final\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 296,
      "metadata": {
        "id": "2CGgdO1V0zA9"
      },
      "outputs": [],
      "source": [
        "newdata = pd.DataFrame({\n",
        "    \"SVM\": CVal(SVC(C=0.1, gamma='auto', kernel = 'rbf'))\n",
        "})\n",
        "newdata[\"KNN\"] = CVal(KNeighborsClassifier(n_neighbors=3))\n",
        "newdata[\"RF\"]  = CVal(RandomForestClassifier(n_estimators= 500,max_features = 'sqrt', max_samples = 100, random_state=123))\n",
        "newdata['LR']  = CVal(LogisticRegression(C= 0.1 , penalty='l1', solver='liblinear', max_iter = 1000, random_state=123))\n",
        "newdata[\"ANN\"] = CValANN()\n",
        "newdata[\"XGB\"] = CVal(XGBClassifier(objective='binary:logistic',max_depth= 7,alpha= 10,learning_rate= 1,n_estimators=100))\n",
        "newdata['y_test'] = encoder.fit_transform(df['diagnosis']).copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 297,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "05ryfvyLzFVK",
        "outputId": "ae671ae4-1a5c-42f1-fdfd-51d018b7dbc8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   SVM  KNN  RF  LR  ANN  XGB  y_test\n",
              "0    1    1   1   1    1    1       1\n",
              "1    0    1   1   1    0    1       1\n",
              "2    1    1   1   1    1    1       1\n",
              "3    1    1   1   1    1    1       1\n",
              "4    1    1   1   1    1    1       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c838c3b0-8279-4eca-bb7e-8f881d8e8812\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SVM</th>\n",
              "      <th>KNN</th>\n",
              "      <th>RF</th>\n",
              "      <th>LR</th>\n",
              "      <th>ANN</th>\n",
              "      <th>XGB</th>\n",
              "      <th>y_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c838c3b0-8279-4eca-bb7e-8f881d8e8812')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c838c3b0-8279-4eca-bb7e-8f881d8e8812 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c838c3b0-8279-4eca-bb7e-8f881d8e8812');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b3f47423-c6a5-447a-bf5d-fd270dace114\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b3f47423-c6a5-447a-bf5d-fd270dace114')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b3f47423-c6a5-447a-bf5d-fd270dace114 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "newdata",
              "summary": "{\n  \"name\": \"newdata\",\n  \"rows\": 569,\n  \"fields\": [\n    {\n      \"column\": \"SVM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"KNN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ANN\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"XGB\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 297
        }
      ],
      "source": [
        "newdata.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 298,
      "metadata": {
        "id": "A4kf97a3yX15"
      },
      "outputs": [],
      "source": [
        "# Define the DNN model\n",
        "DNNX = newdata.drop(columns=['y_test']).copy()\n",
        "DNNY = newdata.y_test.copy()\n",
        "DX_train, DX_test, Dy_train, Dy_test = train_test_split(\n",
        "    DNNX, DNNY, test_size=0.2, random_state=123)\n",
        "\n",
        "st = time.time()\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.Input(shape=(DX_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(30, activation='relu'),\n",
        "    tf.keras.layers.Dense(25, activation='relu'),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dense(15, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(DX_train, Dy_train, epochs=500, batch_size=64, validation_split=0.2, verbose=0)\n",
        "dend = time.time() - st"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 299,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POzgPNwbyOn_",
        "outputId": "61163492-d661-405d-abb2-9f7b8c6bd750"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6263736486434937, 0.6228070259094238, 114)"
            ]
          },
          "metadata": {},
          "execution_count": 299
        }
      ],
      "source": [
        "#y_pred_DNN = (model.predict(DNNX) > 0.5).astype(\"int32\")\n",
        "y_pred_DNN = (model.predict(DX_test) > 0.5).astype(\"int32\")\n",
        "DTr = model.evaluate(DX_train, Dy_train,verbose=0)[1]\n",
        "DTe = model.evaluate(DX_test, Dy_test,verbose=0)[1]\n",
        "DTr,DTe, len(y_pred_DNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 300,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V31nqGI432sY",
        "outputId": "ca346690-8db3-4221-c2ea-4fc6fa3aa6f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1\n",
            "Training Accuracy : 0.6242\n",
            "Testing Accuracy  : 0.6053\n",
            "Training Time     : 74.86 seconds\n",
            "\n",
            "Fold 2\n",
            "Training Accuracy : 0.6242\n",
            "Testing Accuracy  : 0.6053\n",
            "Training Time     : 76.22 seconds\n",
            "\n",
            "Fold 3\n",
            "Training Accuracy : 0.6154\n",
            "Testing Accuracy  : 0.6404\n",
            "Training Time     : 77.77 seconds\n",
            "\n",
            "Fold 4\n",
            "Training Accuracy : 0.6176\n",
            "Testing Accuracy  : 0.6316\n",
            "Training Time     : 75.67 seconds\n",
            "\n",
            "Fold 5\n",
            "Training Accuracy : 0.6206\n",
            "Testing Accuracy  : 0.6195\n",
            "Training Time     : 79.71 seconds\n",
            "\n",
            "=== Cross-validation Summary ===\n",
            "Avg Train Accuracy : 0.6204\n",
            "Avg Test Accuracy  : 0.6204\n",
            "Avg Time per Fold  : 76.85 seconds\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Prepare data\n",
        "DNNX = newdata.drop(columns=['y_test']).copy()\n",
        "DNNY = newdata['y_test'].copy()\n",
        "\n",
        "# Encode labels if necessary\n",
        "encoder = LabelEncoder()\n",
        "DNNY = encoder.fit_transform(DNNY)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "DNNX = scaler.fit_transform(DNNX)\n",
        "\n",
        "# Stratified K-Fold initialization\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
        "\n",
        "# Track metrics\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "times = []\n",
        "\n",
        "# Stratified 5-fold CV loop\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(DNNX, DNNY)):\n",
        "    SCVX_train, SCVX_test = DNNX[train_index], DNNX[test_index]\n",
        "    SCVy_train, SCVy_test = DNNY[train_index], DNNY[test_index]\n",
        "\n",
        "    print(f\"\\nFold {fold+1}\")\n",
        "\n",
        "    # Train DNN\n",
        "    tf.random.set_seed(123)\n",
        "    st = time.time()\n",
        "\n",
        "    SCVmodel = tf.keras.Sequential([\n",
        "        tf.keras.Input(shape=(SCVX_train.shape[1],)),\n",
        "        tf.keras.layers.Dense(30, activation='relu',),\n",
        "        tf.keras.layers.Dense(25, activation='relu'),\n",
        "        tf.keras.layers.Dense(20, activation='relu'),\n",
        "        tf.keras.layers.Dense(15, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='relu'),\n",
        "        tf.keras.layers.Dense(5, activation='relu'),\n",
        "        tf.keras.layers.Dense(2, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    SCVmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    SCVmodel.fit(SCVX_train, SCVy_train, epochs=500, batch_size=64, validation_split=0.2, verbose=0)\n",
        "\n",
        "    elapsed = time.time() - st\n",
        "\n",
        "    # Evaluation\n",
        "    SCVDTr = model.evaluate(SCVX_train, SCVy_train, verbose=0)[1]\n",
        "    SCVDTe = model.evaluate(SCVX_test, SCVy_test, verbose=0)[1]\n",
        "\n",
        "    # Store metrics\n",
        "    train_scores.append(SCVDTr)\n",
        "    test_scores.append(SCVDTe)\n",
        "    times.append(elapsed)\n",
        "\n",
        "    # Print fold results\n",
        "    print(f\"Training Accuracy : {SCVDTr:.4f}\")\n",
        "    print(f\"Testing Accuracy  : {SCVDTe:.4f}\")\n",
        "    print(f\"Training Time     : {elapsed:.2f} seconds\")\n",
        "\n",
        "# Summary\n",
        "print(\"\\n=== Cross-validation Summary ===\")\n",
        "print(f\"Avg Train Accuracy : {np.mean(train_scores):.4f}\")\n",
        "print(f\"Avg Test Accuracy  : {np.mean(test_scores):.4f}\")\n",
        "print(f\"Avg Time per Fold  : {np.mean(times):.2f} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 301,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "v_YjlCdOO1JY",
        "outputId": "d4650847-58db-4585-b67b-ebd1d76cb84f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        train      test  SCVTrain   SCVTest\n",
              "SVM  0.953846  0.947368  0.952551  0.952585\n",
              "KNN  0.982418  0.973684  0.980263  0.982301\n",
              "RF   0.975824  0.947368  0.973684  0.964602\n",
              "LR   0.984615  0.973684  0.980263  0.964602\n",
              "ANN  0.964835  0.929825  0.950786  0.954339\n",
              "XGB  0.991209  0.947368  0.993421  0.991150\n",
              "DNN  0.626374  0.622807  0.620614  0.619469"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8e8c741d-6f0b-43a0-a944-05a44705ddc8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "      <th>SCVTrain</th>\n",
              "      <th>SCVTest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>0.953846</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>0.952551</td>\n",
              "      <td>0.952585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>0.982418</td>\n",
              "      <td>0.973684</td>\n",
              "      <td>0.980263</td>\n",
              "      <td>0.982301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>0.975824</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>0.973684</td>\n",
              "      <td>0.964602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LR</th>\n",
              "      <td>0.984615</td>\n",
              "      <td>0.973684</td>\n",
              "      <td>0.980263</td>\n",
              "      <td>0.964602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ANN</th>\n",
              "      <td>0.964835</td>\n",
              "      <td>0.929825</td>\n",
              "      <td>0.950786</td>\n",
              "      <td>0.954339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGB</th>\n",
              "      <td>0.991209</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>0.993421</td>\n",
              "      <td>0.991150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DNN</th>\n",
              "      <td>0.626374</td>\n",
              "      <td>0.622807</td>\n",
              "      <td>0.620614</td>\n",
              "      <td>0.619469</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e8c741d-6f0b-43a0-a944-05a44705ddc8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8e8c741d-6f0b-43a0-a944-05a44705ddc8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8e8c741d-6f0b-43a0-a944-05a44705ddc8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1423f257-7041-49fd-8377-fb4c120a46e5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1423f257-7041-49fd-8377-fb4c120a46e5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1423f257-7041-49fd-8377-fb4c120a46e5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_ba39e877-5d9f-420b-8113-924eb25d679b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('acc')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ba39e877-5d9f-420b-8113-924eb25d679b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('acc');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "acc",
              "summary": "{\n  \"name\": \"acc\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"train\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13254665002542138,\n        \"min\": 0.6263736486434937,\n        \"max\": 0.9912087912087912,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.9538461538461539,\n          0.9824175824175824,\n          0.9912087912087912\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12587176914208176,\n        \"min\": 0.6228070259094238,\n        \"max\": 0.9736842105263158,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9736842105263158,\n          0.6228070259094238,\n          0.9473684210526315\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SCVTrain\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13363883027509893,\n        \"min\": 0.6206140518188477,\n        \"max\": 0.993421052631579,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.9525506072874494,\n          0.9802631578947368,\n          0.6206140518188477\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SCVTest\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1325802379334002,\n        \"min\": 0.6194690465927124,\n        \"max\": 0.9911504424778761,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.952585002328831,\n          0.9823008849557522,\n          0.6194690465927124\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 301
        }
      ],
      "source": [
        "acc = pd.DataFrame(\n",
        "    {\n",
        "    \"SVM\":[STr,STe, SCVSTr,SCVSTe],\n",
        "    \"KNN\":[KTr,KTe, SCVKTr,SCVKTe],\n",
        "    \"RF\" :[RTr,RTe, SCVRTr,SCVRTe],\n",
        "    \"LR\" :[LTr,LTe, SCVLTr,SCVLTe],\n",
        "    \"ANN\":[ATr,ATe, SCVATr,SCVATe],\n",
        "    \"XGB\":[XTr,XTe, SCVXTr,SCVXTe],\n",
        "    \"DNN\":[DTr,DTe, SCVDTr,SCVDTe]})\n",
        "acc.index = [\"train\", \"test\", \"SCVTrain\", \"SCVTest\"]\n",
        "acc = acc.T\n",
        "acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJaAMLDKKfKs"
      },
      "source": [
        "### **AutoML Individual and AutoML DNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 302,
      "metadata": {
        "id": "EhNt_UkjDKcV"
      },
      "outputs": [],
      "source": [
        "#H2O AutoML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 303,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "iwMF9ROeDOzF",
        "outputId": "91df9a65-a020-4fe8-f8b7-b04059cd730e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: h2o in /usr/local/lib/python3.11/dist-packages (3.46.0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from h2o) (2.32.3)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from h2o) (0.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->h2o) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->h2o) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->h2o) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->h2o) (2025.4.26)\n",
            "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "--------------------------  -----------------------------------------------------------------------------------------\n",
              "H2O_cluster_uptime:         4 hours 17 mins\n",
              "H2O_cluster_timezone:       Etc/UTC\n",
              "H2O_data_parsing_timezone:  UTC\n",
              "H2O_cluster_version:        3.46.0.7\n",
              "H2O_cluster_version_age:    1 month and 11 days\n",
              "H2O_cluster_name:           H2O_from_python_unknownUser_7mwzxz\n",
              "H2O_cluster_total_nodes:    1\n",
              "H2O_cluster_free_memory:    2.921 Gb\n",
              "H2O_cluster_total_cores:    2\n",
              "H2O_cluster_allowed_cores:  2\n",
              "H2O_cluster_status:         locked, healthy\n",
              "H2O_connection_url:         http://localhost:54321\n",
              "H2O_connection_proxy:       {\"http\": null, \"https\": null, \"colab_language_server\": \"/usr/colab/bin/language_service\"}\n",
              "H2O_internal_security:      False\n",
              "Python_version:             3.11.12 final\n",
              "--------------------------  -----------------------------------------------------------------------------------------"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "#h2o-table-122.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-122 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-122 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-122 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-122 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-122 .h2o-table th,\n",
              "#h2o-table-122 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-122 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-122\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption></caption>\n",
              "    <thead></thead>\n",
              "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
              "<td>4 hours 17 mins</td></tr>\n",
              "<tr><td>H2O_cluster_timezone:</td>\n",
              "<td>Etc/UTC</td></tr>\n",
              "<tr><td>H2O_data_parsing_timezone:</td>\n",
              "<td>UTC</td></tr>\n",
              "<tr><td>H2O_cluster_version:</td>\n",
              "<td>3.46.0.7</td></tr>\n",
              "<tr><td>H2O_cluster_version_age:</td>\n",
              "<td>1 month and 11 days</td></tr>\n",
              "<tr><td>H2O_cluster_name:</td>\n",
              "<td>H2O_from_python_unknownUser_7mwzxz</td></tr>\n",
              "<tr><td>H2O_cluster_total_nodes:</td>\n",
              "<td>1</td></tr>\n",
              "<tr><td>H2O_cluster_free_memory:</td>\n",
              "<td>2.921 Gb</td></tr>\n",
              "<tr><td>H2O_cluster_total_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_allowed_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_status:</td>\n",
              "<td>locked, healthy</td></tr>\n",
              "<tr><td>H2O_connection_url:</td>\n",
              "<td>http://localhost:54321</td></tr>\n",
              "<tr><td>H2O_connection_proxy:</td>\n",
              "<td>{\"http\": null, \"https\": null, \"colab_language_server\": \"/usr/colab/bin/language_service\"}</td></tr>\n",
              "<tr><td>H2O_internal_security:</td>\n",
              "<td>False</td></tr>\n",
              "<tr><td>Python_version:</td>\n",
              "<td>3.11.12 final</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Library Loaded\n"
          ]
        }
      ],
      "source": [
        "!pip install h2o\n",
        "import h2o\n",
        "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
        "h2o.init()\n",
        "from h2o.model.segment_models import H2OFrame\n",
        "from h2o.automl import H2OAutoML\n",
        "print(\"All Library Loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 304,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVoFNbYCGxGh",
        "outputId": "aeac5659-e8c8-43b8-f374-3db33647ed96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n",
            "Parse progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n",
            "AutoML progress: |\n",
            "08:28:03.824: Project: AutoML_19_20250509_82803\n",
            "08:28:03.825: 5-fold cross-validation will be used.\n",
            "08:28:03.825: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n",
            "08:28:03.829: Setting stopping tolerance adaptively based on the training frame: 0.04688072309384954\n",
            "08:28:03.829: Build control seed: 123\n",
            "08:28:03.829: training frame: Frame key: AutoML_19_20250509_82803_training_py_147_sid_a292    cols: 31    rows: 455  chunks: 1    size: 111919  checksum: -6999049652048799504\n",
            "08:28:03.830: validation frame: Frame key: py_148_sid_a292    cols: 31    rows: 114  chunks: 1    size: 30037  checksum: 1244986154056216624\n",
            "08:28:03.830: leaderboard frame: NULL\n",
            "08:28:03.830: blending frame: NULL\n",
            "08:28:03.830: response column: diagnosis\n",
            "08:28:03.830: fold column: null\n",
            "08:28:03.830: weights column: null\n",
            "08:28:03.830: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (7g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (7g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (6g, 60w)]}, {StackedEnsemble : [monotonic (9g, 10w), best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
            "08:28:03.832: AutoML job created: 2025.05.09 08:28:03.824\n",
            "08:28:03.838: AutoML build started: 2025.05.09 08:28:03.838\n",
            "08:28:03.839: AutoML: starting XGBoost_1_AutoML_19_20250509_82803 model training\n",
            "\n",
            "â–ˆ\n",
            "08:28:10.358: New leader: XGBoost_1_AutoML_19_20250509_82803, accuracy: 0.9494505494505494\n",
            "08:28:10.362: AutoML: starting GLM_1_AutoML_19_20250509_82803 model training\n",
            "\n",
            "â–ˆ\n",
            "08:28:12.690: AutoML: starting GBM_1_AutoML_19_20250509_82803 model training\n",
            "\n",
            "â–ˆâ–ˆ\n",
            "08:28:20.24: AutoML: starting XGBoost_2_AutoML_19_20250509_82803 model training\n",
            "\n",
            "â–ˆâ–ˆ\n",
            "08:28:29.323: AutoML: starting DRF_1_AutoML_19_20250509_82803 model training\n",
            "\n",
            "\n",
            "08:28:31.428: AutoML: starting GBM_2_AutoML_19_20250509_82803 model training\n",
            "\n",
            "â–ˆâ–ˆ\n",
            "08:28:39.548: AutoML: starting GBM_3_AutoML_19_20250509_82803 model training\n",
            "\n",
            "â–ˆâ–ˆ\n",
            "08:28:46.222: AutoML: starting GBM_4_AutoML_19_20250509_82803 model training\n",
            "\n",
            "â–ˆ\n",
            "08:28:51.898: AutoML: starting XGBoost_3_AutoML_19_20250509_82803 model training\n",
            "\n",
            "â–ˆ\n",
            "08:28:57.378: AutoML: starting XRT_1_AutoML_19_20250509_82803 model training\n",
            "\n",
            "\n",
            "08:28:59.297: No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'monotonic'.\n",
            "08:28:59.298: AutoML: starting StackedEnsemble_BestOfFamily_1_AutoML_19_20250509_82803 model training\n",
            "\n",
            "â–ˆ\n",
            "08:29:00.720: AutoML: starting StackedEnsemble_AllModels_1_AutoML_19_20250509_82803 model training\n",
            "\n",
            "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n",
            "\n",
            "08:29:02.128: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GLM : [def_1 (1g, 10w)]}, {GBM : [def_5 (1g, 10w)]}, {XGBoost : [def_1 (2g, 10w)]}, {DRF : [def_1 (2g, 10w)]}, {GBM : [def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w)]}, {XGBoost : [def_3 (3g, 10w)]}, {DRF : [XRT (3g, 10w)]}, {StackedEnsemble : [best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
            "08:29:02.128: AutoML build stopped: 2025.05.09 08:29:02.128\n",
            "08:29:02.128: AutoML build done: built 10 models\n",
            "08:29:02.128: AutoML duration: 58.290 sec\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#train, valid = hdf.split_frame(ratios=[.8], seed=123)\n",
        "#hdf = h2o.H2OFrame(df)\n",
        "#hdf[\"diagnosis\"] = hdf[\"diagnosis\"].asfactor()\n",
        "hy = \"diagnosis\"\n",
        "hx = list(df.columns)\n",
        "hx.remove(hy)\n",
        "hdf  = df.copy()\n",
        "hdf.iloc[:,1:] = StandardScaler().fit_transform(hdf.iloc[:,1:])\n",
        "hdf.iloc[:,0] = LabelEncoder().fit_transform(hdf.iloc[:,0])\n",
        "hdf.iloc[:,0] = hdf.iloc[:,0].astype('category')\n",
        "train1, valid1 = train_test_split(hdf, test_size=0.2,random_state=123)\n",
        "train = h2o.H2OFrame(train1)\n",
        "valid = h2o.H2OFrame(valid1)\n",
        "train[\"diagnosis\"] = train[\"diagnosis\"].asfactor()\n",
        "valid[\"diagnosis\"] = valid[\"diagnosis\"].asfactor()\n",
        "\n",
        "st = time.time()\n",
        "aml = H2OAutoML(max_models = 10, seed = 123, verbosity=\"info\", sort_metric='accuracy')\n",
        "aml.train(x = hx, y = hy, training_frame = train,\n",
        "          validation_frame = valid)\n",
        "autoend = time.time() - st\n",
        "\n",
        "best_model = aml.get_best_model()\n",
        "HATr  = best_model.model_performance(train)\n",
        "HATe  = best_model.model_performance(valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 305,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JNO6XnVHH5P",
        "outputId": "be6d97a0-6956-41fa-ed41-6de75cdb0f1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xgboost prediction progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n",
            "Export File progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n"
          ]
        }
      ],
      "source": [
        "#y_pred_h2o = pd.DataFrame(h2o.as_list(best_model.predict(valid)))['predict']\n",
        "y_pred_h2o = np.array(best_model.predict(valid).as_data_frame(use_multi_thread=True)['predict'])\n",
        "y_test_h2o = np.array(valid1['diagnosis']).copy().astype(np.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 306,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "gmCXw_D_4y1D",
        "outputId": "48704905-2974-4a77-b9ec-7d1c0516c7de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model_id                              accuracy       auc    logloss     aucpr    mean_per_class_error      rmse        mse\n",
              "----------------------------------  ----------  --------  ---------  --------  ----------------------  --------  ---------\n",
              "XGBoost_1_AutoML_19_20250509_82803    0.949451  0.98434   0.170914   0.980608               0.0562145  0.208348  0.0434089\n",
              "DRF_1_AutoML_19_20250509_82803        0.956044  0.986471  0.255546   0.985057               0.0433552  0.186958  0.0349535\n",
              "XRT_1_AutoML_19_20250509_82803        0.958242  0.989076  0.186773   0.986326               0.0462482  0.185875  0.0345494\n",
              "XGBoost_3_AutoML_19_20250509_82803    0.962637  0.992175  0.105667   0.98925                0.0363438  0.173386  0.0300628\n",
              "XGBoost_2_AutoML_19_20250509_82803    0.967033  0.99129   0.116476   0.988269               0.0333889  0.177387  0.0314663\n",
              "GBM_2_AutoML_19_20250509_82803        0.967033  0.993555  0.0982281  0.990844               0.0403694  0.166536  0.0277343\n",
              "GBM_4_AutoML_19_20250509_82803        0.969231  0.99407   0.0978783  0.991578               0.0397723  0.167164  0.0279438\n",
              "GBM_1_AutoML_19_20250509_82803        0.969231  0.993164  0.0993037  0.990717               0.0293015  0.164931  0.0272023\n",
              "GBM_3_AutoML_19_20250509_82803        0.973626  0.994543  0.0897099  0.992244               0.0269438  0.153898  0.0236846\n",
              "GLM_1_AutoML_19_20250509_82803        0.975824  0.99479   0.0817313  0.992976               0.0263467  0.148979  0.0221946\n",
              "[10 rows x 8 columns]\n"
            ],
            "text/html": [
              "<table class='dataframe'>\n",
              "<thead>\n",
              "<tr><th>model_id                          </th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">      mse</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>XGBoost_1_AutoML_19_20250509_82803</td><td style=\"text-align: right;\">  0.949451</td><td style=\"text-align: right;\">0.98434 </td><td style=\"text-align: right;\">0.170914 </td><td style=\"text-align: right;\">0.980608</td><td style=\"text-align: right;\">             0.0562145</td><td style=\"text-align: right;\">0.208348</td><td style=\"text-align: right;\">0.0434089</td></tr>\n",
              "<tr><td>DRF_1_AutoML_19_20250509_82803    </td><td style=\"text-align: right;\">  0.956044</td><td style=\"text-align: right;\">0.986471</td><td style=\"text-align: right;\">0.255546 </td><td style=\"text-align: right;\">0.985057</td><td style=\"text-align: right;\">             0.0433552</td><td style=\"text-align: right;\">0.186958</td><td style=\"text-align: right;\">0.0349535</td></tr>\n",
              "<tr><td>XRT_1_AutoML_19_20250509_82803    </td><td style=\"text-align: right;\">  0.958242</td><td style=\"text-align: right;\">0.989076</td><td style=\"text-align: right;\">0.186773 </td><td style=\"text-align: right;\">0.986326</td><td style=\"text-align: right;\">             0.0462482</td><td style=\"text-align: right;\">0.185875</td><td style=\"text-align: right;\">0.0345494</td></tr>\n",
              "<tr><td>XGBoost_3_AutoML_19_20250509_82803</td><td style=\"text-align: right;\">  0.962637</td><td style=\"text-align: right;\">0.992175</td><td style=\"text-align: right;\">0.105667 </td><td style=\"text-align: right;\">0.98925 </td><td style=\"text-align: right;\">             0.0363438</td><td style=\"text-align: right;\">0.173386</td><td style=\"text-align: right;\">0.0300628</td></tr>\n",
              "<tr><td>XGBoost_2_AutoML_19_20250509_82803</td><td style=\"text-align: right;\">  0.967033</td><td style=\"text-align: right;\">0.99129 </td><td style=\"text-align: right;\">0.116476 </td><td style=\"text-align: right;\">0.988269</td><td style=\"text-align: right;\">             0.0333889</td><td style=\"text-align: right;\">0.177387</td><td style=\"text-align: right;\">0.0314663</td></tr>\n",
              "<tr><td>GBM_2_AutoML_19_20250509_82803    </td><td style=\"text-align: right;\">  0.967033</td><td style=\"text-align: right;\">0.993555</td><td style=\"text-align: right;\">0.0982281</td><td style=\"text-align: right;\">0.990844</td><td style=\"text-align: right;\">             0.0403694</td><td style=\"text-align: right;\">0.166536</td><td style=\"text-align: right;\">0.0277343</td></tr>\n",
              "<tr><td>GBM_4_AutoML_19_20250509_82803    </td><td style=\"text-align: right;\">  0.969231</td><td style=\"text-align: right;\">0.99407 </td><td style=\"text-align: right;\">0.0978783</td><td style=\"text-align: right;\">0.991578</td><td style=\"text-align: right;\">             0.0397723</td><td style=\"text-align: right;\">0.167164</td><td style=\"text-align: right;\">0.0279438</td></tr>\n",
              "<tr><td>GBM_1_AutoML_19_20250509_82803    </td><td style=\"text-align: right;\">  0.969231</td><td style=\"text-align: right;\">0.993164</td><td style=\"text-align: right;\">0.0993037</td><td style=\"text-align: right;\">0.990717</td><td style=\"text-align: right;\">             0.0293015</td><td style=\"text-align: right;\">0.164931</td><td style=\"text-align: right;\">0.0272023</td></tr>\n",
              "<tr><td>GBM_3_AutoML_19_20250509_82803    </td><td style=\"text-align: right;\">  0.973626</td><td style=\"text-align: right;\">0.994543</td><td style=\"text-align: right;\">0.0897099</td><td style=\"text-align: right;\">0.992244</td><td style=\"text-align: right;\">             0.0269438</td><td style=\"text-align: right;\">0.153898</td><td style=\"text-align: right;\">0.0236846</td></tr>\n",
              "<tr><td>GLM_1_AutoML_19_20250509_82803    </td><td style=\"text-align: right;\">  0.975824</td><td style=\"text-align: right;\">0.99479 </td><td style=\"text-align: right;\">0.0817313</td><td style=\"text-align: right;\">0.992976</td><td style=\"text-align: right;\">             0.0263467</td><td style=\"text-align: right;\">0.148979</td><td style=\"text-align: right;\">0.0221946</td></tr>\n",
              "</tbody>\n",
              "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[10 rows x 8 columns]</pre>"
            ]
          },
          "metadata": {},
          "execution_count": 306
        }
      ],
      "source": [
        "lb = aml.leaderboard\n",
        "lb.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 307,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vlH8zwtisQU1",
        "outputId": "3d5c7347-58f7-4cdf-fa07-5f6b3d09cc68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model Details\n",
              "=============\n",
              "H2OXGBoostEstimator : XGBoost\n",
              "Model Key: XGBoost_1_AutoML_19_20250509_82803\n",
              "\n",
              "\n",
              "Model Summary: \n",
              "    number_of_trees\n",
              "--  -----------------\n",
              "    36\n",
              "\n",
              "ModelMetricsBinomial: xgboost\n",
              "** Reported on train data. **\n",
              "\n",
              "MSE: 0.029074514855628383\n",
              "RMSE: 0.17051250644931704\n",
              "LogLoss: 0.12394929039565182\n",
              "Mean Per-Class Error: 0.029270653158718393\n",
              "AUC: 0.9940799769376494\n",
              "AUCPR: 0.992056368504806\n",
              "Gini: 0.9881599538752988\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4925362765789032\n",
              "       0    1    Error    Rate\n",
              "-----  ---  ---  -------  ------------\n",
              "0      279  5    0.0176   (5.0/284.0)\n",
              "1      7    164  0.0409   (7.0/171.0)\n",
              "Total  286  169  0.0264   (12.0/455.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.492536     0.964706  38\n",
              "max f2                       0.317989     0.971098  49\n",
              "max f0point5                 0.514766     0.971395  37\n",
              "max accuracy                 0.514766     0.973626  37\n",
              "max precision                0.968002     1         0\n",
              "max recall                   0.0588847    1         100\n",
              "max specificity              0.968002     1         0\n",
              "max absolute_mcc             0.492536     0.943696  38\n",
              "max min_per_class_accuracy   0.402806     0.964912  42\n",
              "max mean_per_class_accuracy  0.492536     0.970729  38\n",
              "max tns                      0.968002     284       0\n",
              "max fns                      0.968002     110       0\n",
              "max fps                      0.0148769    284       134\n",
              "max tps                      0.0588847    171       100\n",
              "max tnr                      0.968002     1         0\n",
              "max fnr                      0.968002     0.643275  0\n",
              "max fpr                      0.0148769    1         134\n",
              "max tpr                      0.0588847    1         100\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 37.58 %, avg score: 37.29 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.134066                    0.968002           2.66082    2.66082            1                0.968002   1                           0.968002            0.356725        0.356725                   166.082   166.082            0.356725\n",
              "2        0.162637                    0.957612           2.66082    2.66082            1                0.957612   1                           0.966177            0.0760234       0.432749                   166.082   166.082            0.432749\n",
              "3        0.2                         0.950501           2.66082    2.66082            1                0.953488   1                           0.963806            0.0994152       0.532164                   166.082   166.082            0.532164\n",
              "4        0.301099                    0.807568           2.66082    2.66082            1                0.897179   1                           0.941435            0.269006        0.80117                    166.082   166.082            0.80117\n",
              "5        0.4                         0.314704           1.83301    2.45614            0.688889         0.582323   0.923077                    0.852644            0.181287        0.982456                   83.3008   145.614            0.93316\n",
              "6        0.501099                    0.076693           0.0578439  1.97227            0.0217391        0.161579   0.741228                    0.713218            0.00584795      0.988304                   -94.2156  97.2274            0.780558\n",
              "7        0.624176                    0.0503081          0.0950292  1.60211            0.0357143        0.058398   0.602113                    0.584099            0.0116959       1                          -90.4971  60.2113            0.602113\n",
              "8        0.698901                    0.0279195          0          1.43082            0                0.0365022  0.537736                    0.525551            0               1                          -100      43.0818            0.482394\n",
              "9        0.804396                    0.0177071          0          1.24317            0                0.0225316  0.467213                    0.459581            0               1                          -100      24.3169            0.31338\n",
              "10       0.931868                    0.0175245          0          1.07311            0                0.0175245  0.403302                    0.399111            0               1                          -100      7.31132            0.109155\n",
              "11       1                           0.0148769          0          1                  0                0.0148769  0.375824                    0.372932            0               1                          -100      0                  0\n",
              "\n",
              "ModelMetricsBinomial: xgboost\n",
              "** Reported on validation data. **\n",
              "\n",
              "MSE: 0.03762067586537018\n",
              "RMSE: 0.19396050078655236\n",
              "LogLoss: 0.1512542647982658\n",
              "Mean Per-Class Error: 0.03274306715669896\n",
              "AUC: 0.976445038422987\n",
              "AUCPR: 0.9791961628675718\n",
              "Gini: 0.952890076845974\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.25368359684944153\n",
              "       0    1    Error    Rate\n",
              "-----  ---  ---  -------  -----------\n",
              "0      70   3    0.0411   (3.0/73.0)\n",
              "1      1    40   0.0244   (1.0/41.0)\n",
              "Total  71   43   0.0351   (4.0/114.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.253684     0.952381  20\n",
              "max f2                       0.253684     0.966184  20\n",
              "max f0point5                 0.705651     0.972973  15\n",
              "max accuracy                 0.253684     0.964912  20\n",
              "max precision                0.968002     1         0\n",
              "max recall                   0.0175245    1         46\n",
              "max specificity              0.968002     1         0\n",
              "max absolute_mcc             0.253684     0.925285  20\n",
              "max min_per_class_accuracy   0.253684     0.958904  20\n",
              "max mean_per_class_accuracy  0.253684     0.967257  20\n",
              "max tns                      0.968002     73        0\n",
              "max fns                      0.968002     27        0\n",
              "max fps                      0.0148769    73        47\n",
              "max tps                      0.0175245    41        46\n",
              "max tnr                      0.968002     1         0\n",
              "max fnr                      0.968002     0.658537  0\n",
              "max fpr                      0.0148769    1         47\n",
              "max tpr                      0.0175245    1         46\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 35.96 %, avg score: 34.85 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.122807                    0.968002           2.78049    2.78049            1                0.968002   1                           0.968002            0.341463        0.341463                   178.049   178.049            0.341463\n",
              "2        0.157895                    0.954363           2.78049    2.78049            1                0.955175   1                           0.965152            0.097561        0.439024                   178.049   178.049            0.439024\n",
              "3        0.210526                    0.932284           2.78049    2.78049            1                0.935408   1                           0.957716            0.146341        0.585366                   178.049   178.049            0.585366\n",
              "4        0.298246                    0.717271           2.78049    2.78049            1                0.870593   1                           0.932091            0.243902        0.829268                   178.049   178.049            0.829268\n",
              "5        0.403509                    0.169029           1.39024    2.41782            0.5              0.45112    0.869565                    0.806621            0.146341        0.97561                    39.0244   141.782            0.893418\n",
              "6        0.508772                    0.0588847          0          1.91758            0                0.093715   0.689655                    0.659123            0               0.97561                    -100      91.7578            0.729034\n",
              "7        0.596491                    0.0359404          0          1.63558            0                0.0470055  0.588235                    0.569106            0               0.97561                    -100      63.5581            0.592048\n",
              "8        0.701754                    0.023509           0          1.39024            0                0.0319946  0.5                         0.488539            0               0.97561                    -100      39.0244            0.427665\n",
              "9        0.973684                    0.0175245          0.0896932  1.02703            0.0322581        0.0192596  0.369369                    0.357479            0.0243902       1                          -91.0307  2.7027             0.0410959\n",
              "10       1                           0.0148769          0          1                  0                0.0148769  0.359649                    0.348463            0               1                          -100      0                  0\n",
              "\n",
              "ModelMetricsBinomial: xgboost\n",
              "** Reported on cross-validation data. **\n",
              "\n",
              "MSE: 0.04340888001758289\n",
              "RMSE: 0.20834797819413292\n",
              "LogLoss: 0.17091363880751467\n",
              "Mean Per-Class Error: 0.05621447986162589\n",
              "AUC: 0.984340252038547\n",
              "AUCPR: 0.9806080024284464\n",
              "Gini: 0.968680504077094\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.46881043910980225\n",
              "       0    1    Error    Rate\n",
              "-----  ---  ---  -------  ------------\n",
              "0      272  12   0.0423   (12.0/284.0)\n",
              "1      12   159  0.0702   (12.0/171.0)\n",
              "Total  284  171  0.0527   (24.0/455.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.46881      0.929825  65\n",
              "max f2                       0.263177     0.952381  90\n",
              "max f0point5                 0.600738     0.956354  46\n",
              "max accuracy                 0.567315     0.949451  50\n",
              "max precision                0.946152     1         0\n",
              "max recall                   0.0347225    1         172\n",
              "max specificity              0.946152     1         0\n",
              "max absolute_mcc             0.567315     0.892628  50\n",
              "max min_per_class_accuracy   0.423845     0.94152   71\n",
              "max mean_per_class_accuracy  0.46881      0.943786  65\n",
              "max tns                      0.946152     284       0\n",
              "max fns                      0.946152     158       0\n",
              "max fps                      0.0259651    284       180\n",
              "max tps                      0.0347225    171       172\n",
              "max tnr                      0.946152     1         0\n",
              "max fnr                      0.946152     0.923977  0\n",
              "max fpr                      0.0259651    1         180\n",
              "max tpr                      0.0347225    1         172\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 37.58 %, avg score: 37.45 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.0285714                   0.946152           2.66082    2.66082            1                0.946152   1                           0.946152            0.0760234       0.0760234                  166.082   166.082            0.0760234\n",
              "2        0.0615385                   0.942744           2.66082    2.66082            1                0.942744   1                           0.944326            0.0877193       0.163743                   166.082   166.082            0.163743\n",
              "3        0.123077                    0.937152           2.66082    2.66082            1                0.93951    1                           0.941918            0.163743        0.327485                   166.082   166.082            0.327485\n",
              "4        0.18022                     0.933306           2.66082    2.66082            1                0.93422    1                           0.939477            0.152047        0.479532                   166.082   166.082            0.479532\n",
              "5        0.206593                    0.916636           2.66082    2.66082            1                0.92026    1                           0.937024            0.0701754       0.549708                   166.082   166.082            0.549708\n",
              "6        0.301099                    0.745783           2.47518    2.60255            0.930233         0.878144   0.978102                    0.918543            0.233918        0.783626                   147.518   160.255            0.773062\n",
              "7        0.4                         0.378306           1.65562    2.36842            0.622222         0.548027   0.89011                     0.826932            0.163743        0.947368                   65.5621   136.842            0.876946\n",
              "8        0.501099                    0.0993004          0.347063   1.9606             0.130435         0.211507   0.736842                    0.702767            0.0350877       0.982456                   -65.2937  96.0603            0.771189\n",
              "9        0.6                         0.0590016          0.0591293  1.64717            0.0222222        0.0714737  0.619048                    0.598708            0.00584795      0.988304                   -94.0871  64.7173            0.622107\n",
              "10       0.698901                    0.0447799          0.0591293  1.42245            0.0222222        0.0532896  0.534591                    0.521526            0.00584795      0.994152                   -94.0871  42.245             0.473025\n",
              "11       0.824176                    0.0347225          0.046681   1.21333            0.0175439        0.0376506  0.456                       0.447977            0.00584795      1                          -95.3319  21.3333            0.28169\n",
              "12       0.945055                    0.0308269          0          1.05814            0                0.0316372  0.397674                    0.394724            0               1                          -100      5.81395            0.0880282\n",
              "13       1                           0.0259651          0          1                  0                0.027382   0.375824                    0.374541            0               1                          -100      0                  0\n",
              "\n",
              "Cross-Validation Metrics Summary: \n",
              "                         mean         sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
              "-----------------------  -----------  -----------  ------------  ------------  ------------  ------------  ------------\n",
              "accuracy                 0.95824176   0.021137785  0.95604396    0.989011      0.93406594    0.96703297    0.94505495\n",
              "aic                      nan          0.0          nan           nan           nan           nan           nan\n",
              "auc                      0.9839799    0.012506209  0.9747449     0.9980392     0.9676071     0.99174404    0.9877642\n",
              "err                      0.041758243  0.021137785  0.043956045   0.010989011   0.06593407    0.032967035   0.054945055\n",
              "err_count                3.8          1.9235384    4.0           1.0           6.0           3.0           5.0\n",
              "f0point5                 0.94456017   0.04262893   0.9580838     0.99489796    0.8839779     0.96385545    0.9219858\n",
              "f1                       0.9420617    0.031155758  0.9411765     0.98734176    0.9142857     0.95522386    0.9122807\n",
              "f2                       0.9402048    0.028712435  0.9248555     0.9798995     0.9467456     0.9467456     0.9027778\n",
              "lift_top_group           2.6893954    0.31052977   2.6           2.275         2.7575758     2.6764705     3.137931\n",
              "loglikelihood            nan          0.0          nan           nan           nan           nan           nan\n",
              "---                      ---          ---          ---           ---           ---           ---           ---\n",
              "mcc                      0.9103449    0.045941036  0.90713674    0.97788036    0.8647188     0.9294054     0.87258327\n",
              "mean_per_class_accuracy  0.9542845    0.02147184   0.9482143     0.9875        0.94174504    0.9618163     0.93214685\n",
              "mean_per_class_error     0.045715507  0.02147184   0.051785715   0.0125        0.058254965   0.038183693   0.06785317\n",
              "mse                      0.043408882  0.011240261  0.051458385   0.025732946   0.053452004   0.039513424   0.04688764\n",
              "pr_auc                   0.98038423   0.011757183  0.9739539     0.99770105    0.9678358     0.9863562     0.9760743\n",
              "precision                0.94656605   0.052259345  0.969697      1.0           0.8648649     0.969697      0.9285714\n",
              "r2                       0.8124159    0.05211368   0.7825883     0.8955419     0.7687377     0.83116066    0.7840509\n",
              "recall                   0.9393422    0.034114175  0.9142857     0.975         0.969697      0.9411765     0.8965517\n",
              "rmse                     0.20675433   0.02875611   0.22684442    0.16041492    0.2311969     0.19877984    0.21653554\n",
              "specificity              0.9692268    0.033030022  0.98214287    1.0           0.9137931     0.98245615    0.9677419\n",
              "[22 rows x 8 columns]\n",
              "\n",
              "\n",
              "Scoring History: \n",
              "    timestamp            duration    number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
              "--  -------------------  ----------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ----------------  -------------------  -----------------  ---------------------------------\n",
              "    2025-05-09 08:28:07  3.930 sec   0                  0.5              0.693147            0.5             0.375824           1                0.624176                         0.5                0.693147              0.5               0.359649             1                  0.640351\n",
              "    2025-05-09 08:28:08  4.287 sec   5                  0.225101         0.220985            0.991465        0.987958           2.66082          0.0307692                        0.225428           0.222521              0.976779          0.978796             2.78049            0.0438596\n",
              "    2025-05-09 08:28:08  4.527 sec   10                 0.182175         0.144104            0.993503        0.991125           2.66082          0.0307692                        0.194942           0.160143              0.97728           0.979975             2.78049            0.0350877\n",
              "    2025-05-09 08:28:08  4.858 sec   15                 0.172352         0.130611            0.994533        0.992725           2.66082          0.0241758                        0.191048           0.152637              0.977113          0.980463             2.78049            0.0350877\n",
              "    2025-05-09 08:28:08  4.919 sec   20                 0.170296         0.1239              0.99408         0.992056           2.66082          0.0263736                        0.193492           0.150659              0.976445          0.979196             2.78049            0.0350877\n",
              "    2025-05-09 08:28:09  5.375 sec   25                 0.170296         0.1239              0.99408         0.992056           2.66082          0.0263736                        0.193495           0.150663              0.976445          0.979196             2.78049            0.0350877\n",
              "    2025-05-09 08:28:09  5.876 sec   30                 0.170295         0.123902            0.99408         0.992056           2.66082          0.0263736                        0.193487           0.150653              0.976445          0.979196             2.78049            0.0350877\n",
              "    2025-05-09 08:28:10  6.325 sec   35                 0.17029          0.123951            0.99408         0.992056           2.66082          0.0263736                        0.193367           0.150506              0.976445          0.979196             2.78049            0.0350877\n",
              "    2025-05-09 08:28:10  6.387 sec   36                 0.170513         0.123949            0.99408         0.992056           2.66082          0.0263736                        0.193961           0.151254              0.976445          0.979196             2.78049            0.0350877\n",
              "\n",
              "Variable Importances: \n",
              "variable              relative_importance    scaled_importance    percentage\n",
              "--------------------  ---------------------  -------------------  ------------\n",
              "concave points_worst  204.282                1                    0.341069\n",
              "area_worst            111.787                0.547218             0.186639\n",
              "concave points_mean   80.5573                0.394343             0.134498\n",
              "radius_worst          72.7003                0.355881             0.12138\n",
              "perimeter_worst       63.8343                0.312481             0.106577\n",
              "texture_worst         22.0758                0.108065             0.0368576\n",
              "concavity_worst       20.4532                0.100122             0.0341486\n",
              "texture_mean          10.5059                0.0514284            0.0175406\n",
              "radius_mean           8.47355                0.0414796            0.0141474\n",
              "concavity_mean        3.36487                0.0164716            0.00561796\n",
              "compactness_se        0.913376               0.00447114           0.00152497\n",
              "\n",
              "[tips]\n",
              "Use `model.explain()` to inspect the model.\n",
              "--\n",
              "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
            ],
            "text/html": [
              "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
              "=============\n",
              "H2OXGBoostEstimator : XGBoost\n",
              "Model Key: XGBoost_1_AutoML_19_20250509_82803\n",
              "</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-123.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-123 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-123 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-123 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-123 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-123 .h2o-table th,\n",
              "#h2o-table-123 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-123 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-123\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Model Summary: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>number_of_trees</th></tr></thead>\n",
              "    <tbody><tr><td></td>\n",
              "<td>36.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: xgboost\n",
              "** Reported on train data. **\n",
              "\n",
              "MSE: 0.029074514855628383\n",
              "RMSE: 0.17051250644931704\n",
              "LogLoss: 0.12394929039565182\n",
              "Mean Per-Class Error: 0.029270653158718393\n",
              "AUC: 0.9940799769376494\n",
              "AUCPR: 0.992056368504806\n",
              "Gini: 0.9881599538752988</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-124.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-124 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-124 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-124 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-124 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-124 .h2o-table th,\n",
              "#h2o-table-124 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-124 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-124\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4925362765789032</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>0</th>\n",
              "<th>1</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>0</td>\n",
              "<td>279.0</td>\n",
              "<td>5.0</td>\n",
              "<td>0.0176</td>\n",
              "<td> (5.0/284.0)</td></tr>\n",
              "<tr><td>1</td>\n",
              "<td>7.0</td>\n",
              "<td>164.0</td>\n",
              "<td>0.0409</td>\n",
              "<td> (7.0/171.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>286.0</td>\n",
              "<td>169.0</td>\n",
              "<td>0.0264</td>\n",
              "<td> (12.0/455.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-125.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-125 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-125 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-125 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-125 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-125 .h2o-table th,\n",
              "#h2o-table-125 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-125 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-125\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.4925363</td>\n",
              "<td>0.9647059</td>\n",
              "<td>38.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.3179893</td>\n",
              "<td>0.9710983</td>\n",
              "<td>49.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.5147656</td>\n",
              "<td>0.9713945</td>\n",
              "<td>37.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.5147656</td>\n",
              "<td>0.9736264</td>\n",
              "<td>37.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>0.9680020</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0588847</td>\n",
              "<td>1.0</td>\n",
              "<td>100.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>0.9680020</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.4925363</td>\n",
              "<td>0.9436960</td>\n",
              "<td>38.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.4028056</td>\n",
              "<td>0.9649123</td>\n",
              "<td>42.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.4925363</td>\n",
              "<td>0.9707293</td>\n",
              "<td>38.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>0.9680020</td>\n",
              "<td>284.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>0.9680020</td>\n",
              "<td>110.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0148769</td>\n",
              "<td>284.0</td>\n",
              "<td>134.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0588847</td>\n",
              "<td>171.0</td>\n",
              "<td>100.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>0.9680020</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>0.9680020</td>\n",
              "<td>0.6432749</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0148769</td>\n",
              "<td>1.0</td>\n",
              "<td>134.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0588847</td>\n",
              "<td>1.0</td>\n",
              "<td>100.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-126.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-126 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-126 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-126 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-126 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-126 .h2o-table th,\n",
              "#h2o-table-126 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-126 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-126\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 37.58 %, avg score: 37.29 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.1340659</td>\n",
              "<td>0.9680020</td>\n",
              "<td>2.6608187</td>\n",
              "<td>2.6608187</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9680020</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9680020</td>\n",
              "<td>0.3567251</td>\n",
              "<td>0.3567251</td>\n",
              "<td>166.0818713</td>\n",
              "<td>166.0818713</td>\n",
              "<td>0.3567251</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.1626374</td>\n",
              "<td>0.9576122</td>\n",
              "<td>2.6608187</td>\n",
              "<td>2.6608187</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9576122</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9661767</td>\n",
              "<td>0.0760234</td>\n",
              "<td>0.4327485</td>\n",
              "<td>166.0818713</td>\n",
              "<td>166.0818713</td>\n",
              "<td>0.4327485</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.2</td>\n",
              "<td>0.9505008</td>\n",
              "<td>2.6608187</td>\n",
              "<td>2.6608187</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9534877</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9638063</td>\n",
              "<td>0.0994152</td>\n",
              "<td>0.5321637</td>\n",
              "<td>166.0818713</td>\n",
              "<td>166.0818713</td>\n",
              "<td>0.5321637</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.3010989</td>\n",
              "<td>0.8075677</td>\n",
              "<td>2.6608187</td>\n",
              "<td>2.6608187</td>\n",
              "<td>1.0</td>\n",
              "<td>0.8971791</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9414351</td>\n",
              "<td>0.2690058</td>\n",
              "<td>0.8011696</td>\n",
              "<td>166.0818713</td>\n",
              "<td>166.0818713</td>\n",
              "<td>0.8011696</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.4</td>\n",
              "<td>0.3147044</td>\n",
              "<td>1.8330084</td>\n",
              "<td>2.4561404</td>\n",
              "<td>0.6888889</td>\n",
              "<td>0.5823229</td>\n",
              "<td>0.9230769</td>\n",
              "<td>0.8526436</td>\n",
              "<td>0.1812865</td>\n",
              "<td>0.9824561</td>\n",
              "<td>83.3008447</td>\n",
              "<td>145.6140351</td>\n",
              "<td>0.9331604</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.5010989</td>\n",
              "<td>0.0766930</td>\n",
              "<td>0.0578439</td>\n",
              "<td>1.9722735</td>\n",
              "<td>0.0217391</td>\n",
              "<td>0.1615786</td>\n",
              "<td>0.7412281</td>\n",
              "<td>0.7132182</td>\n",
              "<td>0.0058480</td>\n",
              "<td>0.9883041</td>\n",
              "<td>-94.2156115</td>\n",
              "<td>97.2273520</td>\n",
              "<td>0.7805576</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>0.6241758</td>\n",
              "<td>0.0503081</td>\n",
              "<td>0.0950292</td>\n",
              "<td>1.6021127</td>\n",
              "<td>0.0357143</td>\n",
              "<td>0.0583980</td>\n",
              "<td>0.6021127</td>\n",
              "<td>0.5840988</td>\n",
              "<td>0.0116959</td>\n",
              "<td>1.0</td>\n",
              "<td>-90.4970760</td>\n",
              "<td>60.2112676</td>\n",
              "<td>0.6021127</td></tr>\n",
              "<tr><td>8</td>\n",
              "<td>0.6989011</td>\n",
              "<td>0.0279195</td>\n",
              "<td>0.0</td>\n",
              "<td>1.4308176</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0365022</td>\n",
              "<td>0.5377358</td>\n",
              "<td>0.5255507</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>43.0817610</td>\n",
              "<td>0.4823944</td></tr>\n",
              "<tr><td>9</td>\n",
              "<td>0.8043956</td>\n",
              "<td>0.0177071</td>\n",
              "<td>0.0</td>\n",
              "<td>1.2431694</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0225316</td>\n",
              "<td>0.4672131</td>\n",
              "<td>0.4595810</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>24.3169399</td>\n",
              "<td>0.3133803</td></tr>\n",
              "<tr><td>10</td>\n",
              "<td>0.9318681</td>\n",
              "<td>0.0175245</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0731132</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0175245</td>\n",
              "<td>0.4033019</td>\n",
              "<td>0.3991110</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>7.3113208</td>\n",
              "<td>0.1091549</td></tr>\n",
              "<tr><td>11</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0148769</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0148769</td>\n",
              "<td>0.3758242</td>\n",
              "<td>0.3729324</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: xgboost\n",
              "** Reported on validation data. **\n",
              "\n",
              "MSE: 0.03762067586537018\n",
              "RMSE: 0.19396050078655236\n",
              "LogLoss: 0.1512542647982658\n",
              "Mean Per-Class Error: 0.03274306715669896\n",
              "AUC: 0.976445038422987\n",
              "AUCPR: 0.9791961628675718\n",
              "Gini: 0.952890076845974</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-127.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-127 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-127 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-127 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-127 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-127 .h2o-table th,\n",
              "#h2o-table-127 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-127 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-127\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.25368359684944153</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>0</th>\n",
              "<th>1</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>0</td>\n",
              "<td>70.0</td>\n",
              "<td>3.0</td>\n",
              "<td>0.0411</td>\n",
              "<td> (3.0/73.0)</td></tr>\n",
              "<tr><td>1</td>\n",
              "<td>1.0</td>\n",
              "<td>40.0</td>\n",
              "<td>0.0244</td>\n",
              "<td> (1.0/41.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>71.0</td>\n",
              "<td>43.0</td>\n",
              "<td>0.0351</td>\n",
              "<td> (4.0/114.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-128.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-128 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-128 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-128 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-128 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-128 .h2o-table th,\n",
              "#h2o-table-128 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-128 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-128\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.2536836</td>\n",
              "<td>0.9523810</td>\n",
              "<td>20.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.2536836</td>\n",
              "<td>0.9661836</td>\n",
              "<td>20.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.7056506</td>\n",
              "<td>0.9729730</td>\n",
              "<td>15.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.2536836</td>\n",
              "<td>0.9649123</td>\n",
              "<td>20.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>0.9680020</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0175245</td>\n",
              "<td>1.0</td>\n",
              "<td>46.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>0.9680020</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.2536836</td>\n",
              "<td>0.9252854</td>\n",
              "<td>20.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.2536836</td>\n",
              "<td>0.9589041</td>\n",
              "<td>20.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.2536836</td>\n",
              "<td>0.9672569</td>\n",
              "<td>20.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>0.9680020</td>\n",
              "<td>73.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>0.9680020</td>\n",
              "<td>27.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0148769</td>\n",
              "<td>73.0</td>\n",
              "<td>47.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0175245</td>\n",
              "<td>41.0</td>\n",
              "<td>46.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>0.9680020</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>0.9680020</td>\n",
              "<td>0.6585366</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0148769</td>\n",
              "<td>1.0</td>\n",
              "<td>47.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0175245</td>\n",
              "<td>1.0</td>\n",
              "<td>46.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-129.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-129 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-129 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-129 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-129 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-129 .h2o-table th,\n",
              "#h2o-table-129 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-129 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-129\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 35.96 %, avg score: 34.85 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.1228070</td>\n",
              "<td>0.9680020</td>\n",
              "<td>2.7804878</td>\n",
              "<td>2.7804878</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9680020</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9680020</td>\n",
              "<td>0.3414634</td>\n",
              "<td>0.3414634</td>\n",
              "<td>178.0487805</td>\n",
              "<td>178.0487805</td>\n",
              "<td>0.3414634</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.1578947</td>\n",
              "<td>0.9543629</td>\n",
              "<td>2.7804878</td>\n",
              "<td>2.7804878</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9551752</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9651516</td>\n",
              "<td>0.0975610</td>\n",
              "<td>0.4390244</td>\n",
              "<td>178.0487805</td>\n",
              "<td>178.0487805</td>\n",
              "<td>0.4390244</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.2105263</td>\n",
              "<td>0.9322835</td>\n",
              "<td>2.7804878</td>\n",
              "<td>2.7804878</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9354083</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9577157</td>\n",
              "<td>0.1463415</td>\n",
              "<td>0.5853659</td>\n",
              "<td>178.0487805</td>\n",
              "<td>178.0487805</td>\n",
              "<td>0.5853659</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.2982456</td>\n",
              "<td>0.7172713</td>\n",
              "<td>2.7804878</td>\n",
              "<td>2.7804878</td>\n",
              "<td>1.0</td>\n",
              "<td>0.8705932</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9320915</td>\n",
              "<td>0.2439024</td>\n",
              "<td>0.8292683</td>\n",
              "<td>178.0487805</td>\n",
              "<td>178.0487805</td>\n",
              "<td>0.8292683</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.4035088</td>\n",
              "<td>0.1690287</td>\n",
              "<td>1.3902439</td>\n",
              "<td>2.4178155</td>\n",
              "<td>0.5</td>\n",
              "<td>0.4511201</td>\n",
              "<td>0.8695652</td>\n",
              "<td>0.8066207</td>\n",
              "<td>0.1463415</td>\n",
              "<td>0.9756098</td>\n",
              "<td>39.0243902</td>\n",
              "<td>141.7815483</td>\n",
              "<td>0.8934180</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.5087719</td>\n",
              "<td>0.0588847</td>\n",
              "<td>0.0</td>\n",
              "<td>1.9175778</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0937150</td>\n",
              "<td>0.6896552</td>\n",
              "<td>0.6591230</td>\n",
              "<td>0.0</td>\n",
              "<td>0.9756098</td>\n",
              "<td>-100.0</td>\n",
              "<td>91.7577796</td>\n",
              "<td>0.7290344</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>0.5964912</td>\n",
              "<td>0.0359404</td>\n",
              "<td>0.0</td>\n",
              "<td>1.6355811</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0470055</td>\n",
              "<td>0.5882353</td>\n",
              "<td>0.5691057</td>\n",
              "<td>0.0</td>\n",
              "<td>0.9756098</td>\n",
              "<td>-100.0</td>\n",
              "<td>63.5581062</td>\n",
              "<td>0.5920481</td></tr>\n",
              "<tr><td>8</td>\n",
              "<td>0.7017544</td>\n",
              "<td>0.0235090</td>\n",
              "<td>0.0</td>\n",
              "<td>1.3902439</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0319946</td>\n",
              "<td>0.5</td>\n",
              "<td>0.4885390</td>\n",
              "<td>0.0</td>\n",
              "<td>0.9756098</td>\n",
              "<td>-100.0</td>\n",
              "<td>39.0243902</td>\n",
              "<td>0.4276646</td></tr>\n",
              "<tr><td>9</td>\n",
              "<td>0.9736842</td>\n",
              "<td>0.0175245</td>\n",
              "<td>0.0896932</td>\n",
              "<td>1.0270270</td>\n",
              "<td>0.0322581</td>\n",
              "<td>0.0192596</td>\n",
              "<td>0.3693694</td>\n",
              "<td>0.3574790</td>\n",
              "<td>0.0243902</td>\n",
              "<td>1.0</td>\n",
              "<td>-91.0306845</td>\n",
              "<td>2.7027027</td>\n",
              "<td>0.0410959</td></tr>\n",
              "<tr><td>10</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0148769</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0148769</td>\n",
              "<td>0.3596491</td>\n",
              "<td>0.3484632</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: xgboost\n",
              "** Reported on cross-validation data. **\n",
              "\n",
              "MSE: 0.04340888001758289\n",
              "RMSE: 0.20834797819413292\n",
              "LogLoss: 0.17091363880751467\n",
              "Mean Per-Class Error: 0.05621447986162589\n",
              "AUC: 0.984340252038547\n",
              "AUCPR: 0.9806080024284464\n",
              "Gini: 0.968680504077094</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-130.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-130 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-130 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-130 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-130 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-130 .h2o-table th,\n",
              "#h2o-table-130 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-130 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-130\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.46881043910980225</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>0</th>\n",
              "<th>1</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>0</td>\n",
              "<td>272.0</td>\n",
              "<td>12.0</td>\n",
              "<td>0.0423</td>\n",
              "<td> (12.0/284.0)</td></tr>\n",
              "<tr><td>1</td>\n",
              "<td>12.0</td>\n",
              "<td>159.0</td>\n",
              "<td>0.0702</td>\n",
              "<td> (12.0/171.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>284.0</td>\n",
              "<td>171.0</td>\n",
              "<td>0.0527</td>\n",
              "<td> (24.0/455.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-131.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-131 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-131 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-131 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-131 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-131 .h2o-table th,\n",
              "#h2o-table-131 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-131 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-131\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.4688104</td>\n",
              "<td>0.9298246</td>\n",
              "<td>65.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.2631769</td>\n",
              "<td>0.9523810</td>\n",
              "<td>90.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.6007378</td>\n",
              "<td>0.9563543</td>\n",
              "<td>46.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.5673153</td>\n",
              "<td>0.9494505</td>\n",
              "<td>50.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>0.9461521</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0347225</td>\n",
              "<td>1.0</td>\n",
              "<td>172.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>0.9461521</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.5673153</td>\n",
              "<td>0.8926275</td>\n",
              "<td>50.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.4238449</td>\n",
              "<td>0.9415205</td>\n",
              "<td>71.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.4688104</td>\n",
              "<td>0.9437855</td>\n",
              "<td>65.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>0.9461521</td>\n",
              "<td>284.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>0.9461521</td>\n",
              "<td>158.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0259651</td>\n",
              "<td>284.0</td>\n",
              "<td>180.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0347225</td>\n",
              "<td>171.0</td>\n",
              "<td>172.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>0.9461521</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>0.9461521</td>\n",
              "<td>0.9239766</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0259651</td>\n",
              "<td>1.0</td>\n",
              "<td>180.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0347225</td>\n",
              "<td>1.0</td>\n",
              "<td>172.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-132.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-132 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-132 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-132 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-132 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-132 .h2o-table th,\n",
              "#h2o-table-132 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-132 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-132\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 37.58 %, avg score: 37.45 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.0285714</td>\n",
              "<td>0.9461521</td>\n",
              "<td>2.6608187</td>\n",
              "<td>2.6608187</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9461521</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9461521</td>\n",
              "<td>0.0760234</td>\n",
              "<td>0.0760234</td>\n",
              "<td>166.0818713</td>\n",
              "<td>166.0818713</td>\n",
              "<td>0.0760234</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.0615385</td>\n",
              "<td>0.9427440</td>\n",
              "<td>2.6608187</td>\n",
              "<td>2.6608187</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9427440</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9443263</td>\n",
              "<td>0.0877193</td>\n",
              "<td>0.1637427</td>\n",
              "<td>166.0818713</td>\n",
              "<td>166.0818713</td>\n",
              "<td>0.1637427</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.1230769</td>\n",
              "<td>0.9371518</td>\n",
              "<td>2.6608187</td>\n",
              "<td>2.6608187</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9395100</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9419182</td>\n",
              "<td>0.1637427</td>\n",
              "<td>0.3274854</td>\n",
              "<td>166.0818713</td>\n",
              "<td>166.0818713</td>\n",
              "<td>0.3274854</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.1802198</td>\n",
              "<td>0.9333059</td>\n",
              "<td>2.6608187</td>\n",
              "<td>2.6608187</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9342200</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9394773</td>\n",
              "<td>0.1520468</td>\n",
              "<td>0.4795322</td>\n",
              "<td>166.0818713</td>\n",
              "<td>166.0818713</td>\n",
              "<td>0.4795322</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.2065934</td>\n",
              "<td>0.9166355</td>\n",
              "<td>2.6608187</td>\n",
              "<td>2.6608187</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9202600</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9370240</td>\n",
              "<td>0.0701754</td>\n",
              "<td>0.5497076</td>\n",
              "<td>166.0818713</td>\n",
              "<td>166.0818713</td>\n",
              "<td>0.5497076</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.3010989</td>\n",
              "<td>0.7457831</td>\n",
              "<td>2.4751802</td>\n",
              "<td>2.6025526</td>\n",
              "<td>0.9302326</td>\n",
              "<td>0.8781437</td>\n",
              "<td>0.9781022</td>\n",
              "<td>0.9185433</td>\n",
              "<td>0.2339181</td>\n",
              "<td>0.7836257</td>\n",
              "<td>147.5180199</td>\n",
              "<td>160.2552610</td>\n",
              "<td>0.7730624</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>0.4</td>\n",
              "<td>0.3783062</td>\n",
              "<td>1.6556205</td>\n",
              "<td>2.3684211</td>\n",
              "<td>0.6222222</td>\n",
              "<td>0.5480268</td>\n",
              "<td>0.8901099</td>\n",
              "<td>0.8269321</td>\n",
              "<td>0.1637427</td>\n",
              "<td>0.9473684</td>\n",
              "<td>65.5620533</td>\n",
              "<td>136.8421053</td>\n",
              "<td>0.8769459</td></tr>\n",
              "<tr><td>8</td>\n",
              "<td>0.5010989</td>\n",
              "<td>0.0993004</td>\n",
              "<td>0.3470633</td>\n",
              "<td>1.9606033</td>\n",
              "<td>0.1304348</td>\n",
              "<td>0.2115066</td>\n",
              "<td>0.7368421</td>\n",
              "<td>0.7027673</td>\n",
              "<td>0.0350877</td>\n",
              "<td>0.9824561</td>\n",
              "<td>-65.2936690</td>\n",
              "<td>96.0603263</td>\n",
              "<td>0.7711885</td></tr>\n",
              "<tr><td>9</td>\n",
              "<td>0.6</td>\n",
              "<td>0.0590016</td>\n",
              "<td>0.0591293</td>\n",
              "<td>1.6471735</td>\n",
              "<td>0.0222222</td>\n",
              "<td>0.0714737</td>\n",
              "<td>0.6190476</td>\n",
              "<td>0.5987079</td>\n",
              "<td>0.0058480</td>\n",
              "<td>0.9883041</td>\n",
              "<td>-94.0870695</td>\n",
              "<td>64.7173489</td>\n",
              "<td>0.6221069</td></tr>\n",
              "<tr><td>10</td>\n",
              "<td>0.6989011</td>\n",
              "<td>0.0447799</td>\n",
              "<td>0.0591293</td>\n",
              "<td>1.4224503</td>\n",
              "<td>0.0222222</td>\n",
              "<td>0.0532896</td>\n",
              "<td>0.5345912</td>\n",
              "<td>0.5215261</td>\n",
              "<td>0.0058480</td>\n",
              "<td>0.9941520</td>\n",
              "<td>-94.0870695</td>\n",
              "<td>42.2450256</td>\n",
              "<td>0.4730253</td></tr>\n",
              "<tr><td>11</td>\n",
              "<td>0.8241758</td>\n",
              "<td>0.0347225</td>\n",
              "<td>0.0466810</td>\n",
              "<td>1.2133333</td>\n",
              "<td>0.0175439</td>\n",
              "<td>0.0376506</td>\n",
              "<td>0.456</td>\n",
              "<td>0.4479770</td>\n",
              "<td>0.0058480</td>\n",
              "<td>1.0</td>\n",
              "<td>-95.3318970</td>\n",
              "<td>21.3333333</td>\n",
              "<td>0.2816901</td></tr>\n",
              "<tr><td>12</td>\n",
              "<td>0.9450549</td>\n",
              "<td>0.0308269</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0581395</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0316372</td>\n",
              "<td>0.3976744</td>\n",
              "<td>0.3947242</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>5.8139535</td>\n",
              "<td>0.0880282</td></tr>\n",
              "<tr><td>13</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0259651</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0273820</td>\n",
              "<td>0.3758242</td>\n",
              "<td>0.3745406</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-133.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-133 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-133 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-133 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-133 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-133 .h2o-table th,\n",
              "#h2o-table-133 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-133 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-133\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Cross-Validation Metrics Summary: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>mean</th>\n",
              "<th>sd</th>\n",
              "<th>cv_1_valid</th>\n",
              "<th>cv_2_valid</th>\n",
              "<th>cv_3_valid</th>\n",
              "<th>cv_4_valid</th>\n",
              "<th>cv_5_valid</th></tr></thead>\n",
              "    <tbody><tr><td>accuracy</td>\n",
              "<td>0.9582418</td>\n",
              "<td>0.0211378</td>\n",
              "<td>0.9560440</td>\n",
              "<td>0.989011</td>\n",
              "<td>0.9340659</td>\n",
              "<td>0.9670330</td>\n",
              "<td>0.9450549</td></tr>\n",
              "<tr><td>aic</td>\n",
              "<td>nan</td>\n",
              "<td>0.0</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td></tr>\n",
              "<tr><td>auc</td>\n",
              "<td>0.9839799</td>\n",
              "<td>0.0125062</td>\n",
              "<td>0.9747449</td>\n",
              "<td>0.9980392</td>\n",
              "<td>0.9676071</td>\n",
              "<td>0.9917440</td>\n",
              "<td>0.9877642</td></tr>\n",
              "<tr><td>err</td>\n",
              "<td>0.0417582</td>\n",
              "<td>0.0211378</td>\n",
              "<td>0.0439560</td>\n",
              "<td>0.0109890</td>\n",
              "<td>0.0659341</td>\n",
              "<td>0.0329670</td>\n",
              "<td>0.0549451</td></tr>\n",
              "<tr><td>err_count</td>\n",
              "<td>3.8</td>\n",
              "<td>1.9235384</td>\n",
              "<td>4.0</td>\n",
              "<td>1.0</td>\n",
              "<td>6.0</td>\n",
              "<td>3.0</td>\n",
              "<td>5.0</td></tr>\n",
              "<tr><td>f0point5</td>\n",
              "<td>0.9445602</td>\n",
              "<td>0.0426289</td>\n",
              "<td>0.9580838</td>\n",
              "<td>0.9948980</td>\n",
              "<td>0.8839779</td>\n",
              "<td>0.9638554</td>\n",
              "<td>0.9219858</td></tr>\n",
              "<tr><td>f1</td>\n",
              "<td>0.9420617</td>\n",
              "<td>0.0311558</td>\n",
              "<td>0.9411765</td>\n",
              "<td>0.9873418</td>\n",
              "<td>0.9142857</td>\n",
              "<td>0.9552239</td>\n",
              "<td>0.9122807</td></tr>\n",
              "<tr><td>f2</td>\n",
              "<td>0.9402048</td>\n",
              "<td>0.0287124</td>\n",
              "<td>0.9248555</td>\n",
              "<td>0.9798995</td>\n",
              "<td>0.9467456</td>\n",
              "<td>0.9467456</td>\n",
              "<td>0.9027778</td></tr>\n",
              "<tr><td>lift_top_group</td>\n",
              "<td>2.6893954</td>\n",
              "<td>0.3105298</td>\n",
              "<td>2.6</td>\n",
              "<td>2.275</td>\n",
              "<td>2.7575758</td>\n",
              "<td>2.6764705</td>\n",
              "<td>3.137931</td></tr>\n",
              "<tr><td>loglikelihood</td>\n",
              "<td>nan</td>\n",
              "<td>0.0</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td></tr>\n",
              "<tr><td>---</td>\n",
              "<td>---</td>\n",
              "<td>---</td>\n",
              "<td>---</td>\n",
              "<td>---</td>\n",
              "<td>---</td>\n",
              "<td>---</td>\n",
              "<td>---</td></tr>\n",
              "<tr><td>mcc</td>\n",
              "<td>0.9103449</td>\n",
              "<td>0.0459410</td>\n",
              "<td>0.9071367</td>\n",
              "<td>0.9778804</td>\n",
              "<td>0.8647188</td>\n",
              "<td>0.9294054</td>\n",
              "<td>0.8725833</td></tr>\n",
              "<tr><td>mean_per_class_accuracy</td>\n",
              "<td>0.9542845</td>\n",
              "<td>0.0214718</td>\n",
              "<td>0.9482143</td>\n",
              "<td>0.9875</td>\n",
              "<td>0.9417450</td>\n",
              "<td>0.9618163</td>\n",
              "<td>0.9321468</td></tr>\n",
              "<tr><td>mean_per_class_error</td>\n",
              "<td>0.0457155</td>\n",
              "<td>0.0214718</td>\n",
              "<td>0.0517857</td>\n",
              "<td>0.0125</td>\n",
              "<td>0.0582550</td>\n",
              "<td>0.0381837</td>\n",
              "<td>0.0678532</td></tr>\n",
              "<tr><td>mse</td>\n",
              "<td>0.0434089</td>\n",
              "<td>0.0112403</td>\n",
              "<td>0.0514584</td>\n",
              "<td>0.0257329</td>\n",
              "<td>0.0534520</td>\n",
              "<td>0.0395134</td>\n",
              "<td>0.0468876</td></tr>\n",
              "<tr><td>pr_auc</td>\n",
              "<td>0.9803842</td>\n",
              "<td>0.0117572</td>\n",
              "<td>0.9739539</td>\n",
              "<td>0.9977010</td>\n",
              "<td>0.9678358</td>\n",
              "<td>0.9863562</td>\n",
              "<td>0.9760743</td></tr>\n",
              "<tr><td>precision</td>\n",
              "<td>0.9465661</td>\n",
              "<td>0.0522593</td>\n",
              "<td>0.969697</td>\n",
              "<td>1.0</td>\n",
              "<td>0.8648649</td>\n",
              "<td>0.969697</td>\n",
              "<td>0.9285714</td></tr>\n",
              "<tr><td>r2</td>\n",
              "<td>0.8124159</td>\n",
              "<td>0.0521137</td>\n",
              "<td>0.7825883</td>\n",
              "<td>0.8955419</td>\n",
              "<td>0.7687377</td>\n",
              "<td>0.8311607</td>\n",
              "<td>0.7840509</td></tr>\n",
              "<tr><td>recall</td>\n",
              "<td>0.9393422</td>\n",
              "<td>0.0341142</td>\n",
              "<td>0.9142857</td>\n",
              "<td>0.975</td>\n",
              "<td>0.969697</td>\n",
              "<td>0.9411765</td>\n",
              "<td>0.8965517</td></tr>\n",
              "<tr><td>rmse</td>\n",
              "<td>0.2067543</td>\n",
              "<td>0.0287561</td>\n",
              "<td>0.2268444</td>\n",
              "<td>0.1604149</td>\n",
              "<td>0.2311969</td>\n",
              "<td>0.1987798</td>\n",
              "<td>0.2165355</td></tr>\n",
              "<tr><td>specificity</td>\n",
              "<td>0.9692268</td>\n",
              "<td>0.0330300</td>\n",
              "<td>0.9821429</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9137931</td>\n",
              "<td>0.9824561</td>\n",
              "<td>0.9677419</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "<pre style='font-size: smaller; margin-bottom: 1em;'>[22 rows x 8 columns]</pre></div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-134.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-134 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-134 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-134 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-134 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-134 .h2o-table th,\n",
              "#h2o-table-134 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-134 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-134\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Scoring History: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>timestamp</th>\n",
              "<th>duration</th>\n",
              "<th>number_of_trees</th>\n",
              "<th>training_rmse</th>\n",
              "<th>training_logloss</th>\n",
              "<th>training_auc</th>\n",
              "<th>training_pr_auc</th>\n",
              "<th>training_lift</th>\n",
              "<th>training_classification_error</th>\n",
              "<th>validation_rmse</th>\n",
              "<th>validation_logloss</th>\n",
              "<th>validation_auc</th>\n",
              "<th>validation_pr_auc</th>\n",
              "<th>validation_lift</th>\n",
              "<th>validation_classification_error</th></tr></thead>\n",
              "    <tbody><tr><td></td>\n",
              "<td>2025-05-09 08:28:07</td>\n",
              "<td> 3.930 sec</td>\n",
              "<td>0.0</td>\n",
              "<td>0.5</td>\n",
              "<td>0.6931472</td>\n",
              "<td>0.5</td>\n",
              "<td>0.3758242</td>\n",
              "<td>1.0</td>\n",
              "<td>0.6241758</td>\n",
              "<td>0.5</td>\n",
              "<td>0.6931472</td>\n",
              "<td>0.5</td>\n",
              "<td>0.3596491</td>\n",
              "<td>1.0</td>\n",
              "<td>0.6403509</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2025-05-09 08:28:08</td>\n",
              "<td> 4.287 sec</td>\n",
              "<td>5.0</td>\n",
              "<td>0.2251009</td>\n",
              "<td>0.2209849</td>\n",
              "<td>0.9914649</td>\n",
              "<td>0.9879580</td>\n",
              "<td>2.6608187</td>\n",
              "<td>0.0307692</td>\n",
              "<td>0.2254283</td>\n",
              "<td>0.2225214</td>\n",
              "<td>0.9767792</td>\n",
              "<td>0.9787964</td>\n",
              "<td>2.7804878</td>\n",
              "<td>0.0438596</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2025-05-09 08:28:08</td>\n",
              "<td> 4.527 sec</td>\n",
              "<td>10.0</td>\n",
              "<td>0.1821748</td>\n",
              "<td>0.1441039</td>\n",
              "<td>0.9935034</td>\n",
              "<td>0.9911247</td>\n",
              "<td>2.6608187</td>\n",
              "<td>0.0307692</td>\n",
              "<td>0.1949417</td>\n",
              "<td>0.1601430</td>\n",
              "<td>0.9772803</td>\n",
              "<td>0.9799751</td>\n",
              "<td>2.7804878</td>\n",
              "<td>0.0350877</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2025-05-09 08:28:08</td>\n",
              "<td> 4.858 sec</td>\n",
              "<td>15.0</td>\n",
              "<td>0.1723523</td>\n",
              "<td>0.1306105</td>\n",
              "<td>0.9945330</td>\n",
              "<td>0.9927252</td>\n",
              "<td>2.6608187</td>\n",
              "<td>0.0241758</td>\n",
              "<td>0.1910482</td>\n",
              "<td>0.1526369</td>\n",
              "<td>0.9771133</td>\n",
              "<td>0.9804633</td>\n",
              "<td>2.7804878</td>\n",
              "<td>0.0350877</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2025-05-09 08:28:08</td>\n",
              "<td> 4.919 sec</td>\n",
              "<td>20.0</td>\n",
              "<td>0.1702960</td>\n",
              "<td>0.1239005</td>\n",
              "<td>0.9940800</td>\n",
              "<td>0.9920564</td>\n",
              "<td>2.6608187</td>\n",
              "<td>0.0263736</td>\n",
              "<td>0.1934925</td>\n",
              "<td>0.1506594</td>\n",
              "<td>0.9764450</td>\n",
              "<td>0.9791962</td>\n",
              "<td>2.7804878</td>\n",
              "<td>0.0350877</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2025-05-09 08:28:09</td>\n",
              "<td> 5.375 sec</td>\n",
              "<td>25.0</td>\n",
              "<td>0.1702965</td>\n",
              "<td>0.1238999</td>\n",
              "<td>0.9940800</td>\n",
              "<td>0.9920564</td>\n",
              "<td>2.6608187</td>\n",
              "<td>0.0263736</td>\n",
              "<td>0.1934951</td>\n",
              "<td>0.1506626</td>\n",
              "<td>0.9764450</td>\n",
              "<td>0.9791962</td>\n",
              "<td>2.7804878</td>\n",
              "<td>0.0350877</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2025-05-09 08:28:09</td>\n",
              "<td> 5.876 sec</td>\n",
              "<td>30.0</td>\n",
              "<td>0.1702950</td>\n",
              "<td>0.1239018</td>\n",
              "<td>0.9940800</td>\n",
              "<td>0.9920564</td>\n",
              "<td>2.6608187</td>\n",
              "<td>0.0263736</td>\n",
              "<td>0.1934870</td>\n",
              "<td>0.1506526</td>\n",
              "<td>0.9764450</td>\n",
              "<td>0.9791962</td>\n",
              "<td>2.7804878</td>\n",
              "<td>0.0350877</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2025-05-09 08:28:10</td>\n",
              "<td> 6.325 sec</td>\n",
              "<td>35.0</td>\n",
              "<td>0.1702896</td>\n",
              "<td>0.1239514</td>\n",
              "<td>0.9940800</td>\n",
              "<td>0.9920564</td>\n",
              "<td>2.6608187</td>\n",
              "<td>0.0263736</td>\n",
              "<td>0.1933670</td>\n",
              "<td>0.1505057</td>\n",
              "<td>0.9764450</td>\n",
              "<td>0.9791962</td>\n",
              "<td>2.7804878</td>\n",
              "<td>0.0350877</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2025-05-09 08:28:10</td>\n",
              "<td> 6.387 sec</td>\n",
              "<td>36.0</td>\n",
              "<td>0.1705125</td>\n",
              "<td>0.1239493</td>\n",
              "<td>0.9940800</td>\n",
              "<td>0.9920564</td>\n",
              "<td>2.6608187</td>\n",
              "<td>0.0263736</td>\n",
              "<td>0.1939605</td>\n",
              "<td>0.1512543</td>\n",
              "<td>0.9764450</td>\n",
              "<td>0.9791962</td>\n",
              "<td>2.7804878</td>\n",
              "<td>0.0350877</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-135.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-135 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-135 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-135 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-135 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-135 .h2o-table th,\n",
              "#h2o-table-135 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-135 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-135\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Variable Importances: </caption>\n",
              "    <thead><tr><th>variable</th>\n",
              "<th>relative_importance</th>\n",
              "<th>scaled_importance</th>\n",
              "<th>percentage</th></tr></thead>\n",
              "    <tbody><tr><td>concave points_worst</td>\n",
              "<td>204.2824097</td>\n",
              "<td>1.0</td>\n",
              "<td>0.3410687</td></tr>\n",
              "<tr><td>area_worst</td>\n",
              "<td>111.7869415</td>\n",
              "<td>0.5472177</td>\n",
              "<td>0.1866388</td></tr>\n",
              "<tr><td>concave points_mean</td>\n",
              "<td>80.5573425</td>\n",
              "<td>0.3943430</td>\n",
              "<td>0.1344981</td></tr>\n",
              "<tr><td>radius_worst</td>\n",
              "<td>72.7002869</td>\n",
              "<td>0.3558813</td>\n",
              "<td>0.1213800</td></tr>\n",
              "<tr><td>perimeter_worst</td>\n",
              "<td>63.8343277</td>\n",
              "<td>0.3124808</td>\n",
              "<td>0.1065774</td></tr>\n",
              "<tr><td>texture_worst</td>\n",
              "<td>22.0757656</td>\n",
              "<td>0.1080649</td>\n",
              "<td>0.0368576</td></tr>\n",
              "<tr><td>concavity_worst</td>\n",
              "<td>20.4532471</td>\n",
              "<td>0.1001224</td>\n",
              "<td>0.0341486</td></tr>\n",
              "<tr><td>texture_mean</td>\n",
              "<td>10.5059090</td>\n",
              "<td>0.0514284</td>\n",
              "<td>0.0175406</td></tr>\n",
              "<tr><td>radius_mean</td>\n",
              "<td>8.4735489</td>\n",
              "<td>0.0414796</td>\n",
              "<td>0.0141474</td></tr>\n",
              "<tr><td>concavity_mean</td>\n",
              "<td>3.3648682</td>\n",
              "<td>0.0164716</td>\n",
              "<td>0.0056180</td></tr>\n",
              "<tr><td>compactness_se</td>\n",
              "<td>0.9133759</td>\n",
              "<td>0.0044711</td>\n",
              "<td>0.0015250</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
              "\n",
              "[tips]\n",
              "Use `model.explain()` to inspect the model.\n",
              "--\n",
              "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
            ]
          },
          "metadata": {},
          "execution_count": 307
        }
      ],
      "source": [
        "best_model = aml.get_best_model()\n",
        "best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 308,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_PyYFNMs97_",
        "outputId": "d162f933-e9ef-4b40-c332-06b59124b965"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.5147656202316284, 0.9736263736263736]]"
            ]
          },
          "metadata": {},
          "execution_count": 308
        }
      ],
      "source": [
        "best_model.model_performance(train).accuracy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 309,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bl8kINUgAHpF",
        "outputId": "b67abaaa-7b88-4d9d-a86a-851def31cd3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
              "       0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
              "       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
              "       1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 309
        }
      ],
      "source": [
        "y_test_h2o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 310,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLbzNA84DPJO",
        "outputId": "c463655e-2bb1-4fb4-d0a5-faae32b57fef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n",
            "Parse progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n",
            "AutoML progress: |\n",
            "08:29:12.798: Project: AutoML_20_20250509_82912\n",
            "08:29:12.800: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n",
            "08:29:12.801: Setting stopping tolerance adaptively based on the training frame: 0.04688072309384954\n",
            "08:29:12.801: Build control seed: 123\n",
            "08:29:12.801: training frame: Frame key: AutoML_20_20250509_82912_training_py_157_sid_a292    cols: 31    rows: 455  chunks: 1    size: 111919  checksum: -6999049652048799504\n",
            "08:29:12.801: validation frame: Frame key: py_158_sid_a292    cols: 31    rows: 114  chunks: 1    size: 30037  checksum: 1244986154056216624\n",
            "08:29:12.801: leaderboard frame: NULL\n",
            "08:29:12.801: blending frame: NULL\n",
            "08:29:12.801: response column: diagnosis\n",
            "08:29:12.801: fold column: null\n",
            "08:29:12.801: weights column: null\n",
            "08:29:12.801: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (7g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (7g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (6g, 60w)]}, {StackedEnsemble : [monotonic (9g, 10w), best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
            "08:29:12.802: AutoML job created: 2025.05.09 08:29:12.797\n",
            "08:29:12.808: AutoML build started: 2025.05.09 08:29:12.808\n",
            "08:29:12.810: AutoML: starting XGBoost_1_AutoML_20_20250509_82912 model training\n",
            "\n",
            "â–ˆâ–ˆ\n",
            "08:29:22.386: New leader: XGBoost_1_AutoML_20_20250509_82912, accuracy: 0.9494505494505494\n",
            "08:29:22.387: AutoML: starting GLM_1_AutoML_20_20250509_82912 model training\n",
            "\n",
            "\n",
            "08:29:24.691: AutoML: starting GBM_1_AutoML_20_20250509_82912 model training\n",
            "\n",
            "â–ˆâ–ˆ\n",
            "08:29:31.544: AutoML: starting XGBoost_2_AutoML_20_20250509_82912 model training\n",
            "\n",
            "â–ˆ\n",
            "08:29:39.953: AutoML: starting DRF_1_AutoML_20_20250509_82912 model training\n",
            "\n",
            "â–ˆ\n",
            "08:29:41.976: AutoML: starting GBM_2_AutoML_20_20250509_82912 model training\n",
            "\n",
            "â–ˆâ–ˆ\n",
            "08:29:49.684: AutoML: starting GBM_3_AutoML_20_20250509_82912 model training\n",
            "\n",
            "â–ˆ\n",
            "08:29:56.321: AutoML: starting GBM_4_AutoML_20_20250509_82912 model training\n",
            "\n",
            "â–ˆ\n",
            "08:30:01.653: AutoML: starting XGBoost_3_AutoML_20_20250509_82912 model training\n",
            "\n",
            "â–ˆâ–ˆ\n",
            "08:30:08.467: AutoML: starting XRT_1_AutoML_20_20250509_82912 model training\n",
            "08:30:10.262: No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'monotonic'.\n",
            "08:30:10.264: AutoML: starting StackedEnsemble_BestOfFamily_1_AutoML_20_20250509_82912 model training\n",
            "\n",
            "\n",
            "08:30:11.826: AutoML: starting StackedEnsemble_AllModels_1_AutoML_20_20250509_82912 model training\n",
            "\n",
            "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n",
            "\n",
            "08:30:13.553: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GLM : [def_1 (1g, 10w)]}, {GBM : [def_5 (1g, 10w)]}, {XGBoost : [def_1 (2g, 10w)]}, {DRF : [def_1 (2g, 10w)]}, {GBM : [def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w)]}, {XGBoost : [def_3 (3g, 10w)]}, {DRF : [XRT (3g, 10w)]}, {StackedEnsemble : [best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
            "08:30:13.553: AutoML build stopped: 2025.05.09 08:30:13.553\n",
            "08:30:13.553: AutoML build done: built 10 models\n",
            "08:30:13.553: AutoML duration:  1 min  0.745 sec\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def SCVhdf(df):\n",
        "  #train, valid = hdf.split_frame(ratios=[.8], seed=123)\n",
        "  #hdf = h2o.H2OFrame(df)\n",
        "  #hdf[\"diagnosis\"] = hdf[\"diagnosis\"].asfactor()\n",
        "  hy = \"diagnosis\"\n",
        "  hx = list(df.columns)\n",
        "  hx.remove(hy)\n",
        "  hdf  = df.copy()\n",
        "  hdf.iloc[:,1:] = StandardScaler().fit_transform(hdf.iloc[:,1:])\n",
        "  hdf.iloc[:,0] = LabelEncoder().fit_transform(hdf.iloc[:,0])\n",
        "  hdf.iloc[:,0] = hdf.iloc[:,0].astype('category')\n",
        "  train1, valid1 = train_test_split(hdf, test_size=0.2,random_state=123)\n",
        "  train = h2o.H2OFrame(train1)\n",
        "  valid = h2o.H2OFrame(valid1)\n",
        "  train[\"diagnosis\"] = train[\"diagnosis\"].asfactor()\n",
        "  valid[\"diagnosis\"] = valid[\"diagnosis\"].asfactor()\n",
        "\n",
        "  st = time.time()\n",
        "  aml = H2OAutoML(max_models = 10, seed = 123, verbosity=\"info\", nfolds=5, sort_metric='accuracy')\n",
        "  aml.train(x = hx, y = hy, training_frame = train,\n",
        "            validation_frame = valid)\n",
        "  autoend = time.time() - st\n",
        "\n",
        "  best_model = aml.get_best_model()\n",
        "  HATr  = best_model.model_performance(train)\n",
        "  HATe  = best_model.model_performance(valid)\n",
        "  return HATr, HATe\n",
        "SCVHATr, SCVHATe = SCVhdf(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 310,
      "metadata": {
        "id": "PGV6AdtfDnUh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 311,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnycQ8zxB8np",
        "outputId": "171f06f2-4325-4e57-e114-6a2095a90c78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-311-5d92bdc4dfd6>:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1.36884527 -0.73054276  1.36884527  1.36884527  1.36884527  1.36884527\n",
            " -0.73054276  1.36884527  1.36884527 -0.73054276  1.36884527 -0.73054276\n",
            " -0.73054276  1.36884527 -0.73054276  1.36884527 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276  1.36884527 -0.73054276\n",
            "  1.36884527  1.36884527 -0.73054276  1.36884527 -0.73054276 -0.73054276\n",
            " -0.73054276  1.36884527 -0.73054276 -0.73054276  1.36884527 -0.73054276\n",
            "  1.36884527  1.36884527 -0.73054276 -0.73054276  1.36884527 -0.73054276\n",
            " -0.73054276  1.36884527 -0.73054276 -0.73054276  1.36884527 -0.73054276\n",
            "  1.36884527 -0.73054276 -0.73054276 -0.73054276 -0.73054276  1.36884527\n",
            "  1.36884527  1.36884527 -0.73054276  1.36884527  1.36884527 -0.73054276\n",
            " -0.73054276 -0.73054276  1.36884527 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276  1.36884527 -0.73054276  1.36884527 -0.73054276 -0.73054276\n",
            " -0.73054276  1.36884527 -0.73054276 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276  1.36884527\n",
            " -0.73054276 -0.73054276 -0.73054276  1.36884527 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276\n",
            "  1.36884527 -0.73054276  1.36884527 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276  1.36884527\n",
            "  1.36884527  1.36884527 -0.73054276  1.36884527 -0.73054276  1.36884527\n",
            " -0.73054276 -0.73054276 -0.73054276  1.36884527 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276  1.36884527 -0.73054276  1.36884527 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276  1.36884527  1.36884527 -0.73054276\n",
            " -0.73054276 -0.73054276  1.36884527 -0.73054276 -0.73054276  1.36884527\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276  1.36884527\n",
            "  1.36884527 -0.73054276  1.36884527  1.36884527  1.36884527 -0.73054276\n",
            " -0.73054276  1.36884527 -0.73054276  1.36884527 -0.73054276  1.36884527\n",
            " -0.73054276  1.36884527 -0.73054276 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276  1.36884527 -0.73054276 -0.73054276\n",
            " -0.73054276  1.36884527 -0.73054276 -0.73054276  1.36884527  1.36884527\n",
            "  1.36884527  1.36884527 -0.73054276  1.36884527 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276  1.36884527  1.36884527 -0.73054276\n",
            " -0.73054276 -0.73054276  1.36884527 -0.73054276 -0.73054276  1.36884527\n",
            " -0.73054276 -0.73054276 -0.73054276  1.36884527 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276  1.36884527 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276  1.36884527 -0.73054276 -0.73054276\n",
            "  1.36884527 -0.73054276 -0.73054276 -0.73054276  1.36884527  1.36884527\n",
            "  1.36884527  1.36884527 -0.73054276  1.36884527  1.36884527  1.36884527\n",
            "  1.36884527 -0.73054276  1.36884527 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276  1.36884527 -0.73054276 -0.73054276\n",
            "  1.36884527  1.36884527  1.36884527 -0.73054276 -0.73054276  1.36884527\n",
            "  1.36884527  1.36884527 -0.73054276  1.36884527 -0.73054276 -0.73054276\n",
            "  1.36884527 -0.73054276  1.36884527 -0.73054276  1.36884527 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276  1.36884527 -0.73054276\n",
            "  1.36884527 -0.73054276  1.36884527 -0.73054276 -0.73054276 -0.73054276\n",
            "  1.36884527 -0.73054276  1.36884527 -0.73054276 -0.73054276 -0.73054276\n",
            "  1.36884527 -0.73054276 -0.73054276 -0.73054276 -0.73054276  1.36884527\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276  1.36884527 -0.73054276  1.36884527 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276  1.36884527  1.36884527 -0.73054276\n",
            "  1.36884527  1.36884527 -0.73054276 -0.73054276 -0.73054276  1.36884527\n",
            " -0.73054276  1.36884527  1.36884527 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276  1.36884527 -0.73054276  1.36884527 -0.73054276\n",
            "  1.36884527 -0.73054276  1.36884527  1.36884527 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276  1.36884527  1.36884527  1.36884527\n",
            "  1.36884527  1.36884527  1.36884527  1.36884527  1.36884527  1.36884527\n",
            "  1.36884527  1.36884527 -0.73054276  1.36884527  1.36884527  1.36884527\n",
            " -0.73054276 -0.73054276  1.36884527  1.36884527 -0.73054276 -0.73054276\n",
            "  1.36884527 -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276\n",
            "  1.36884527  1.36884527 -0.73054276 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276  1.36884527  1.36884527  1.36884527\n",
            "  1.36884527 -0.73054276 -0.73054276  1.36884527  1.36884527  1.36884527\n",
            "  1.36884527  1.36884527 -0.73054276  1.36884527  1.36884527 -0.73054276\n",
            " -0.73054276  1.36884527  1.36884527  1.36884527  1.36884527 -0.73054276\n",
            " -0.73054276  1.36884527 -0.73054276 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276  1.36884527  1.36884527 -0.73054276 -0.73054276 -0.73054276\n",
            "  1.36884527  1.36884527 -0.73054276 -0.73054276  1.36884527  1.36884527\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276  1.36884527 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276  1.36884527 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276  1.36884527 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276\n",
            "  1.36884527  1.36884527  1.36884527  1.36884527  1.36884527  1.36884527\n",
            "  1.36884527  1.36884527  1.36884527 -0.73054276  1.36884527  1.36884527\n",
            "  1.36884527  1.36884527  1.36884527  1.36884527 -0.73054276 -0.73054276\n",
            "  1.36884527  1.36884527 -0.73054276  1.36884527 -0.73054276 -0.73054276\n",
            "  1.36884527 -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276  1.36884527\n",
            "  1.36884527  1.36884527 -0.73054276 -0.73054276 -0.73054276  1.36884527\n",
            "  1.36884527  1.36884527 -0.73054276 -0.73054276 -0.73054276  1.36884527\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276  1.36884527\n",
            " -0.73054276  1.36884527  1.36884527  1.36884527 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276  1.36884527 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276  1.36884527\n",
            "  1.36884527 -0.73054276 -0.73054276 -0.73054276 -0.73054276  1.36884527\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276  1.36884527 -0.73054276 -0.73054276  1.36884527  1.36884527\n",
            "  1.36884527 -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276  1.36884527\n",
            " -0.73054276  1.36884527  1.36884527  1.36884527 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  shdf.iloc[:,0:6] = StandardScaler().fit_transform(shdf.iloc[:,0:6])\n",
            "<ipython-input-311-5d92bdc4dfd6>:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1.34274185  1.34274185  1.34274185  1.34274185  1.34274185  1.34274185\n",
            " -0.74474479  1.34274185  1.34274185 -0.74474479  1.34274185 -0.74474479\n",
            " -0.74474479  1.34274185 -0.74474479  1.34274185 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479  1.34274185 -0.74474479\n",
            "  1.34274185  1.34274185 -0.74474479  1.34274185 -0.74474479 -0.74474479\n",
            " -0.74474479  1.34274185 -0.74474479 -0.74474479  1.34274185  1.34274185\n",
            "  1.34274185  1.34274185 -0.74474479 -0.74474479  1.34274185 -0.74474479\n",
            " -0.74474479  1.34274185 -0.74474479 -0.74474479  1.34274185 -0.74474479\n",
            "  1.34274185 -0.74474479 -0.74474479 -0.74474479 -0.74474479  1.34274185\n",
            "  1.34274185  1.34274185 -0.74474479  1.34274185  1.34274185 -0.74474479\n",
            " -0.74474479 -0.74474479  1.34274185 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479  1.34274185 -0.74474479  1.34274185 -0.74474479 -0.74474479\n",
            " -0.74474479  1.34274185 -0.74474479 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479  1.34274185\n",
            " -0.74474479 -0.74474479 -0.74474479  1.34274185 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479  1.34274185 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479  1.34274185\n",
            "  1.34274185  1.34274185 -0.74474479  1.34274185  1.34274185  1.34274185\n",
            " -0.74474479 -0.74474479 -0.74474479  1.34274185 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479  1.34274185 -0.74474479  1.34274185 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479  1.34274185  1.34274185 -0.74474479\n",
            " -0.74474479 -0.74474479  1.34274185 -0.74474479 -0.74474479  1.34274185\n",
            " -0.74474479 -0.74474479 -0.74474479  1.34274185 -0.74474479  1.34274185\n",
            "  1.34274185 -0.74474479  1.34274185 -0.74474479  1.34274185 -0.74474479\n",
            " -0.74474479  1.34274185 -0.74474479  1.34274185  1.34274185  1.34274185\n",
            " -0.74474479  1.34274185 -0.74474479 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479  1.34274185 -0.74474479 -0.74474479\n",
            " -0.74474479  1.34274185 -0.74474479 -0.74474479  1.34274185  1.34274185\n",
            "  1.34274185  1.34274185 -0.74474479  1.34274185 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479  1.34274185  1.34274185 -0.74474479\n",
            " -0.74474479 -0.74474479  1.34274185 -0.74474479 -0.74474479  1.34274185\n",
            " -0.74474479 -0.74474479 -0.74474479  1.34274185 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479  1.34274185 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479  1.34274185  1.34274185 -0.74474479\n",
            "  1.34274185 -0.74474479 -0.74474479 -0.74474479  1.34274185  1.34274185\n",
            "  1.34274185  1.34274185 -0.74474479  1.34274185  1.34274185  1.34274185\n",
            "  1.34274185 -0.74474479  1.34274185 -0.74474479 -0.74474479  1.34274185\n",
            " -0.74474479 -0.74474479 -0.74474479  1.34274185 -0.74474479 -0.74474479\n",
            "  1.34274185  1.34274185  1.34274185 -0.74474479 -0.74474479 -0.74474479\n",
            "  1.34274185  1.34274185 -0.74474479  1.34274185 -0.74474479 -0.74474479\n",
            "  1.34274185 -0.74474479 -0.74474479 -0.74474479  1.34274185 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479  1.34274185 -0.74474479\n",
            "  1.34274185 -0.74474479  1.34274185 -0.74474479 -0.74474479 -0.74474479\n",
            "  1.34274185 -0.74474479  1.34274185 -0.74474479 -0.74474479 -0.74474479\n",
            "  1.34274185 -0.74474479 -0.74474479 -0.74474479 -0.74474479  1.34274185\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479  1.34274185 -0.74474479  1.34274185 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479  1.34274185  1.34274185 -0.74474479\n",
            "  1.34274185  1.34274185 -0.74474479 -0.74474479 -0.74474479  1.34274185\n",
            " -0.74474479  1.34274185  1.34274185 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479  1.34274185 -0.74474479  1.34274185 -0.74474479\n",
            "  1.34274185 -0.74474479  1.34274185  1.34274185 -0.74474479 -0.74474479\n",
            " -0.74474479  1.34274185 -0.74474479  1.34274185  1.34274185  1.34274185\n",
            "  1.34274185  1.34274185  1.34274185  1.34274185  1.34274185  1.34274185\n",
            "  1.34274185  1.34274185 -0.74474479  1.34274185  1.34274185 -0.74474479\n",
            " -0.74474479 -0.74474479  1.34274185  1.34274185  1.34274185 -0.74474479\n",
            "  1.34274185 -0.74474479 -0.74474479 -0.74474479 -0.74474479  1.34274185\n",
            "  1.34274185  1.34274185 -0.74474479 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479  1.34274185  1.34274185  1.34274185\n",
            "  1.34274185 -0.74474479 -0.74474479  1.34274185  1.34274185  1.34274185\n",
            "  1.34274185  1.34274185 -0.74474479  1.34274185  1.34274185 -0.74474479\n",
            " -0.74474479  1.34274185  1.34274185  1.34274185  1.34274185 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479  1.34274185  1.34274185 -0.74474479 -0.74474479 -0.74474479\n",
            "  1.34274185  1.34274185 -0.74474479 -0.74474479  1.34274185  1.34274185\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479  1.34274185 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479  1.34274185 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479  1.34274185 -0.74474479  1.34274185 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479\n",
            "  1.34274185  1.34274185  1.34274185  1.34274185  1.34274185  1.34274185\n",
            "  1.34274185  1.34274185  1.34274185 -0.74474479  1.34274185  1.34274185\n",
            "  1.34274185  1.34274185 -0.74474479  1.34274185 -0.74474479 -0.74474479\n",
            "  1.34274185  1.34274185 -0.74474479  1.34274185 -0.74474479 -0.74474479\n",
            "  1.34274185 -0.74474479  1.34274185 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479  1.34274185\n",
            "  1.34274185  1.34274185 -0.74474479 -0.74474479 -0.74474479  1.34274185\n",
            "  1.34274185  1.34274185 -0.74474479 -0.74474479 -0.74474479  1.34274185\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479  1.34274185\n",
            " -0.74474479  1.34274185  1.34274185  1.34274185 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479  1.34274185 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479  1.34274185\n",
            "  1.34274185 -0.74474479 -0.74474479 -0.74474479 -0.74474479  1.34274185\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479  1.34274185 -0.74474479 -0.74474479  1.34274185  1.34274185\n",
            "  1.34274185 -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479  1.34274185\n",
            " -0.74474479  1.34274185  1.34274185  1.34274185 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  shdf.iloc[:,0:6] = StandardScaler().fit_transform(shdf.iloc[:,0:6])\n",
            "<ipython-input-311-5d92bdc4dfd6>:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1.32745468  1.32745468  1.32745468  1.32745468  1.32745468  1.32745468\n",
            " -0.75332139  1.32745468 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139  1.32745468 -0.75332139  1.32745468  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468 -0.75332139  1.32745468\n",
            " -0.75332139  1.32745468 -0.75332139 -0.75332139  1.32745468  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139 -0.75332139  1.32745468  1.32745468\n",
            " -0.75332139  1.32745468 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            "  1.32745468 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139  1.32745468 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468 -0.75332139  1.32745468\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468  1.32745468 -0.75332139\n",
            " -0.75332139  1.32745468  1.32745468 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139  1.32745468\n",
            "  1.32745468 -0.75332139  1.32745468  1.32745468  1.32745468 -0.75332139\n",
            " -0.75332139  1.32745468 -0.75332139  1.32745468  1.32745468  1.32745468\n",
            " -0.75332139  1.32745468 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139  1.32745468 -0.75332139 -0.75332139  1.32745468  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139 -0.75332139  1.32745468  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468  1.32745468  1.32745468\n",
            "  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            "  1.32745468  1.32745468  1.32745468 -0.75332139 -0.75332139  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            "  1.32745468 -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139 -0.75332139\n",
            "  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139 -0.75332139\n",
            "  1.32745468 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468  1.32745468 -0.75332139\n",
            "  1.32745468  1.32745468 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139  1.32745468  1.32745468 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468 -0.75332139  1.32745468 -0.75332139\n",
            "  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468  1.32745468  1.32745468\n",
            "  1.32745468  1.32745468  1.32745468  1.32745468  1.32745468  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468  1.32745468 -0.75332139  1.32745468\n",
            "  1.32745468 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            "  1.32745468  1.32745468 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468  1.32745468  1.32745468\n",
            "  1.32745468 -0.75332139 -0.75332139 -0.75332139  1.32745468  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468  1.32745468 -0.75332139\n",
            " -0.75332139  1.32745468  1.32745468  1.32745468  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139  1.32745468  1.32745468 -0.75332139 -0.75332139 -0.75332139\n",
            "  1.32745468  1.32745468 -0.75332139 -0.75332139  1.32745468  1.32745468\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            "  1.32745468  1.32745468  1.32745468  1.32745468  1.32745468  1.32745468\n",
            "  1.32745468  1.32745468  1.32745468 -0.75332139  1.32745468  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            "  1.32745468 -0.75332139  1.32745468 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139  1.32745468  1.32745468  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            "  1.32745468 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139  1.32745468 -0.75332139 -0.75332139  1.32745468  1.32745468\n",
            "  1.32745468 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139  1.32745468  1.32745468  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  shdf.iloc[:,0:6] = StandardScaler().fit_transform(shdf.iloc[:,0:6])\n",
            "<ipython-input-311-5d92bdc4dfd6>:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1.32745468  1.32745468  1.32745468  1.32745468  1.32745468  1.32745468\n",
            " -0.75332139  1.32745468  1.32745468 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139  1.32745468 -0.75332139  1.32745468  1.32745468 -0.75332139\n",
            "  1.32745468 -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139  1.32745468 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            "  1.32745468  1.32745468 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139  1.32745468 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            "  1.32745468 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139  1.32745468 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468 -0.75332139  1.32745468\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139  1.32745468\n",
            "  1.32745468 -0.75332139  1.32745468  1.32745468  1.32745468 -0.75332139\n",
            " -0.75332139  1.32745468 -0.75332139  1.32745468  1.32745468  1.32745468\n",
            " -0.75332139  1.32745468 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139  1.32745468 -0.75332139 -0.75332139  1.32745468  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            "  1.32745468 -0.75332139 -0.75332139 -0.75332139  1.32745468  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468  1.32745468  1.32745468\n",
            "  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            "  1.32745468  1.32745468  1.32745468 -0.75332139 -0.75332139 -0.75332139\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            "  1.32745468 -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139 -0.75332139\n",
            "  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139 -0.75332139\n",
            "  1.32745468 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468  1.32745468 -0.75332139\n",
            "  1.32745468  1.32745468  1.32745468 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139  1.32745468  1.32745468 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468 -0.75332139  1.32745468 -0.75332139\n",
            "  1.32745468 -0.75332139  1.32745468  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468  1.32745468  1.32745468\n",
            "  1.32745468  1.32745468  1.32745468  1.32745468  1.32745468  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468  1.32745468  1.32745468 -0.75332139\n",
            "  1.32745468 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468  1.32745468  1.32745468\n",
            "  1.32745468 -0.75332139 -0.75332139  1.32745468  1.32745468  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468  1.32745468 -0.75332139\n",
            " -0.75332139  1.32745468  1.32745468  1.32745468  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139  1.32745468  1.32745468 -0.75332139 -0.75332139 -0.75332139\n",
            "  1.32745468  1.32745468 -0.75332139 -0.75332139  1.32745468  1.32745468\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            "  1.32745468  1.32745468  1.32745468  1.32745468  1.32745468  1.32745468\n",
            "  1.32745468  1.32745468  1.32745468 -0.75332139  1.32745468  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            "  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139  1.32745468 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139  1.32745468  1.32745468  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            "  1.32745468 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            "  1.32745468 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139  1.32745468 -0.75332139 -0.75332139  1.32745468  1.32745468\n",
            "  1.32745468 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139  1.32745468  1.32745468  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  shdf.iloc[:,0:6] = StandardScaler().fit_transform(shdf.iloc[:,0:6])\n",
            "<ipython-input-311-5d92bdc4dfd6>:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1.34789899 -0.74189536  1.34789899  1.34789899  1.34789899  1.34789899\n",
            " -0.74189536  1.34789899 -0.74189536 -0.74189536  1.34789899 -0.74189536\n",
            " -0.74189536  1.34789899 -0.74189536  1.34789899  1.34789899 -0.74189536\n",
            "  1.34789899 -0.74189536 -0.74189536 -0.74189536  1.34789899 -0.74189536\n",
            "  1.34789899  1.34789899 -0.74189536  1.34789899 -0.74189536  1.34789899\n",
            " -0.74189536  1.34789899 -0.74189536 -0.74189536  1.34789899 -0.74189536\n",
            "  1.34789899  1.34789899 -0.74189536 -0.74189536  1.34789899 -0.74189536\n",
            " -0.74189536  1.34789899 -0.74189536 -0.74189536  1.34789899 -0.74189536\n",
            "  1.34789899 -0.74189536 -0.74189536 -0.74189536 -0.74189536  1.34789899\n",
            "  1.34789899  1.34789899 -0.74189536  1.34789899  1.34789899 -0.74189536\n",
            " -0.74189536 -0.74189536  1.34789899 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536  1.34789899 -0.74189536  1.34789899 -0.74189536 -0.74189536\n",
            " -0.74189536  1.34789899 -0.74189536 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536  1.34789899 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536  1.34789899\n",
            " -0.74189536 -0.74189536 -0.74189536  1.34789899 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536  1.34789899 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536  1.34789899\n",
            "  1.34789899  1.34789899 -0.74189536  1.34789899 -0.74189536  1.34789899\n",
            " -0.74189536 -0.74189536 -0.74189536  1.34789899 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536  1.34789899 -0.74189536  1.34789899 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536  1.34789899  1.34789899 -0.74189536\n",
            " -0.74189536  1.34789899  1.34789899 -0.74189536 -0.74189536  1.34789899\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536  1.34789899\n",
            "  1.34789899 -0.74189536  1.34789899 -0.74189536  1.34789899 -0.74189536\n",
            " -0.74189536  1.34789899 -0.74189536  1.34789899 -0.74189536  1.34789899\n",
            " -0.74189536  1.34789899 -0.74189536 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536  1.34789899 -0.74189536 -0.74189536\n",
            " -0.74189536  1.34789899 -0.74189536 -0.74189536  1.34789899  1.34789899\n",
            "  1.34789899  1.34789899 -0.74189536  1.34789899 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536  1.34789899 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536  1.34789899  1.34789899 -0.74189536\n",
            " -0.74189536 -0.74189536  1.34789899 -0.74189536 -0.74189536  1.34789899\n",
            " -0.74189536 -0.74189536 -0.74189536  1.34789899 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536  1.34789899 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536  1.34789899 -0.74189536 -0.74189536\n",
            "  1.34789899 -0.74189536 -0.74189536 -0.74189536  1.34789899  1.34789899\n",
            "  1.34789899  1.34789899 -0.74189536  1.34789899  1.34789899  1.34789899\n",
            "  1.34789899 -0.74189536  1.34789899 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536  1.34789899 -0.74189536 -0.74189536\n",
            "  1.34789899  1.34789899  1.34789899 -0.74189536 -0.74189536  1.34789899\n",
            "  1.34789899  1.34789899 -0.74189536  1.34789899 -0.74189536 -0.74189536\n",
            "  1.34789899 -0.74189536 -0.74189536 -0.74189536  1.34789899 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536  1.34789899 -0.74189536\n",
            "  1.34789899 -0.74189536  1.34789899 -0.74189536 -0.74189536 -0.74189536\n",
            "  1.34789899 -0.74189536  1.34789899 -0.74189536 -0.74189536 -0.74189536\n",
            "  1.34789899 -0.74189536 -0.74189536 -0.74189536 -0.74189536  1.34789899\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536  1.34789899 -0.74189536  1.34789899  1.34789899 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536  1.34789899  1.34789899 -0.74189536\n",
            "  1.34789899  1.34789899 -0.74189536 -0.74189536 -0.74189536  1.34789899\n",
            " -0.74189536  1.34789899  1.34789899 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536  1.34789899 -0.74189536  1.34789899 -0.74189536\n",
            "  1.34789899 -0.74189536  1.34789899  1.34789899 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536  1.34789899  1.34789899  1.34789899\n",
            "  1.34789899  1.34789899  1.34789899  1.34789899  1.34789899  1.34789899\n",
            "  1.34789899  1.34789899 -0.74189536  1.34789899  1.34789899  1.34789899\n",
            " -0.74189536 -0.74189536  1.34789899  1.34789899  1.34789899  1.34789899\n",
            "  1.34789899 -0.74189536 -0.74189536 -0.74189536 -0.74189536  1.34789899\n",
            "  1.34789899  1.34789899 -0.74189536 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536  1.34789899  1.34789899  1.34789899\n",
            "  1.34789899 -0.74189536 -0.74189536  1.34789899  1.34789899  1.34789899\n",
            "  1.34789899  1.34789899 -0.74189536  1.34789899  1.34789899 -0.74189536\n",
            " -0.74189536  1.34789899  1.34789899  1.34789899  1.34789899 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536  1.34789899  1.34789899 -0.74189536 -0.74189536 -0.74189536\n",
            "  1.34789899  1.34789899 -0.74189536 -0.74189536  1.34789899  1.34789899\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536  1.34789899 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536  1.34789899 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536  1.34789899 -0.74189536  1.34789899 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536\n",
            "  1.34789899  1.34789899  1.34789899  1.34789899  1.34789899  1.34789899\n",
            "  1.34789899  1.34789899 -0.74189536 -0.74189536  1.34789899  1.34789899\n",
            "  1.34789899  1.34789899 -0.74189536  1.34789899 -0.74189536 -0.74189536\n",
            "  1.34789899  1.34789899 -0.74189536  1.34789899 -0.74189536 -0.74189536\n",
            "  1.34789899 -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536  1.34789899\n",
            "  1.34789899  1.34789899 -0.74189536 -0.74189536 -0.74189536  1.34789899\n",
            "  1.34789899  1.34789899 -0.74189536 -0.74189536 -0.74189536  1.34789899\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536  1.34789899\n",
            " -0.74189536  1.34789899  1.34789899  1.34789899 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536  1.34789899 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536  1.34789899\n",
            "  1.34789899 -0.74189536 -0.74189536 -0.74189536 -0.74189536  1.34789899\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536  1.34789899 -0.74189536 -0.74189536  1.34789899  1.34789899\n",
            "  1.34789899 -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536  1.34789899\n",
            " -0.74189536  1.34789899  1.34789899  1.34789899 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
            "  shdf.iloc[:,0:6] = StandardScaler().fit_transform(shdf.iloc[:,0:6])\n",
            "<ipython-input-311-5d92bdc4dfd6>:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1.35830777  1.35830777  1.35830777  1.35830777  1.35830777  1.35830777\n",
            " -0.73621017  1.35830777 -0.73621017 -0.73621017  1.35830777 -0.73621017\n",
            " -0.73621017  1.35830777 -0.73621017  1.35830777  1.35830777 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017  1.35830777 -0.73621017\n",
            "  1.35830777  1.35830777 -0.73621017  1.35830777 -0.73621017  1.35830777\n",
            " -0.73621017  1.35830777 -0.73621017 -0.73621017  1.35830777 -0.73621017\n",
            "  1.35830777 -0.73621017 -0.73621017 -0.73621017  1.35830777 -0.73621017\n",
            " -0.73621017  1.35830777 -0.73621017 -0.73621017  1.35830777 -0.73621017\n",
            "  1.35830777 -0.73621017 -0.73621017 -0.73621017 -0.73621017  1.35830777\n",
            "  1.35830777  1.35830777 -0.73621017  1.35830777  1.35830777 -0.73621017\n",
            " -0.73621017 -0.73621017  1.35830777 -0.73621017 -0.73621017 -0.73621017\n",
            " -0.73621017  1.35830777 -0.73621017  1.35830777 -0.73621017 -0.73621017\n",
            " -0.73621017  1.35830777 -0.73621017 -0.73621017  1.35830777 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017  1.35830777\n",
            " -0.73621017 -0.73621017 -0.73621017  1.35830777 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017  1.35830777 -0.73621017 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017  1.35830777\n",
            "  1.35830777  1.35830777 -0.73621017  1.35830777 -0.73621017  1.35830777\n",
            " -0.73621017 -0.73621017 -0.73621017  1.35830777 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017  1.35830777 -0.73621017  1.35830777 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017  1.35830777  1.35830777 -0.73621017\n",
            " -0.73621017  1.35830777  1.35830777 -0.73621017 -0.73621017  1.35830777\n",
            " -0.73621017 -0.73621017 -0.73621017  1.35830777 -0.73621017  1.35830777\n",
            "  1.35830777 -0.73621017  1.35830777  1.35830777  1.35830777 -0.73621017\n",
            " -0.73621017  1.35830777 -0.73621017  1.35830777  1.35830777  1.35830777\n",
            " -0.73621017  1.35830777 -0.73621017 -0.73621017 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017  1.35830777 -0.73621017 -0.73621017\n",
            " -0.73621017  1.35830777 -0.73621017 -0.73621017  1.35830777  1.35830777\n",
            "  1.35830777  1.35830777 -0.73621017 -0.73621017 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017  1.35830777  1.35830777 -0.73621017\n",
            " -0.73621017 -0.73621017  1.35830777 -0.73621017 -0.73621017  1.35830777\n",
            " -0.73621017 -0.73621017  1.35830777  1.35830777 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017  1.35830777  1.35830777 -0.73621017 -0.73621017\n",
            " -0.73621017  1.35830777 -0.73621017  1.35830777 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017  1.35830777  1.35830777\n",
            "  1.35830777  1.35830777 -0.73621017  1.35830777  1.35830777 -0.73621017\n",
            "  1.35830777 -0.73621017  1.35830777 -0.73621017 -0.73621017  1.35830777\n",
            " -0.73621017 -0.73621017 -0.73621017  1.35830777 -0.73621017 -0.73621017\n",
            "  1.35830777  1.35830777  1.35830777 -0.73621017 -0.73621017  1.35830777\n",
            "  1.35830777  1.35830777 -0.73621017  1.35830777 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017  1.35830777 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017  1.35830777 -0.73621017\n",
            " -0.73621017 -0.73621017  1.35830777 -0.73621017 -0.73621017 -0.73621017\n",
            "  1.35830777 -0.73621017  1.35830777 -0.73621017 -0.73621017 -0.73621017\n",
            "  1.35830777 -0.73621017 -0.73621017 -0.73621017 -0.73621017  1.35830777\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017\n",
            " -0.73621017  1.35830777 -0.73621017  1.35830777 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017\n",
            "  1.35830777 -0.73621017 -0.73621017  1.35830777  1.35830777 -0.73621017\n",
            "  1.35830777  1.35830777 -0.73621017 -0.73621017 -0.73621017  1.35830777\n",
            " -0.73621017  1.35830777  1.35830777 -0.73621017 -0.73621017 -0.73621017\n",
            " -0.73621017  1.35830777  1.35830777 -0.73621017  1.35830777 -0.73621017\n",
            "  1.35830777 -0.73621017  1.35830777 -0.73621017 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017  1.35830777  1.35830777  1.35830777\n",
            "  1.35830777  1.35830777  1.35830777  1.35830777  1.35830777  1.35830777\n",
            "  1.35830777  1.35830777 -0.73621017  1.35830777  1.35830777 -0.73621017\n",
            " -0.73621017 -0.73621017  1.35830777  1.35830777  1.35830777  1.35830777\n",
            "  1.35830777 -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017\n",
            "  1.35830777  1.35830777 -0.73621017 -0.73621017 -0.73621017  1.35830777\n",
            " -0.73621017 -0.73621017 -0.73621017  1.35830777  1.35830777  1.35830777\n",
            "  1.35830777 -0.73621017 -0.73621017  1.35830777  1.35830777  1.35830777\n",
            "  1.35830777  1.35830777 -0.73621017  1.35830777  1.35830777 -0.73621017\n",
            " -0.73621017  1.35830777  1.35830777  1.35830777  1.35830777 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017\n",
            " -0.73621017  1.35830777  1.35830777 -0.73621017 -0.73621017 -0.73621017\n",
            "  1.35830777  1.35830777 -0.73621017 -0.73621017  1.35830777  1.35830777\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017  1.35830777 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017  1.35830777 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017  1.35830777 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017\n",
            " -0.73621017  1.35830777  1.35830777 -0.73621017  1.35830777  1.35830777\n",
            "  1.35830777 -0.73621017  1.35830777 -0.73621017  1.35830777  1.35830777\n",
            "  1.35830777  1.35830777 -0.73621017  1.35830777 -0.73621017 -0.73621017\n",
            "  1.35830777  1.35830777 -0.73621017 -0.73621017 -0.73621017 -0.73621017\n",
            "  1.35830777 -0.73621017  1.35830777 -0.73621017 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017  1.35830777\n",
            "  1.35830777  1.35830777 -0.73621017 -0.73621017 -0.73621017  1.35830777\n",
            "  1.35830777  1.35830777 -0.73621017 -0.73621017 -0.73621017  1.35830777\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017  1.35830777\n",
            " -0.73621017  1.35830777  1.35830777  1.35830777 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017  1.35830777 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017  1.35830777\n",
            "  1.35830777 -0.73621017 -0.73621017 -0.73621017 -0.73621017  1.35830777\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017\n",
            " -0.73621017  1.35830777 -0.73621017 -0.73621017  1.35830777  1.35830777\n",
            "  1.35830777 -0.73621017 -0.73621017 -0.73621017  1.35830777 -0.73621017\n",
            " -0.73621017 -0.73621017  1.35830777 -0.73621017 -0.73621017  1.35830777\n",
            " -0.73621017  1.35830777  1.35830777  1.35830777 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  shdf.iloc[:,0:6] = StandardScaler().fit_transform(shdf.iloc[:,0:6])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n",
            "Parse progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n",
            "AutoML progress: |\n",
            "08:30:21.776: Project: AutoML_21_20250509_83021\n",
            "08:30:21.776: 5-fold cross-validation will be used.\n",
            "08:30:21.777: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n",
            "08:30:21.777: Setting stopping tolerance adaptively based on the training frame: 0.04688072309384954\n",
            "08:30:21.777: Build control seed: 123\n",
            "08:30:21.777: training frame: Frame key: AutoML_21_20250509_83021_training_py_164_sid_a292    cols: 7    rows: 455  chunks: 1    size: 6691  checksum: 3864364185958266976\n",
            "08:30:21.778: validation frame: Frame key: py_165_sid_a292    cols: 7    rows: 114  chunks: 1    size: 2557  checksum: 7632085554672578544\n",
            "08:30:21.778: leaderboard frame: NULL\n",
            "08:30:21.778: blending frame: NULL\n",
            "08:30:21.778: response column: y_test\n",
            "08:30:21.778: fold column: null\n",
            "08:30:21.778: weights column: null\n",
            "08:30:21.778: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (7g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (7g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (6g, 60w)]}, {StackedEnsemble : [monotonic (9g, 10w), best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
            "08:30:21.779: Disabling Algo: XGBoost as requested by the user.\n",
            "08:30:21.779: Disabling Algo: DRF as requested by the user.\n",
            "08:30:21.779: Disabling Algo: GLM as requested by the user.\n",
            "08:30:21.779: Disabling Algo: StackedEnsemble as requested by the user.\n",
            "08:30:21.779: Disabling Algo: GBM as requested by the user.\n",
            "08:30:21.779: AutoML job created: 2025.05.09 08:30:21.776\n",
            "08:30:21.784: AutoML build started: 2025.05.09 08:30:21.783\n",
            "08:30:21.785: AutoML: starting DeepLearning_1_AutoML_21_20250509_83021 model training\n",
            "\n",
            "\n",
            "08:30:22.620: New leader: DeepLearning_1_AutoML_21_20250509_83021, accuracy: 0.6241758241758242\n",
            "08:30:22.621: AutoML: starting DeepLearning_grid_1_AutoML_21_20250509_83021 hyperparameter search\n",
            "\n",
            "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "08:32:45.732: New leader: DeepLearning_grid_1_AutoML_21_20250509_83021_model_2, accuracy: 0.621978021978022\n",
            "08:34:16.385: New leader: DeepLearning_grid_1_AutoML_21_20250509_83021_model_3, accuracy: 0.621978021978022\n",
            "08:34:16.386: AutoML: starting DeepLearning_grid_2_AutoML_21_20250509_83021 hyperparameter search\n",
            "\n",
            "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "08:39:21.101: AutoML: starting DeepLearning_grid_3_AutoML_21_20250509_83021 hyperparameter search\n",
            "\n",
            "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n",
            "\n",
            "08:44:08.276: Skipping StackedEnsemble 'monotonic' due to the exclude_algos option or it is already trained.\n",
            "08:44:08.276: Skipping StackedEnsemble 'best_of_family_xglm' due to the exclude_algos option or it is already trained.\n",
            "08:44:08.276: Skipping StackedEnsemble 'all_xglm' due to the exclude_algos option or it is already trained.\n",
            "08:44:08.276: Actual modeling steps: [{DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}]\n",
            "08:44:08.277: AutoML build stopped: 2025.05.09 08:44:08.276\n",
            "08:44:08.277: AutoML build done: built 10 models\n",
            "08:44:08.277: AutoML duration: 13 min 46.493 sec\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#SFOLD DATA AUTOML\n",
        "#strain, svalid = shdf.split_frame(ratios=[.8], seed=123)\n",
        "shdf  = newdata.copy()\n",
        "#shdf['y_test'] = shdf['y_test'].replace(0,\"B\")\n",
        "#shdf['y_test'] = shdf['y_test'].replace(1,\"M\")\n",
        "shy = \"y_test\"\n",
        "shx = list(shdf.columns)\n",
        "shx.remove(shy)\n",
        "\n",
        "shdf.iloc[:,0:6] = StandardScaler().fit_transform(shdf.iloc[:,0:6])\n",
        "#shdf.iloc[:,-1] = LabelEncoder().fit_transform(shdf.iloc[:,-1])\n",
        "strain1, svalid1 = train_test_split(shdf, test_size=0.2,random_state=123)\n",
        "strain = h2o.H2OFrame(strain1)\n",
        "svalid = h2o.H2OFrame(svalid1)\n",
        "strain[\"y_test\"] = strain[\"y_test\"].asfactor()\n",
        "svalid[\"y_test\"] = svalid[\"y_test\"].asfactor()\n",
        "\n",
        "st = time.time()\n",
        "\n",
        "\n",
        "saml = H2OAutoML(include_algos = ['DeepLearning'],max_models = 10, seed = 123, verbosity=\"info\", sort_metric='accuracy')\n",
        "\n",
        "\n",
        "saml.train(x = shx, y = shy, training_frame = strain, validation_frame = svalid)\n",
        "sautoend = time.time() - st\n",
        "sbest_model = saml.get_best_model()\n",
        "sHATr  = sbest_model.model_performance(strain)\n",
        "sHATe  = sbest_model.model_performance(svalid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 312,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BYOGPuHKVLdT",
        "outputId": "4fd8ca70-9409-483a-cd43-d24d185fbd93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModelMetricsBinomial: deeplearning\n",
              "** Reported on test data. **\n",
              "\n",
              "MSE: 0.23126613667018606\n",
              "RMSE: 0.4809013793598289\n",
              "LogLoss: 0.65195596836825\n",
              "Mean Per-Class Error: 0.4520547945205479\n",
              "AUC: 0.5060140327430671\n",
              "AUCPR: 0.3478262733527602\n",
              "Gini: 0.01202806548613422\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3823572083523052\n",
              "       0    1    Error    Rate\n",
              "-----  ---  ---  -------  ------------\n",
              "0      7    66   0.9041   (66.0/73.0)\n",
              "1      0    41   0        (0.0/41.0)\n",
              "Total  7    107  0.5789   (66.0/114.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.382357     0.554054  3\n",
              "max f2                       0.382357     0.756458  3\n",
              "max f0point5                 0.382357     0.4371    3\n",
              "max accuracy                 0.762745     0.631579  0\n",
              "max precision                0.382357     0.383178  3\n",
              "max recall                   0.382357     1         3\n",
              "max specificity              0.762745     0.986301  0\n",
              "max absolute_mcc             0.382357     0.191685  3\n",
              "max min_per_class_accuracy   0.4175       0.365854  1\n",
              "max mean_per_class_accuracy  0.382357     0.547945  3\n",
              "max tns                      0.762745     72        0\n",
              "max fns                      0.762745     41        0\n",
              "max fps                      0.0296183    73        8\n",
              "max tps                      0.382357     41        3\n",
              "max tnr                      0.762745     0.986301  0\n",
              "max fnr                      0.762745     1         0\n",
              "max fpr                      0.0296183    1         8\n",
              "max tpr                      0.382357     1         3\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 35.96 %, avg score: 39.83 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score     cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  --------  -----------------  ---------------  --------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.385965                    0.4175             0.947894  0.947894           0.340909         0.425347  0.340909                    0.425347            0.365854        0.365854                   -5.21064  -5.21064           -0.0314066\n",
              "2        0.929825                    0.399446           1.12116   1.04924            0.403226         0.399446  0.377358                    0.410197            0.609756        0.97561                    12.1164   4.92407            0.0715002\n",
              "3        1                           0.0296183          0.347561  1                  0.125            0.240641  0.359649                    0.398299            0.0243902       1                          -65.2439  0                  0"
            ],
            "text/html": [
              "<pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
              "** Reported on test data. **\n",
              "\n",
              "MSE: 0.23126613667018606\n",
              "RMSE: 0.4809013793598289\n",
              "LogLoss: 0.65195596836825\n",
              "Mean Per-Class Error: 0.4520547945205479\n",
              "AUC: 0.5060140327430671\n",
              "AUCPR: 0.3478262733527602\n",
              "Gini: 0.01202806548613422</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-136.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-136 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-136 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-136 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-136 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-136 .h2o-table th,\n",
              "#h2o-table-136 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-136 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-136\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3823572083523052</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>0</th>\n",
              "<th>1</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>0</td>\n",
              "<td>7.0</td>\n",
              "<td>66.0</td>\n",
              "<td>0.9041</td>\n",
              "<td> (66.0/73.0)</td></tr>\n",
              "<tr><td>1</td>\n",
              "<td>0.0</td>\n",
              "<td>41.0</td>\n",
              "<td>0.0</td>\n",
              "<td> (0.0/41.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>7.0</td>\n",
              "<td>107.0</td>\n",
              "<td>0.5789</td>\n",
              "<td> (66.0/114.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-137.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-137 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-137 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-137 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-137 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-137 .h2o-table th,\n",
              "#h2o-table-137 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-137 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-137\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.3823572</td>\n",
              "<td>0.5540541</td>\n",
              "<td>3.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.3823572</td>\n",
              "<td>0.7564576</td>\n",
              "<td>3.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.3823572</td>\n",
              "<td>0.4371002</td>\n",
              "<td>3.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.7627450</td>\n",
              "<td>0.6315789</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>0.3823572</td>\n",
              "<td>0.3831776</td>\n",
              "<td>3.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.3823572</td>\n",
              "<td>1.0</td>\n",
              "<td>3.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>0.7627450</td>\n",
              "<td>0.9863014</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.3823572</td>\n",
              "<td>0.1916848</td>\n",
              "<td>3.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.4175003</td>\n",
              "<td>0.3658537</td>\n",
              "<td>1.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.3823572</td>\n",
              "<td>0.5479452</td>\n",
              "<td>3.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>0.7627450</td>\n",
              "<td>72.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>0.7627450</td>\n",
              "<td>41.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0296183</td>\n",
              "<td>73.0</td>\n",
              "<td>8.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.3823572</td>\n",
              "<td>41.0</td>\n",
              "<td>3.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>0.7627450</td>\n",
              "<td>0.9863014</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>0.7627450</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0296183</td>\n",
              "<td>1.0</td>\n",
              "<td>8.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.3823572</td>\n",
              "<td>1.0</td>\n",
              "<td>3.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-138.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-138 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-138 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-138 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-138 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-138 .h2o-table th,\n",
              "#h2o-table-138 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-138 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-138\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 35.96 %, avg score: 39.83 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.3859649</td>\n",
              "<td>0.4175003</td>\n",
              "<td>0.9478936</td>\n",
              "<td>0.9478936</td>\n",
              "<td>0.3409091</td>\n",
              "<td>0.4253468</td>\n",
              "<td>0.3409091</td>\n",
              "<td>0.4253468</td>\n",
              "<td>0.3658537</td>\n",
              "<td>0.3658537</td>\n",
              "<td>-5.2106430</td>\n",
              "<td>-5.2106430</td>\n",
              "<td>-0.0314066</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.9298246</td>\n",
              "<td>0.3994461</td>\n",
              "<td>1.1211644</td>\n",
              "<td>1.0492407</td>\n",
              "<td>0.4032258</td>\n",
              "<td>0.3994461</td>\n",
              "<td>0.3773585</td>\n",
              "<td>0.4101973</td>\n",
              "<td>0.6097561</td>\n",
              "<td>0.9756098</td>\n",
              "<td>12.1164437</td>\n",
              "<td>4.9240681</td>\n",
              "<td>0.0715002</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0296183</td>\n",
              "<td>0.3475610</td>\n",
              "<td>1.0</td>\n",
              "<td>0.125</td>\n",
              "<td>0.2406413</td>\n",
              "<td>0.3596491</td>\n",
              "<td>0.3982986</td>\n",
              "<td>0.0243902</td>\n",
              "<td>1.0</td>\n",
              "<td>-65.2439024</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 312
        }
      ],
      "source": [
        "sHATe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 313,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMDqylVK7svS",
        "outputId": "c48aa61b-1f0f-4b39-8acf-d1bbf0007438"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n",
            "Parse progress: |"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-313-e7350dacbebd>:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1.36884527 -0.73054276  1.36884527  1.36884527  1.36884527  1.36884527\n",
            " -0.73054276  1.36884527  1.36884527 -0.73054276  1.36884527 -0.73054276\n",
            " -0.73054276  1.36884527 -0.73054276  1.36884527 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276  1.36884527 -0.73054276\n",
            "  1.36884527  1.36884527 -0.73054276  1.36884527 -0.73054276 -0.73054276\n",
            " -0.73054276  1.36884527 -0.73054276 -0.73054276  1.36884527 -0.73054276\n",
            "  1.36884527  1.36884527 -0.73054276 -0.73054276  1.36884527 -0.73054276\n",
            " -0.73054276  1.36884527 -0.73054276 -0.73054276  1.36884527 -0.73054276\n",
            "  1.36884527 -0.73054276 -0.73054276 -0.73054276 -0.73054276  1.36884527\n",
            "  1.36884527  1.36884527 -0.73054276  1.36884527  1.36884527 -0.73054276\n",
            " -0.73054276 -0.73054276  1.36884527 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276  1.36884527 -0.73054276  1.36884527 -0.73054276 -0.73054276\n",
            " -0.73054276  1.36884527 -0.73054276 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276  1.36884527\n",
            " -0.73054276 -0.73054276 -0.73054276  1.36884527 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276\n",
            "  1.36884527 -0.73054276  1.36884527 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276  1.36884527\n",
            "  1.36884527  1.36884527 -0.73054276  1.36884527 -0.73054276  1.36884527\n",
            " -0.73054276 -0.73054276 -0.73054276  1.36884527 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276  1.36884527 -0.73054276  1.36884527 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276  1.36884527  1.36884527 -0.73054276\n",
            " -0.73054276 -0.73054276  1.36884527 -0.73054276 -0.73054276  1.36884527\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276  1.36884527\n",
            "  1.36884527 -0.73054276  1.36884527  1.36884527  1.36884527 -0.73054276\n",
            " -0.73054276  1.36884527 -0.73054276  1.36884527 -0.73054276  1.36884527\n",
            " -0.73054276  1.36884527 -0.73054276 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276  1.36884527 -0.73054276 -0.73054276\n",
            " -0.73054276  1.36884527 -0.73054276 -0.73054276  1.36884527  1.36884527\n",
            "  1.36884527  1.36884527 -0.73054276  1.36884527 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276  1.36884527  1.36884527 -0.73054276\n",
            " -0.73054276 -0.73054276  1.36884527 -0.73054276 -0.73054276  1.36884527\n",
            " -0.73054276 -0.73054276 -0.73054276  1.36884527 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276  1.36884527 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276  1.36884527 -0.73054276 -0.73054276\n",
            "  1.36884527 -0.73054276 -0.73054276 -0.73054276  1.36884527  1.36884527\n",
            "  1.36884527  1.36884527 -0.73054276  1.36884527  1.36884527  1.36884527\n",
            "  1.36884527 -0.73054276  1.36884527 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276  1.36884527 -0.73054276 -0.73054276\n",
            "  1.36884527  1.36884527  1.36884527 -0.73054276 -0.73054276  1.36884527\n",
            "  1.36884527  1.36884527 -0.73054276  1.36884527 -0.73054276 -0.73054276\n",
            "  1.36884527 -0.73054276  1.36884527 -0.73054276  1.36884527 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276  1.36884527 -0.73054276\n",
            "  1.36884527 -0.73054276  1.36884527 -0.73054276 -0.73054276 -0.73054276\n",
            "  1.36884527 -0.73054276  1.36884527 -0.73054276 -0.73054276 -0.73054276\n",
            "  1.36884527 -0.73054276 -0.73054276 -0.73054276 -0.73054276  1.36884527\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276  1.36884527 -0.73054276  1.36884527 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276  1.36884527  1.36884527 -0.73054276\n",
            "  1.36884527  1.36884527 -0.73054276 -0.73054276 -0.73054276  1.36884527\n",
            " -0.73054276  1.36884527  1.36884527 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276  1.36884527 -0.73054276  1.36884527 -0.73054276\n",
            "  1.36884527 -0.73054276  1.36884527  1.36884527 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276  1.36884527  1.36884527  1.36884527\n",
            "  1.36884527  1.36884527  1.36884527  1.36884527  1.36884527  1.36884527\n",
            "  1.36884527  1.36884527 -0.73054276  1.36884527  1.36884527  1.36884527\n",
            " -0.73054276 -0.73054276  1.36884527  1.36884527 -0.73054276 -0.73054276\n",
            "  1.36884527 -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276\n",
            "  1.36884527  1.36884527 -0.73054276 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276  1.36884527  1.36884527  1.36884527\n",
            "  1.36884527 -0.73054276 -0.73054276  1.36884527  1.36884527  1.36884527\n",
            "  1.36884527  1.36884527 -0.73054276  1.36884527  1.36884527 -0.73054276\n",
            " -0.73054276  1.36884527  1.36884527  1.36884527  1.36884527 -0.73054276\n",
            " -0.73054276  1.36884527 -0.73054276 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276  1.36884527  1.36884527 -0.73054276 -0.73054276 -0.73054276\n",
            "  1.36884527  1.36884527 -0.73054276 -0.73054276  1.36884527  1.36884527\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276  1.36884527 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276  1.36884527 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276  1.36884527 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276\n",
            "  1.36884527  1.36884527  1.36884527  1.36884527  1.36884527  1.36884527\n",
            "  1.36884527  1.36884527  1.36884527 -0.73054276  1.36884527  1.36884527\n",
            "  1.36884527  1.36884527  1.36884527  1.36884527 -0.73054276 -0.73054276\n",
            "  1.36884527  1.36884527 -0.73054276  1.36884527 -0.73054276 -0.73054276\n",
            "  1.36884527 -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276  1.36884527\n",
            "  1.36884527  1.36884527 -0.73054276 -0.73054276 -0.73054276  1.36884527\n",
            "  1.36884527  1.36884527 -0.73054276 -0.73054276 -0.73054276  1.36884527\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276  1.36884527\n",
            " -0.73054276  1.36884527  1.36884527  1.36884527 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276  1.36884527 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276  1.36884527\n",
            "  1.36884527 -0.73054276 -0.73054276 -0.73054276 -0.73054276  1.36884527\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276  1.36884527 -0.73054276 -0.73054276  1.36884527  1.36884527\n",
            "  1.36884527 -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276  1.36884527\n",
            " -0.73054276  1.36884527  1.36884527  1.36884527 -0.73054276 -0.73054276\n",
            " -0.73054276 -0.73054276 -0.73054276 -0.73054276 -0.73054276]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  shdf.iloc[:,0:6] = StandardScaler().fit_transform(shdf.iloc[:,0:6])\n",
            "<ipython-input-313-e7350dacbebd>:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1.34274185  1.34274185  1.34274185  1.34274185  1.34274185  1.34274185\n",
            " -0.74474479  1.34274185  1.34274185 -0.74474479  1.34274185 -0.74474479\n",
            " -0.74474479  1.34274185 -0.74474479  1.34274185 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479  1.34274185 -0.74474479\n",
            "  1.34274185  1.34274185 -0.74474479  1.34274185 -0.74474479 -0.74474479\n",
            " -0.74474479  1.34274185 -0.74474479 -0.74474479  1.34274185  1.34274185\n",
            "  1.34274185  1.34274185 -0.74474479 -0.74474479  1.34274185 -0.74474479\n",
            " -0.74474479  1.34274185 -0.74474479 -0.74474479  1.34274185 -0.74474479\n",
            "  1.34274185 -0.74474479 -0.74474479 -0.74474479 -0.74474479  1.34274185\n",
            "  1.34274185  1.34274185 -0.74474479  1.34274185  1.34274185 -0.74474479\n",
            " -0.74474479 -0.74474479  1.34274185 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479  1.34274185 -0.74474479  1.34274185 -0.74474479 -0.74474479\n",
            " -0.74474479  1.34274185 -0.74474479 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479  1.34274185\n",
            " -0.74474479 -0.74474479 -0.74474479  1.34274185 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479  1.34274185 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479  1.34274185\n",
            "  1.34274185  1.34274185 -0.74474479  1.34274185  1.34274185  1.34274185\n",
            " -0.74474479 -0.74474479 -0.74474479  1.34274185 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479  1.34274185 -0.74474479  1.34274185 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479  1.34274185  1.34274185 -0.74474479\n",
            " -0.74474479 -0.74474479  1.34274185 -0.74474479 -0.74474479  1.34274185\n",
            " -0.74474479 -0.74474479 -0.74474479  1.34274185 -0.74474479  1.34274185\n",
            "  1.34274185 -0.74474479  1.34274185 -0.74474479  1.34274185 -0.74474479\n",
            " -0.74474479  1.34274185 -0.74474479  1.34274185  1.34274185  1.34274185\n",
            " -0.74474479  1.34274185 -0.74474479 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479  1.34274185 -0.74474479 -0.74474479\n",
            " -0.74474479  1.34274185 -0.74474479 -0.74474479  1.34274185  1.34274185\n",
            "  1.34274185  1.34274185 -0.74474479  1.34274185 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479  1.34274185  1.34274185 -0.74474479\n",
            " -0.74474479 -0.74474479  1.34274185 -0.74474479 -0.74474479  1.34274185\n",
            " -0.74474479 -0.74474479 -0.74474479  1.34274185 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479  1.34274185 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479  1.34274185  1.34274185 -0.74474479\n",
            "  1.34274185 -0.74474479 -0.74474479 -0.74474479  1.34274185  1.34274185\n",
            "  1.34274185  1.34274185 -0.74474479  1.34274185  1.34274185  1.34274185\n",
            "  1.34274185 -0.74474479  1.34274185 -0.74474479 -0.74474479  1.34274185\n",
            " -0.74474479 -0.74474479 -0.74474479  1.34274185 -0.74474479 -0.74474479\n",
            "  1.34274185  1.34274185  1.34274185 -0.74474479 -0.74474479 -0.74474479\n",
            "  1.34274185  1.34274185 -0.74474479  1.34274185 -0.74474479 -0.74474479\n",
            "  1.34274185 -0.74474479 -0.74474479 -0.74474479  1.34274185 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479  1.34274185 -0.74474479\n",
            "  1.34274185 -0.74474479  1.34274185 -0.74474479 -0.74474479 -0.74474479\n",
            "  1.34274185 -0.74474479  1.34274185 -0.74474479 -0.74474479 -0.74474479\n",
            "  1.34274185 -0.74474479 -0.74474479 -0.74474479 -0.74474479  1.34274185\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479  1.34274185 -0.74474479  1.34274185 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479  1.34274185  1.34274185 -0.74474479\n",
            "  1.34274185  1.34274185 -0.74474479 -0.74474479 -0.74474479  1.34274185\n",
            " -0.74474479  1.34274185  1.34274185 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479  1.34274185 -0.74474479  1.34274185 -0.74474479\n",
            "  1.34274185 -0.74474479  1.34274185  1.34274185 -0.74474479 -0.74474479\n",
            " -0.74474479  1.34274185 -0.74474479  1.34274185  1.34274185  1.34274185\n",
            "  1.34274185  1.34274185  1.34274185  1.34274185  1.34274185  1.34274185\n",
            "  1.34274185  1.34274185 -0.74474479  1.34274185  1.34274185 -0.74474479\n",
            " -0.74474479 -0.74474479  1.34274185  1.34274185  1.34274185 -0.74474479\n",
            "  1.34274185 -0.74474479 -0.74474479 -0.74474479 -0.74474479  1.34274185\n",
            "  1.34274185  1.34274185 -0.74474479 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479  1.34274185  1.34274185  1.34274185\n",
            "  1.34274185 -0.74474479 -0.74474479  1.34274185  1.34274185  1.34274185\n",
            "  1.34274185  1.34274185 -0.74474479  1.34274185  1.34274185 -0.74474479\n",
            " -0.74474479  1.34274185  1.34274185  1.34274185  1.34274185 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479  1.34274185  1.34274185 -0.74474479 -0.74474479 -0.74474479\n",
            "  1.34274185  1.34274185 -0.74474479 -0.74474479  1.34274185  1.34274185\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479  1.34274185 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479  1.34274185 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479  1.34274185 -0.74474479  1.34274185 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479\n",
            "  1.34274185  1.34274185  1.34274185  1.34274185  1.34274185  1.34274185\n",
            "  1.34274185  1.34274185  1.34274185 -0.74474479  1.34274185  1.34274185\n",
            "  1.34274185  1.34274185 -0.74474479  1.34274185 -0.74474479 -0.74474479\n",
            "  1.34274185  1.34274185 -0.74474479  1.34274185 -0.74474479 -0.74474479\n",
            "  1.34274185 -0.74474479  1.34274185 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479  1.34274185\n",
            "  1.34274185  1.34274185 -0.74474479 -0.74474479 -0.74474479  1.34274185\n",
            "  1.34274185  1.34274185 -0.74474479 -0.74474479 -0.74474479  1.34274185\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479  1.34274185\n",
            " -0.74474479  1.34274185  1.34274185  1.34274185 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479  1.34274185 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479  1.34274185\n",
            "  1.34274185 -0.74474479 -0.74474479 -0.74474479 -0.74474479  1.34274185\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479  1.34274185 -0.74474479 -0.74474479  1.34274185  1.34274185\n",
            "  1.34274185 -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479  1.34274185\n",
            " -0.74474479  1.34274185  1.34274185  1.34274185 -0.74474479 -0.74474479\n",
            " -0.74474479 -0.74474479 -0.74474479 -0.74474479 -0.74474479]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  shdf.iloc[:,0:6] = StandardScaler().fit_transform(shdf.iloc[:,0:6])\n",
            "<ipython-input-313-e7350dacbebd>:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1.32745468  1.32745468  1.32745468  1.32745468  1.32745468  1.32745468\n",
            " -0.75332139  1.32745468 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139  1.32745468 -0.75332139  1.32745468  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468 -0.75332139  1.32745468\n",
            " -0.75332139  1.32745468 -0.75332139 -0.75332139  1.32745468  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139 -0.75332139  1.32745468  1.32745468\n",
            " -0.75332139  1.32745468 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            "  1.32745468 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139  1.32745468 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468 -0.75332139  1.32745468\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468  1.32745468 -0.75332139\n",
            " -0.75332139  1.32745468  1.32745468 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139  1.32745468\n",
            "  1.32745468 -0.75332139  1.32745468  1.32745468  1.32745468 -0.75332139\n",
            " -0.75332139  1.32745468 -0.75332139  1.32745468  1.32745468  1.32745468\n",
            " -0.75332139  1.32745468 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139  1.32745468 -0.75332139 -0.75332139  1.32745468  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139 -0.75332139  1.32745468  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468  1.32745468  1.32745468\n",
            "  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            "  1.32745468  1.32745468  1.32745468 -0.75332139 -0.75332139  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            "  1.32745468 -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139 -0.75332139\n",
            "  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139 -0.75332139\n",
            "  1.32745468 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468  1.32745468 -0.75332139\n",
            "  1.32745468  1.32745468 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139  1.32745468  1.32745468 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468 -0.75332139  1.32745468 -0.75332139\n",
            "  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468  1.32745468  1.32745468\n",
            "  1.32745468  1.32745468  1.32745468  1.32745468  1.32745468  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468  1.32745468 -0.75332139  1.32745468\n",
            "  1.32745468 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            "  1.32745468  1.32745468 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468  1.32745468  1.32745468\n",
            "  1.32745468 -0.75332139 -0.75332139 -0.75332139  1.32745468  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468  1.32745468 -0.75332139\n",
            " -0.75332139  1.32745468  1.32745468  1.32745468  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139  1.32745468  1.32745468 -0.75332139 -0.75332139 -0.75332139\n",
            "  1.32745468  1.32745468 -0.75332139 -0.75332139  1.32745468  1.32745468\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            "  1.32745468  1.32745468  1.32745468  1.32745468  1.32745468  1.32745468\n",
            "  1.32745468  1.32745468  1.32745468 -0.75332139  1.32745468  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            "  1.32745468 -0.75332139  1.32745468 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139  1.32745468  1.32745468  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            "  1.32745468 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139  1.32745468 -0.75332139 -0.75332139  1.32745468  1.32745468\n",
            "  1.32745468 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139  1.32745468  1.32745468  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  shdf.iloc[:,0:6] = StandardScaler().fit_transform(shdf.iloc[:,0:6])\n",
            "<ipython-input-313-e7350dacbebd>:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1.32745468  1.32745468  1.32745468  1.32745468  1.32745468  1.32745468\n",
            " -0.75332139  1.32745468  1.32745468 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139  1.32745468 -0.75332139  1.32745468  1.32745468 -0.75332139\n",
            "  1.32745468 -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139  1.32745468 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            "  1.32745468  1.32745468 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139  1.32745468 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            "  1.32745468 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139  1.32745468 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468 -0.75332139  1.32745468\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139  1.32745468\n",
            "  1.32745468 -0.75332139  1.32745468  1.32745468  1.32745468 -0.75332139\n",
            " -0.75332139  1.32745468 -0.75332139  1.32745468  1.32745468  1.32745468\n",
            " -0.75332139  1.32745468 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139  1.32745468 -0.75332139 -0.75332139  1.32745468  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            "  1.32745468 -0.75332139 -0.75332139 -0.75332139  1.32745468  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468  1.32745468  1.32745468\n",
            "  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            "  1.32745468  1.32745468  1.32745468 -0.75332139 -0.75332139 -0.75332139\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            "  1.32745468 -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139 -0.75332139\n",
            "  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139 -0.75332139\n",
            "  1.32745468 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468  1.32745468 -0.75332139\n",
            "  1.32745468  1.32745468  1.32745468 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139  1.32745468  1.32745468 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468 -0.75332139  1.32745468 -0.75332139\n",
            "  1.32745468 -0.75332139  1.32745468  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468  1.32745468  1.32745468\n",
            "  1.32745468  1.32745468  1.32745468  1.32745468  1.32745468  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468  1.32745468  1.32745468 -0.75332139\n",
            "  1.32745468 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468  1.32745468  1.32745468\n",
            "  1.32745468 -0.75332139 -0.75332139  1.32745468  1.32745468  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468  1.32745468 -0.75332139\n",
            " -0.75332139  1.32745468  1.32745468  1.32745468  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139  1.32745468  1.32745468 -0.75332139 -0.75332139 -0.75332139\n",
            "  1.32745468  1.32745468 -0.75332139 -0.75332139  1.32745468  1.32745468\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139  1.32745468 -0.75332139  1.32745468 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            "  1.32745468  1.32745468  1.32745468  1.32745468  1.32745468  1.32745468\n",
            "  1.32745468  1.32745468  1.32745468 -0.75332139  1.32745468  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            "  1.32745468  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            "  1.32745468 -0.75332139  1.32745468 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            "  1.32745468  1.32745468 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139  1.32745468 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139  1.32745468  1.32745468  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139  1.32745468 -0.75332139 -0.75332139\n",
            "  1.32745468 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            "  1.32745468 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139  1.32745468 -0.75332139 -0.75332139  1.32745468  1.32745468\n",
            "  1.32745468 -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139  1.32745468\n",
            " -0.75332139  1.32745468  1.32745468  1.32745468 -0.75332139 -0.75332139\n",
            " -0.75332139 -0.75332139 -0.75332139 -0.75332139 -0.75332139]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  shdf.iloc[:,0:6] = StandardScaler().fit_transform(shdf.iloc[:,0:6])\n",
            "<ipython-input-313-e7350dacbebd>:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1.34789899 -0.74189536  1.34789899  1.34789899  1.34789899  1.34789899\n",
            " -0.74189536  1.34789899 -0.74189536 -0.74189536  1.34789899 -0.74189536\n",
            " -0.74189536  1.34789899 -0.74189536  1.34789899  1.34789899 -0.74189536\n",
            "  1.34789899 -0.74189536 -0.74189536 -0.74189536  1.34789899 -0.74189536\n",
            "  1.34789899  1.34789899 -0.74189536  1.34789899 -0.74189536  1.34789899\n",
            " -0.74189536  1.34789899 -0.74189536 -0.74189536  1.34789899 -0.74189536\n",
            "  1.34789899  1.34789899 -0.74189536 -0.74189536  1.34789899 -0.74189536\n",
            " -0.74189536  1.34789899 -0.74189536 -0.74189536  1.34789899 -0.74189536\n",
            "  1.34789899 -0.74189536 -0.74189536 -0.74189536 -0.74189536  1.34789899\n",
            "  1.34789899  1.34789899 -0.74189536  1.34789899  1.34789899 -0.74189536\n",
            " -0.74189536 -0.74189536  1.34789899 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536  1.34789899 -0.74189536  1.34789899 -0.74189536 -0.74189536\n",
            " -0.74189536  1.34789899 -0.74189536 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536  1.34789899 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536  1.34789899\n",
            " -0.74189536 -0.74189536 -0.74189536  1.34789899 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536  1.34789899 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536  1.34789899\n",
            "  1.34789899  1.34789899 -0.74189536  1.34789899 -0.74189536  1.34789899\n",
            " -0.74189536 -0.74189536 -0.74189536  1.34789899 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536  1.34789899 -0.74189536  1.34789899 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536  1.34789899  1.34789899 -0.74189536\n",
            " -0.74189536  1.34789899  1.34789899 -0.74189536 -0.74189536  1.34789899\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536  1.34789899\n",
            "  1.34789899 -0.74189536  1.34789899 -0.74189536  1.34789899 -0.74189536\n",
            " -0.74189536  1.34789899 -0.74189536  1.34789899 -0.74189536  1.34789899\n",
            " -0.74189536  1.34789899 -0.74189536 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536  1.34789899 -0.74189536 -0.74189536\n",
            " -0.74189536  1.34789899 -0.74189536 -0.74189536  1.34789899  1.34789899\n",
            "  1.34789899  1.34789899 -0.74189536  1.34789899 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536  1.34789899 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536  1.34789899  1.34789899 -0.74189536\n",
            " -0.74189536 -0.74189536  1.34789899 -0.74189536 -0.74189536  1.34789899\n",
            " -0.74189536 -0.74189536 -0.74189536  1.34789899 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536  1.34789899 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536  1.34789899 -0.74189536 -0.74189536\n",
            "  1.34789899 -0.74189536 -0.74189536 -0.74189536  1.34789899  1.34789899\n",
            "  1.34789899  1.34789899 -0.74189536  1.34789899  1.34789899  1.34789899\n",
            "  1.34789899 -0.74189536  1.34789899 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536  1.34789899 -0.74189536 -0.74189536\n",
            "  1.34789899  1.34789899  1.34789899 -0.74189536 -0.74189536  1.34789899\n",
            "  1.34789899  1.34789899 -0.74189536  1.34789899 -0.74189536 -0.74189536\n",
            "  1.34789899 -0.74189536 -0.74189536 -0.74189536  1.34789899 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536  1.34789899 -0.74189536\n",
            "  1.34789899 -0.74189536  1.34789899 -0.74189536 -0.74189536 -0.74189536\n",
            "  1.34789899 -0.74189536  1.34789899 -0.74189536 -0.74189536 -0.74189536\n",
            "  1.34789899 -0.74189536 -0.74189536 -0.74189536 -0.74189536  1.34789899\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536  1.34789899 -0.74189536  1.34789899  1.34789899 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536  1.34789899  1.34789899 -0.74189536\n",
            "  1.34789899  1.34789899 -0.74189536 -0.74189536 -0.74189536  1.34789899\n",
            " -0.74189536  1.34789899  1.34789899 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536  1.34789899 -0.74189536  1.34789899 -0.74189536\n",
            "  1.34789899 -0.74189536  1.34789899  1.34789899 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536  1.34789899  1.34789899  1.34789899\n",
            "  1.34789899  1.34789899  1.34789899  1.34789899  1.34789899  1.34789899\n",
            "  1.34789899  1.34789899 -0.74189536  1.34789899  1.34789899  1.34789899\n",
            " -0.74189536 -0.74189536  1.34789899  1.34789899  1.34789899  1.34789899\n",
            "  1.34789899 -0.74189536 -0.74189536 -0.74189536 -0.74189536  1.34789899\n",
            "  1.34789899  1.34789899 -0.74189536 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536  1.34789899  1.34789899  1.34789899\n",
            "  1.34789899 -0.74189536 -0.74189536  1.34789899  1.34789899  1.34789899\n",
            "  1.34789899  1.34789899 -0.74189536  1.34789899  1.34789899 -0.74189536\n",
            " -0.74189536  1.34789899  1.34789899  1.34789899  1.34789899 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536  1.34789899  1.34789899 -0.74189536 -0.74189536 -0.74189536\n",
            "  1.34789899  1.34789899 -0.74189536 -0.74189536  1.34789899  1.34789899\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536  1.34789899 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536  1.34789899 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536  1.34789899 -0.74189536  1.34789899 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536\n",
            "  1.34789899  1.34789899  1.34789899  1.34789899  1.34789899  1.34789899\n",
            "  1.34789899  1.34789899 -0.74189536 -0.74189536  1.34789899  1.34789899\n",
            "  1.34789899  1.34789899 -0.74189536  1.34789899 -0.74189536 -0.74189536\n",
            "  1.34789899  1.34789899 -0.74189536  1.34789899 -0.74189536 -0.74189536\n",
            "  1.34789899 -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536  1.34789899\n",
            "  1.34789899  1.34789899 -0.74189536 -0.74189536 -0.74189536  1.34789899\n",
            "  1.34789899  1.34789899 -0.74189536 -0.74189536 -0.74189536  1.34789899\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536  1.34789899\n",
            " -0.74189536  1.34789899  1.34789899  1.34789899 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536  1.34789899 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536  1.34789899\n",
            "  1.34789899 -0.74189536 -0.74189536 -0.74189536 -0.74189536  1.34789899\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536  1.34789899 -0.74189536 -0.74189536  1.34789899  1.34789899\n",
            "  1.34789899 -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536  1.34789899\n",
            " -0.74189536  1.34789899  1.34789899  1.34789899 -0.74189536 -0.74189536\n",
            " -0.74189536 -0.74189536 -0.74189536 -0.74189536 -0.74189536]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
            "  shdf.iloc[:,0:6] = StandardScaler().fit_transform(shdf.iloc[:,0:6])\n",
            "<ipython-input-313-e7350dacbebd>:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1.35830777  1.35830777  1.35830777  1.35830777  1.35830777  1.35830777\n",
            " -0.73621017  1.35830777 -0.73621017 -0.73621017  1.35830777 -0.73621017\n",
            " -0.73621017  1.35830777 -0.73621017  1.35830777  1.35830777 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017  1.35830777 -0.73621017\n",
            "  1.35830777  1.35830777 -0.73621017  1.35830777 -0.73621017  1.35830777\n",
            " -0.73621017  1.35830777 -0.73621017 -0.73621017  1.35830777 -0.73621017\n",
            "  1.35830777 -0.73621017 -0.73621017 -0.73621017  1.35830777 -0.73621017\n",
            " -0.73621017  1.35830777 -0.73621017 -0.73621017  1.35830777 -0.73621017\n",
            "  1.35830777 -0.73621017 -0.73621017 -0.73621017 -0.73621017  1.35830777\n",
            "  1.35830777  1.35830777 -0.73621017  1.35830777  1.35830777 -0.73621017\n",
            " -0.73621017 -0.73621017  1.35830777 -0.73621017 -0.73621017 -0.73621017\n",
            " -0.73621017  1.35830777 -0.73621017  1.35830777 -0.73621017 -0.73621017\n",
            " -0.73621017  1.35830777 -0.73621017 -0.73621017  1.35830777 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017  1.35830777\n",
            " -0.73621017 -0.73621017 -0.73621017  1.35830777 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017  1.35830777 -0.73621017 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017  1.35830777\n",
            "  1.35830777  1.35830777 -0.73621017  1.35830777 -0.73621017  1.35830777\n",
            " -0.73621017 -0.73621017 -0.73621017  1.35830777 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017  1.35830777 -0.73621017  1.35830777 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017  1.35830777  1.35830777 -0.73621017\n",
            " -0.73621017  1.35830777  1.35830777 -0.73621017 -0.73621017  1.35830777\n",
            " -0.73621017 -0.73621017 -0.73621017  1.35830777 -0.73621017  1.35830777\n",
            "  1.35830777 -0.73621017  1.35830777  1.35830777  1.35830777 -0.73621017\n",
            " -0.73621017  1.35830777 -0.73621017  1.35830777  1.35830777  1.35830777\n",
            " -0.73621017  1.35830777 -0.73621017 -0.73621017 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017  1.35830777 -0.73621017 -0.73621017\n",
            " -0.73621017  1.35830777 -0.73621017 -0.73621017  1.35830777  1.35830777\n",
            "  1.35830777  1.35830777 -0.73621017 -0.73621017 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017  1.35830777  1.35830777 -0.73621017\n",
            " -0.73621017 -0.73621017  1.35830777 -0.73621017 -0.73621017  1.35830777\n",
            " -0.73621017 -0.73621017  1.35830777  1.35830777 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017  1.35830777  1.35830777 -0.73621017 -0.73621017\n",
            " -0.73621017  1.35830777 -0.73621017  1.35830777 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017  1.35830777  1.35830777\n",
            "  1.35830777  1.35830777 -0.73621017  1.35830777  1.35830777 -0.73621017\n",
            "  1.35830777 -0.73621017  1.35830777 -0.73621017 -0.73621017  1.35830777\n",
            " -0.73621017 -0.73621017 -0.73621017  1.35830777 -0.73621017 -0.73621017\n",
            "  1.35830777  1.35830777  1.35830777 -0.73621017 -0.73621017  1.35830777\n",
            "  1.35830777  1.35830777 -0.73621017  1.35830777 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017  1.35830777 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017  1.35830777 -0.73621017\n",
            " -0.73621017 -0.73621017  1.35830777 -0.73621017 -0.73621017 -0.73621017\n",
            "  1.35830777 -0.73621017  1.35830777 -0.73621017 -0.73621017 -0.73621017\n",
            "  1.35830777 -0.73621017 -0.73621017 -0.73621017 -0.73621017  1.35830777\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017\n",
            " -0.73621017  1.35830777 -0.73621017  1.35830777 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017\n",
            "  1.35830777 -0.73621017 -0.73621017  1.35830777  1.35830777 -0.73621017\n",
            "  1.35830777  1.35830777 -0.73621017 -0.73621017 -0.73621017  1.35830777\n",
            " -0.73621017  1.35830777  1.35830777 -0.73621017 -0.73621017 -0.73621017\n",
            " -0.73621017  1.35830777  1.35830777 -0.73621017  1.35830777 -0.73621017\n",
            "  1.35830777 -0.73621017  1.35830777 -0.73621017 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017  1.35830777  1.35830777  1.35830777\n",
            "  1.35830777  1.35830777  1.35830777  1.35830777  1.35830777  1.35830777\n",
            "  1.35830777  1.35830777 -0.73621017  1.35830777  1.35830777 -0.73621017\n",
            " -0.73621017 -0.73621017  1.35830777  1.35830777  1.35830777  1.35830777\n",
            "  1.35830777 -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017\n",
            "  1.35830777  1.35830777 -0.73621017 -0.73621017 -0.73621017  1.35830777\n",
            " -0.73621017 -0.73621017 -0.73621017  1.35830777  1.35830777  1.35830777\n",
            "  1.35830777 -0.73621017 -0.73621017  1.35830777  1.35830777  1.35830777\n",
            "  1.35830777  1.35830777 -0.73621017  1.35830777  1.35830777 -0.73621017\n",
            " -0.73621017  1.35830777  1.35830777  1.35830777  1.35830777 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017\n",
            " -0.73621017  1.35830777  1.35830777 -0.73621017 -0.73621017 -0.73621017\n",
            "  1.35830777  1.35830777 -0.73621017 -0.73621017  1.35830777  1.35830777\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017  1.35830777 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017  1.35830777 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017  1.35830777 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017\n",
            " -0.73621017  1.35830777  1.35830777 -0.73621017  1.35830777  1.35830777\n",
            "  1.35830777 -0.73621017  1.35830777 -0.73621017  1.35830777  1.35830777\n",
            "  1.35830777  1.35830777 -0.73621017  1.35830777 -0.73621017 -0.73621017\n",
            "  1.35830777  1.35830777 -0.73621017 -0.73621017 -0.73621017 -0.73621017\n",
            "  1.35830777 -0.73621017  1.35830777 -0.73621017 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017  1.35830777\n",
            "  1.35830777  1.35830777 -0.73621017 -0.73621017 -0.73621017  1.35830777\n",
            "  1.35830777  1.35830777 -0.73621017 -0.73621017 -0.73621017  1.35830777\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017  1.35830777\n",
            " -0.73621017  1.35830777  1.35830777  1.35830777 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017  1.35830777 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017  1.35830777\n",
            "  1.35830777 -0.73621017 -0.73621017 -0.73621017 -0.73621017  1.35830777\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017\n",
            " -0.73621017  1.35830777 -0.73621017 -0.73621017  1.35830777  1.35830777\n",
            "  1.35830777 -0.73621017 -0.73621017 -0.73621017  1.35830777 -0.73621017\n",
            " -0.73621017 -0.73621017  1.35830777 -0.73621017 -0.73621017  1.35830777\n",
            " -0.73621017  1.35830777  1.35830777  1.35830777 -0.73621017 -0.73621017\n",
            " -0.73621017 -0.73621017 -0.73621017 -0.73621017 -0.73621017]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  shdf.iloc[:,0:6] = StandardScaler().fit_transform(shdf.iloc[:,0:6])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n",
            "AutoML progress: |\n",
            "08:44:15.803: Project: AutoML_22_20250509_84415\n",
            "08:44:15.803: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n",
            "08:44:15.803: Setting stopping tolerance adaptively based on the training frame: 0.04688072309384954\n",
            "08:44:15.803: Build control seed: 123\n",
            "08:44:15.803: training frame: Frame key: AutoML_22_20250509_84415_training_py_171_sid_a292    cols: 7    rows: 455  chunks: 1    size: 6691  checksum: 3864364185958266976\n",
            "08:44:15.803: validation frame: Frame key: py_172_sid_a292    cols: 7    rows: 114  chunks: 1    size: 2557  checksum: 7632085554672578544\n",
            "08:44:15.803: leaderboard frame: NULL\n",
            "08:44:15.803: blending frame: NULL\n",
            "08:44:15.803: response column: y_test\n",
            "08:44:15.803: fold column: null\n",
            "08:44:15.804: weights column: null\n",
            "08:44:15.804: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (7g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (7g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (6g, 60w)]}, {StackedEnsemble : [monotonic (9g, 10w), best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
            "08:44:15.805: Disabling Algo: XGBoost as requested by the user.\n",
            "08:44:15.805: Disabling Algo: DRF as requested by the user.\n",
            "08:44:15.805: Disabling Algo: GLM as requested by the user.\n",
            "08:44:15.805: Disabling Algo: StackedEnsemble as requested by the user.\n",
            "08:44:15.805: Disabling Algo: GBM as requested by the user.\n",
            "08:44:15.805: AutoML job created: 2025.05.09 08:44:15.802\n",
            "08:44:15.838: AutoML build started: 2025.05.09 08:44:15.838\n",
            "08:44:15.843: AutoML: starting DeepLearning_1_AutoML_22_20250509_84415 model training\n",
            "\n",
            "â–ˆ\n",
            "08:44:17.560: New leader: DeepLearning_1_AutoML_22_20250509_84415, accuracy: 0.6241758241758242\n",
            "08:44:17.562: AutoML: starting DeepLearning_grid_1_AutoML_22_20250509_84415 hyperparameter search\n",
            "\n",
            "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "08:48:24.755: New leader: DeepLearning_grid_1_AutoML_22_20250509_84415_model_2, accuracy: 0.621978021978022\n",
            "08:50:45.217: New leader: DeepLearning_grid_1_AutoML_22_20250509_84415_model_3, accuracy: 0.621978021978022\n",
            "08:50:45.218: AutoML: starting DeepLearning_grid_2_AutoML_22_20250509_84415 hyperparameter search\n",
            "\n",
            "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "08:55:38.419: New leader: DeepLearning_grid_2_AutoML_22_20250509_84415_model_2, accuracy: 0.621978021978022\n",
            "08:58:05.686: AutoML: starting DeepLearning_grid_3_AutoML_22_20250509_84415 hyperparameter search\n",
            "\n",
            "â–ˆâ–ˆâ–ˆ| (done) 100%\n",
            "\n",
            "09:06:29.970: New leader: DeepLearning_grid_1_AutoML_22_20250509_84415_model_3, accuracy: 0.621978021978022\n",
            "09:06:29.971: Skipping StackedEnsemble 'monotonic' due to the exclude_algos option or it is already trained.\n",
            "09:06:29.971: Skipping StackedEnsemble 'best_of_family_xglm' due to the exclude_algos option or it is already trained.\n",
            "09:06:29.971: Skipping StackedEnsemble 'all_xglm' due to the exclude_algos option or it is already trained.\n",
            "09:06:29.971: Actual modeling steps: [{DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}]\n",
            "09:06:29.971: AutoML build stopped: 2025.05.09 09:06:29.971\n",
            "09:06:29.972: AutoML build done: built 10 models\n",
            "09:06:29.972: AutoML duration: 22 min 14.133 sec\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def SCVshdf(newdata):\n",
        "  #SFOLD DATA AUTOML\n",
        "  #strain, svalid = shdf.split_frame(ratios=[.8], seed=123)\n",
        "  shdf  = newdata.copy()\n",
        "  #shdf['y_test'] = shdf['y_test'].replace(0,\"B\")\n",
        "  #shdf['y_test'] = shdf['y_test'].replace(1,\"M\")\n",
        "  shy = \"y_test\"\n",
        "  shx = list(shdf.columns)\n",
        "  shx.remove(shy)\n",
        "\n",
        "  shdf.iloc[:,0:6] = StandardScaler().fit_transform(shdf.iloc[:,0:6])\n",
        "  #shdf.iloc[:,-1] = LabelEncoder().fit_transform(shdf.iloc[:,-1])\n",
        "  strain1, svalid1 = train_test_split(shdf, test_size=0.2,random_state=123)\n",
        "  strain = h2o.H2OFrame(strain1)\n",
        "  svalid = h2o.H2OFrame(svalid1)\n",
        "  strain[\"y_test\"] = strain[\"y_test\"].asfactor()\n",
        "  svalid[\"y_test\"] = svalid[\"y_test\"].asfactor()\n",
        "\n",
        "  st = time.time()\n",
        "\n",
        "\n",
        "  saml = H2OAutoML(include_algos = ['DeepLearning'],max_models = 10, seed = 123, verbosity=\"info\", nfolds=10, sort_metric='accuracy')\n",
        "\n",
        "\n",
        "  saml.train(x = shx, y = shy, training_frame = strain, validation_frame = svalid)\n",
        "  sautoend = time.time() - st\n",
        "  sbest_model = saml.get_best_model()\n",
        "  sHATr  = sbest_model.model_performance(strain)\n",
        "  sHATe  = sbest_model.model_performance(svalid)\n",
        "  return sHATr, sHATe\n",
        "SCVsHATr, SCVsHATe = SCVshdf(newdata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 314,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W-pmhLYk7zQ9",
        "outputId": "34cd97d7-e1c4-4475-eeb6-1c004eb4409c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model Details\n",
              "=============\n",
              "H2ODeepLearningEstimator : Deep Learning\n",
              "Model Key: DeepLearning_grid_1_AutoML_21_20250509_83021_model_3\n",
              "\n",
              "\n",
              "Status of Neuron Layers: predicting y_test, 2-class classification, bernoulli distribution, CrossEntropy loss, 452 weights/biases, 9.5 KB, 2,584,400 training samples, mini-batch size 1\n",
              "    layer    units    type              dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight          weight_rms          mean_bias             bias_rms\n",
              "--  -------  -------  ----------------  ---------  ----  ----  --------------------  ---------------------  ----------  -------------------  ------------------  --------------------  -------------------\n",
              "    1        6        Input             5.0\n",
              "    2        50       RectifierDropout  20.0       0.0   0.0   0.04141052315089231   0.057576969265937805   0.0         -0.1236626791053762  1.2216238975524902  -2.1185772032523924   2.3408308029174805\n",
              "    3        2        Softmax                      0.0   0.0   0.001571682429057546  0.0015304619446396828  0.0         0.04119396212045103  0.5925519466400146  -0.01999339214365116  0.12572908401489258\n",
              "\n",
              "ModelMetricsBinomial: deeplearning\n",
              "** Reported on train data. **\n",
              "\n",
              "MSE: 0.22658068382541427\n",
              "RMSE: 0.47600491995925237\n",
              "LogLoss: 0.6399438775158185\n",
              "Mean Per-Class Error: 0.4747549625236801\n",
              "AUC: 0.5543612552508032\n",
              "AUCPR: 0.4497979891608425\n",
              "Gini: 0.1087225105016063\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3404688987455928\n",
              "       0    1    Error    Rate\n",
              "-----  ---  ---  -------  -------------\n",
              "0      16   268  0.9437   (268.0/284.0)\n",
              "1      1    170  0.0058   (1.0/171.0)\n",
              "Total  17   438  0.5912   (269.0/455.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.340469     0.558292  12\n",
              "max f2                       0.278603     0.759325  14\n",
              "max f0point5                 0.399446     0.442667  9\n",
              "max accuracy                 0.695681     0.637363  5\n",
              "max precision                0.984772     1         0\n",
              "max recall                   0.278603     1         14\n",
              "max specificity              0.984772     1         0\n",
              "max absolute_mcc             0.278603     0.133076  14\n",
              "max min_per_class_accuracy   0.4175       0.374269  8\n",
              "max mean_per_class_accuracy  0.4175       0.530444  8\n",
              "max tns                      0.984772     284       0\n",
              "max fns                      0.984772     170       0\n",
              "max fps                      0.00104882   284       22\n",
              "max tps                      0.278603     171       14\n",
              "max tnr                      0.984772     1         0\n",
              "max fnr                      0.984772     0.994152  0\n",
              "max fpr                      0.00104882   1         22\n",
              "max tpr                      0.278603     1         14\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 37.58 %, avg score: 40.27 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score     cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain       cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  --------  -----------------  ---------------  --------  --------------------------  ------------------  --------------  -------------------------  ---------  -----------------  --------------------\n",
              "1        0.0153846                   0.781334           2.2807    2.2807             0.857143         0.880542  0.857143                    0.880542            0.0350877       0.0350877                  128.07     128.07             0.0315666\n",
              "2        0.021978                    0.680573           1.77388   2.12865            0.666667         0.695681  0.8                         0.825084            0.0116959       0.0467836                  77.3879    112.865            0.0397414\n",
              "3        0.0307692                   0.456775           1.33041   1.90058            0.5              0.506832  0.714286                    0.734155            0.0116959       0.0584795                  33.0409    90.0585            0.044395\n",
              "4        0.0417582                   0.424719           1.06433   1.68052            0.4              0.426094  0.631579                    0.653086            0.0116959       0.0701754                  6.43275    68.0517            0.0455276\n",
              "5        0.336264                    0.4175             1.03256   1.11302            0.38806          0.4175    0.418301                    0.446756            0.304094        0.374269                   3.25565    11.3022            0.0608887\n",
              "6        0.936264                    0.399446           0.994152  1.03684            0.373626         0.399446  0.389671                    0.416438            0.596491        0.97076                    -0.584795  3.68449            0.0552673\n",
              "7        1                           0.00104882         0.458762  1                  0.172414         0.200471  0.375824                    0.402673            0.0292398       1                          -54.1238   0                  0\n",
              "\n",
              "ModelMetricsBinomial: deeplearning\n",
              "** Reported on validation data. **\n",
              "\n",
              "MSE: 0.23126613667018606\n",
              "RMSE: 0.4809013793598289\n",
              "LogLoss: 0.65195596836825\n",
              "Mean Per-Class Error: 0.4520547945205479\n",
              "AUC: 0.5060140327430671\n",
              "AUCPR: 0.3478262733527602\n",
              "Gini: 0.01202806548613422\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3823572083523052\n",
              "       0    1    Error    Rate\n",
              "-----  ---  ---  -------  ------------\n",
              "0      7    66   0.9041   (66.0/73.0)\n",
              "1      0    41   0        (0.0/41.0)\n",
              "Total  7    107  0.5789   (66.0/114.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.382357     0.554054  3\n",
              "max f2                       0.382357     0.756458  3\n",
              "max f0point5                 0.382357     0.4371    3\n",
              "max accuracy                 0.762745     0.631579  0\n",
              "max precision                0.382357     0.383178  3\n",
              "max recall                   0.382357     1         3\n",
              "max specificity              0.762745     0.986301  0\n",
              "max absolute_mcc             0.382357     0.191685  3\n",
              "max min_per_class_accuracy   0.4175       0.365854  1\n",
              "max mean_per_class_accuracy  0.382357     0.547945  3\n",
              "max tns                      0.762745     72        0\n",
              "max fns                      0.762745     41        0\n",
              "max fps                      0.0296183    73        8\n",
              "max tps                      0.382357     41        3\n",
              "max tnr                      0.762745     0.986301  0\n",
              "max fnr                      0.762745     1         0\n",
              "max fpr                      0.0296183    1         8\n",
              "max tpr                      0.382357     1         3\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 35.96 %, avg score: 39.83 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score     cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  --------  -----------------  ---------------  --------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.385965                    0.4175             0.947894  0.947894           0.340909         0.425347  0.340909                    0.425347            0.365854        0.365854                   -5.21064  -5.21064           -0.0314066\n",
              "2        0.929825                    0.399446           1.12116   1.04924            0.403226         0.399446  0.377358                    0.410197            0.609756        0.97561                    12.1164   4.92407            0.0715002\n",
              "3        1                           0.0296183          0.347561  1                  0.125            0.240641  0.359649                    0.398299            0.0243902       1                          -65.2439  0                  0\n",
              "\n",
              "ModelMetricsBinomial: deeplearning\n",
              "** Reported on cross-validation data. **\n",
              "\n",
              "MSE: 0.24434707203544653\n",
              "RMSE: 0.4943147499675147\n",
              "LogLoss: 0.6838578191468734\n",
              "Mean Per-Class Error: 0.4894366197183099\n",
              "AUC: 0.45065274689070095\n",
              "AUCPR: 0.33730718492640754\n",
              "Gini: -0.0986945062185981\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.08861203417248224\n",
              "       0    1    Error    Rate\n",
              "-----  ---  ---  -------  -------------\n",
              "0      6    278  0.9789   (278.0/284.0)\n",
              "1      0    171  0        (0.0/171.0)\n",
              "Total  6    449  0.611    (278.0/455.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.088612     0.551613  43\n",
              "max f2                       0.088612     0.754634  43\n",
              "max f0point5                 0.088612     0.434672  43\n",
              "max accuracy                 0.914181     0.621978  0\n",
              "max precision                0.593357     0.4       3\n",
              "max recall                   0.088612     1         43\n",
              "max specificity              0.914181     0.996479  0\n",
              "max absolute_mcc             0.46638      0.114646  10\n",
              "max min_per_class_accuracy   0.400576     0.471831  21\n",
              "max mean_per_class_accuracy  0.088612     0.510563  43\n",
              "max tns                      0.914181     283       0\n",
              "max fns                      0.914181     171       0\n",
              "max fps                      0.0100889    284       46\n",
              "max tps                      0.088612     171       43\n",
              "max tnr                      0.914181     0.996479  0\n",
              "max fnr                      0.914181     1         0\n",
              "max fpr                      0.0100889    1         46\n",
              "max tpr                      0.088612     1         43\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 37.58 %, avg score: 39.33 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score     cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  --------  -----------------  ---------------  --------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.010989                    0.589411           1.06433   1.06433            0.4              0.753189  0.4                         0.753189            0.0116959       0.0116959                  6.43275   6.43275            0.00113253\n",
              "2        0.021978                    0.529083           0.532164  0.798246           0.2              0.548556  0.3                         0.650873            0.00584795      0.0175439                  -46.7836  -20.1754           -0.00710403\n",
              "3        0.0813187                   0.46638            0.394195  0.503398           0.148148         0.468889  0.189189                    0.518074            0.0233918       0.0409357                  -60.5805  -49.6602           -0.0646981\n",
              "4        0.151648                    0.461772           1.08096   0.771252           0.40625          0.461772  0.289855                    0.491963            0.0760234       0.116959                   8.09576   -22.8748           -0.0555761\n",
              "5        0.151648                    0.461009           0         0.771252           0                0         0.289855                    0.491963            0               0.116959                   -100      -22.8748           -0.0555761\n",
              "6        0.204396                    0.444615           1.10867   0.858329           0.416667         0.445663  0.322581                    0.480015            0.0584795       0.175439                   10.8674   -14.1671           -0.0463924\n",
              "7        0.384615                    0.410144           0.941021  0.897076           0.353659         0.41299   0.337143                    0.448609            0.169591        0.345029                   -5.89787  -10.2924           -0.0634215\n",
              "8        0.514286                    0.400576           1.12747   0.955166           0.423729         0.400692  0.358974                    0.436527            0.146199        0.491228                   12.7466   -4.48343           -0.0369409\n",
              "9        0.652747                    0.399004           0.929175  0.949652           0.349206         0.399004  0.356902                    0.428568            0.128655        0.619883                   -7.08252  -5.03475           -0.0526522\n",
              "10       0.789011                    0.369899           0.815412  0.926469           0.306452         0.371706  0.348189                    0.418748            0.111111        0.730994                   -18.4588  -7.35311           -0.0929495\n",
              "11       0.898901                    0.337167           1.27719   0.969345           0.48             0.337487  0.364303                    0.408813            0.140351        0.871345                   27.7193   -3.06553           -0.0441479\n",
              "12       0.898901                    0.318195           0         0.969345           0                0         0.364303                    0.408813            0               0.871345                   -100      -3.06553           -0.0441479\n",
              "13       1                           0.0100889          1.27257   1                  0.478261         0.255845  0.375824                    0.393349            0.128655        1                          27.2565   0                  0\n",
              "\n",
              "Cross-Validation Metrics Summary: \n",
              "                         mean          sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
              "-----------------------  ------------  -----------  ------------  ------------  ------------  ------------  ------------\n",
              "accuracy                 0.3912088     0.036113575  0.3846154     0.43956044    0.3846154     0.4065934     0.34065935\n",
              "aic                      nan           0.0          nan           nan           nan           nan           nan\n",
              "auc                      0.44922647    0.06258031   0.4007653     0.45171568    0.5300418     0.4873581     0.3762514\n",
              "err                      0.60879123    0.036113575  0.61538464    0.5604396     0.61538464    0.5934066     0.6593407\n",
              "err_count                55.4          3.2863352    56.0          51.0          56.0          54.0          60.0\n",
              "f0point5                 0.4349697     0.042348046  0.4385965     0.4950495     0.42416453    0.44041452    0.37662336\n",
              "f1                       0.5512257     0.04260651   0.5555556     0.610687      0.5409836     0.55737704    0.4915254\n",
              "f2                       0.75344807    0.032025173  0.75757575    0.7968128     0.74660635    0.7589286     0.70731705\n",
              "lift_top_group           0.52          1.1627554    2.6           0.0           0.0           0.0           0.0\n",
              "loglikelihood            nan           0.0          nan           nan           nan           nan           nan\n",
              "---                      ---           ---          ---           ---           ---           ---           ---\n",
              "mcc                      0.11939936    0.020773822  nan           nan           0.11307406    0.1426006     0.10252344\n",
              "mean_per_class_accuracy  0.51193726    0.011591409  0.5           0.5           0.51724136    0.5263158     0.516129\n",
              "mean_per_class_error     0.48806277    0.011591409  0.5           0.5           0.4827586     0.47368422    0.48387095\n",
              "mse                      0.24434707    0.010544071  0.24536888    0.2598531     0.23095387    0.23970255    0.24585697\n",
              "pr_auc                   0.34888813    0.05933763   0.36759627    0.39258844    0.36749396    0.37239772    0.24436432\n",
              "precision                0.38143373    0.040672064  0.3846154     0.43956044    0.37078652    0.38636363    0.3258427\n",
              "r2                       -0.049463365  0.05054589   -0.036683552  -0.05482519   0.0007685502  -0.024239847  -0.1323368\n",
              "recall                   1.0           0.0          1.0           1.0           1.0           1.0           1.0\n",
              "rmse                     0.49422312    0.010640241  0.49534723    0.5097579     0.4805766     0.48959428    0.49583966\n",
              "specificity              0.02387448    0.023182819  0.0           0.0           0.03448276    0.05263158    0.032258064\n",
              "[22 rows x 8 columns]\n",
              "\n",
              "\n",
              "Scoring History: \n",
              "    timestamp            duration          training_speed    epochs    iterations    samples      training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
              "--  -------------------  ----------------  ----------------  --------  ------------  -----------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------\n",
              "    2025-05-09 08:34:00  0.000 sec                           0         0             0            nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan\n",
              "    2025-05-09 08:34:00  3 min 37.605 sec  59868 obs/sec     10        1             4550         0.485221         0.663331            -0.00366097    0.498888        0.375032           1.59649          0.610989                         0.475796           0.644455              0.0170192        0.531407          0.38145              1.39024            0.614035\n",
              "    2025-05-09 08:34:05  3 min 42.620 sec  122827 obs/sec    1370      137           623350       0.47783          0.64558             0.0266817      0.549893        0.443034           2.21735          0.6                              0.480956           0.653371              -0.00441703      0.492315          0.337408             0                  0.587719\n",
              "    2025-05-09 08:34:10  3 min 47.629 sec  149691 obs/sec    3310      331           1.50605e+06  0.477226         0.643025            0.0291396      0.552076        0.447025           2.2807           0.595604                         0.481488           0.652855              -0.00663895      0.491981          0.337323             0                  0.596491\n",
              "    2025-05-09 08:34:15  3 min 52.624 sec  156103 obs/sec    5160      516           2.3478e+06   0.476055         0.640124            0.0338999      0.553435        0.449085           2.2807           0.595604                         0.479615           0.648982              0.00117549       0.527731          0.370712             1.39024            0.578947\n",
              "    2025-05-09 08:34:16  3 min 53.745 sec  160074 obs/sec    5680      568           2.5844e+06   0.476005         0.639944            0.0341021      0.554361        0.449798           2.2807           0.591209                         0.480901           0.651956              -0.00418801      0.506014          0.347826             0.947894           0.578947\n",
              "\n",
              "Variable Importances: \n",
              "variable    relative_importance    scaled_importance    percentage\n",
              "----------  ---------------------  -------------------  ------------\n",
              "XGB         1                      1                    0.190024\n",
              "RF          0.970753               0.970753             0.184467\n",
              "SVM         0.959715               0.959715             0.182369\n",
              "LR          0.882247               0.882247             0.167648\n",
              "ANN         0.827309               0.827309             0.157209\n",
              "KNN         0.622461               0.622461             0.118283\n",
              "\n",
              "[tips]\n",
              "Use `model.explain()` to inspect the model.\n",
              "--\n",
              "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
            ],
            "text/html": [
              "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
              "=============\n",
              "H2ODeepLearningEstimator : Deep Learning\n",
              "Model Key: DeepLearning_grid_1_AutoML_21_20250509_83021_model_3\n",
              "</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-139.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-139 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-139 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-139 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-139 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-139 .h2o-table th,\n",
              "#h2o-table-139 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-139 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-139\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Status of Neuron Layers: predicting y_test, 2-class classification, bernoulli distribution, CrossEntropy loss, 452 weights/biases, 9.5 KB, 2,584,400 training samples, mini-batch size 1</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>layer</th>\n",
              "<th>units</th>\n",
              "<th>type</th>\n",
              "<th>dropout</th>\n",
              "<th>l1</th>\n",
              "<th>l2</th>\n",
              "<th>mean_rate</th>\n",
              "<th>rate_rms</th>\n",
              "<th>momentum</th>\n",
              "<th>mean_weight</th>\n",
              "<th>weight_rms</th>\n",
              "<th>mean_bias</th>\n",
              "<th>bias_rms</th></tr></thead>\n",
              "    <tbody><tr><td></td>\n",
              "<td>1</td>\n",
              "<td>6</td>\n",
              "<td>Input</td>\n",
              "<td>5.0</td>\n",
              "<td></td>\n",
              "<td></td>\n",
              "<td></td>\n",
              "<td></td>\n",
              "<td></td>\n",
              "<td></td>\n",
              "<td></td>\n",
              "<td></td>\n",
              "<td></td></tr>\n",
              "<tr><td></td>\n",
              "<td>2</td>\n",
              "<td>50</td>\n",
              "<td>RectifierDropout</td>\n",
              "<td>20.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0414105</td>\n",
              "<td>0.0575770</td>\n",
              "<td>0.0</td>\n",
              "<td>-0.1236627</td>\n",
              "<td>1.2216239</td>\n",
              "<td>-2.1185772</td>\n",
              "<td>2.3408308</td></tr>\n",
              "<tr><td></td>\n",
              "<td>3</td>\n",
              "<td>2</td>\n",
              "<td>Softmax</td>\n",
              "<td></td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0015717</td>\n",
              "<td>0.0015305</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0411940</td>\n",
              "<td>0.5925519</td>\n",
              "<td>-0.0199934</td>\n",
              "<td>0.1257291</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
              "** Reported on train data. **\n",
              "\n",
              "MSE: 0.22658068382541427\n",
              "RMSE: 0.47600491995925237\n",
              "LogLoss: 0.6399438775158185\n",
              "Mean Per-Class Error: 0.4747549625236801\n",
              "AUC: 0.5543612552508032\n",
              "AUCPR: 0.4497979891608425\n",
              "Gini: 0.1087225105016063</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-140.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-140 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-140 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-140 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-140 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-140 .h2o-table th,\n",
              "#h2o-table-140 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-140 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-140\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3404688987455928</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>0</th>\n",
              "<th>1</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>0</td>\n",
              "<td>16.0</td>\n",
              "<td>268.0</td>\n",
              "<td>0.9437</td>\n",
              "<td> (268.0/284.0)</td></tr>\n",
              "<tr><td>1</td>\n",
              "<td>1.0</td>\n",
              "<td>170.0</td>\n",
              "<td>0.0058</td>\n",
              "<td> (1.0/171.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>17.0</td>\n",
              "<td>438.0</td>\n",
              "<td>0.5912</td>\n",
              "<td> (269.0/455.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-141.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-141 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-141 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-141 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-141 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-141 .h2o-table th,\n",
              "#h2o-table-141 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-141 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-141\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.3404689</td>\n",
              "<td>0.5582923</td>\n",
              "<td>12.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.2786027</td>\n",
              "<td>0.7593250</td>\n",
              "<td>14.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.3994461</td>\n",
              "<td>0.4426667</td>\n",
              "<td>9.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.6956812</td>\n",
              "<td>0.6373626</td>\n",
              "<td>5.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>0.9847719</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.2786027</td>\n",
              "<td>1.0</td>\n",
              "<td>14.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>0.9847719</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.2786027</td>\n",
              "<td>0.1330759</td>\n",
              "<td>14.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.4175003</td>\n",
              "<td>0.3742690</td>\n",
              "<td>8.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.4175003</td>\n",
              "<td>0.5304444</td>\n",
              "<td>8.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>0.9847719</td>\n",
              "<td>284.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>0.9847719</td>\n",
              "<td>170.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0010488</td>\n",
              "<td>284.0</td>\n",
              "<td>22.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.2786027</td>\n",
              "<td>171.0</td>\n",
              "<td>14.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>0.9847719</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>0.9847719</td>\n",
              "<td>0.9941520</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0010488</td>\n",
              "<td>1.0</td>\n",
              "<td>22.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.2786027</td>\n",
              "<td>1.0</td>\n",
              "<td>14.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-142.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-142 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-142 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-142 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-142 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-142 .h2o-table th,\n",
              "#h2o-table-142 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-142 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-142\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 37.58 %, avg score: 40.27 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.0153846</td>\n",
              "<td>0.7813339</td>\n",
              "<td>2.2807018</td>\n",
              "<td>2.2807018</td>\n",
              "<td>0.8571429</td>\n",
              "<td>0.8805425</td>\n",
              "<td>0.8571429</td>\n",
              "<td>0.8805425</td>\n",
              "<td>0.0350877</td>\n",
              "<td>0.0350877</td>\n",
              "<td>128.0701754</td>\n",
              "<td>128.0701754</td>\n",
              "<td>0.0315666</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.0219780</td>\n",
              "<td>0.6805733</td>\n",
              "<td>1.7738791</td>\n",
              "<td>2.1286550</td>\n",
              "<td>0.6666667</td>\n",
              "<td>0.6956812</td>\n",
              "<td>0.8</td>\n",
              "<td>0.8250841</td>\n",
              "<td>0.0116959</td>\n",
              "<td>0.0467836</td>\n",
              "<td>77.3879142</td>\n",
              "<td>112.8654971</td>\n",
              "<td>0.0397414</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.0307692</td>\n",
              "<td>0.4567745</td>\n",
              "<td>1.3304094</td>\n",
              "<td>1.9005848</td>\n",
              "<td>0.5</td>\n",
              "<td>0.5068322</td>\n",
              "<td>0.7142857</td>\n",
              "<td>0.7341550</td>\n",
              "<td>0.0116959</td>\n",
              "<td>0.0584795</td>\n",
              "<td>33.0409357</td>\n",
              "<td>90.0584795</td>\n",
              "<td>0.0443950</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.0417582</td>\n",
              "<td>0.4247191</td>\n",
              "<td>1.0643275</td>\n",
              "<td>1.6805171</td>\n",
              "<td>0.4</td>\n",
              "<td>0.4260941</td>\n",
              "<td>0.6315789</td>\n",
              "<td>0.6530863</td>\n",
              "<td>0.0116959</td>\n",
              "<td>0.0701754</td>\n",
              "<td>6.4327485</td>\n",
              "<td>68.0517082</td>\n",
              "<td>0.0455276</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.3362637</td>\n",
              "<td>0.4175003</td>\n",
              "<td>1.0325565</td>\n",
              "<td>1.1130222</td>\n",
              "<td>0.3880597</td>\n",
              "<td>0.4175003</td>\n",
              "<td>0.4183007</td>\n",
              "<td>0.4467561</td>\n",
              "<td>0.3040936</td>\n",
              "<td>0.3742690</td>\n",
              "<td>3.2556516</td>\n",
              "<td>11.3022207</td>\n",
              "<td>0.0608887</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.9362637</td>\n",
              "<td>0.3994461</td>\n",
              "<td>0.9941520</td>\n",
              "<td>1.0368449</td>\n",
              "<td>0.3736264</td>\n",
              "<td>0.3994461</td>\n",
              "<td>0.3896714</td>\n",
              "<td>0.4164377</td>\n",
              "<td>0.5964912</td>\n",
              "<td>0.9707602</td>\n",
              "<td>-0.5847953</td>\n",
              "<td>3.6844851</td>\n",
              "<td>0.0552673</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0010488</td>\n",
              "<td>0.4587618</td>\n",
              "<td>1.0</td>\n",
              "<td>0.1724138</td>\n",
              "<td>0.2004706</td>\n",
              "<td>0.3758242</td>\n",
              "<td>0.4026728</td>\n",
              "<td>0.0292398</td>\n",
              "<td>1.0</td>\n",
              "<td>-54.1238153</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
              "** Reported on validation data. **\n",
              "\n",
              "MSE: 0.23126613667018606\n",
              "RMSE: 0.4809013793598289\n",
              "LogLoss: 0.65195596836825\n",
              "Mean Per-Class Error: 0.4520547945205479\n",
              "AUC: 0.5060140327430671\n",
              "AUCPR: 0.3478262733527602\n",
              "Gini: 0.01202806548613422</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-143.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-143 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-143 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-143 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-143 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-143 .h2o-table th,\n",
              "#h2o-table-143 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-143 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-143\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3823572083523052</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>0</th>\n",
              "<th>1</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>0</td>\n",
              "<td>7.0</td>\n",
              "<td>66.0</td>\n",
              "<td>0.9041</td>\n",
              "<td> (66.0/73.0)</td></tr>\n",
              "<tr><td>1</td>\n",
              "<td>0.0</td>\n",
              "<td>41.0</td>\n",
              "<td>0.0</td>\n",
              "<td> (0.0/41.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>7.0</td>\n",
              "<td>107.0</td>\n",
              "<td>0.5789</td>\n",
              "<td> (66.0/114.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-144.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-144 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-144 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-144 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-144 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-144 .h2o-table th,\n",
              "#h2o-table-144 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-144 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-144\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.3823572</td>\n",
              "<td>0.5540541</td>\n",
              "<td>3.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.3823572</td>\n",
              "<td>0.7564576</td>\n",
              "<td>3.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.3823572</td>\n",
              "<td>0.4371002</td>\n",
              "<td>3.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.7627450</td>\n",
              "<td>0.6315789</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>0.3823572</td>\n",
              "<td>0.3831776</td>\n",
              "<td>3.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.3823572</td>\n",
              "<td>1.0</td>\n",
              "<td>3.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>0.7627450</td>\n",
              "<td>0.9863014</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.3823572</td>\n",
              "<td>0.1916848</td>\n",
              "<td>3.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.4175003</td>\n",
              "<td>0.3658537</td>\n",
              "<td>1.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.3823572</td>\n",
              "<td>0.5479452</td>\n",
              "<td>3.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>0.7627450</td>\n",
              "<td>72.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>0.7627450</td>\n",
              "<td>41.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0296183</td>\n",
              "<td>73.0</td>\n",
              "<td>8.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.3823572</td>\n",
              "<td>41.0</td>\n",
              "<td>3.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>0.7627450</td>\n",
              "<td>0.9863014</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>0.7627450</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0296183</td>\n",
              "<td>1.0</td>\n",
              "<td>8.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.3823572</td>\n",
              "<td>1.0</td>\n",
              "<td>3.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-145.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-145 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-145 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-145 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-145 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-145 .h2o-table th,\n",
              "#h2o-table-145 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-145 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-145\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 35.96 %, avg score: 39.83 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.3859649</td>\n",
              "<td>0.4175003</td>\n",
              "<td>0.9478936</td>\n",
              "<td>0.9478936</td>\n",
              "<td>0.3409091</td>\n",
              "<td>0.4253468</td>\n",
              "<td>0.3409091</td>\n",
              "<td>0.4253468</td>\n",
              "<td>0.3658537</td>\n",
              "<td>0.3658537</td>\n",
              "<td>-5.2106430</td>\n",
              "<td>-5.2106430</td>\n",
              "<td>-0.0314066</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.9298246</td>\n",
              "<td>0.3994461</td>\n",
              "<td>1.1211644</td>\n",
              "<td>1.0492407</td>\n",
              "<td>0.4032258</td>\n",
              "<td>0.3994461</td>\n",
              "<td>0.3773585</td>\n",
              "<td>0.4101973</td>\n",
              "<td>0.6097561</td>\n",
              "<td>0.9756098</td>\n",
              "<td>12.1164437</td>\n",
              "<td>4.9240681</td>\n",
              "<td>0.0715002</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0296183</td>\n",
              "<td>0.3475610</td>\n",
              "<td>1.0</td>\n",
              "<td>0.125</td>\n",
              "<td>0.2406413</td>\n",
              "<td>0.3596491</td>\n",
              "<td>0.3982986</td>\n",
              "<td>0.0243902</td>\n",
              "<td>1.0</td>\n",
              "<td>-65.2439024</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
              "** Reported on cross-validation data. **\n",
              "\n",
              "MSE: 0.24434707203544653\n",
              "RMSE: 0.4943147499675147\n",
              "LogLoss: 0.6838578191468734\n",
              "Mean Per-Class Error: 0.4894366197183099\n",
              "AUC: 0.45065274689070095\n",
              "AUCPR: 0.33730718492640754\n",
              "Gini: -0.0986945062185981</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-146.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-146 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-146 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-146 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-146 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-146 .h2o-table th,\n",
              "#h2o-table-146 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-146 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-146\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.08861203417248224</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>0</th>\n",
              "<th>1</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>0</td>\n",
              "<td>6.0</td>\n",
              "<td>278.0</td>\n",
              "<td>0.9789</td>\n",
              "<td> (278.0/284.0)</td></tr>\n",
              "<tr><td>1</td>\n",
              "<td>0.0</td>\n",
              "<td>171.0</td>\n",
              "<td>0.0</td>\n",
              "<td> (0.0/171.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>6.0</td>\n",
              "<td>449.0</td>\n",
              "<td>0.611</td>\n",
              "<td> (278.0/455.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-147.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-147 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-147 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-147 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-147 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-147 .h2o-table th,\n",
              "#h2o-table-147 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-147 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-147\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.0886120</td>\n",
              "<td>0.5516129</td>\n",
              "<td>43.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.0886120</td>\n",
              "<td>0.7546337</td>\n",
              "<td>43.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.0886120</td>\n",
              "<td>0.4346721</td>\n",
              "<td>43.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.9141810</td>\n",
              "<td>0.6219780</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>0.5933566</td>\n",
              "<td>0.4</td>\n",
              "<td>3.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0886120</td>\n",
              "<td>1.0</td>\n",
              "<td>43.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>0.9141810</td>\n",
              "<td>0.9964789</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.4663798</td>\n",
              "<td>0.1146463</td>\n",
              "<td>10.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.4005755</td>\n",
              "<td>0.4718310</td>\n",
              "<td>21.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.0886120</td>\n",
              "<td>0.5105634</td>\n",
              "<td>43.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>0.9141810</td>\n",
              "<td>283.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>0.9141810</td>\n",
              "<td>171.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0100889</td>\n",
              "<td>284.0</td>\n",
              "<td>46.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0886120</td>\n",
              "<td>171.0</td>\n",
              "<td>43.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>0.9141810</td>\n",
              "<td>0.9964789</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>0.9141810</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0100889</td>\n",
              "<td>1.0</td>\n",
              "<td>46.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0886120</td>\n",
              "<td>1.0</td>\n",
              "<td>43.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-148.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-148 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-148 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-148 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-148 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-148 .h2o-table th,\n",
              "#h2o-table-148 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-148 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-148\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 37.58 %, avg score: 39.33 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.0109890</td>\n",
              "<td>0.5894114</td>\n",
              "<td>1.0643275</td>\n",
              "<td>1.0643275</td>\n",
              "<td>0.4</td>\n",
              "<td>0.7531887</td>\n",
              "<td>0.4</td>\n",
              "<td>0.7531887</td>\n",
              "<td>0.0116959</td>\n",
              "<td>0.0116959</td>\n",
              "<td>6.4327485</td>\n",
              "<td>6.4327485</td>\n",
              "<td>0.0011325</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.0219780</td>\n",
              "<td>0.5290830</td>\n",
              "<td>0.5321637</td>\n",
              "<td>0.7982456</td>\n",
              "<td>0.2</td>\n",
              "<td>0.5485563</td>\n",
              "<td>0.3</td>\n",
              "<td>0.6508725</td>\n",
              "<td>0.0058480</td>\n",
              "<td>0.0175439</td>\n",
              "<td>-46.7836257</td>\n",
              "<td>-20.1754386</td>\n",
              "<td>-0.0071040</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.0813187</td>\n",
              "<td>0.4663798</td>\n",
              "<td>0.3941954</td>\n",
              "<td>0.5033981</td>\n",
              "<td>0.1481481</td>\n",
              "<td>0.4688893</td>\n",
              "<td>0.1891892</td>\n",
              "<td>0.5180739</td>\n",
              "<td>0.0233918</td>\n",
              "<td>0.0409357</td>\n",
              "<td>-60.5804635</td>\n",
              "<td>-49.6601865</td>\n",
              "<td>-0.0646981</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.1516484</td>\n",
              "<td>0.4617722</td>\n",
              "<td>1.0809576</td>\n",
              "<td>0.7712518</td>\n",
              "<td>0.40625</td>\n",
              "<td>0.4617722</td>\n",
              "<td>0.2898551</td>\n",
              "<td>0.4919630</td>\n",
              "<td>0.0760234</td>\n",
              "<td>0.1169591</td>\n",
              "<td>8.0957602</td>\n",
              "<td>-22.8748199</td>\n",
              "<td>-0.0555761</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.1516484</td>\n",
              "<td>0.4610086</td>\n",
              "<td>0.0</td>\n",
              "<td>0.7712518</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.2898551</td>\n",
              "<td>0.4919630</td>\n",
              "<td>0.0</td>\n",
              "<td>0.1169591</td>\n",
              "<td>-100.0</td>\n",
              "<td>-22.8748199</td>\n",
              "<td>-0.0555761</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.2043956</td>\n",
              "<td>0.4446154</td>\n",
              "<td>1.1086745</td>\n",
              "<td>0.8583286</td>\n",
              "<td>0.4166667</td>\n",
              "<td>0.4456630</td>\n",
              "<td>0.3225806</td>\n",
              "<td>0.4800146</td>\n",
              "<td>0.0584795</td>\n",
              "<td>0.1754386</td>\n",
              "<td>10.8674464</td>\n",
              "<td>-14.1671383</td>\n",
              "<td>-0.0463924</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>0.3846154</td>\n",
              "<td>0.4101442</td>\n",
              "<td>0.9410213</td>\n",
              "<td>0.8970760</td>\n",
              "<td>0.3536585</td>\n",
              "<td>0.4129897</td>\n",
              "<td>0.3371429</td>\n",
              "<td>0.4486086</td>\n",
              "<td>0.1695906</td>\n",
              "<td>0.3450292</td>\n",
              "<td>-5.8978748</td>\n",
              "<td>-10.2923977</td>\n",
              "<td>-0.0634215</td></tr>\n",
              "<tr><td>8</td>\n",
              "<td>0.5142857</td>\n",
              "<td>0.4005755</td>\n",
              "<td>1.1274656</td>\n",
              "<td>0.9551657</td>\n",
              "<td>0.4237288</td>\n",
              "<td>0.4006920</td>\n",
              "<td>0.3589744</td>\n",
              "<td>0.4365271</td>\n",
              "<td>0.1461988</td>\n",
              "<td>0.4912281</td>\n",
              "<td>12.7465557</td>\n",
              "<td>-4.4834308</td>\n",
              "<td>-0.0369409</td></tr>\n",
              "<tr><td>9</td>\n",
              "<td>0.6527473</td>\n",
              "<td>0.3990036</td>\n",
              "<td>0.9291748</td>\n",
              "<td>0.9496525</td>\n",
              "<td>0.3492063</td>\n",
              "<td>0.3990036</td>\n",
              "<td>0.3569024</td>\n",
              "<td>0.4285676</td>\n",
              "<td>0.1286550</td>\n",
              "<td>0.6198830</td>\n",
              "<td>-7.0825211</td>\n",
              "<td>-5.0347530</td>\n",
              "<td>-0.0526522</td></tr>\n",
              "<tr><td>10</td>\n",
              "<td>0.7890110</td>\n",
              "<td>0.3698994</td>\n",
              "<td>0.8154122</td>\n",
              "<td>0.9264689</td>\n",
              "<td>0.3064516</td>\n",
              "<td>0.3717065</td>\n",
              "<td>0.3481894</td>\n",
              "<td>0.4187475</td>\n",
              "<td>0.1111111</td>\n",
              "<td>0.7309942</td>\n",
              "<td>-18.4587814</td>\n",
              "<td>-7.3531089</td>\n",
              "<td>-0.0929495</td></tr>\n",
              "<tr><td>11</td>\n",
              "<td>0.8989011</td>\n",
              "<td>0.3371673</td>\n",
              "<td>1.2771930</td>\n",
              "<td>0.9693447</td>\n",
              "<td>0.48</td>\n",
              "<td>0.3374870</td>\n",
              "<td>0.3643032</td>\n",
              "<td>0.4088135</td>\n",
              "<td>0.1403509</td>\n",
              "<td>0.8713450</td>\n",
              "<td>27.7192982</td>\n",
              "<td>-3.0655285</td>\n",
              "<td>-0.0441479</td></tr>\n",
              "<tr><td>12</td>\n",
              "<td>0.8989011</td>\n",
              "<td>0.3181952</td>\n",
              "<td>0.0</td>\n",
              "<td>0.9693447</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.3643032</td>\n",
              "<td>0.4088135</td>\n",
              "<td>0.0</td>\n",
              "<td>0.8713450</td>\n",
              "<td>-100.0</td>\n",
              "<td>-3.0655285</td>\n",
              "<td>-0.0441479</td></tr>\n",
              "<tr><td>13</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0100889</td>\n",
              "<td>1.2725655</td>\n",
              "<td>1.0</td>\n",
              "<td>0.4782609</td>\n",
              "<td>0.2558450</td>\n",
              "<td>0.3758242</td>\n",
              "<td>0.3933485</td>\n",
              "<td>0.1286550</td>\n",
              "<td>1.0</td>\n",
              "<td>27.2565472</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-149.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-149 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-149 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-149 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-149 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-149 .h2o-table th,\n",
              "#h2o-table-149 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-149 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-149\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Cross-Validation Metrics Summary: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>mean</th>\n",
              "<th>sd</th>\n",
              "<th>cv_1_valid</th>\n",
              "<th>cv_2_valid</th>\n",
              "<th>cv_3_valid</th>\n",
              "<th>cv_4_valid</th>\n",
              "<th>cv_5_valid</th></tr></thead>\n",
              "    <tbody><tr><td>accuracy</td>\n",
              "<td>0.3912088</td>\n",
              "<td>0.0361136</td>\n",
              "<td>0.3846154</td>\n",
              "<td>0.4395604</td>\n",
              "<td>0.3846154</td>\n",
              "<td>0.4065934</td>\n",
              "<td>0.3406594</td></tr>\n",
              "<tr><td>aic</td>\n",
              "<td>nan</td>\n",
              "<td>0.0</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td></tr>\n",
              "<tr><td>auc</td>\n",
              "<td>0.4492265</td>\n",
              "<td>0.0625803</td>\n",
              "<td>0.4007653</td>\n",
              "<td>0.4517157</td>\n",
              "<td>0.5300418</td>\n",
              "<td>0.4873581</td>\n",
              "<td>0.3762514</td></tr>\n",
              "<tr><td>err</td>\n",
              "<td>0.6087912</td>\n",
              "<td>0.0361136</td>\n",
              "<td>0.6153846</td>\n",
              "<td>0.5604396</td>\n",
              "<td>0.6153846</td>\n",
              "<td>0.5934066</td>\n",
              "<td>0.6593407</td></tr>\n",
              "<tr><td>err_count</td>\n",
              "<td>55.4</td>\n",
              "<td>3.2863352</td>\n",
              "<td>56.0</td>\n",
              "<td>51.0</td>\n",
              "<td>56.0</td>\n",
              "<td>54.0</td>\n",
              "<td>60.0</td></tr>\n",
              "<tr><td>f0point5</td>\n",
              "<td>0.4349697</td>\n",
              "<td>0.0423480</td>\n",
              "<td>0.4385965</td>\n",
              "<td>0.4950495</td>\n",
              "<td>0.4241645</td>\n",
              "<td>0.4404145</td>\n",
              "<td>0.3766234</td></tr>\n",
              "<tr><td>f1</td>\n",
              "<td>0.5512257</td>\n",
              "<td>0.0426065</td>\n",
              "<td>0.5555556</td>\n",
              "<td>0.610687</td>\n",
              "<td>0.5409836</td>\n",
              "<td>0.5573770</td>\n",
              "<td>0.4915254</td></tr>\n",
              "<tr><td>f2</td>\n",
              "<td>0.7534481</td>\n",
              "<td>0.0320252</td>\n",
              "<td>0.7575757</td>\n",
              "<td>0.7968128</td>\n",
              "<td>0.7466063</td>\n",
              "<td>0.7589286</td>\n",
              "<td>0.7073171</td></tr>\n",
              "<tr><td>lift_top_group</td>\n",
              "<td>0.52</td>\n",
              "<td>1.1627554</td>\n",
              "<td>2.6</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>loglikelihood</td>\n",
              "<td>nan</td>\n",
              "<td>0.0</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td></tr>\n",
              "<tr><td>---</td>\n",
              "<td>---</td>\n",
              "<td>---</td>\n",
              "<td>---</td>\n",
              "<td>---</td>\n",
              "<td>---</td>\n",
              "<td>---</td>\n",
              "<td>---</td></tr>\n",
              "<tr><td>mcc</td>\n",
              "<td>0.1193994</td>\n",
              "<td>0.0207738</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>0.1130741</td>\n",
              "<td>0.1426006</td>\n",
              "<td>0.1025234</td></tr>\n",
              "<tr><td>mean_per_class_accuracy</td>\n",
              "<td>0.5119373</td>\n",
              "<td>0.0115914</td>\n",
              "<td>0.5</td>\n",
              "<td>0.5</td>\n",
              "<td>0.5172414</td>\n",
              "<td>0.5263158</td>\n",
              "<td>0.516129</td></tr>\n",
              "<tr><td>mean_per_class_error</td>\n",
              "<td>0.4880628</td>\n",
              "<td>0.0115914</td>\n",
              "<td>0.5</td>\n",
              "<td>0.5</td>\n",
              "<td>0.4827586</td>\n",
              "<td>0.4736842</td>\n",
              "<td>0.4838710</td></tr>\n",
              "<tr><td>mse</td>\n",
              "<td>0.2443471</td>\n",
              "<td>0.0105441</td>\n",
              "<td>0.2453689</td>\n",
              "<td>0.2598531</td>\n",
              "<td>0.2309539</td>\n",
              "<td>0.2397025</td>\n",
              "<td>0.2458570</td></tr>\n",
              "<tr><td>pr_auc</td>\n",
              "<td>0.3488881</td>\n",
              "<td>0.0593376</td>\n",
              "<td>0.3675963</td>\n",
              "<td>0.3925884</td>\n",
              "<td>0.3674940</td>\n",
              "<td>0.3723977</td>\n",
              "<td>0.2443643</td></tr>\n",
              "<tr><td>precision</td>\n",
              "<td>0.3814337</td>\n",
              "<td>0.0406721</td>\n",
              "<td>0.3846154</td>\n",
              "<td>0.4395604</td>\n",
              "<td>0.3707865</td>\n",
              "<td>0.3863636</td>\n",
              "<td>0.3258427</td></tr>\n",
              "<tr><td>r2</td>\n",
              "<td>-0.0494634</td>\n",
              "<td>0.0505459</td>\n",
              "<td>-0.0366836</td>\n",
              "<td>-0.0548252</td>\n",
              "<td>0.0007686</td>\n",
              "<td>-0.0242398</td>\n",
              "<td>-0.1323368</td></tr>\n",
              "<tr><td>recall</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td></tr>\n",
              "<tr><td>rmse</td>\n",
              "<td>0.4942231</td>\n",
              "<td>0.0106402</td>\n",
              "<td>0.4953472</td>\n",
              "<td>0.5097579</td>\n",
              "<td>0.4805766</td>\n",
              "<td>0.4895943</td>\n",
              "<td>0.4958397</td></tr>\n",
              "<tr><td>specificity</td>\n",
              "<td>0.0238745</td>\n",
              "<td>0.0231828</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0344828</td>\n",
              "<td>0.0526316</td>\n",
              "<td>0.0322581</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "<pre style='font-size: smaller; margin-bottom: 1em;'>[22 rows x 8 columns]</pre></div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-150.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-150 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-150 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-150 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-150 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-150 .h2o-table th,\n",
              "#h2o-table-150 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-150 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-150\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Scoring History: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>timestamp</th>\n",
              "<th>duration</th>\n",
              "<th>training_speed</th>\n",
              "<th>epochs</th>\n",
              "<th>iterations</th>\n",
              "<th>samples</th>\n",
              "<th>training_rmse</th>\n",
              "<th>training_logloss</th>\n",
              "<th>training_r2</th>\n",
              "<th>training_auc</th>\n",
              "<th>training_pr_auc</th>\n",
              "<th>training_lift</th>\n",
              "<th>training_classification_error</th>\n",
              "<th>validation_rmse</th>\n",
              "<th>validation_logloss</th>\n",
              "<th>validation_r2</th>\n",
              "<th>validation_auc</th>\n",
              "<th>validation_pr_auc</th>\n",
              "<th>validation_lift</th>\n",
              "<th>validation_classification_error</th></tr></thead>\n",
              "    <tbody><tr><td></td>\n",
              "<td>2025-05-09 08:34:00</td>\n",
              "<td> 0.000 sec</td>\n",
              "<td>None</td>\n",
              "<td>0.0</td>\n",
              "<td>0</td>\n",
              "<td>0.0</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2025-05-09 08:34:00</td>\n",
              "<td> 3 min 37.605 sec</td>\n",
              "<td>59868 obs/sec</td>\n",
              "<td>10.0</td>\n",
              "<td>1</td>\n",
              "<td>4550.0</td>\n",
              "<td>0.4852207</td>\n",
              "<td>0.6633310</td>\n",
              "<td>-0.0036610</td>\n",
              "<td>0.4988881</td>\n",
              "<td>0.3750321</td>\n",
              "<td>1.5964912</td>\n",
              "<td>0.6109890</td>\n",
              "<td>0.4757963</td>\n",
              "<td>0.6444548</td>\n",
              "<td>0.0170192</td>\n",
              "<td>0.5314066</td>\n",
              "<td>0.3814495</td>\n",
              "<td>1.3902439</td>\n",
              "<td>0.6140351</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2025-05-09 08:34:05</td>\n",
              "<td> 3 min 42.620 sec</td>\n",
              "<td>122827 obs/sec</td>\n",
              "<td>1370.0</td>\n",
              "<td>137</td>\n",
              "<td>623350.0</td>\n",
              "<td>0.4778298</td>\n",
              "<td>0.6455805</td>\n",
              "<td>0.0266817</td>\n",
              "<td>0.5498929</td>\n",
              "<td>0.4430341</td>\n",
              "<td>2.2173489</td>\n",
              "<td>0.6</td>\n",
              "<td>0.4809562</td>\n",
              "<td>0.6533707</td>\n",
              "<td>-0.0044170</td>\n",
              "<td>0.4923154</td>\n",
              "<td>0.3374076</td>\n",
              "<td>0.0</td>\n",
              "<td>0.5877193</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2025-05-09 08:34:10</td>\n",
              "<td> 3 min 47.629 sec</td>\n",
              "<td>149691 obs/sec</td>\n",
              "<td>3310.0</td>\n",
              "<td>331</td>\n",
              "<td>1506050.0</td>\n",
              "<td>0.4772261</td>\n",
              "<td>0.6430246</td>\n",
              "<td>0.0291396</td>\n",
              "<td>0.5520756</td>\n",
              "<td>0.4470255</td>\n",
              "<td>2.2807018</td>\n",
              "<td>0.5956044</td>\n",
              "<td>0.4814879</td>\n",
              "<td>0.6528546</td>\n",
              "<td>-0.0066390</td>\n",
              "<td>0.4919813</td>\n",
              "<td>0.3373229</td>\n",
              "<td>0.0</td>\n",
              "<td>0.5964912</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2025-05-09 08:34:15</td>\n",
              "<td> 3 min 52.624 sec</td>\n",
              "<td>156103 obs/sec</td>\n",
              "<td>5160.0</td>\n",
              "<td>516</td>\n",
              "<td>2347800.0</td>\n",
              "<td>0.4760547</td>\n",
              "<td>0.6401244</td>\n",
              "<td>0.0338999</td>\n",
              "<td>0.5534346</td>\n",
              "<td>0.4490850</td>\n",
              "<td>2.2807018</td>\n",
              "<td>0.5956044</td>\n",
              "<td>0.4796154</td>\n",
              "<td>0.6489818</td>\n",
              "<td>0.0011755</td>\n",
              "<td>0.5277314</td>\n",
              "<td>0.3707121</td>\n",
              "<td>1.3902439</td>\n",
              "<td>0.5789474</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2025-05-09 08:34:16</td>\n",
              "<td> 3 min 53.745 sec</td>\n",
              "<td>160074 obs/sec</td>\n",
              "<td>5680.0</td>\n",
              "<td>568</td>\n",
              "<td>2584400.0</td>\n",
              "<td>0.4760049</td>\n",
              "<td>0.6399439</td>\n",
              "<td>0.0341021</td>\n",
              "<td>0.5543613</td>\n",
              "<td>0.4497980</td>\n",
              "<td>2.2807018</td>\n",
              "<td>0.5912088</td>\n",
              "<td>0.4809014</td>\n",
              "<td>0.6519560</td>\n",
              "<td>-0.0041880</td>\n",
              "<td>0.5060140</td>\n",
              "<td>0.3478263</td>\n",
              "<td>0.9478936</td>\n",
              "<td>0.5789474</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-151.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-151 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-151 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-151 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-151 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-151 .h2o-table th,\n",
              "#h2o-table-151 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-151 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-151\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Variable Importances: </caption>\n",
              "    <thead><tr><th>variable</th>\n",
              "<th>relative_importance</th>\n",
              "<th>scaled_importance</th>\n",
              "<th>percentage</th></tr></thead>\n",
              "    <tbody><tr><td>XGB</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.1900243</td></tr>\n",
              "<tr><td>RF</td>\n",
              "<td>0.9707528</td>\n",
              "<td>0.9707528</td>\n",
              "<td>0.1844666</td></tr>\n",
              "<tr><td>SVM</td>\n",
              "<td>0.9597155</td>\n",
              "<td>0.9597155</td>\n",
              "<td>0.1823692</td></tr>\n",
              "<tr><td>LR</td>\n",
              "<td>0.8822470</td>\n",
              "<td>0.8822470</td>\n",
              "<td>0.1676483</td></tr>\n",
              "<tr><td>ANN</td>\n",
              "<td>0.8273094</td>\n",
              "<td>0.8273094</td>\n",
              "<td>0.1572089</td></tr>\n",
              "<tr><td>KNN</td>\n",
              "<td>0.6224613</td>\n",
              "<td>0.6224613</td>\n",
              "<td>0.1182827</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
              "\n",
              "[tips]\n",
              "Use `model.explain()` to inspect the model.\n",
              "--\n",
              "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
            ]
          },
          "metadata": {},
          "execution_count": 314
        }
      ],
      "source": [
        "sbest_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 315,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "clvKV92Y0wjQ",
        "outputId": "35d94e2a-367a-4976-bd56-6ea1ecd8f00d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model_id                                                accuracy       auc    logloss     aucpr    mean_per_class_error      rmse       mse\n",
              "----------------------------------------------------  ----------  --------  ---------  --------  ----------------------  --------  --------\n",
              "DeepLearning_grid_1_AutoML_21_20250509_83021_model_3    0.621978  0.450653   0.683858  0.337307                0.489437  0.494315  0.244347\n",
              "DeepLearning_grid_2_AutoML_21_20250509_83021_model_2    0.621978  0.484011   0.699029  0.368307                0.489437  0.497686  0.247691\n",
              "DeepLearning_grid_2_AutoML_21_20250509_83021_model_3    0.621978  0.443981   0.68223   0.337563                0.4906    0.493816  0.243854\n",
              "DeepLearning_grid_1_AutoML_21_20250509_83021_model_2    0.621978  0.530805   0.693847  0.397136                0.488242  0.494565  0.244595\n",
              "DeepLearning_grid_2_AutoML_21_20250509_83021_model_1    0.621978  0.432162   0.692146  0.326449                0.492958  0.495433  0.245454\n",
              "DeepLearning_1_AutoML_21_20250509_83021                 0.624176  0.496201   0.766961  0.370906                0.487614  0.516922  0.267209\n",
              "DeepLearning_grid_3_AutoML_21_20250509_83021_model_3    0.624176  0.492608   0.664501  0.357044                0.484155  0.485872  0.236072\n",
              "DeepLearning_grid_3_AutoML_21_20250509_83021_model_1    0.624176  0.515639   0.67657   0.369973                0.488839  0.491821  0.241888\n",
              "DeepLearning_grid_3_AutoML_21_20250509_83021_model_2    0.624176  0.524648   0.671219  0.39873                 0.488839  0.487279  0.237441\n",
              "DeepLearning_grid_1_AutoML_21_20250509_83021_model_1    0.626374  0.503428   0.729475  0.373927                0.493524  0.507097  0.257148\n",
              "[10 rows x 8 columns]\n"
            ],
            "text/html": [
              "<table class='dataframe'>\n",
              "<thead>\n",
              "<tr><th>model_id                                            </th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DeepLearning_grid_1_AutoML_21_20250509_83021_model_3</td><td style=\"text-align: right;\">  0.621978</td><td style=\"text-align: right;\">0.450653</td><td style=\"text-align: right;\"> 0.683858</td><td style=\"text-align: right;\">0.337307</td><td style=\"text-align: right;\">              0.489437</td><td style=\"text-align: right;\">0.494315</td><td style=\"text-align: right;\">0.244347</td></tr>\n",
              "<tr><td>DeepLearning_grid_2_AutoML_21_20250509_83021_model_2</td><td style=\"text-align: right;\">  0.621978</td><td style=\"text-align: right;\">0.484011</td><td style=\"text-align: right;\"> 0.699029</td><td style=\"text-align: right;\">0.368307</td><td style=\"text-align: right;\">              0.489437</td><td style=\"text-align: right;\">0.497686</td><td style=\"text-align: right;\">0.247691</td></tr>\n",
              "<tr><td>DeepLearning_grid_2_AutoML_21_20250509_83021_model_3</td><td style=\"text-align: right;\">  0.621978</td><td style=\"text-align: right;\">0.443981</td><td style=\"text-align: right;\"> 0.68223 </td><td style=\"text-align: right;\">0.337563</td><td style=\"text-align: right;\">              0.4906  </td><td style=\"text-align: right;\">0.493816</td><td style=\"text-align: right;\">0.243854</td></tr>\n",
              "<tr><td>DeepLearning_grid_1_AutoML_21_20250509_83021_model_2</td><td style=\"text-align: right;\">  0.621978</td><td style=\"text-align: right;\">0.530805</td><td style=\"text-align: right;\"> 0.693847</td><td style=\"text-align: right;\">0.397136</td><td style=\"text-align: right;\">              0.488242</td><td style=\"text-align: right;\">0.494565</td><td style=\"text-align: right;\">0.244595</td></tr>\n",
              "<tr><td>DeepLearning_grid_2_AutoML_21_20250509_83021_model_1</td><td style=\"text-align: right;\">  0.621978</td><td style=\"text-align: right;\">0.432162</td><td style=\"text-align: right;\"> 0.692146</td><td style=\"text-align: right;\">0.326449</td><td style=\"text-align: right;\">              0.492958</td><td style=\"text-align: right;\">0.495433</td><td style=\"text-align: right;\">0.245454</td></tr>\n",
              "<tr><td>DeepLearning_1_AutoML_21_20250509_83021             </td><td style=\"text-align: right;\">  0.624176</td><td style=\"text-align: right;\">0.496201</td><td style=\"text-align: right;\"> 0.766961</td><td style=\"text-align: right;\">0.370906</td><td style=\"text-align: right;\">              0.487614</td><td style=\"text-align: right;\">0.516922</td><td style=\"text-align: right;\">0.267209</td></tr>\n",
              "<tr><td>DeepLearning_grid_3_AutoML_21_20250509_83021_model_3</td><td style=\"text-align: right;\">  0.624176</td><td style=\"text-align: right;\">0.492608</td><td style=\"text-align: right;\"> 0.664501</td><td style=\"text-align: right;\">0.357044</td><td style=\"text-align: right;\">              0.484155</td><td style=\"text-align: right;\">0.485872</td><td style=\"text-align: right;\">0.236072</td></tr>\n",
              "<tr><td>DeepLearning_grid_3_AutoML_21_20250509_83021_model_1</td><td style=\"text-align: right;\">  0.624176</td><td style=\"text-align: right;\">0.515639</td><td style=\"text-align: right;\"> 0.67657 </td><td style=\"text-align: right;\">0.369973</td><td style=\"text-align: right;\">              0.488839</td><td style=\"text-align: right;\">0.491821</td><td style=\"text-align: right;\">0.241888</td></tr>\n",
              "<tr><td>DeepLearning_grid_3_AutoML_21_20250509_83021_model_2</td><td style=\"text-align: right;\">  0.624176</td><td style=\"text-align: right;\">0.524648</td><td style=\"text-align: right;\"> 0.671219</td><td style=\"text-align: right;\">0.39873 </td><td style=\"text-align: right;\">              0.488839</td><td style=\"text-align: right;\">0.487279</td><td style=\"text-align: right;\">0.237441</td></tr>\n",
              "<tr><td>DeepLearning_grid_1_AutoML_21_20250509_83021_model_1</td><td style=\"text-align: right;\">  0.626374</td><td style=\"text-align: right;\">0.503428</td><td style=\"text-align: right;\"> 0.729475</td><td style=\"text-align: right;\">0.373927</td><td style=\"text-align: right;\">              0.493524</td><td style=\"text-align: right;\">0.507097</td><td style=\"text-align: right;\">0.257148</td></tr>\n",
              "</tbody>\n",
              "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[10 rows x 8 columns]</pre>"
            ]
          },
          "metadata": {},
          "execution_count": 315
        }
      ],
      "source": [
        "saml.leaderboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 316,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q04QZjRG89Ca",
        "outputId": "0934a1ff-f461-4a43-cdf3-c81059d72ae9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: polars in /usr/local/lib/python3.11/dist-packages (1.21.0)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (18.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install polars pyarrow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 317,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivMaaDNNmYY2",
        "outputId": "7835881b-cbe9-4413-f881-02779a285040"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deeplearning prediction progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n",
            "Export File progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n"
          ]
        }
      ],
      "source": [
        "#y_pred_sh2o = pd.DataFrame(h2o.as_list(sbest_model.predict(svalid)))['predict']\n",
        "y_pred_sh2o = np.array(pd.DataFrame(sbest_model.predict(svalid).as_data_frame(use_multi_thread=True))['predict'])\n",
        "y_test_sh2o = np.array(svalid1['y_test']).copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 318,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bstP8_j09fSx",
        "outputId": "a15a826a-b7d1-484b-8966-767e1ddb298d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
              "       1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 318
        }
      ],
      "source": [
        "y_pred_sh2o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 319,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "nJrcI3Gn8we2",
        "outputId": "d145fbf6-1d5f-4b84-d183-12d8fb697a32"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 7 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 319
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.bar(acc.index, acc['train'], color ='black',width = 0.4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 320,
      "metadata": {
        "id": "Ba6kRO-eI60S"
      },
      "outputs": [],
      "source": [
        "m = [ANNmodel, model, knn, lr, rf, svm, xgb, best_model]\n",
        "\n",
        "label = [\"ArtificialNeuralNetwork\", 'DeepNeuralNetwork',\n",
        "         'KNearestNeighborsClassifier', 'LogisticRegression',\n",
        "         'RandomForestClassifier', 'SupportVectorClassifier',\n",
        "         'XGBoost', type(best_model).__name__, type(sbest_model).__name__ ]\n",
        "\n",
        "acc = pd.DataFrame(\n",
        "    {\n",
        "    \"ANN\":[ATr,ATe, SCVATr,SCVATe],\n",
        "    \"DNN\":[DTr,DTe, SCVDTr,SCVDTe],\n",
        "    \"KNN\":[KTr,KTe, SCVKTr,SCVKTe],\n",
        "    \"LR\" :[LTr,LTe, SCVLTr,SCVLTe],\n",
        "    \"RF\" :[RTr,RTe, SCVRTr,SCVRTe],\n",
        "    \"SVM\":[STr,STe, SCVSTr,SCVSTe],\n",
        "    \"XGB\":[XTr,XTe, SCVXTr,SCVXTe],\n",
        "    \"H_OD\":[HATr.accuracy()[0][1],HATe.accuracy()[0][1], SCVHATr.accuracy()[0][1], SCVHATe.accuracy()[0][1]],\n",
        "    \"H_SOD\":[sHATr.accuracy()[0][1],sHATe.accuracy()[0][1], SCVsHATr.accuracy()[0][1], SCVsHATe.accuracy()[0][1]]\n",
        "    })\n",
        "acc.index = [\"train\", \"test\", \"SCVTrain\", \"SCVTest\"]\n",
        "acc = acc.T\n",
        "acc['Model'] = label\n",
        "\n",
        "acc = acc[['Model', 'train', 'test', \"SCVTrain\", \"SCVTest\"]]\n",
        "#acc['avg'] = round((acc['train'] + acc['test'])/2, 6)\n",
        "#acc[acc[\"avg\"] == acc[\"avg\"].max()]\n",
        "#acc['BestModel'] = 0\n",
        "\n",
        "acc[\"Precision\"] = np.zeros(len(acc))\n",
        "acc[\"Recall\"]    = np.zeros(len(acc))\n",
        "acc[\"F1_Score\"]  = np.zeros(len(acc))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 321,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "VGIMsnwSVB5m",
        "outputId": "7427b1b0-d4fe-4a0c-f82c-4b849388789d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             Model     train      test  SCVTrain   SCVTest  \\\n",
              "ANN        ArtificialNeuralNetwork  0.964835  0.929825  0.950786  0.954339   \n",
              "DNN              DeepNeuralNetwork  0.626374  0.622807  0.620614  0.619469   \n",
              "KNN    KNearestNeighborsClassifier  0.982418  0.973684  0.980263  0.982301   \n",
              "LR              LogisticRegression  0.984615  0.973684  0.980263  0.964602   \n",
              "RF          RandomForestClassifier  0.975824  0.947368  0.973684  0.964602   \n",
              "SVM        SupportVectorClassifier  0.953846  0.947368  0.952551  0.952585   \n",
              "XGB                        XGBoost  0.991209  0.947368  0.993421  0.991150   \n",
              "H_OD           H2OXGBoostEstimator  0.973626  0.964912  0.973626  0.964912   \n",
              "H_SOD     H2ODeepLearningEstimator  0.637363  0.631579  0.637363  0.640351   \n",
              "\n",
              "       Precision  Recall  F1_Score  \n",
              "ANN          0.0     0.0       0.0  \n",
              "DNN          0.0     0.0       0.0  \n",
              "KNN          0.0     0.0       0.0  \n",
              "LR           0.0     0.0       0.0  \n",
              "RF           0.0     0.0       0.0  \n",
              "SVM          0.0     0.0       0.0  \n",
              "XGB          0.0     0.0       0.0  \n",
              "H_OD         0.0     0.0       0.0  \n",
              "H_SOD        0.0     0.0       0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cd8cfcd9-d39b-4ec1-90c4-b06b4212d9fa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "      <th>SCVTrain</th>\n",
              "      <th>SCVTest</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ANN</th>\n",
              "      <td>ArtificialNeuralNetwork</td>\n",
              "      <td>0.964835</td>\n",
              "      <td>0.929825</td>\n",
              "      <td>0.950786</td>\n",
              "      <td>0.954339</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DNN</th>\n",
              "      <td>DeepNeuralNetwork</td>\n",
              "      <td>0.626374</td>\n",
              "      <td>0.622807</td>\n",
              "      <td>0.620614</td>\n",
              "      <td>0.619469</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>KNearestNeighborsClassifier</td>\n",
              "      <td>0.982418</td>\n",
              "      <td>0.973684</td>\n",
              "      <td>0.980263</td>\n",
              "      <td>0.982301</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LR</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.984615</td>\n",
              "      <td>0.973684</td>\n",
              "      <td>0.980263</td>\n",
              "      <td>0.964602</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.975824</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>0.973684</td>\n",
              "      <td>0.964602</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>SupportVectorClassifier</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>0.952551</td>\n",
              "      <td>0.952585</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGB</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.991209</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>0.993421</td>\n",
              "      <td>0.991150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H_OD</th>\n",
              "      <td>H2OXGBoostEstimator</td>\n",
              "      <td>0.973626</td>\n",
              "      <td>0.964912</td>\n",
              "      <td>0.973626</td>\n",
              "      <td>0.964912</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H_SOD</th>\n",
              "      <td>H2ODeepLearningEstimator</td>\n",
              "      <td>0.637363</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>0.637363</td>\n",
              "      <td>0.640351</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd8cfcd9-d39b-4ec1-90c4-b06b4212d9fa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cd8cfcd9-d39b-4ec1-90c4-b06b4212d9fa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cd8cfcd9-d39b-4ec1-90c4-b06b4212d9fa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-86e54103-012c-4874-b0da-cf78bea61a1a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-86e54103-012c-4874-b0da-cf78bea61a1a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-86e54103-012c-4874-b0da-cf78bea61a1a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_05aadba9-8acf-4610-ae4d-d85b10736cac\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('acc')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_05aadba9-8acf-4610-ae4d-d85b10736cac button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('acc');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "acc",
              "summary": "{\n  \"name\": \"acc\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"H2OXGBoostEstimator\",\n          \"DeepNeuralNetwork\",\n          \"SupportVectorClassifier\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15181547874699977,\n        \"min\": 0.6263736486434937,\n        \"max\": 0.9912087912087912,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.9736263736263736,\n          0.6263736486434937,\n          0.9538461538461539\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14520863437571288,\n        \"min\": 0.6228070259094238,\n        \"max\": 0.9736842105263158,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.9298245906829834,\n          0.6228070259094238,\n          0.631578947368421\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SCVTrain\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1519383206532474,\n        \"min\": 0.6206140518188477,\n        \"max\": 0.993421052631579,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.6206140518188477,\n          0.993421052631579,\n          0.9507856249809266\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SCVTest\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1495810865733744,\n        \"min\": 0.6194690465927124,\n        \"max\": 0.9911504424778761,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.6194690465927124,\n          0.9911504424778761,\n          0.9543393850326538\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1_Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 321
        }
      ],
      "source": [
        "acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 322,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "2YYDFPA3Utll",
        "outputId": "a41129fc-40c3-48dc-d0ac-b161bc8f26f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             Model     train      test  SCVTrain   SCVTest  \\\n",
              "ANN        ArtificialNeuralNetwork  0.964835  0.929825  0.950786  0.954339   \n",
              "DNN              DeepNeuralNetwork  0.626374  0.622807  0.620614  0.619469   \n",
              "KNN    KNearestNeighborsClassifier  0.982418  0.973684  0.980263  0.982301   \n",
              "LR              LogisticRegression  0.984615  0.973684  0.980263  0.964602   \n",
              "RF          RandomForestClassifier  0.975824  0.947368  0.973684  0.964602   \n",
              "SVM        SupportVectorClassifier  0.953846  0.947368  0.952551  0.952585   \n",
              "XGB                        XGBoost  0.991209  0.947368  0.993421  0.991150   \n",
              "H_OD           H2OXGBoostEstimator  0.973626  0.964912  0.973626  0.964912   \n",
              "H_SOD     H2ODeepLearningEstimator  0.637363  0.631579  0.637363  0.640351   \n",
              "\n",
              "       Precision  Recall  F1_Score  \n",
              "ANN          0.0     0.0       0.0  \n",
              "DNN          0.0     0.0       0.0  \n",
              "KNN          0.0     0.0       0.0  \n",
              "LR           0.0     0.0       0.0  \n",
              "RF           0.0     0.0       0.0  \n",
              "SVM          0.0     0.0       0.0  \n",
              "XGB          0.0     0.0       0.0  \n",
              "H_OD         0.0     0.0       0.0  \n",
              "H_SOD        0.0     0.0       0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d3503393-6a12-4472-be13-2a9cee1194b6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "      <th>SCVTrain</th>\n",
              "      <th>SCVTest</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ANN</th>\n",
              "      <td>ArtificialNeuralNetwork</td>\n",
              "      <td>0.964835</td>\n",
              "      <td>0.929825</td>\n",
              "      <td>0.950786</td>\n",
              "      <td>0.954339</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DNN</th>\n",
              "      <td>DeepNeuralNetwork</td>\n",
              "      <td>0.626374</td>\n",
              "      <td>0.622807</td>\n",
              "      <td>0.620614</td>\n",
              "      <td>0.619469</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>KNearestNeighborsClassifier</td>\n",
              "      <td>0.982418</td>\n",
              "      <td>0.973684</td>\n",
              "      <td>0.980263</td>\n",
              "      <td>0.982301</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LR</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.984615</td>\n",
              "      <td>0.973684</td>\n",
              "      <td>0.980263</td>\n",
              "      <td>0.964602</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.975824</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>0.973684</td>\n",
              "      <td>0.964602</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>SupportVectorClassifier</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>0.952551</td>\n",
              "      <td>0.952585</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGB</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.991209</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>0.993421</td>\n",
              "      <td>0.991150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H_OD</th>\n",
              "      <td>H2OXGBoostEstimator</td>\n",
              "      <td>0.973626</td>\n",
              "      <td>0.964912</td>\n",
              "      <td>0.973626</td>\n",
              "      <td>0.964912</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H_SOD</th>\n",
              "      <td>H2ODeepLearningEstimator</td>\n",
              "      <td>0.637363</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>0.637363</td>\n",
              "      <td>0.640351</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3503393-6a12-4472-be13-2a9cee1194b6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d3503393-6a12-4472-be13-2a9cee1194b6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d3503393-6a12-4472-be13-2a9cee1194b6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-43dbd83d-c586-494d-ba28-4e5e177a4910\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-43dbd83d-c586-494d-ba28-4e5e177a4910')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-43dbd83d-c586-494d-ba28-4e5e177a4910 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_ae3103ab-38a7-4d8d-9420-55f6814a6b48\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('acc')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ae3103ab-38a7-4d8d-9420-55f6814a6b48 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('acc');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "acc",
              "summary": "{\n  \"name\": \"acc\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"H2OXGBoostEstimator\",\n          \"DeepNeuralNetwork\",\n          \"SupportVectorClassifier\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15181547874699977,\n        \"min\": 0.6263736486434937,\n        \"max\": 0.9912087912087912,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.9736263736263736,\n          0.6263736486434937,\n          0.9538461538461539\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14520863437571288,\n        \"min\": 0.6228070259094238,\n        \"max\": 0.9736842105263158,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.9298245906829834,\n          0.6228070259094238,\n          0.631578947368421\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SCVTrain\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1519383206532474,\n        \"min\": 0.6206140518188477,\n        \"max\": 0.993421052631579,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.6206140518188477,\n          0.993421052631579,\n          0.9507856249809266\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SCVTest\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1495810865733744,\n        \"min\": 0.6194690465927124,\n        \"max\": 0.9911504424778761,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.6194690465927124,\n          0.9911504424778761,\n          0.9543393850326538\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1_Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 322
        }
      ],
      "source": [
        "acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 323,
      "metadata": {
        "id": "S7pf8G6ao4oF"
      },
      "outputs": [],
      "source": [
        "y_pred_ANNn = []\n",
        "y_pred_DNNn = []\n",
        "for i in range(len(y_pred_ANN)):\n",
        "  y_pred_ANNn.append(y_pred_ANN[i][0])\n",
        "  y_pred_DNNn.append(y_pred_DNN[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 324,
      "metadata": {
        "id": "D2n2VnW1jKp4"
      },
      "outputs": [],
      "source": [
        "pred = [np.array(y_pred_ANNn), np.array(y_pred_DNNn), y_pred_knn,\n",
        "        y_pred_lr, y_pred_rf,\n",
        "        y_pred_svm, y_pred_xgb, y_pred_h2o, y_pred_sh2o]\n",
        "\n",
        "tes  = [y_test_indi_ML, np.array(Dy_test), y_test_indi_ML, y_test_indi_ML,\n",
        "        y_test_indi_ML, y_test_indi_ML, y_test_indi_ML,\n",
        "        y_test_h2o.copy(), y_test_sh2o.copy()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 325,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FM27JHld_2ox",
        "outputId": "ce73c0db-3db1-41e3-edab-cb85cbceb82e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
              "        0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "        1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
              "        0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
              "        0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
              "        0, 0, 0, 0]),\n",
              " array([0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
              "        0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
              "        1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
              "        0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
              "        1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 1]),\n",
              " array([0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
              "        0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "        1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
              "        0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
              "        0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
              "        0, 0, 0, 0]),\n",
              " array([0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
              "        0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "        1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
              "        0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
              "        0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
              "        0, 0, 0, 0]),\n",
              " array([0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
              "        0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "        1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
              "        0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
              "        0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
              "        0, 0, 0, 0]),\n",
              " array([0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
              "        0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "        1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
              "        0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
              "        0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
              "        0, 0, 0, 0]),\n",
              " array([0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
              "        0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "        1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
              "        0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
              "        0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
              "        0, 0, 0, 0]),\n",
              " array([0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
              "        0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
              "        1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
              "        0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
              "        1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 1], dtype=int32),\n",
              " array([0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
              "        0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
              "        1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
              "        0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
              "        1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 1])]"
            ]
          },
          "metadata": {},
          "execution_count": 325
        }
      ],
      "source": [
        "tes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 326,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "vR3fjkiLZERP",
        "outputId": "0dda6b4c-c257-4a4b-824f-66cb0d6a1b90"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ANN      0.0\n",
              "DNN      0.0\n",
              "KNN      0.0\n",
              "LR       0.0\n",
              "RF       0.0\n",
              "SVM      0.0\n",
              "XGB      0.0\n",
              "H_OD     0.0\n",
              "H_SOD    0.0\n",
              "Name: Precision, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Precision</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ANN</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DNN</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LR</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGB</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H_OD</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H_SOD</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 326
        }
      ],
      "source": [
        "acc.iloc[:,5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 327,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "2DlSQ29moN9T",
        "outputId": "850209e2-c2dc-4864-dc02-0fd024d84678"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             Model     train      test  SCVTrain   SCVTest  \\\n",
              "ANN        ArtificialNeuralNetwork  0.964835  0.929825  0.950786  0.954339   \n",
              "DNN              DeepNeuralNetwork  0.626374  0.622807  0.620614  0.619469   \n",
              "KNN    KNearestNeighborsClassifier  0.982418  0.973684  0.980263  0.982301   \n",
              "LR              LogisticRegression  0.984615  0.973684  0.980263  0.964602   \n",
              "RF          RandomForestClassifier  0.975824  0.947368  0.973684  0.964602   \n",
              "SVM        SupportVectorClassifier  0.953846  0.947368  0.952551  0.952585   \n",
              "XGB                        XGBoost  0.991209  0.947368  0.993421  0.991150   \n",
              "H_OD           H2OXGBoostEstimator  0.973626  0.964912  0.973626  0.964912   \n",
              "H_SOD     H2ODeepLearningEstimator  0.637363  0.631579  0.637363  0.640351   \n",
              "\n",
              "       Precision    Recall  F1_Score  \n",
              "ANN     0.924603  0.924603  0.924603  \n",
              "DNN     0.316964  0.486301  0.383784  \n",
              "KNN     0.974106  0.969246  0.971583  \n",
              "LR      0.969702  0.974206  0.971863  \n",
              "RF      0.938299  0.953373  0.944481  \n",
              "SVM     0.940260  0.948413  0.943990  \n",
              "XGB     0.940260  0.948413  0.943990  \n",
              "H_OD    0.958074  0.967257  0.962302  \n",
              "H_SOD   0.691589  0.547945  0.364527  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f4923aad-2282-4afa-9d45-818e28932e5a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "      <th>SCVTrain</th>\n",
              "      <th>SCVTest</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ANN</th>\n",
              "      <td>ArtificialNeuralNetwork</td>\n",
              "      <td>0.964835</td>\n",
              "      <td>0.929825</td>\n",
              "      <td>0.950786</td>\n",
              "      <td>0.954339</td>\n",
              "      <td>0.924603</td>\n",
              "      <td>0.924603</td>\n",
              "      <td>0.924603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DNN</th>\n",
              "      <td>DeepNeuralNetwork</td>\n",
              "      <td>0.626374</td>\n",
              "      <td>0.622807</td>\n",
              "      <td>0.620614</td>\n",
              "      <td>0.619469</td>\n",
              "      <td>0.316964</td>\n",
              "      <td>0.486301</td>\n",
              "      <td>0.383784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>KNearestNeighborsClassifier</td>\n",
              "      <td>0.982418</td>\n",
              "      <td>0.973684</td>\n",
              "      <td>0.980263</td>\n",
              "      <td>0.982301</td>\n",
              "      <td>0.974106</td>\n",
              "      <td>0.969246</td>\n",
              "      <td>0.971583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LR</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.984615</td>\n",
              "      <td>0.973684</td>\n",
              "      <td>0.980263</td>\n",
              "      <td>0.964602</td>\n",
              "      <td>0.969702</td>\n",
              "      <td>0.974206</td>\n",
              "      <td>0.971863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.975824</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>0.973684</td>\n",
              "      <td>0.964602</td>\n",
              "      <td>0.938299</td>\n",
              "      <td>0.953373</td>\n",
              "      <td>0.944481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>SupportVectorClassifier</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>0.952551</td>\n",
              "      <td>0.952585</td>\n",
              "      <td>0.940260</td>\n",
              "      <td>0.948413</td>\n",
              "      <td>0.943990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGB</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.991209</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>0.993421</td>\n",
              "      <td>0.991150</td>\n",
              "      <td>0.940260</td>\n",
              "      <td>0.948413</td>\n",
              "      <td>0.943990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H_OD</th>\n",
              "      <td>H2OXGBoostEstimator</td>\n",
              "      <td>0.973626</td>\n",
              "      <td>0.964912</td>\n",
              "      <td>0.973626</td>\n",
              "      <td>0.964912</td>\n",
              "      <td>0.958074</td>\n",
              "      <td>0.967257</td>\n",
              "      <td>0.962302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H_SOD</th>\n",
              "      <td>H2ODeepLearningEstimator</td>\n",
              "      <td>0.637363</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>0.637363</td>\n",
              "      <td>0.640351</td>\n",
              "      <td>0.691589</td>\n",
              "      <td>0.547945</td>\n",
              "      <td>0.364527</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4923aad-2282-4afa-9d45-818e28932e5a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f4923aad-2282-4afa-9d45-818e28932e5a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f4923aad-2282-4afa-9d45-818e28932e5a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6fd9f8b0-3d26-4270-a6ae-8a77e300e64d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6fd9f8b0-3d26-4270-a6ae-8a77e300e64d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6fd9f8b0-3d26-4270-a6ae-8a77e300e64d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_82b0c8d4-7138-4a84-95c9-5c79dcb41d26\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('acc')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_82b0c8d4-7138-4a84-95c9-5c79dcb41d26 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('acc');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "acc",
              "summary": "{\n  \"name\": \"acc\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"H2OXGBoostEstimator\",\n          \"DeepNeuralNetwork\",\n          \"SupportVectorClassifier\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15181547874699977,\n        \"min\": 0.6263736486434937,\n        \"max\": 0.9912087912087912,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.9736263736263736,\n          0.6263736486434937,\n          0.9538461538461539\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14520863437571288,\n        \"min\": 0.6228070259094238,\n        \"max\": 0.9736842105263158,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.9298245906829834,\n          0.6228070259094238,\n          0.631578947368421\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SCVTrain\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1519383206532474,\n        \"min\": 0.6206140518188477,\n        \"max\": 0.993421052631579,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.6206140518188477,\n          0.993421052631579,\n          0.9507856249809266\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SCVTest\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1495810865733744,\n        \"min\": 0.6194690465927124,\n        \"max\": 0.9911504424778761,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.6194690465927124,\n          0.9911504424778761,\n          0.9543393850326538\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21802708279385302,\n        \"min\": 0.3169642857142857,\n        \"max\": 0.9741062479117941,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.3169642857142857,\n          0.9402597402597402,\n          0.9246031746031746\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19429065473048354,\n        \"min\": 0.4863013698630137,\n        \"max\": 0.9742063492063492,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.4863013698630137,\n          0.9484126984126984,\n          0.9246031746031746\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1_Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.25522202086251405,\n        \"min\": 0.364527027027027,\n        \"max\": 0.9718634306869601,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.3837837837837838,\n          0.9439895185063871,\n          0.9246031746031746\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 327
        }
      ],
      "source": [
        "for i in range(len(pred)):\n",
        "  p,r,f,_ = precision_recall_fscore_support(tes[i], pred[i],\n",
        "                                            average='macro',zero_division=0)\n",
        "  acc.iloc[i,5]= p\n",
        "  acc.iloc[i,6]= r\n",
        "  acc.iloc[i,7]= f\n",
        "  p = 0\n",
        "  r = 0\n",
        "  f = 0\n",
        "acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 328,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "ru4oH6-YzGPw",
        "outputId": "4439a74b-e218-41d8-bdd9-d94f589a9c2c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 9 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 328
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.bar(acc.index, acc['train'], color ='black',width = 0.4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 329,
      "metadata": {
        "id": "Qma6hWrmDBvf"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 330,
      "metadata": {
        "id": "03rwpiYpoAGs"
      },
      "outputs": [],
      "source": [
        "m = [ANNmodel, model, knn, lr, rf, svm, xgb, best_model]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 331,
      "metadata": {
        "id": "x5wrzn-qPaXw"
      },
      "outputs": [],
      "source": [
        "#encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(df['diagnosis']).copy()\n",
        "X = df.drop(columns=['diagnosis']).copy()\n",
        "X = StandardScaler().fit_transform(X).copy()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=123)\n",
        "y_test_indi_ML = y_test.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 332,
      "metadata": {
        "id": "C80ESe__xB5x"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 333,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "id": "4Bi4CMUJm6yH",
        "outputId": "4572f3ee-aed4-4c36-8ad9-bf5085f29d35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "xgboost prediction progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
            "\n",
            "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n",
            "/usr/local/lib/python3.11/dist-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
            "\n",
            "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deeplearning prediction progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
            "\n",
            "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n",
            "/usr/local/lib/python3.11/dist-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
            "\n",
            "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(1)\n",
        "plt.rcParams[\"figure.figsize\"] = [10, 5]\n",
        "\n",
        "y_pred = ANNmodel.predict(X_test).ravel()\n",
        "y_test = y_test_indi_ML\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[0]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = model.predict(DX_test).ravel()\n",
        "y_test = Dy_test.copy()\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[1]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = knn.predict_proba(X_test)[:, 1]\n",
        "y_test = y_test_indi_ML\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[2]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = lr.predict_proba(X_test)[:, 1]\n",
        "y_test = y_test_indi_ML\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[3]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = rf.predict_proba(X_test)[:, 1]\n",
        "y_test = y_test_indi_ML\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[4]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = svm.predict_proba(X_test)[:, 1]\n",
        "y_test = y_test_indi_ML\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[5]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = xgb.predict_proba(X_test)[:, 1]\n",
        "y_test = y_test_indi_ML\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, label=str(label[6]) + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = pd.DataFrame(h2o.as_list(best_model.predict(valid)))\n",
        "y_test = h2o.as_list(valid['diagnosis'])\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred[\"p1\"])\n",
        "auc = metrics.roc_auc_score(y_test, y_pred[\"p1\"])\n",
        "plt.plot(fpr, tpr,label=type(best_model).__name__ + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "y_pred = pd.DataFrame(h2o.as_list(sbest_model.predict(svalid)))\n",
        "y_test = h2o.as_list(svalid['y_test'])\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred[\"p1\"])\n",
        "auc = metrics.roc_auc_score(y_test, y_pred[\"p1\"])\n",
        "plt.plot(fpr, tpr,label=type(sbest_model).__name__ + '(area = {:.3f})'.format(auc))\n",
        "\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('AUC ROC curve')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 334,
      "metadata": {
        "id": "6vUubKKMxLIP"
      },
      "outputs": [],
      "source": [
        "tm = [aend,dend,kend,lend,rend,send,xend,autoend,sautoend]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 335,
      "metadata": {
        "id": "_1wKoAe9wIPn"
      },
      "outputs": [],
      "source": [
        "acc['time'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 336,
      "metadata": {
        "id": "P-K86caJxhvX"
      },
      "outputs": [],
      "source": [
        "acc['time'] = tm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 337,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "Oc880RvD9ibh",
        "outputId": "66139082-743c-4b30-e107-3d92b5e5ad86"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             Model     train      test  SCVTrain   SCVTest  \\\n",
              "ANN        ArtificialNeuralNetwork  0.964835  0.929825  0.950786  0.954339   \n",
              "DNN              DeepNeuralNetwork  0.626374  0.622807  0.620614  0.619469   \n",
              "KNN    KNearestNeighborsClassifier  0.982418  0.973684  0.980263  0.982301   \n",
              "LR              LogisticRegression  0.984615  0.973684  0.980263  0.964602   \n",
              "RF          RandomForestClassifier  0.975824  0.947368  0.973684  0.964602   \n",
              "SVM        SupportVectorClassifier  0.953846  0.947368  0.952551  0.952585   \n",
              "XGB                        XGBoost  0.991209  0.947368  0.993421  0.991150   \n",
              "H_OD           H2OXGBoostEstimator  0.973626  0.964912  0.973626  0.964912   \n",
              "H_SOD     H2ODeepLearningEstimator  0.637363  0.631579  0.637363  0.640351   \n",
              "\n",
              "       Precision    Recall  F1_Score        time  \n",
              "ANN     0.924603  0.924603  0.924603    5.586303  \n",
              "DNN     0.316964  0.486301  0.383784   74.244325  \n",
              "KNN     0.974106  0.969246  0.971583    0.000888  \n",
              "LR      0.969702  0.974206  0.971863    0.005752  \n",
              "RF      0.938299  0.953373  0.944481    0.845500  \n",
              "SVM     0.940260  0.948413  0.943990    0.039052  \n",
              "XGB     0.940260  0.948413  0.943990    2.533981  \n",
              "H_OD    0.958074  0.967257  0.962302   63.034867  \n",
              "H_SOD   0.691589  0.547945  0.364527  831.742351  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e79d34fa-927d-48bc-bdc7-1d21f3a044c9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "      <th>SCVTrain</th>\n",
              "      <th>SCVTest</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1_Score</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ANN</th>\n",
              "      <td>ArtificialNeuralNetwork</td>\n",
              "      <td>0.964835</td>\n",
              "      <td>0.929825</td>\n",
              "      <td>0.950786</td>\n",
              "      <td>0.954339</td>\n",
              "      <td>0.924603</td>\n",
              "      <td>0.924603</td>\n",
              "      <td>0.924603</td>\n",
              "      <td>5.586303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DNN</th>\n",
              "      <td>DeepNeuralNetwork</td>\n",
              "      <td>0.626374</td>\n",
              "      <td>0.622807</td>\n",
              "      <td>0.620614</td>\n",
              "      <td>0.619469</td>\n",
              "      <td>0.316964</td>\n",
              "      <td>0.486301</td>\n",
              "      <td>0.383784</td>\n",
              "      <td>74.244325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>KNearestNeighborsClassifier</td>\n",
              "      <td>0.982418</td>\n",
              "      <td>0.973684</td>\n",
              "      <td>0.980263</td>\n",
              "      <td>0.982301</td>\n",
              "      <td>0.974106</td>\n",
              "      <td>0.969246</td>\n",
              "      <td>0.971583</td>\n",
              "      <td>0.000888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LR</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.984615</td>\n",
              "      <td>0.973684</td>\n",
              "      <td>0.980263</td>\n",
              "      <td>0.964602</td>\n",
              "      <td>0.969702</td>\n",
              "      <td>0.974206</td>\n",
              "      <td>0.971863</td>\n",
              "      <td>0.005752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.975824</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>0.973684</td>\n",
              "      <td>0.964602</td>\n",
              "      <td>0.938299</td>\n",
              "      <td>0.953373</td>\n",
              "      <td>0.944481</td>\n",
              "      <td>0.845500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>SupportVectorClassifier</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>0.952551</td>\n",
              "      <td>0.952585</td>\n",
              "      <td>0.940260</td>\n",
              "      <td>0.948413</td>\n",
              "      <td>0.943990</td>\n",
              "      <td>0.039052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGB</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.991209</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>0.993421</td>\n",
              "      <td>0.991150</td>\n",
              "      <td>0.940260</td>\n",
              "      <td>0.948413</td>\n",
              "      <td>0.943990</td>\n",
              "      <td>2.533981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H_OD</th>\n",
              "      <td>H2OXGBoostEstimator</td>\n",
              "      <td>0.973626</td>\n",
              "      <td>0.964912</td>\n",
              "      <td>0.973626</td>\n",
              "      <td>0.964912</td>\n",
              "      <td>0.958074</td>\n",
              "      <td>0.967257</td>\n",
              "      <td>0.962302</td>\n",
              "      <td>63.034867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H_SOD</th>\n",
              "      <td>H2ODeepLearningEstimator</td>\n",
              "      <td>0.637363</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>0.637363</td>\n",
              "      <td>0.640351</td>\n",
              "      <td>0.691589</td>\n",
              "      <td>0.547945</td>\n",
              "      <td>0.364527</td>\n",
              "      <td>831.742351</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e79d34fa-927d-48bc-bdc7-1d21f3a044c9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e79d34fa-927d-48bc-bdc7-1d21f3a044c9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e79d34fa-927d-48bc-bdc7-1d21f3a044c9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-df7d4d2d-5e17-4f01-9289-dc657dca63e0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-df7d4d2d-5e17-4f01-9289-dc657dca63e0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-df7d4d2d-5e17-4f01-9289-dc657dca63e0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_57a1a160-7330-4976-bcfd-271183101df9\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('acc')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_57a1a160-7330-4976-bcfd-271183101df9 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('acc');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "acc",
              "summary": "{\n  \"name\": \"acc\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"H2OXGBoostEstimator\",\n          \"DeepNeuralNetwork\",\n          \"SupportVectorClassifier\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15181547874699977,\n        \"min\": 0.6263736486434937,\n        \"max\": 0.9912087912087912,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.9736263736263736,\n          0.6263736486434937,\n          0.9538461538461539\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14520863437571288,\n        \"min\": 0.6228070259094238,\n        \"max\": 0.9736842105263158,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.9298245906829834,\n          0.6228070259094238,\n          0.631578947368421\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SCVTrain\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1519383206532474,\n        \"min\": 0.6206140518188477,\n        \"max\": 0.993421052631579,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.6206140518188477,\n          0.993421052631579,\n          0.9507856249809266\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SCVTest\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1495810865733744,\n        \"min\": 0.6194690465927124,\n        \"max\": 0.9911504424778761,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.6194690465927124,\n          0.9911504424778761,\n          0.9543393850326538\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21802708279385302,\n        \"min\": 0.3169642857142857,\n        \"max\": 0.9741062479117941,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.3169642857142857,\n          0.9402597402597402,\n          0.9246031746031746\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19429065473048354,\n        \"min\": 0.4863013698630137,\n        \"max\": 0.9742063492063492,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.4863013698630137,\n          0.9484126984126984,\n          0.9246031746031746\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1_Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.25522202086251405,\n        \"min\": 0.364527027027027,\n        \"max\": 0.9718634306869601,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.3837837837837838,\n          0.9439895185063871,\n          0.9246031746031746\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 272.72608053718193,\n        \"min\": 0.0008878707885742188,\n        \"max\": 831.7423505783081,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          63.03486728668213,\n          74.24432468414307,\n          0.03905224800109863\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 337
        }
      ],
      "source": [
        "acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 338,
      "metadata": {
        "id": "92rbe1HkV2KZ"
      },
      "outputs": [],
      "source": [
        "acc.to_csv(\"Result_of_original_Data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9giwij3GbjKc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}