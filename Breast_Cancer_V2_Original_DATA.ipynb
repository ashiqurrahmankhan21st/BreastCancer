{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashiqurrahmankhan21st/BreastCancer/blob/main/Breast_Cancer_V2_Original_DATA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EUMYU_d6_J-X"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "#import keras_metrics\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from sklearn.inspection import PartialDependenceDisplay\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#original data\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/ashiqurrahmankhan21st/BreastCancer/main/data.csv\")\n",
        "del df['id']\n",
        "df"
      ],
      "metadata": {
        "id": "Ntdqq4T_aGXN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "outputId": "54feacf4-7a75-4586-bc60-20b97aa91f2a"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0           M        17.99         10.38          122.80     1001.0   \n",
              "1           M        20.57         17.77          132.90     1326.0   \n",
              "2           M        19.69         21.25          130.00     1203.0   \n",
              "3           M        11.42         20.38           77.58      386.1   \n",
              "4           M        20.29         14.34          135.10     1297.0   \n",
              "..        ...          ...           ...             ...        ...   \n",
              "564         M        21.56         22.39          142.00     1479.0   \n",
              "565         M        20.13         28.25          131.20     1261.0   \n",
              "566         M        16.60         28.08          108.30      858.1   \n",
              "567         M        20.60         29.33          140.10     1265.0   \n",
              "568         B         7.76         24.54           47.92      181.0   \n",
              "\n",
              "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0            0.11840           0.27760         0.30010              0.14710   \n",
              "1            0.08474           0.07864         0.08690              0.07017   \n",
              "2            0.10960           0.15990         0.19740              0.12790   \n",
              "3            0.14250           0.28390         0.24140              0.10520   \n",
              "4            0.10030           0.13280         0.19800              0.10430   \n",
              "..               ...               ...             ...                  ...   \n",
              "564          0.11100           0.11590         0.24390              0.13890   \n",
              "565          0.09780           0.10340         0.14400              0.09791   \n",
              "566          0.08455           0.10230         0.09251              0.05302   \n",
              "567          0.11780           0.27700         0.35140              0.15200   \n",
              "568          0.05263           0.04362         0.00000              0.00000   \n",
              "\n",
              "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
              "0           0.2419  ...        25.380          17.33           184.60   \n",
              "1           0.1812  ...        24.990          23.41           158.80   \n",
              "2           0.2069  ...        23.570          25.53           152.50   \n",
              "3           0.2597  ...        14.910          26.50            98.87   \n",
              "4           0.1809  ...        22.540          16.67           152.20   \n",
              "..             ...  ...           ...            ...              ...   \n",
              "564         0.1726  ...        25.450          26.40           166.10   \n",
              "565         0.1752  ...        23.690          38.25           155.00   \n",
              "566         0.1590  ...        18.980          34.12           126.70   \n",
              "567         0.2397  ...        25.740          39.42           184.60   \n",
              "568         0.1587  ...         9.456          30.37            59.16   \n",
              "\n",
              "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
              "0        2019.0           0.16220            0.66560           0.7119   \n",
              "1        1956.0           0.12380            0.18660           0.2416   \n",
              "2        1709.0           0.14440            0.42450           0.4504   \n",
              "3         567.7           0.20980            0.86630           0.6869   \n",
              "4        1575.0           0.13740            0.20500           0.4000   \n",
              "..          ...               ...                ...              ...   \n",
              "564      2027.0           0.14100            0.21130           0.4107   \n",
              "565      1731.0           0.11660            0.19220           0.3215   \n",
              "566      1124.0           0.11390            0.30940           0.3403   \n",
              "567      1821.0           0.16500            0.86810           0.9387   \n",
              "568       268.6           0.08996            0.06444           0.0000   \n",
              "\n",
              "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
              "0                  0.2654          0.4601                  0.11890  \n",
              "1                  0.1860          0.2750                  0.08902  \n",
              "2                  0.2430          0.3613                  0.08758  \n",
              "3                  0.2575          0.6638                  0.17300  \n",
              "4                  0.1625          0.2364                  0.07678  \n",
              "..                    ...             ...                      ...  \n",
              "564                0.2216          0.2060                  0.07115  \n",
              "565                0.1628          0.2572                  0.06637  \n",
              "566                0.1418          0.2218                  0.07820  \n",
              "567                0.2650          0.4087                  0.12400  \n",
              "568                0.0000          0.2871                  0.07039  \n",
              "\n",
              "[569 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d671970f-3e86-478c-ae14-159fb92714f0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>...</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>...</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>...</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>...</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>...</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>M</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>...</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>M</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>...</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>M</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>...</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>M</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>...</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>B</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>...</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d671970f-3e86-478c-ae14-159fb92714f0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d671970f-3e86-478c-ae14-159fb92714f0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d671970f-3e86-478c-ae14-159fb92714f0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(df['diagnosis']).copy()\n",
        "X = df.drop(columns=['diagnosis']).copy()\n",
        "X = StandardScaler().fit_transform(X).copy()"
      ],
      "metadata": {
        "id": "4cimS259ti6F"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['diagnosis'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bv9sG-P8M1Fe",
        "outputId": "3a842acb-f494-4137-b96f-6208007ab732"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "B    357\n",
              "M    212\n",
              "Name: diagnosis, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "#X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=123)\n",
        "print(\"Original data : \",df.shape)\n",
        "print(\"tarin         : \",X_train.shape)\n",
        "print(\"test          : \",X_test.shape[0])\n",
        "print(\"validation    : \",X_val.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpyVwv13CTut",
        "outputId": "142ded07-1462-4e4e-a3eb-952d6a48ba49"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original data :  (569, 31)\n",
            "tarin         :  (455, 30)\n",
            "test          :  114\n",
            "validation    :  57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM\n",
        "svm = SVC(C=0.1, gamma='auto', kernel = 'rbf')\n",
        "svm.fit(X_train, y_train)\n",
        "STr = svm.score(X_train, y_train)\n",
        "STe = svm.score(X_test, y_test)\n",
        "y_pred_svm = svm.predict(X_test)"
      ],
      "metadata": {
        "id": "wnRYFOkyEEZ9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ANN\n",
        "tf.random.set_seed(123)\n",
        "ANNmodel = Sequential()\n",
        "ANNmodel.add(Dense(30, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "ANNmodel.add(Dense(10, activation='relu'))\n",
        "ANNmodel.add(Dense(1, activation='sigmoid'))\n",
        "ANNmodel.compile(loss='BinaryCrossentropy', optimizer='adam', metrics=['accuracy']) #tf.keras.metrics.Precision(), tf.keras.metrics.Recall()\n",
        "ANNmodel.fit(X_train,y_train, batch_size = 128, epochs = 20, validation_split = 0.1)\n",
        "ATr = ANNmodel.evaluate(X_train,y_train,verbose=0)[1]\n",
        "ATe = ANNmodel.evaluate(X_test,y_test,verbose=0)[1]\n",
        "y_pred_ANN = (ANNmodel.predict(X_test) > 0.5).astype(\"int32\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZX7DbN-OIyu",
        "outputId": "37176537-4d7f-4e79-a9e4-52b37b4995fc"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "4/4 [==============================] - 1s 69ms/step - loss: 0.5701 - accuracy: 0.7463 - val_loss: 0.5706 - val_accuracy: 0.8043\n",
            "Epoch 2/20\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5053 - accuracy: 0.8341 - val_loss: 0.5191 - val_accuracy: 0.8913\n",
            "Epoch 3/20\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4534 - accuracy: 0.8878 - val_loss: 0.4746 - val_accuracy: 0.9348\n",
            "Epoch 4/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4099 - accuracy: 0.9146 - val_loss: 0.4355 - val_accuracy: 0.9565\n",
            "Epoch 5/20\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3717 - accuracy: 0.9268 - val_loss: 0.3998 - val_accuracy: 0.9565\n",
            "Epoch 6/20\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3376 - accuracy: 0.9341 - val_loss: 0.3664 - val_accuracy: 0.9565\n",
            "Epoch 7/20\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3074 - accuracy: 0.9439 - val_loss: 0.3358 - val_accuracy: 0.9565\n",
            "Epoch 8/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.2803 - accuracy: 0.9463 - val_loss: 0.3080 - val_accuracy: 0.9565\n",
            "Epoch 9/20\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.2560 - accuracy: 0.9463 - val_loss: 0.2825 - val_accuracy: 0.9565\n",
            "Epoch 10/20\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.2352 - accuracy: 0.9512 - val_loss: 0.2591 - val_accuracy: 0.9565\n",
            "Epoch 11/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.2170 - accuracy: 0.9537 - val_loss: 0.2381 - val_accuracy: 0.9565\n",
            "Epoch 12/20\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.2009 - accuracy: 0.9561 - val_loss: 0.2196 - val_accuracy: 0.9565\n",
            "Epoch 13/20\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.1871 - accuracy: 0.9585 - val_loss: 0.2039 - val_accuracy: 0.9565\n",
            "Epoch 14/20\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.1750 - accuracy: 0.9610 - val_loss: 0.1909 - val_accuracy: 0.9565\n",
            "Epoch 15/20\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1644 - accuracy: 0.9634 - val_loss: 0.1798 - val_accuracy: 0.9565\n",
            "Epoch 16/20\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1551 - accuracy: 0.9634 - val_loss: 0.1698 - val_accuracy: 0.9565\n",
            "Epoch 17/20\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1468 - accuracy: 0.9634 - val_loss: 0.1612 - val_accuracy: 0.9565\n",
            "Epoch 18/20\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1394 - accuracy: 0.9610 - val_loss: 0.1539 - val_accuracy: 0.9565\n",
            "Epoch 19/20\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1329 - accuracy: 0.9585 - val_loss: 0.1475 - val_accuracy: 0.9565\n",
            "Epoch 20/20\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.1269 - accuracy: 0.9585 - val_loss: 0.1425 - val_accuracy: 0.9565\n",
            "4/4 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XGBoost\n",
        "params = {\n",
        "            'objective':'binary:logistic',\n",
        "            'max_depth': 7,\n",
        "            'alpha': 10,\n",
        "            'learning_rate': 1,\n",
        "            'n_estimators':100\n",
        "        }\n",
        "xgb = XGBClassifier(objective='binary:logistic',max_depth= 7,alpha= 10,learning_rate= 1,n_estimators=100)\n",
        "xgb.fit(X_train, y_train)\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "XTr = accuracy_score(y_train, xgb.predict(X_train))\n",
        "XTe = accuracy_score(y_test, xgb.predict(X_test))\n",
        "XTr,XTe"
      ],
      "metadata": {
        "id": "PCP82YZ9RjgJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95f5af12-b6ea-49ba-928d-89ba9db27782"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.989010989010989, 0.9824561403508771)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#KNN\n",
        "# Define the range of n_neighbors values to test\n",
        "n_neighbors_values = [1,3, 5, 7, 9, 11]\n",
        "\n",
        "best_accuracy = 0.0\n",
        "best_n_neighbors = None\n",
        "\n",
        "for n_neighbors in n_neighbors_values:\n",
        "    print(\"Number of Neighbors:\", n_neighbors)\n",
        "\n",
        "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    y_pred_knn = knn.predict(X_test)\n",
        "\n",
        "    train_accuracy = accuracy_score(y_train, knn.predict(X_train))\n",
        "    test_accuracy = accuracy_score(y_test, knn.predict(X_test))\n",
        "\n",
        "    print('KNN model train accuracy score: {0:0.4f}'.format(train_accuracy))\n",
        "    print('KNN model test accuracy score: {0:0.4f}'.format(test_accuracy))\n",
        "    print()\n",
        "\n",
        "    # Check if the current test accuracy is better than the previous best\n",
        "    if test_accuracy > best_accuracy:\n",
        "        best_accuracy = test_accuracy\n",
        "        best_n_neighbors = n_neighbors\n",
        "print(\"best neighbours: \", best_n_neighbors)\n",
        "knn = KNeighborsClassifier(n_neighbors=best_n_neighbors)\n",
        "knn.fit(X_train, y_train)\n",
        "KTr = accuracy_score(y_train, knn.predict(X_train))\n",
        "KTe = accuracy_score(y_test, knn.predict(X_test))\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "KTr,KTe\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Y_6b33A1imy",
        "outputId": "52537459-1342-4abf-eef1-2bece2c3a25c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Neighbors: 1\n",
            "KNN model train accuracy score: 1.0000\n",
            "KNN model test accuracy score: 0.9737\n",
            "\n",
            "Number of Neighbors: 3\n",
            "KNN model train accuracy score: 0.9802\n",
            "KNN model test accuracy score: 0.9912\n",
            "\n",
            "Number of Neighbors: 5\n",
            "KNN model train accuracy score: 0.9692\n",
            "KNN model test accuracy score: 0.9825\n",
            "\n",
            "Number of Neighbors: 7\n",
            "KNN model train accuracy score: 0.9692\n",
            "KNN model test accuracy score: 0.9737\n",
            "\n",
            "Number of Neighbors: 9\n",
            "KNN model train accuracy score: 0.9692\n",
            "KNN model test accuracy score: 0.9825\n",
            "\n",
            "Number of Neighbors: 11\n",
            "KNN model train accuracy score: 0.9714\n",
            "KNN model test accuracy score: 0.9825\n",
            "\n",
            "best neighbours:  3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9802197802197802, 0.9912280701754386)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RF\n",
        "rf = RandomForestClassifier(n_estimators= 500,max_features = 'sqrt', max_samples = 100, random_state=123)\n",
        "rf.fit(X_train, y_train)\n",
        "RTr = accuracy_score(y_train, rf.predict(X_train))\n",
        "RTe = accuracy_score(y_test, rf.predict(X_test))\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "RTr,RTe"
      ],
      "metadata": {
        "id": "k_kyk_E92bSX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31dd8796-584c-46d8-9c02-d4542734c5f7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9758241758241758, 0.9912280701754386)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LR\n",
        "lr = LogisticRegression(C= 0.1 , penalty='l1', solver='liblinear', max_iter = 1000, random_state=123)\n",
        "lr.fit(X_train, y_train)\n",
        "LTr = accuracy_score(y_train, lr.predict(X_train))\n",
        "LTe = accuracy_score(y_test, lr.predict(X_test))\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "LTr,LTe"
      ],
      "metadata": {
        "id": "OWkZmwL23Fm_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dc9dc78-d4e7-4967-9de1-ae4f5dd1c80d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9802197802197802, 0.9736842105263158)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E9_l6r5f0w5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CVal(ML):\n",
        "\n",
        "  df = pd.read_csv(\"https://raw.githubusercontent.com/ashiqurrahmankhan21st/BreastCancer/main/data.csv\")\n",
        "  del df['id']\n",
        "\n",
        "  s = 0\n",
        "  e = round(df.shape[0]*.2)\n",
        "\n",
        "  y_pred = []\n",
        "  y_original = []\n",
        "\n",
        "  for i in range(5):\n",
        "\n",
        "    test_set  = df.iloc[s:e,:]\n",
        "    train_set = df.drop(test_set.index)\n",
        "\n",
        "    X_train = StandardScaler().fit_transform(train_set.drop(columns=['diagnosis'])).copy()\n",
        "    y_train = encoder.fit_transform(train_set['diagnosis']).copy()\n",
        "    X_test = StandardScaler().fit_transform(test_set.drop(columns=['diagnosis'])).copy()\n",
        "    y_test = encoder.fit_transform(test_set['diagnosis']).copy()\n",
        "\n",
        "    #svm = SVC(C=0.1, gamma='auto', kernel = 'rbf')\n",
        "    ML.fit(X_train, y_train)\n",
        "    y_pred_ML = ML.predict(X_test)\n",
        "\n",
        "\n",
        "    y_pred.append(y_pred_ML)\n",
        "    y_original.append(y_test)\n",
        "\n",
        "    s = e\n",
        "    e = e + round(df.shape[0]*.2)\n",
        "    if e-s < round(df.shape[0]*.2):\n",
        "      e = df.shape[0]+1\n",
        "\n",
        "  y_pred_final = []\n",
        "  y_original_final = []\n",
        "\n",
        "  try:\n",
        "    for i in range(5):\n",
        "      for j in range(round(df.shape[0]*.2)):\n",
        "        y_pred_final.append(y_pred[i][j])\n",
        "        y_original_final.append(y_original[i][j])\n",
        "  except:\n",
        "    pass\n",
        "  return y_pred_final"
      ],
      "metadata": {
        "id": "XqaJZ1Mb0xAe"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CValANN():\n",
        "\n",
        "  df = pd.read_csv(\"https://raw.githubusercontent.com/ashiqurrahmankhan21st/BreastCancer/main/data.csv\")\n",
        "  del df['id']\n",
        "\n",
        "  s = 0\n",
        "  e = round(df.shape[0]*.2)\n",
        "\n",
        "  y_pred = []\n",
        "  y_original = []\n",
        "\n",
        "  for i in range(5):\n",
        "\n",
        "    test_set  = df.iloc[s:e,:]\n",
        "    train_set = df.drop(test_set.index)\n",
        "\n",
        "    X_train = StandardScaler().fit_transform(train_set.drop(columns=['diagnosis'])).copy()\n",
        "    y_train = encoder.fit_transform(train_set['diagnosis']).copy()\n",
        "    X_test = StandardScaler().fit_transform(test_set.drop(columns=['diagnosis'])).copy()\n",
        "    y_test = encoder.fit_transform(test_set['diagnosis']).copy()\n",
        "\n",
        "    #svm = SVC(C=0.1, gamma='auto', kernel = 'rbf')\n",
        "    tf.random.set_seed(123)\n",
        "    ANNmodel = Sequential()\n",
        "    ANNmodel.add(Dense(30, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "    ANNmodel.add(Dense(10, activation='relu'))\n",
        "    ANNmodel.add(Dense(1, activation='sigmoid'))\n",
        "    ANNmodel.compile(loss='BinaryCrossentropy', optimizer='adam', metrics=['accuracy']) #tf.keras.metrics.Precision(), tf.keras.metrics.Recall()\n",
        "    ANNmodel.fit(X_train,y_train, batch_size = 128, epochs = 20, validation_split = 0.1)\n",
        "    y_pred_ANN = (ANNmodel.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "\n",
        "    y_pred.append(y_pred_ANN)\n",
        "    y_original.append(y_test)\n",
        "\n",
        "    s = e\n",
        "    e = e + round(df.shape[0]*.2)\n",
        "    if e-s < round(df.shape[0]*.2):\n",
        "      e = df.shape[0]\n",
        "\n",
        "  y_pred_fina = []\n",
        "  y_original_final = []\n",
        "\n",
        "  try:\n",
        "    for i in range(5):\n",
        "      for j in range(round(df.shape[0]*.2)):\n",
        "        y_pred_fina.append(y_pred[i][j])\n",
        "        y_original_final.append(y_original[i][j])\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  y_pred_final = []\n",
        "\n",
        "  for i in range(len(y_pred_fina)):\n",
        "    y_pred_final.append(y_pred_fina[i][0])\n",
        "\n",
        "  return y_pred_final"
      ],
      "metadata": {
        "id": "jRa_a7EY0y6B"
      },
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newdata = pd.DataFrame({\n",
        "    \"SVM\": CVal(SVC(C=0.1, gamma='auto', kernel = 'rbf'))\n",
        "})\n",
        "newdata[\"KNN\"] = CVal(KNeighborsClassifier(n_neighbors=3))\n",
        "newdata[\"RF\"]  = CVal(RandomForestClassifier(n_estimators= 500,max_features = 'sqrt', max_samples = 100, random_state=123))\n",
        "newdata['LR']  = CVal(LogisticRegression(C= 0.1 , penalty='l1', solver='liblinear', max_iter = 1000, random_state=123))\n",
        "newdata[\"ANN\"] = CValANN()\n",
        "newdata[\"XGB\"] = CVal(XGBClassifier(objective='binary:logistic',max_depth= 7,alpha= 10,learning_rate= 1,n_estimators=100))\n",
        "newdata['y_test'] = encoder.fit_transform(df['diagnosis']).copy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CGgdO1V0zA9",
        "outputId": "fe8a0d75-0797-421d-d553-6dd65096872f"
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "4/4 [==============================] - 2s 79ms/step - loss: 0.6073 - accuracy: 0.6088 - val_loss: 0.6240 - val_accuracy: 0.5435\n",
            "Epoch 2/20\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5481 - accuracy: 0.7800 - val_loss: 0.5760 - val_accuracy: 0.6739\n",
            "Epoch 3/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4965 - accuracy: 0.8509 - val_loss: 0.5305 - val_accuracy: 0.8043\n",
            "Epoch 4/20\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4503 - accuracy: 0.8826 - val_loss: 0.4883 - val_accuracy: 0.8913\n",
            "Epoch 5/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4085 - accuracy: 0.8875 - val_loss: 0.4488 - val_accuracy: 0.9348\n",
            "Epoch 6/20\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3720 - accuracy: 0.9095 - val_loss: 0.4117 - val_accuracy: 0.9348\n",
            "Epoch 7/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3396 - accuracy: 0.9120 - val_loss: 0.3779 - val_accuracy: 0.9348\n",
            "Epoch 8/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3114 - accuracy: 0.9169 - val_loss: 0.3472 - val_accuracy: 0.9348\n",
            "Epoch 9/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2860 - accuracy: 0.9169 - val_loss: 0.3199 - val_accuracy: 0.9348\n",
            "Epoch 10/20\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.2643 - accuracy: 0.9267 - val_loss: 0.2955 - val_accuracy: 0.9348\n",
            "Epoch 11/20\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.2450 - accuracy: 0.9340 - val_loss: 0.2734 - val_accuracy: 0.9348\n",
            "Epoch 12/20\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2281 - accuracy: 0.9364 - val_loss: 0.2540 - val_accuracy: 0.9565\n",
            "Epoch 13/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.2130 - accuracy: 0.9389 - val_loss: 0.2369 - val_accuracy: 0.9783\n",
            "Epoch 14/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2000 - accuracy: 0.9389 - val_loss: 0.2210 - val_accuracy: 0.9783\n",
            "Epoch 15/20\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1880 - accuracy: 0.9462 - val_loss: 0.2063 - val_accuracy: 0.9783\n",
            "Epoch 16/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.1771 - accuracy: 0.9487 - val_loss: 0.1937 - val_accuracy: 0.9783\n",
            "Epoch 17/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.1673 - accuracy: 0.9462 - val_loss: 0.1826 - val_accuracy: 0.9783\n",
            "Epoch 18/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1586 - accuracy: 0.9462 - val_loss: 0.1719 - val_accuracy: 0.9783\n",
            "Epoch 19/20\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1506 - accuracy: 0.9487 - val_loss: 0.1627 - val_accuracy: 0.9783\n",
            "Epoch 20/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1431 - accuracy: 0.9487 - val_loss: 0.1549 - val_accuracy: 0.9783\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 1/20\n",
            "4/4 [==============================] - 1s 84ms/step - loss: 0.6356 - accuracy: 0.6333 - val_loss: 0.6152 - val_accuracy: 0.6304\n",
            "Epoch 2/20\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.5854 - accuracy: 0.7482 - val_loss: 0.5606 - val_accuracy: 0.7609\n",
            "Epoch 3/20\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.5461 - accuracy: 0.8362 - val_loss: 0.5192 - val_accuracy: 0.8478\n",
            "Epoch 4/20\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.5136 - accuracy: 0.8753 - val_loss: 0.4861 - val_accuracy: 0.8913\n",
            "Epoch 5/20\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.4848 - accuracy: 0.9022 - val_loss: 0.4557 - val_accuracy: 0.8913\n",
            "Epoch 6/20\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.4580 - accuracy: 0.9193 - val_loss: 0.4287 - val_accuracy: 0.8913\n",
            "Epoch 7/20\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4320 - accuracy: 0.9389 - val_loss: 0.4018 - val_accuracy: 0.9130\n",
            "Epoch 8/20\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4058 - accuracy: 0.9462 - val_loss: 0.3766 - val_accuracy: 0.9130\n",
            "Epoch 9/20\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.3793 - accuracy: 0.9511 - val_loss: 0.3529 - val_accuracy: 0.9130\n",
            "Epoch 10/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3523 - accuracy: 0.9511 - val_loss: 0.3298 - val_accuracy: 0.9130\n",
            "Epoch 11/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3260 - accuracy: 0.9511 - val_loss: 0.3075 - val_accuracy: 0.9130\n",
            "Epoch 12/20\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3012 - accuracy: 0.9535 - val_loss: 0.2872 - val_accuracy: 0.9130\n",
            "Epoch 13/20\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.2782 - accuracy: 0.9535 - val_loss: 0.2691 - val_accuracy: 0.9348\n",
            "Epoch 14/20\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.2573 - accuracy: 0.9535 - val_loss: 0.2521 - val_accuracy: 0.9348\n",
            "Epoch 15/20\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.2383 - accuracy: 0.9535 - val_loss: 0.2365 - val_accuracy: 0.9348\n",
            "Epoch 16/20\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.2206 - accuracy: 0.9584 - val_loss: 0.2226 - val_accuracy: 0.9348\n",
            "Epoch 17/20\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.2048 - accuracy: 0.9560 - val_loss: 0.2099 - val_accuracy: 0.9348\n",
            "Epoch 18/20\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.1907 - accuracy: 0.9609 - val_loss: 0.1977 - val_accuracy: 0.9348\n",
            "Epoch 19/20\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.1779 - accuracy: 0.9560 - val_loss: 0.1867 - val_accuracy: 0.9348\n",
            "Epoch 20/20\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.1660 - accuracy: 0.9609 - val_loss: 0.1768 - val_accuracy: 0.9348\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "Epoch 1/20\n",
            "4/4 [==============================] - 1s 74ms/step - loss: 0.8336 - accuracy: 0.5770 - val_loss: 0.6095 - val_accuracy: 0.7174\n",
            "Epoch 2/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.7455 - accuracy: 0.5941 - val_loss: 0.5486 - val_accuracy: 0.7609\n",
            "Epoch 3/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.6764 - accuracy: 0.6186 - val_loss: 0.4972 - val_accuracy: 0.8043\n",
            "Epoch 4/20\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.6128 - accuracy: 0.6479 - val_loss: 0.4549 - val_accuracy: 0.8478\n",
            "Epoch 5/20\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5604 - accuracy: 0.6919 - val_loss: 0.4165 - val_accuracy: 0.8478\n",
            "Epoch 6/20\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.5169 - accuracy: 0.7408 - val_loss: 0.3812 - val_accuracy: 0.8913\n",
            "Epoch 7/20\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4780 - accuracy: 0.7946 - val_loss: 0.3500 - val_accuracy: 0.9130\n",
            "Epoch 8/20\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4439 - accuracy: 0.8411 - val_loss: 0.3228 - val_accuracy: 0.9130\n",
            "Epoch 9/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4147 - accuracy: 0.8680 - val_loss: 0.2985 - val_accuracy: 0.9130\n",
            "Epoch 10/20\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3875 - accuracy: 0.8924 - val_loss: 0.2776 - val_accuracy: 0.9348\n",
            "Epoch 11/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3633 - accuracy: 0.8973 - val_loss: 0.2590 - val_accuracy: 0.9348\n",
            "Epoch 12/20\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3408 - accuracy: 0.9095 - val_loss: 0.2421 - val_accuracy: 0.9565\n",
            "Epoch 13/20\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3203 - accuracy: 0.9169 - val_loss: 0.2270 - val_accuracy: 0.9783\n",
            "Epoch 14/20\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.3011 - accuracy: 0.9193 - val_loss: 0.2131 - val_accuracy: 0.9783\n",
            "Epoch 15/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2831 - accuracy: 0.9242 - val_loss: 0.2014 - val_accuracy: 0.9565\n",
            "Epoch 16/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.2670 - accuracy: 0.9291 - val_loss: 0.1903 - val_accuracy: 0.9565\n",
            "Epoch 17/20\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2525 - accuracy: 0.9315 - val_loss: 0.1802 - val_accuracy: 0.9565\n",
            "Epoch 18/20\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2390 - accuracy: 0.9315 - val_loss: 0.1711 - val_accuracy: 0.9565\n",
            "Epoch 19/20\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.2263 - accuracy: 0.9340 - val_loss: 0.1631 - val_accuracy: 0.9565\n",
            "Epoch 20/20\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.2146 - accuracy: 0.9389 - val_loss: 0.1563 - val_accuracy: 0.9565\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "Epoch 1/20\n",
            "4/4 [==============================] - 2s 80ms/step - loss: 0.9067 - accuracy: 0.4352 - val_loss: 0.9366 - val_accuracy: 0.2174\n",
            "Epoch 2/20\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.7936 - accuracy: 0.4792 - val_loss: 0.7991 - val_accuracy: 0.3043\n",
            "Epoch 3/20\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.6902 - accuracy: 0.5990 - val_loss: 0.6840 - val_accuracy: 0.5217\n",
            "Epoch 4/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6057 - accuracy: 0.7188 - val_loss: 0.5895 - val_accuracy: 0.6957\n",
            "Epoch 5/20\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5352 - accuracy: 0.8191 - val_loss: 0.5116 - val_accuracy: 0.7826\n",
            "Epoch 6/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4761 - accuracy: 0.8753 - val_loss: 0.4492 - val_accuracy: 0.8478\n",
            "Epoch 7/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4308 - accuracy: 0.8973 - val_loss: 0.3976 - val_accuracy: 0.8913\n",
            "Epoch 8/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3919 - accuracy: 0.9022 - val_loss: 0.3546 - val_accuracy: 0.8913\n",
            "Epoch 9/20\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.3589 - accuracy: 0.9120 - val_loss: 0.3182 - val_accuracy: 0.9348\n",
            "Epoch 10/20\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.3310 - accuracy: 0.9169 - val_loss: 0.2875 - val_accuracy: 0.9783\n",
            "Epoch 11/20\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3059 - accuracy: 0.9267 - val_loss: 0.2615 - val_accuracy: 0.9783\n",
            "Epoch 12/20\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2840 - accuracy: 0.9315 - val_loss: 0.2394 - val_accuracy: 0.9783\n",
            "Epoch 13/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2644 - accuracy: 0.9340 - val_loss: 0.2200 - val_accuracy: 0.9783\n",
            "Epoch 14/20\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.2470 - accuracy: 0.9340 - val_loss: 0.2033 - val_accuracy: 0.9783\n",
            "Epoch 15/20\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.2317 - accuracy: 0.9340 - val_loss: 0.1896 - val_accuracy: 0.9783\n",
            "Epoch 16/20\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.2173 - accuracy: 0.9413 - val_loss: 0.1783 - val_accuracy: 0.9783\n",
            "Epoch 17/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2051 - accuracy: 0.9389 - val_loss: 0.1680 - val_accuracy: 0.9783\n",
            "Epoch 18/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1935 - accuracy: 0.9438 - val_loss: 0.1591 - val_accuracy: 0.9783\n",
            "Epoch 19/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1832 - accuracy: 0.9438 - val_loss: 0.1515 - val_accuracy: 0.9783\n",
            "Epoch 20/20\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1736 - accuracy: 0.9462 - val_loss: 0.1452 - val_accuracy: 0.9783\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 1/20\n",
            "4/4 [==============================] - 1s 71ms/step - loss: 0.6506 - accuracy: 0.6000 - val_loss: 0.4982 - val_accuracy: 0.7826\n",
            "Epoch 2/20\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5586 - accuracy: 0.7024 - val_loss: 0.4374 - val_accuracy: 0.8261\n",
            "Epoch 3/20\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4886 - accuracy: 0.8024 - val_loss: 0.3878 - val_accuracy: 0.8913\n",
            "Epoch 4/20\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4321 - accuracy: 0.8512 - val_loss: 0.3484 - val_accuracy: 0.8913\n",
            "Epoch 5/20\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3846 - accuracy: 0.9000 - val_loss: 0.3146 - val_accuracy: 0.9130\n",
            "Epoch 6/20\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3448 - accuracy: 0.9195 - val_loss: 0.2854 - val_accuracy: 0.9348\n",
            "Epoch 7/20\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3111 - accuracy: 0.9317 - val_loss: 0.2617 - val_accuracy: 0.9565\n",
            "Epoch 8/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2815 - accuracy: 0.9390 - val_loss: 0.2419 - val_accuracy: 0.9565\n",
            "Epoch 9/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2561 - accuracy: 0.9415 - val_loss: 0.2248 - val_accuracy: 0.9565\n",
            "Epoch 10/20\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.2348 - accuracy: 0.9488 - val_loss: 0.2090 - val_accuracy: 0.9565\n",
            "Epoch 11/20\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.2152 - accuracy: 0.9512 - val_loss: 0.1950 - val_accuracy: 0.9565\n",
            "Epoch 12/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1985 - accuracy: 0.9537 - val_loss: 0.1826 - val_accuracy: 0.9565\n",
            "Epoch 13/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1838 - accuracy: 0.9585 - val_loss: 0.1715 - val_accuracy: 0.9565\n",
            "Epoch 14/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1710 - accuracy: 0.9634 - val_loss: 0.1621 - val_accuracy: 0.9565\n",
            "Epoch 15/20\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1596 - accuracy: 0.9610 - val_loss: 0.1537 - val_accuracy: 0.9565\n",
            "Epoch 16/20\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1496 - accuracy: 0.9683 - val_loss: 0.1456 - val_accuracy: 0.9565\n",
            "Epoch 17/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1408 - accuracy: 0.9707 - val_loss: 0.1390 - val_accuracy: 0.9565\n",
            "Epoch 18/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1331 - accuracy: 0.9707 - val_loss: 0.1333 - val_accuracy: 0.9565\n",
            "Epoch 19/20\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1261 - accuracy: 0.9732 - val_loss: 0.1283 - val_accuracy: 0.9565\n",
            "Epoch 20/20\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.1201 - accuracy: 0.9732 - val_loss: 0.1241 - val_accuracy: 0.9565\n",
            "4/4 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newdata.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "05ryfvyLzFVK",
        "outputId": "ab5d60d1-2eff-4e69-8f81-d7593e173872"
      },
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   SVM  KNN  RF  LR  ANN  XGB  y_test\n",
              "0    1    1   1   1    1    0       1\n",
              "1    1    1   1   1    1    1       1\n",
              "2    1    1   1   1    1    1       1\n",
              "3    1    1   1   1    1    1       1\n",
              "4    1    1   1   1    1    0       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-86c6348a-5eae-4da2-810c-ffd31a4c1e9f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SVM</th>\n",
              "      <th>KNN</th>\n",
              "      <th>RF</th>\n",
              "      <th>LR</th>\n",
              "      <th>ANN</th>\n",
              "      <th>XGB</th>\n",
              "      <th>y_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86c6348a-5eae-4da2-810c-ffd31a4c1e9f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-86c6348a-5eae-4da2-810c-ffd31a4c1e9f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-86c6348a-5eae-4da2-810c-ffd31a4c1e9f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the DNN model\n",
        "DNNX = newdata.drop(columns=['y_test']).copy()\n",
        "DNNY = newdata.y_test.copy()\n",
        "DX_train, DX_test, Dy_train, Dy_test = train_test_split(\n",
        "    DNNX, DNNY, test_size=0.2, random_state=123)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(30, activation='relu', input_shape=DNNX.shape[1:]),\n",
        "    tf.keras.layers.Dense(25, activation='relu'),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dense(15, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(DX_train, Dy_train, epochs=500, batch_size=64, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4kf97a3yX15",
        "outputId": "a8a335f7-75f5-4277-fd3e-48cac9f56643"
      },
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "6/6 [==============================] - 2s 49ms/step - loss: 0.6598 - accuracy: 0.6868 - val_loss: 0.6346 - val_accuracy: 0.8791\n",
            "Epoch 2/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6321 - accuracy: 0.8819 - val_loss: 0.6020 - val_accuracy: 0.8791\n",
            "Epoch 3/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6051 - accuracy: 0.8819 - val_loss: 0.5700 - val_accuracy: 0.8791\n",
            "Epoch 4/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5802 - accuracy: 0.8819 - val_loss: 0.5421 - val_accuracy: 0.8791\n",
            "Epoch 5/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5602 - accuracy: 0.8819 - val_loss: 0.5198 - val_accuracy: 0.8791\n",
            "Epoch 6/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5453 - accuracy: 0.8819 - val_loss: 0.5048 - val_accuracy: 0.8791\n",
            "Epoch 7/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5361 - accuracy: 0.8819 - val_loss: 0.4961 - val_accuracy: 0.8791\n",
            "Epoch 8/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5313 - accuracy: 0.8846 - val_loss: 0.4899 - val_accuracy: 0.8901\n",
            "Epoch 9/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.5260 - accuracy: 0.8984 - val_loss: 0.4852 - val_accuracy: 0.8901\n",
            "Epoch 10/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5208 - accuracy: 0.8984 - val_loss: 0.4810 - val_accuracy: 0.8901\n",
            "Epoch 11/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.5153 - accuracy: 0.8984 - val_loss: 0.4776 - val_accuracy: 0.8901\n",
            "Epoch 12/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5103 - accuracy: 0.8984 - val_loss: 0.4729 - val_accuracy: 0.8901\n",
            "Epoch 13/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.5056 - accuracy: 0.9038 - val_loss: 0.4694 - val_accuracy: 0.9011\n",
            "Epoch 14/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5006 - accuracy: 0.9231 - val_loss: 0.4642 - val_accuracy: 0.9011\n",
            "Epoch 15/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4960 - accuracy: 0.9258 - val_loss: 0.4595 - val_accuracy: 0.9011\n",
            "Epoch 16/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4923 - accuracy: 0.9313 - val_loss: 0.4552 - val_accuracy: 0.9121\n",
            "Epoch 17/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4883 - accuracy: 0.9313 - val_loss: 0.4516 - val_accuracy: 0.9121\n",
            "Epoch 18/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4849 - accuracy: 0.9313 - val_loss: 0.4483 - val_accuracy: 0.9121\n",
            "Epoch 19/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4816 - accuracy: 0.9313 - val_loss: 0.4450 - val_accuracy: 0.9121\n",
            "Epoch 20/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.4783 - accuracy: 0.9368 - val_loss: 0.4429 - val_accuracy: 0.9121\n",
            "Epoch 21/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4752 - accuracy: 0.9396 - val_loss: 0.4401 - val_accuracy: 0.9121\n",
            "Epoch 22/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4719 - accuracy: 0.9423 - val_loss: 0.4376 - val_accuracy: 0.9011\n",
            "Epoch 23/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4694 - accuracy: 0.9423 - val_loss: 0.4349 - val_accuracy: 0.9011\n",
            "Epoch 24/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4672 - accuracy: 0.9423 - val_loss: 0.4327 - val_accuracy: 0.9011\n",
            "Epoch 25/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4643 - accuracy: 0.9423 - val_loss: 0.4305 - val_accuracy: 0.9011\n",
            "Epoch 26/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4615 - accuracy: 0.9451 - val_loss: 0.4287 - val_accuracy: 0.9011\n",
            "Epoch 27/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4593 - accuracy: 0.9451 - val_loss: 0.4270 - val_accuracy: 0.9011\n",
            "Epoch 28/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4569 - accuracy: 0.9451 - val_loss: 0.4256 - val_accuracy: 0.9121\n",
            "Epoch 29/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4541 - accuracy: 0.9478 - val_loss: 0.4243 - val_accuracy: 0.9121\n",
            "Epoch 30/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4516 - accuracy: 0.9478 - val_loss: 0.4232 - val_accuracy: 0.9121\n",
            "Epoch 31/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4495 - accuracy: 0.9478 - val_loss: 0.4222 - val_accuracy: 0.9121\n",
            "Epoch 32/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4472 - accuracy: 0.9478 - val_loss: 0.4191 - val_accuracy: 0.9121\n",
            "Epoch 33/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4448 - accuracy: 0.9478 - val_loss: 0.4166 - val_accuracy: 0.9231\n",
            "Epoch 34/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4426 - accuracy: 0.9478 - val_loss: 0.4155 - val_accuracy: 0.9121\n",
            "Epoch 35/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4408 - accuracy: 0.9505 - val_loss: 0.4160 - val_accuracy: 0.9121\n",
            "Epoch 36/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4385 - accuracy: 0.9478 - val_loss: 0.4151 - val_accuracy: 0.9121\n",
            "Epoch 37/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4367 - accuracy: 0.9560 - val_loss: 0.4129 - val_accuracy: 0.9231\n",
            "Epoch 38/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4344 - accuracy: 0.9588 - val_loss: 0.4125 - val_accuracy: 0.9231\n",
            "Epoch 39/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4325 - accuracy: 0.9560 - val_loss: 0.4118 - val_accuracy: 0.9231\n",
            "Epoch 40/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4305 - accuracy: 0.9588 - val_loss: 0.4097 - val_accuracy: 0.9231\n",
            "Epoch 41/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4291 - accuracy: 0.9588 - val_loss: 0.4072 - val_accuracy: 0.9231\n",
            "Epoch 42/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4271 - accuracy: 0.9588 - val_loss: 0.4065 - val_accuracy: 0.9231\n",
            "Epoch 43/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4251 - accuracy: 0.9588 - val_loss: 0.4067 - val_accuracy: 0.9231\n",
            "Epoch 44/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4233 - accuracy: 0.9588 - val_loss: 0.4069 - val_accuracy: 0.9231\n",
            "Epoch 45/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4213 - accuracy: 0.9588 - val_loss: 0.4048 - val_accuracy: 0.9231\n",
            "Epoch 46/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4199 - accuracy: 0.9588 - val_loss: 0.4026 - val_accuracy: 0.9231\n",
            "Epoch 47/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4178 - accuracy: 0.9588 - val_loss: 0.4020 - val_accuracy: 0.9231\n",
            "Epoch 48/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4154 - accuracy: 0.9615 - val_loss: 0.4028 - val_accuracy: 0.9231\n",
            "Epoch 49/500\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.4144 - accuracy: 0.9588 - val_loss: 0.4006 - val_accuracy: 0.9231\n",
            "Epoch 50/500\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.4120 - accuracy: 0.9615 - val_loss: 0.3990 - val_accuracy: 0.9231\n",
            "Epoch 51/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.4103 - accuracy: 0.9615 - val_loss: 0.3976 - val_accuracy: 0.9231\n",
            "Epoch 52/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.4085 - accuracy: 0.9615 - val_loss: 0.3966 - val_accuracy: 0.9231\n",
            "Epoch 53/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.4067 - accuracy: 0.9615 - val_loss: 0.3966 - val_accuracy: 0.9231\n",
            "Epoch 54/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.4048 - accuracy: 0.9615 - val_loss: 0.3960 - val_accuracy: 0.9231\n",
            "Epoch 55/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4036 - accuracy: 0.9615 - val_loss: 0.3950 - val_accuracy: 0.9231\n",
            "Epoch 56/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4017 - accuracy: 0.9615 - val_loss: 0.3925 - val_accuracy: 0.9231\n",
            "Epoch 57/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.4004 - accuracy: 0.9615 - val_loss: 0.3884 - val_accuracy: 0.9231\n",
            "Epoch 58/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3995 - accuracy: 0.9615 - val_loss: 0.3876 - val_accuracy: 0.9231\n",
            "Epoch 59/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3970 - accuracy: 0.9615 - val_loss: 0.3855 - val_accuracy: 0.9231\n",
            "Epoch 60/500\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.3968 - accuracy: 0.9615 - val_loss: 0.3856 - val_accuracy: 0.9231\n",
            "Epoch 61/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3936 - accuracy: 0.9643 - val_loss: 0.3859 - val_accuracy: 0.9231\n",
            "Epoch 62/500\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.3925 - accuracy: 0.9615 - val_loss: 0.3860 - val_accuracy: 0.9231\n",
            "Epoch 63/500\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.3910 - accuracy: 0.9643 - val_loss: 0.3815 - val_accuracy: 0.9231\n",
            "Epoch 64/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3893 - accuracy: 0.9643 - val_loss: 0.3811 - val_accuracy: 0.9231\n",
            "Epoch 65/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3880 - accuracy: 0.9643 - val_loss: 0.3799 - val_accuracy: 0.9231\n",
            "Epoch 66/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3864 - accuracy: 0.9588 - val_loss: 0.3799 - val_accuracy: 0.9231\n",
            "Epoch 67/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3843 - accuracy: 0.9643 - val_loss: 0.3788 - val_accuracy: 0.9231\n",
            "Epoch 68/500\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.3842 - accuracy: 0.9643 - val_loss: 0.3782 - val_accuracy: 0.9231\n",
            "Epoch 69/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3811 - accuracy: 0.9643 - val_loss: 0.3780 - val_accuracy: 0.9231\n",
            "Epoch 70/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3808 - accuracy: 0.9643 - val_loss: 0.3764 - val_accuracy: 0.9231\n",
            "Epoch 71/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3797 - accuracy: 0.9643 - val_loss: 0.3730 - val_accuracy: 0.9231\n",
            "Epoch 72/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3792 - accuracy: 0.9643 - val_loss: 0.3719 - val_accuracy: 0.9231\n",
            "Epoch 73/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3762 - accuracy: 0.9643 - val_loss: 0.3707 - val_accuracy: 0.9231\n",
            "Epoch 74/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3756 - accuracy: 0.9643 - val_loss: 0.3720 - val_accuracy: 0.9231\n",
            "Epoch 75/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3739 - accuracy: 0.9643 - val_loss: 0.3713 - val_accuracy: 0.9231\n",
            "Epoch 76/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3724 - accuracy: 0.9643 - val_loss: 0.3701 - val_accuracy: 0.9231\n",
            "Epoch 77/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3708 - accuracy: 0.9643 - val_loss: 0.3685 - val_accuracy: 0.9231\n",
            "Epoch 78/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3694 - accuracy: 0.9643 - val_loss: 0.3667 - val_accuracy: 0.9231\n",
            "Epoch 79/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3696 - accuracy: 0.9643 - val_loss: 0.3660 - val_accuracy: 0.9231\n",
            "Epoch 80/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3672 - accuracy: 0.9643 - val_loss: 0.3645 - val_accuracy: 0.9231\n",
            "Epoch 81/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3661 - accuracy: 0.9643 - val_loss: 0.3621 - val_accuracy: 0.9231\n",
            "Epoch 82/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3648 - accuracy: 0.9643 - val_loss: 0.3615 - val_accuracy: 0.9231\n",
            "Epoch 83/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3628 - accuracy: 0.9643 - val_loss: 0.3612 - val_accuracy: 0.9231\n",
            "Epoch 84/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3617 - accuracy: 0.9643 - val_loss: 0.3611 - val_accuracy: 0.9231\n",
            "Epoch 85/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3622 - accuracy: 0.9643 - val_loss: 0.3618 - val_accuracy: 0.9231\n",
            "Epoch 86/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3594 - accuracy: 0.9643 - val_loss: 0.3640 - val_accuracy: 0.9231\n",
            "Epoch 87/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3591 - accuracy: 0.9615 - val_loss: 0.3566 - val_accuracy: 0.9231\n",
            "Epoch 88/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3587 - accuracy: 0.9643 - val_loss: 0.3529 - val_accuracy: 0.9231\n",
            "Epoch 89/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3573 - accuracy: 0.9643 - val_loss: 0.3539 - val_accuracy: 0.9231\n",
            "Epoch 90/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3558 - accuracy: 0.9643 - val_loss: 0.3530 - val_accuracy: 0.9231\n",
            "Epoch 91/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3537 - accuracy: 0.9643 - val_loss: 0.3554 - val_accuracy: 0.9231\n",
            "Epoch 92/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3523 - accuracy: 0.9643 - val_loss: 0.3548 - val_accuracy: 0.9231\n",
            "Epoch 93/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3509 - accuracy: 0.9643 - val_loss: 0.3547 - val_accuracy: 0.9231\n",
            "Epoch 94/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3515 - accuracy: 0.9643 - val_loss: 0.3549 - val_accuracy: 0.9231\n",
            "Epoch 95/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3489 - accuracy: 0.9643 - val_loss: 0.3534 - val_accuracy: 0.9231\n",
            "Epoch 96/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3514 - accuracy: 0.9643 - val_loss: 0.3537 - val_accuracy: 0.9231\n",
            "Epoch 97/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3482 - accuracy: 0.9615 - val_loss: 0.3459 - val_accuracy: 0.9231\n",
            "Epoch 98/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3462 - accuracy: 0.9643 - val_loss: 0.3442 - val_accuracy: 0.9231\n",
            "Epoch 99/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3459 - accuracy: 0.9643 - val_loss: 0.3431 - val_accuracy: 0.9231\n",
            "Epoch 100/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3441 - accuracy: 0.9643 - val_loss: 0.3445 - val_accuracy: 0.9231\n",
            "Epoch 101/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3416 - accuracy: 0.9643 - val_loss: 0.3440 - val_accuracy: 0.9231\n",
            "Epoch 102/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3409 - accuracy: 0.9615 - val_loss: 0.3442 - val_accuracy: 0.9231\n",
            "Epoch 103/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3399 - accuracy: 0.9643 - val_loss: 0.3446 - val_accuracy: 0.9231\n",
            "Epoch 104/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3391 - accuracy: 0.9643 - val_loss: 0.3421 - val_accuracy: 0.9231\n",
            "Epoch 105/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3377 - accuracy: 0.9615 - val_loss: 0.3387 - val_accuracy: 0.9231\n",
            "Epoch 106/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3363 - accuracy: 0.9643 - val_loss: 0.3371 - val_accuracy: 0.9231\n",
            "Epoch 107/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3361 - accuracy: 0.9643 - val_loss: 0.3365 - val_accuracy: 0.9231\n",
            "Epoch 108/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3339 - accuracy: 0.9643 - val_loss: 0.3366 - val_accuracy: 0.9231\n",
            "Epoch 109/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3339 - accuracy: 0.9643 - val_loss: 0.3378 - val_accuracy: 0.9231\n",
            "Epoch 110/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3323 - accuracy: 0.9615 - val_loss: 0.3379 - val_accuracy: 0.9231\n",
            "Epoch 111/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3310 - accuracy: 0.9643 - val_loss: 0.3382 - val_accuracy: 0.9231\n",
            "Epoch 112/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3302 - accuracy: 0.9643 - val_loss: 0.3370 - val_accuracy: 0.9231\n",
            "Epoch 113/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3290 - accuracy: 0.9643 - val_loss: 0.3341 - val_accuracy: 0.9231\n",
            "Epoch 114/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3278 - accuracy: 0.9643 - val_loss: 0.3316 - val_accuracy: 0.9231\n",
            "Epoch 115/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3274 - accuracy: 0.9643 - val_loss: 0.3306 - val_accuracy: 0.9231\n",
            "Epoch 116/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3261 - accuracy: 0.9643 - val_loss: 0.3308 - val_accuracy: 0.9231\n",
            "Epoch 117/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3256 - accuracy: 0.9643 - val_loss: 0.3312 - val_accuracy: 0.9231\n",
            "Epoch 118/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3234 - accuracy: 0.9643 - val_loss: 0.3320 - val_accuracy: 0.9231\n",
            "Epoch 119/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3229 - accuracy: 0.9643 - val_loss: 0.3300 - val_accuracy: 0.9231\n",
            "Epoch 120/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3222 - accuracy: 0.9643 - val_loss: 0.3280 - val_accuracy: 0.9231\n",
            "Epoch 121/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3225 - accuracy: 0.9643 - val_loss: 0.3288 - val_accuracy: 0.9231\n",
            "Epoch 122/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3198 - accuracy: 0.9643 - val_loss: 0.3258 - val_accuracy: 0.9231\n",
            "Epoch 123/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3193 - accuracy: 0.9643 - val_loss: 0.3251 - val_accuracy: 0.9231\n",
            "Epoch 124/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3185 - accuracy: 0.9643 - val_loss: 0.3260 - val_accuracy: 0.9231\n",
            "Epoch 125/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3174 - accuracy: 0.9615 - val_loss: 0.3270 - val_accuracy: 0.9231\n",
            "Epoch 126/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3163 - accuracy: 0.9643 - val_loss: 0.3283 - val_accuracy: 0.9231\n",
            "Epoch 127/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3157 - accuracy: 0.9615 - val_loss: 0.3243 - val_accuracy: 0.9231\n",
            "Epoch 128/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3144 - accuracy: 0.9643 - val_loss: 0.3245 - val_accuracy: 0.9231\n",
            "Epoch 129/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3133 - accuracy: 0.9643 - val_loss: 0.3240 - val_accuracy: 0.9231\n",
            "Epoch 130/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3122 - accuracy: 0.9643 - val_loss: 0.3214 - val_accuracy: 0.9231\n",
            "Epoch 131/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3114 - accuracy: 0.9643 - val_loss: 0.3189 - val_accuracy: 0.9231\n",
            "Epoch 132/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3110 - accuracy: 0.9643 - val_loss: 0.3193 - val_accuracy: 0.9231\n",
            "Epoch 133/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3104 - accuracy: 0.9643 - val_loss: 0.3201 - val_accuracy: 0.9231\n",
            "Epoch 134/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3095 - accuracy: 0.9643 - val_loss: 0.3194 - val_accuracy: 0.9231\n",
            "Epoch 135/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3077 - accuracy: 0.9643 - val_loss: 0.3177 - val_accuracy: 0.9231\n",
            "Epoch 136/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3072 - accuracy: 0.9643 - val_loss: 0.3179 - val_accuracy: 0.9231\n",
            "Epoch 137/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3064 - accuracy: 0.9643 - val_loss: 0.3189 - val_accuracy: 0.9231\n",
            "Epoch 138/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3049 - accuracy: 0.9643 - val_loss: 0.3176 - val_accuracy: 0.9231\n",
            "Epoch 139/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3044 - accuracy: 0.9615 - val_loss: 0.3158 - val_accuracy: 0.9231\n",
            "Epoch 140/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3036 - accuracy: 0.9615 - val_loss: 0.3175 - val_accuracy: 0.9231\n",
            "Epoch 141/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3026 - accuracy: 0.9643 - val_loss: 0.3157 - val_accuracy: 0.9231\n",
            "Epoch 142/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3013 - accuracy: 0.9615 - val_loss: 0.3144 - val_accuracy: 0.9231\n",
            "Epoch 143/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3011 - accuracy: 0.9643 - val_loss: 0.3105 - val_accuracy: 0.9231\n",
            "Epoch 144/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2998 - accuracy: 0.9643 - val_loss: 0.3098 - val_accuracy: 0.9231\n",
            "Epoch 145/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2993 - accuracy: 0.9643 - val_loss: 0.3093 - val_accuracy: 0.9231\n",
            "Epoch 146/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2980 - accuracy: 0.9643 - val_loss: 0.3084 - val_accuracy: 0.9231\n",
            "Epoch 147/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2980 - accuracy: 0.9643 - val_loss: 0.3085 - val_accuracy: 0.9231\n",
            "Epoch 148/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2965 - accuracy: 0.9643 - val_loss: 0.3104 - val_accuracy: 0.9231\n",
            "Epoch 149/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2958 - accuracy: 0.9615 - val_loss: 0.3138 - val_accuracy: 0.9231\n",
            "Epoch 150/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2952 - accuracy: 0.9643 - val_loss: 0.3113 - val_accuracy: 0.9231\n",
            "Epoch 151/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2958 - accuracy: 0.9643 - val_loss: 0.3077 - val_accuracy: 0.9231\n",
            "Epoch 152/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2949 - accuracy: 0.9643 - val_loss: 0.3060 - val_accuracy: 0.9231\n",
            "Epoch 153/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2931 - accuracy: 0.9643 - val_loss: 0.3095 - val_accuracy: 0.9231\n",
            "Epoch 154/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2918 - accuracy: 0.9643 - val_loss: 0.3079 - val_accuracy: 0.9231\n",
            "Epoch 155/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2906 - accuracy: 0.9615 - val_loss: 0.3073 - val_accuracy: 0.9231\n",
            "Epoch 156/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2906 - accuracy: 0.9643 - val_loss: 0.3071 - val_accuracy: 0.9231\n",
            "Epoch 157/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2898 - accuracy: 0.9643 - val_loss: 0.3057 - val_accuracy: 0.9231\n",
            "Epoch 158/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2894 - accuracy: 0.9643 - val_loss: 0.3060 - val_accuracy: 0.9231\n",
            "Epoch 159/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2878 - accuracy: 0.9615 - val_loss: 0.3037 - val_accuracy: 0.9231\n",
            "Epoch 160/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2874 - accuracy: 0.9615 - val_loss: 0.3057 - val_accuracy: 0.9231\n",
            "Epoch 161/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2869 - accuracy: 0.9643 - val_loss: 0.3041 - val_accuracy: 0.9231\n",
            "Epoch 162/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2876 - accuracy: 0.9643 - val_loss: 0.3015 - val_accuracy: 0.9231\n",
            "Epoch 163/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2854 - accuracy: 0.9643 - val_loss: 0.3020 - val_accuracy: 0.9231\n",
            "Epoch 164/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2859 - accuracy: 0.9615 - val_loss: 0.3039 - val_accuracy: 0.9231\n",
            "Epoch 165/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2829 - accuracy: 0.9615 - val_loss: 0.2941 - val_accuracy: 0.9231\n",
            "Epoch 166/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2823 - accuracy: 0.9643 - val_loss: 0.2917 - val_accuracy: 0.9231\n",
            "Epoch 167/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2818 - accuracy: 0.9643 - val_loss: 0.2925 - val_accuracy: 0.9231\n",
            "Epoch 168/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2804 - accuracy: 0.9643 - val_loss: 0.2935 - val_accuracy: 0.9231\n",
            "Epoch 169/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2798 - accuracy: 0.9643 - val_loss: 0.2943 - val_accuracy: 0.9231\n",
            "Epoch 170/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2793 - accuracy: 0.9615 - val_loss: 0.2950 - val_accuracy: 0.9231\n",
            "Epoch 171/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2782 - accuracy: 0.9643 - val_loss: 0.2920 - val_accuracy: 0.9231\n",
            "Epoch 172/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2780 - accuracy: 0.9643 - val_loss: 0.2914 - val_accuracy: 0.9231\n",
            "Epoch 173/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2772 - accuracy: 0.9643 - val_loss: 0.2920 - val_accuracy: 0.9231\n",
            "Epoch 174/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2764 - accuracy: 0.9615 - val_loss: 0.2951 - val_accuracy: 0.9231\n",
            "Epoch 175/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2764 - accuracy: 0.9643 - val_loss: 0.2939 - val_accuracy: 0.9231\n",
            "Epoch 176/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2756 - accuracy: 0.9643 - val_loss: 0.2891 - val_accuracy: 0.9231\n",
            "Epoch 177/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2743 - accuracy: 0.9643 - val_loss: 0.2871 - val_accuracy: 0.9231\n",
            "Epoch 178/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2731 - accuracy: 0.9643 - val_loss: 0.2875 - val_accuracy: 0.9231\n",
            "Epoch 179/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2724 - accuracy: 0.9643 - val_loss: 0.2885 - val_accuracy: 0.9231\n",
            "Epoch 180/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2718 - accuracy: 0.9643 - val_loss: 0.2886 - val_accuracy: 0.9231\n",
            "Epoch 181/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2717 - accuracy: 0.9615 - val_loss: 0.2889 - val_accuracy: 0.9231\n",
            "Epoch 182/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2713 - accuracy: 0.9615 - val_loss: 0.2894 - val_accuracy: 0.9231\n",
            "Epoch 183/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2696 - accuracy: 0.9643 - val_loss: 0.2888 - val_accuracy: 0.9231\n",
            "Epoch 184/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2692 - accuracy: 0.9615 - val_loss: 0.2870 - val_accuracy: 0.9231\n",
            "Epoch 185/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2690 - accuracy: 0.9615 - val_loss: 0.2893 - val_accuracy: 0.9231\n",
            "Epoch 186/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2677 - accuracy: 0.9643 - val_loss: 0.2857 - val_accuracy: 0.9231\n",
            "Epoch 187/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2676 - accuracy: 0.9643 - val_loss: 0.2852 - val_accuracy: 0.9231\n",
            "Epoch 188/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2694 - accuracy: 0.9615 - val_loss: 0.2847 - val_accuracy: 0.9231\n",
            "Epoch 189/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2650 - accuracy: 0.9643 - val_loss: 0.2827 - val_accuracy: 0.9231\n",
            "Epoch 190/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2665 - accuracy: 0.9643 - val_loss: 0.2828 - val_accuracy: 0.9231\n",
            "Epoch 191/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2650 - accuracy: 0.9643 - val_loss: 0.2814 - val_accuracy: 0.9231\n",
            "Epoch 192/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2641 - accuracy: 0.9643 - val_loss: 0.2831 - val_accuracy: 0.9231\n",
            "Epoch 193/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2635 - accuracy: 0.9615 - val_loss: 0.2815 - val_accuracy: 0.9231\n",
            "Epoch 194/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2625 - accuracy: 0.9643 - val_loss: 0.2823 - val_accuracy: 0.9231\n",
            "Epoch 195/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2618 - accuracy: 0.9643 - val_loss: 0.2820 - val_accuracy: 0.9231\n",
            "Epoch 196/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2630 - accuracy: 0.9615 - val_loss: 0.2811 - val_accuracy: 0.9231\n",
            "Epoch 197/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2628 - accuracy: 0.9643 - val_loss: 0.2811 - val_accuracy: 0.9231\n",
            "Epoch 198/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2596 - accuracy: 0.9643 - val_loss: 0.2818 - val_accuracy: 0.9231\n",
            "Epoch 199/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2597 - accuracy: 0.9615 - val_loss: 0.2823 - val_accuracy: 0.9231\n",
            "Epoch 200/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2596 - accuracy: 0.9615 - val_loss: 0.2817 - val_accuracy: 0.9231\n",
            "Epoch 201/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2584 - accuracy: 0.9643 - val_loss: 0.2808 - val_accuracy: 0.9231\n",
            "Epoch 202/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2577 - accuracy: 0.9615 - val_loss: 0.2759 - val_accuracy: 0.9231\n",
            "Epoch 203/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2577 - accuracy: 0.9643 - val_loss: 0.2751 - val_accuracy: 0.9231\n",
            "Epoch 204/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2570 - accuracy: 0.9643 - val_loss: 0.2739 - val_accuracy: 0.9231\n",
            "Epoch 205/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.2564 - accuracy: 0.9643 - val_loss: 0.2765 - val_accuracy: 0.9231\n",
            "Epoch 206/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.2548 - accuracy: 0.9643 - val_loss: 0.2776 - val_accuracy: 0.9231\n",
            "Epoch 207/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.2545 - accuracy: 0.9643 - val_loss: 0.2783 - val_accuracy: 0.9231\n",
            "Epoch 208/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.2543 - accuracy: 0.9643 - val_loss: 0.2755 - val_accuracy: 0.9231\n",
            "Epoch 209/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.2531 - accuracy: 0.9643 - val_loss: 0.2728 - val_accuracy: 0.9231\n",
            "Epoch 210/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.2522 - accuracy: 0.9643 - val_loss: 0.2720 - val_accuracy: 0.9231\n",
            "Epoch 211/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2519 - accuracy: 0.9643 - val_loss: 0.2722 - val_accuracy: 0.9231\n",
            "Epoch 212/500\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.2513 - accuracy: 0.9643 - val_loss: 0.2725 - val_accuracy: 0.9231\n",
            "Epoch 213/500\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.2508 - accuracy: 0.9643 - val_loss: 0.2718 - val_accuracy: 0.9231\n",
            "Epoch 214/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.2503 - accuracy: 0.9643 - val_loss: 0.2723 - val_accuracy: 0.9231\n",
            "Epoch 215/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2498 - accuracy: 0.9643 - val_loss: 0.2724 - val_accuracy: 0.9231\n",
            "Epoch 216/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2491 - accuracy: 0.9643 - val_loss: 0.2726 - val_accuracy: 0.9231\n",
            "Epoch 217/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.2483 - accuracy: 0.9643 - val_loss: 0.2700 - val_accuracy: 0.9231\n",
            "Epoch 218/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2490 - accuracy: 0.9643 - val_loss: 0.2705 - val_accuracy: 0.9231\n",
            "Epoch 219/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2476 - accuracy: 0.9643 - val_loss: 0.2706 - val_accuracy: 0.9231\n",
            "Epoch 220/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.2468 - accuracy: 0.9615 - val_loss: 0.2714 - val_accuracy: 0.9231\n",
            "Epoch 221/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.2466 - accuracy: 0.9615 - val_loss: 0.2689 - val_accuracy: 0.9231\n",
            "Epoch 222/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2454 - accuracy: 0.9643 - val_loss: 0.2687 - val_accuracy: 0.9231\n",
            "Epoch 223/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.2451 - accuracy: 0.9643 - val_loss: 0.2693 - val_accuracy: 0.9231\n",
            "Epoch 224/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.2445 - accuracy: 0.9615 - val_loss: 0.2707 - val_accuracy: 0.9231\n",
            "Epoch 225/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.2446 - accuracy: 0.9615 - val_loss: 0.2713 - val_accuracy: 0.9231\n",
            "Epoch 226/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2441 - accuracy: 0.9643 - val_loss: 0.2735 - val_accuracy: 0.9231\n",
            "Epoch 227/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.2447 - accuracy: 0.9643 - val_loss: 0.2715 - val_accuracy: 0.9231\n",
            "Epoch 228/500\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.2416 - accuracy: 0.9670 - val_loss: 0.2641 - val_accuracy: 0.9231\n",
            "Epoch 229/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2427 - accuracy: 0.9643 - val_loss: 0.2620 - val_accuracy: 0.9231\n",
            "Epoch 230/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2420 - accuracy: 0.9643 - val_loss: 0.2603 - val_accuracy: 0.9231\n",
            "Epoch 231/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2410 - accuracy: 0.9643 - val_loss: 0.2616 - val_accuracy: 0.9231\n",
            "Epoch 232/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2404 - accuracy: 0.9643 - val_loss: 0.2642 - val_accuracy: 0.9231\n",
            "Epoch 233/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2396 - accuracy: 0.9643 - val_loss: 0.2657 - val_accuracy: 0.9231\n",
            "Epoch 234/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2391 - accuracy: 0.9643 - val_loss: 0.2652 - val_accuracy: 0.9231\n",
            "Epoch 235/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2386 - accuracy: 0.9643 - val_loss: 0.2682 - val_accuracy: 0.9231\n",
            "Epoch 236/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2386 - accuracy: 0.9643 - val_loss: 0.2674 - val_accuracy: 0.9231\n",
            "Epoch 237/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2386 - accuracy: 0.9615 - val_loss: 0.2669 - val_accuracy: 0.9231\n",
            "Epoch 238/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2373 - accuracy: 0.9643 - val_loss: 0.2667 - val_accuracy: 0.9231\n",
            "Epoch 239/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2359 - accuracy: 0.9643 - val_loss: 0.2695 - val_accuracy: 0.9231\n",
            "Epoch 240/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2361 - accuracy: 0.9643 - val_loss: 0.2688 - val_accuracy: 0.9231\n",
            "Epoch 241/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2371 - accuracy: 0.9643 - val_loss: 0.2679 - val_accuracy: 0.9231\n",
            "Epoch 242/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2357 - accuracy: 0.9615 - val_loss: 0.2709 - val_accuracy: 0.9231\n",
            "Epoch 243/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2357 - accuracy: 0.9643 - val_loss: 0.2692 - val_accuracy: 0.9231\n",
            "Epoch 244/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2341 - accuracy: 0.9643 - val_loss: 0.2659 - val_accuracy: 0.9231\n",
            "Epoch 245/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2338 - accuracy: 0.9643 - val_loss: 0.2646 - val_accuracy: 0.9231\n",
            "Epoch 246/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2331 - accuracy: 0.9643 - val_loss: 0.2619 - val_accuracy: 0.9231\n",
            "Epoch 247/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2342 - accuracy: 0.9615 - val_loss: 0.2650 - val_accuracy: 0.9231\n",
            "Epoch 248/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2319 - accuracy: 0.9643 - val_loss: 0.2622 - val_accuracy: 0.9231\n",
            "Epoch 249/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2335 - accuracy: 0.9643 - val_loss: 0.2603 - val_accuracy: 0.9231\n",
            "Epoch 250/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2335 - accuracy: 0.9643 - val_loss: 0.2618 - val_accuracy: 0.9231\n",
            "Epoch 251/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2314 - accuracy: 0.9615 - val_loss: 0.2634 - val_accuracy: 0.9231\n",
            "Epoch 252/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2295 - accuracy: 0.9643 - val_loss: 0.2630 - val_accuracy: 0.9231\n",
            "Epoch 253/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2302 - accuracy: 0.9643 - val_loss: 0.2647 - val_accuracy: 0.9231\n",
            "Epoch 254/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2298 - accuracy: 0.9643 - val_loss: 0.2666 - val_accuracy: 0.9231\n",
            "Epoch 255/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2288 - accuracy: 0.9643 - val_loss: 0.2656 - val_accuracy: 0.9231\n",
            "Epoch 256/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2294 - accuracy: 0.9643 - val_loss: 0.2643 - val_accuracy: 0.9231\n",
            "Epoch 257/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2279 - accuracy: 0.9643 - val_loss: 0.2613 - val_accuracy: 0.9231\n",
            "Epoch 258/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2286 - accuracy: 0.9643 - val_loss: 0.2617 - val_accuracy: 0.9231\n",
            "Epoch 259/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2273 - accuracy: 0.9643 - val_loss: 0.2574 - val_accuracy: 0.9231\n",
            "Epoch 260/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2273 - accuracy: 0.9643 - val_loss: 0.2598 - val_accuracy: 0.9231\n",
            "Epoch 261/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2261 - accuracy: 0.9643 - val_loss: 0.2589 - val_accuracy: 0.9231\n",
            "Epoch 262/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2263 - accuracy: 0.9643 - val_loss: 0.2613 - val_accuracy: 0.9231\n",
            "Epoch 263/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2253 - accuracy: 0.9615 - val_loss: 0.2596 - val_accuracy: 0.9231\n",
            "Epoch 264/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2246 - accuracy: 0.9643 - val_loss: 0.2590 - val_accuracy: 0.9231\n",
            "Epoch 265/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2244 - accuracy: 0.9615 - val_loss: 0.2610 - val_accuracy: 0.9231\n",
            "Epoch 266/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2232 - accuracy: 0.9615 - val_loss: 0.2602 - val_accuracy: 0.9231\n",
            "Epoch 267/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2229 - accuracy: 0.9643 - val_loss: 0.2592 - val_accuracy: 0.9231\n",
            "Epoch 268/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2232 - accuracy: 0.9643 - val_loss: 0.2566 - val_accuracy: 0.9231\n",
            "Epoch 269/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2221 - accuracy: 0.9615 - val_loss: 0.2577 - val_accuracy: 0.9231\n",
            "Epoch 270/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2216 - accuracy: 0.9643 - val_loss: 0.2559 - val_accuracy: 0.9231\n",
            "Epoch 271/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2216 - accuracy: 0.9643 - val_loss: 0.2552 - val_accuracy: 0.9231\n",
            "Epoch 272/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2213 - accuracy: 0.9643 - val_loss: 0.2571 - val_accuracy: 0.9231\n",
            "Epoch 273/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2209 - accuracy: 0.9643 - val_loss: 0.2574 - val_accuracy: 0.9231\n",
            "Epoch 274/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2199 - accuracy: 0.9643 - val_loss: 0.2578 - val_accuracy: 0.9231\n",
            "Epoch 275/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2199 - accuracy: 0.9643 - val_loss: 0.2564 - val_accuracy: 0.9231\n",
            "Epoch 276/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2192 - accuracy: 0.9615 - val_loss: 0.2550 - val_accuracy: 0.9231\n",
            "Epoch 277/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2187 - accuracy: 0.9643 - val_loss: 0.2552 - val_accuracy: 0.9231\n",
            "Epoch 278/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2182 - accuracy: 0.9643 - val_loss: 0.2565 - val_accuracy: 0.9231\n",
            "Epoch 279/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2185 - accuracy: 0.9643 - val_loss: 0.2575 - val_accuracy: 0.9231\n",
            "Epoch 280/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2179 - accuracy: 0.9643 - val_loss: 0.2566 - val_accuracy: 0.9231\n",
            "Epoch 281/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2182 - accuracy: 0.9643 - val_loss: 0.2518 - val_accuracy: 0.9231\n",
            "Epoch 282/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2164 - accuracy: 0.9643 - val_loss: 0.2510 - val_accuracy: 0.9231\n",
            "Epoch 283/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2173 - accuracy: 0.9643 - val_loss: 0.2505 - val_accuracy: 0.9231\n",
            "Epoch 284/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2168 - accuracy: 0.9615 - val_loss: 0.2544 - val_accuracy: 0.9231\n",
            "Epoch 285/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2157 - accuracy: 0.9643 - val_loss: 0.2549 - val_accuracy: 0.9231\n",
            "Epoch 286/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2153 - accuracy: 0.9615 - val_loss: 0.2523 - val_accuracy: 0.9231\n",
            "Epoch 287/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2146 - accuracy: 0.9643 - val_loss: 0.2539 - val_accuracy: 0.9231\n",
            "Epoch 288/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2141 - accuracy: 0.9615 - val_loss: 0.2538 - val_accuracy: 0.9231\n",
            "Epoch 289/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2139 - accuracy: 0.9643 - val_loss: 0.2554 - val_accuracy: 0.9231\n",
            "Epoch 290/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2138 - accuracy: 0.9643 - val_loss: 0.2543 - val_accuracy: 0.9231\n",
            "Epoch 291/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2128 - accuracy: 0.9643 - val_loss: 0.2539 - val_accuracy: 0.9231\n",
            "Epoch 292/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2132 - accuracy: 0.9643 - val_loss: 0.2546 - val_accuracy: 0.9231\n",
            "Epoch 293/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2132 - accuracy: 0.9643 - val_loss: 0.2514 - val_accuracy: 0.9231\n",
            "Epoch 294/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2125 - accuracy: 0.9643 - val_loss: 0.2483 - val_accuracy: 0.9231\n",
            "Epoch 295/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.2127 - accuracy: 0.9615 - val_loss: 0.2509 - val_accuracy: 0.9231\n",
            "Epoch 296/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2112 - accuracy: 0.9643 - val_loss: 0.2531 - val_accuracy: 0.9231\n",
            "Epoch 297/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2112 - accuracy: 0.9615 - val_loss: 0.2498 - val_accuracy: 0.9231\n",
            "Epoch 298/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2125 - accuracy: 0.9615 - val_loss: 0.2527 - val_accuracy: 0.9231\n",
            "Epoch 299/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2097 - accuracy: 0.9643 - val_loss: 0.2481 - val_accuracy: 0.9231\n",
            "Epoch 300/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2098 - accuracy: 0.9643 - val_loss: 0.2466 - val_accuracy: 0.9231\n",
            "Epoch 301/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2092 - accuracy: 0.9643 - val_loss: 0.2452 - val_accuracy: 0.9231\n",
            "Epoch 302/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2090 - accuracy: 0.9643 - val_loss: 0.2477 - val_accuracy: 0.9231\n",
            "Epoch 303/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2087 - accuracy: 0.9643 - val_loss: 0.2489 - val_accuracy: 0.9231\n",
            "Epoch 304/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.2083 - accuracy: 0.9643 - val_loss: 0.2502 - val_accuracy: 0.9231\n",
            "Epoch 305/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2076 - accuracy: 0.9643 - val_loss: 0.2516 - val_accuracy: 0.9231\n",
            "Epoch 306/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2078 - accuracy: 0.9643 - val_loss: 0.2506 - val_accuracy: 0.9231\n",
            "Epoch 307/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2072 - accuracy: 0.9615 - val_loss: 0.2484 - val_accuracy: 0.9231\n",
            "Epoch 308/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2066 - accuracy: 0.9615 - val_loss: 0.2481 - val_accuracy: 0.9231\n",
            "Epoch 309/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2067 - accuracy: 0.9643 - val_loss: 0.2506 - val_accuracy: 0.9231\n",
            "Epoch 310/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2061 - accuracy: 0.9643 - val_loss: 0.2479 - val_accuracy: 0.9231\n",
            "Epoch 311/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2063 - accuracy: 0.9615 - val_loss: 0.2453 - val_accuracy: 0.9231\n",
            "Epoch 312/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2054 - accuracy: 0.9643 - val_loss: 0.2484 - val_accuracy: 0.9231\n",
            "Epoch 313/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2053 - accuracy: 0.9643 - val_loss: 0.2482 - val_accuracy: 0.9231\n",
            "Epoch 314/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2047 - accuracy: 0.9643 - val_loss: 0.2445 - val_accuracy: 0.9231\n",
            "Epoch 315/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2053 - accuracy: 0.9615 - val_loss: 0.2446 - val_accuracy: 0.9231\n",
            "Epoch 316/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2035 - accuracy: 0.9643 - val_loss: 0.2435 - val_accuracy: 0.9231\n",
            "Epoch 317/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2037 - accuracy: 0.9643 - val_loss: 0.2443 - val_accuracy: 0.9231\n",
            "Epoch 318/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.2038 - accuracy: 0.9615 - val_loss: 0.2474 - val_accuracy: 0.9231\n",
            "Epoch 319/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2036 - accuracy: 0.9615 - val_loss: 0.2462 - val_accuracy: 0.9231\n",
            "Epoch 320/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2025 - accuracy: 0.9643 - val_loss: 0.2452 - val_accuracy: 0.9231\n",
            "Epoch 321/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2028 - accuracy: 0.9643 - val_loss: 0.2476 - val_accuracy: 0.9231\n",
            "Epoch 322/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2030 - accuracy: 0.9643 - val_loss: 0.2438 - val_accuracy: 0.9231\n",
            "Epoch 323/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2029 - accuracy: 0.9643 - val_loss: 0.2414 - val_accuracy: 0.9231\n",
            "Epoch 324/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2033 - accuracy: 0.9615 - val_loss: 0.2457 - val_accuracy: 0.9231\n",
            "Epoch 325/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2021 - accuracy: 0.9615 - val_loss: 0.2413 - val_accuracy: 0.9231\n",
            "Epoch 326/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2010 - accuracy: 0.9643 - val_loss: 0.2401 - val_accuracy: 0.9231\n",
            "Epoch 327/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2005 - accuracy: 0.9643 - val_loss: 0.2436 - val_accuracy: 0.9231\n",
            "Epoch 328/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2000 - accuracy: 0.9643 - val_loss: 0.2451 - val_accuracy: 0.9231\n",
            "Epoch 329/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1996 - accuracy: 0.9643 - val_loss: 0.2454 - val_accuracy: 0.9231\n",
            "Epoch 330/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1999 - accuracy: 0.9643 - val_loss: 0.2455 - val_accuracy: 0.9231\n",
            "Epoch 331/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.2009 - accuracy: 0.9615 - val_loss: 0.2482 - val_accuracy: 0.9231\n",
            "Epoch 332/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1992 - accuracy: 0.9643 - val_loss: 0.2413 - val_accuracy: 0.9231\n",
            "Epoch 333/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1987 - accuracy: 0.9643 - val_loss: 0.2402 - val_accuracy: 0.9231\n",
            "Epoch 334/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1985 - accuracy: 0.9615 - val_loss: 0.2400 - val_accuracy: 0.9231\n",
            "Epoch 335/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1982 - accuracy: 0.9615 - val_loss: 0.2386 - val_accuracy: 0.9231\n",
            "Epoch 336/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1975 - accuracy: 0.9643 - val_loss: 0.2403 - val_accuracy: 0.9231\n",
            "Epoch 337/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1973 - accuracy: 0.9615 - val_loss: 0.2422 - val_accuracy: 0.9231\n",
            "Epoch 338/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1972 - accuracy: 0.9643 - val_loss: 0.2417 - val_accuracy: 0.9231\n",
            "Epoch 339/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1983 - accuracy: 0.9615 - val_loss: 0.2413 - val_accuracy: 0.9231\n",
            "Epoch 340/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1964 - accuracy: 0.9643 - val_loss: 0.2384 - val_accuracy: 0.9231\n",
            "Epoch 341/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1959 - accuracy: 0.9643 - val_loss: 0.2372 - val_accuracy: 0.9231\n",
            "Epoch 342/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1966 - accuracy: 0.9643 - val_loss: 0.2379 - val_accuracy: 0.9231\n",
            "Epoch 343/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1953 - accuracy: 0.9643 - val_loss: 0.2391 - val_accuracy: 0.9231\n",
            "Epoch 344/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1952 - accuracy: 0.9643 - val_loss: 0.2382 - val_accuracy: 0.9231\n",
            "Epoch 345/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1950 - accuracy: 0.9643 - val_loss: 0.2400 - val_accuracy: 0.9231\n",
            "Epoch 346/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1953 - accuracy: 0.9615 - val_loss: 0.2430 - val_accuracy: 0.9231\n",
            "Epoch 347/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1948 - accuracy: 0.9643 - val_loss: 0.2409 - val_accuracy: 0.9231\n",
            "Epoch 348/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1948 - accuracy: 0.9643 - val_loss: 0.2427 - val_accuracy: 0.9231\n",
            "Epoch 349/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1954 - accuracy: 0.9643 - val_loss: 0.2429 - val_accuracy: 0.9231\n",
            "Epoch 350/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1945 - accuracy: 0.9643 - val_loss: 0.2443 - val_accuracy: 0.9231\n",
            "Epoch 351/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1948 - accuracy: 0.9643 - val_loss: 0.2341 - val_accuracy: 0.9231\n",
            "Epoch 352/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1925 - accuracy: 0.9643 - val_loss: 0.2332 - val_accuracy: 0.9231\n",
            "Epoch 353/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1927 - accuracy: 0.9643 - val_loss: 0.2325 - val_accuracy: 0.9231\n",
            "Epoch 354/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1927 - accuracy: 0.9643 - val_loss: 0.2325 - val_accuracy: 0.9231\n",
            "Epoch 355/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1939 - accuracy: 0.9643 - val_loss: 0.2332 - val_accuracy: 0.9231\n",
            "Epoch 356/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1924 - accuracy: 0.9643 - val_loss: 0.2335 - val_accuracy: 0.9231\n",
            "Epoch 357/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1936 - accuracy: 0.9615 - val_loss: 0.2359 - val_accuracy: 0.9231\n",
            "Epoch 358/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1914 - accuracy: 0.9643 - val_loss: 0.2339 - val_accuracy: 0.9231\n",
            "Epoch 359/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1907 - accuracy: 0.9643 - val_loss: 0.2339 - val_accuracy: 0.9231\n",
            "Epoch 360/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1908 - accuracy: 0.9643 - val_loss: 0.2358 - val_accuracy: 0.9231\n",
            "Epoch 361/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1900 - accuracy: 0.9643 - val_loss: 0.2365 - val_accuracy: 0.9231\n",
            "Epoch 362/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1903 - accuracy: 0.9643 - val_loss: 0.2380 - val_accuracy: 0.9231\n",
            "Epoch 363/500\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.1901 - accuracy: 0.9643 - val_loss: 0.2382 - val_accuracy: 0.9231\n",
            "Epoch 364/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1894 - accuracy: 0.9643 - val_loss: 0.2398 - val_accuracy: 0.9231\n",
            "Epoch 365/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1891 - accuracy: 0.9643 - val_loss: 0.2365 - val_accuracy: 0.9231\n",
            "Epoch 366/500\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.1886 - accuracy: 0.9643 - val_loss: 0.2349 - val_accuracy: 0.9231\n",
            "Epoch 367/500\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.1889 - accuracy: 0.9643 - val_loss: 0.2343 - val_accuracy: 0.9231\n",
            "Epoch 368/500\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.1885 - accuracy: 0.9643 - val_loss: 0.2325 - val_accuracy: 0.9231\n",
            "Epoch 369/500\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.1883 - accuracy: 0.9643 - val_loss: 0.2355 - val_accuracy: 0.9231\n",
            "Epoch 370/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1881 - accuracy: 0.9615 - val_loss: 0.2357 - val_accuracy: 0.9231\n",
            "Epoch 371/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1880 - accuracy: 0.9643 - val_loss: 0.2380 - val_accuracy: 0.9231\n",
            "Epoch 372/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1870 - accuracy: 0.9643 - val_loss: 0.2375 - val_accuracy: 0.9231\n",
            "Epoch 373/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1873 - accuracy: 0.9643 - val_loss: 0.2363 - val_accuracy: 0.9231\n",
            "Epoch 374/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1870 - accuracy: 0.9643 - val_loss: 0.2337 - val_accuracy: 0.9231\n",
            "Epoch 375/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1863 - accuracy: 0.9643 - val_loss: 0.2314 - val_accuracy: 0.9231\n",
            "Epoch 376/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1873 - accuracy: 0.9643 - val_loss: 0.2308 - val_accuracy: 0.9231\n",
            "Epoch 377/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1862 - accuracy: 0.9643 - val_loss: 0.2324 - val_accuracy: 0.9231\n",
            "Epoch 378/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1863 - accuracy: 0.9643 - val_loss: 0.2334 - val_accuracy: 0.9231\n",
            "Epoch 379/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.1855 - accuracy: 0.9643 - val_loss: 0.2341 - val_accuracy: 0.9231\n",
            "Epoch 380/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1862 - accuracy: 0.9643 - val_loss: 0.2336 - val_accuracy: 0.9231\n",
            "Epoch 381/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1850 - accuracy: 0.9643 - val_loss: 0.2329 - val_accuracy: 0.9231\n",
            "Epoch 382/500\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.1842 - accuracy: 0.9643 - val_loss: 0.2353 - val_accuracy: 0.9231\n",
            "Epoch 383/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1846 - accuracy: 0.9643 - val_loss: 0.2351 - val_accuracy: 0.9231\n",
            "Epoch 384/500\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.1848 - accuracy: 0.9615 - val_loss: 0.2316 - val_accuracy: 0.9231\n",
            "Epoch 385/500\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.1855 - accuracy: 0.9643 - val_loss: 0.2328 - val_accuracy: 0.9231\n",
            "Epoch 386/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1838 - accuracy: 0.9643 - val_loss: 0.2329 - val_accuracy: 0.9231\n",
            "Epoch 387/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1832 - accuracy: 0.9643 - val_loss: 0.2329 - val_accuracy: 0.9231\n",
            "Epoch 388/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1833 - accuracy: 0.9615 - val_loss: 0.2322 - val_accuracy: 0.9231\n",
            "Epoch 389/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1831 - accuracy: 0.9643 - val_loss: 0.2311 - val_accuracy: 0.9231\n",
            "Epoch 390/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1830 - accuracy: 0.9643 - val_loss: 0.2300 - val_accuracy: 0.9231\n",
            "Epoch 391/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1827 - accuracy: 0.9643 - val_loss: 0.2302 - val_accuracy: 0.9231\n",
            "Epoch 392/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1824 - accuracy: 0.9643 - val_loss: 0.2336 - val_accuracy: 0.9231\n",
            "Epoch 393/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1823 - accuracy: 0.9643 - val_loss: 0.2330 - val_accuracy: 0.9231\n",
            "Epoch 394/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1817 - accuracy: 0.9643 - val_loss: 0.2335 - val_accuracy: 0.9231\n",
            "Epoch 395/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1821 - accuracy: 0.9643 - val_loss: 0.2338 - val_accuracy: 0.9231\n",
            "Epoch 396/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1816 - accuracy: 0.9643 - val_loss: 0.2329 - val_accuracy: 0.9231\n",
            "Epoch 397/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1810 - accuracy: 0.9643 - val_loss: 0.2315 - val_accuracy: 0.9231\n",
            "Epoch 398/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1808 - accuracy: 0.9643 - val_loss: 0.2324 - val_accuracy: 0.9231\n",
            "Epoch 399/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1808 - accuracy: 0.9615 - val_loss: 0.2299 - val_accuracy: 0.9231\n",
            "Epoch 400/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1807 - accuracy: 0.9643 - val_loss: 0.2300 - val_accuracy: 0.9231\n",
            "Epoch 401/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1804 - accuracy: 0.9643 - val_loss: 0.2321 - val_accuracy: 0.9231\n",
            "Epoch 402/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1816 - accuracy: 0.9643 - val_loss: 0.2320 - val_accuracy: 0.9231\n",
            "Epoch 403/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1800 - accuracy: 0.9643 - val_loss: 0.2303 - val_accuracy: 0.9231\n",
            "Epoch 404/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1803 - accuracy: 0.9643 - val_loss: 0.2284 - val_accuracy: 0.9231\n",
            "Epoch 405/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1798 - accuracy: 0.9615 - val_loss: 0.2307 - val_accuracy: 0.9231\n",
            "Epoch 406/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1796 - accuracy: 0.9643 - val_loss: 0.2333 - val_accuracy: 0.9231\n",
            "Epoch 407/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1795 - accuracy: 0.9643 - val_loss: 0.2310 - val_accuracy: 0.9231\n",
            "Epoch 408/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1798 - accuracy: 0.9643 - val_loss: 0.2305 - val_accuracy: 0.9231\n",
            "Epoch 409/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1794 - accuracy: 0.9643 - val_loss: 0.2296 - val_accuracy: 0.9231\n",
            "Epoch 410/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1800 - accuracy: 0.9615 - val_loss: 0.2272 - val_accuracy: 0.9231\n",
            "Epoch 411/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1782 - accuracy: 0.9643 - val_loss: 0.2256 - val_accuracy: 0.9231\n",
            "Epoch 412/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1779 - accuracy: 0.9615 - val_loss: 0.2285 - val_accuracy: 0.9231\n",
            "Epoch 413/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1793 - accuracy: 0.9643 - val_loss: 0.2282 - val_accuracy: 0.9231\n",
            "Epoch 414/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1796 - accuracy: 0.9615 - val_loss: 0.2244 - val_accuracy: 0.9231\n",
            "Epoch 415/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1773 - accuracy: 0.9643 - val_loss: 0.2269 - val_accuracy: 0.9231\n",
            "Epoch 416/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1778 - accuracy: 0.9615 - val_loss: 0.2286 - val_accuracy: 0.9231\n",
            "Epoch 417/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1770 - accuracy: 0.9615 - val_loss: 0.2268 - val_accuracy: 0.9231\n",
            "Epoch 418/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1770 - accuracy: 0.9643 - val_loss: 0.2243 - val_accuracy: 0.9231\n",
            "Epoch 419/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1783 - accuracy: 0.9643 - val_loss: 0.2257 - val_accuracy: 0.9231\n",
            "Epoch 420/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1773 - accuracy: 0.9643 - val_loss: 0.2288 - val_accuracy: 0.9231\n",
            "Epoch 421/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1764 - accuracy: 0.9643 - val_loss: 0.2313 - val_accuracy: 0.9231\n",
            "Epoch 422/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1758 - accuracy: 0.9615 - val_loss: 0.2273 - val_accuracy: 0.9231\n",
            "Epoch 423/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1756 - accuracy: 0.9643 - val_loss: 0.2290 - val_accuracy: 0.9231\n",
            "Epoch 424/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1753 - accuracy: 0.9643 - val_loss: 0.2297 - val_accuracy: 0.9231\n",
            "Epoch 425/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1763 - accuracy: 0.9643 - val_loss: 0.2287 - val_accuracy: 0.9231\n",
            "Epoch 426/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1757 - accuracy: 0.9643 - val_loss: 0.2313 - val_accuracy: 0.9231\n",
            "Epoch 427/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1758 - accuracy: 0.9615 - val_loss: 0.2245 - val_accuracy: 0.9231\n",
            "Epoch 428/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1750 - accuracy: 0.9643 - val_loss: 0.2231 - val_accuracy: 0.9231\n",
            "Epoch 429/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1747 - accuracy: 0.9643 - val_loss: 0.2226 - val_accuracy: 0.9231\n",
            "Epoch 430/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1763 - accuracy: 0.9643 - val_loss: 0.2238 - val_accuracy: 0.9231\n",
            "Epoch 431/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1745 - accuracy: 0.9643 - val_loss: 0.2244 - val_accuracy: 0.9231\n",
            "Epoch 432/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1745 - accuracy: 0.9643 - val_loss: 0.2242 - val_accuracy: 0.9231\n",
            "Epoch 433/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1742 - accuracy: 0.9643 - val_loss: 0.2255 - val_accuracy: 0.9231\n",
            "Epoch 434/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1735 - accuracy: 0.9615 - val_loss: 0.2306 - val_accuracy: 0.9231\n",
            "Epoch 435/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1735 - accuracy: 0.9643 - val_loss: 0.2300 - val_accuracy: 0.9231\n",
            "Epoch 436/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1732 - accuracy: 0.9615 - val_loss: 0.2244 - val_accuracy: 0.9231\n",
            "Epoch 437/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1734 - accuracy: 0.9615 - val_loss: 0.2266 - val_accuracy: 0.9231\n",
            "Epoch 438/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1733 - accuracy: 0.9615 - val_loss: 0.2226 - val_accuracy: 0.9231\n",
            "Epoch 439/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1729 - accuracy: 0.9643 - val_loss: 0.2233 - val_accuracy: 0.9231\n",
            "Epoch 440/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1728 - accuracy: 0.9643 - val_loss: 0.2218 - val_accuracy: 0.9231\n",
            "Epoch 441/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1728 - accuracy: 0.9643 - val_loss: 0.2208 - val_accuracy: 0.9231\n",
            "Epoch 442/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1720 - accuracy: 0.9615 - val_loss: 0.2256 - val_accuracy: 0.9231\n",
            "Epoch 443/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1736 - accuracy: 0.9643 - val_loss: 0.2248 - val_accuracy: 0.9231\n",
            "Epoch 444/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1718 - accuracy: 0.9643 - val_loss: 0.2234 - val_accuracy: 0.9231\n",
            "Epoch 445/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1718 - accuracy: 0.9643 - val_loss: 0.2226 - val_accuracy: 0.9231\n",
            "Epoch 446/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1715 - accuracy: 0.9643 - val_loss: 0.2223 - val_accuracy: 0.9231\n",
            "Epoch 447/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1716 - accuracy: 0.9643 - val_loss: 0.2227 - val_accuracy: 0.9231\n",
            "Epoch 448/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1713 - accuracy: 0.9643 - val_loss: 0.2246 - val_accuracy: 0.9231\n",
            "Epoch 449/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1714 - accuracy: 0.9615 - val_loss: 0.2234 - val_accuracy: 0.9231\n",
            "Epoch 450/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1720 - accuracy: 0.9643 - val_loss: 0.2221 - val_accuracy: 0.9231\n",
            "Epoch 451/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1711 - accuracy: 0.9615 - val_loss: 0.2269 - val_accuracy: 0.9231\n",
            "Epoch 452/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1703 - accuracy: 0.9643 - val_loss: 0.2244 - val_accuracy: 0.9231\n",
            "Epoch 453/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1713 - accuracy: 0.9643 - val_loss: 0.2249 - val_accuracy: 0.9231\n",
            "Epoch 454/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1699 - accuracy: 0.9643 - val_loss: 0.2247 - val_accuracy: 0.9231\n",
            "Epoch 455/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1704 - accuracy: 0.9643 - val_loss: 0.2222 - val_accuracy: 0.9231\n",
            "Epoch 456/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1703 - accuracy: 0.9615 - val_loss: 0.2233 - val_accuracy: 0.9231\n",
            "Epoch 457/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1694 - accuracy: 0.9643 - val_loss: 0.2224 - val_accuracy: 0.9231\n",
            "Epoch 458/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1695 - accuracy: 0.9643 - val_loss: 0.2197 - val_accuracy: 0.9231\n",
            "Epoch 459/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1692 - accuracy: 0.9643 - val_loss: 0.2205 - val_accuracy: 0.9231\n",
            "Epoch 460/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1693 - accuracy: 0.9643 - val_loss: 0.2212 - val_accuracy: 0.9231\n",
            "Epoch 461/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1696 - accuracy: 0.9643 - val_loss: 0.2234 - val_accuracy: 0.9231\n",
            "Epoch 462/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1682 - accuracy: 0.9643 - val_loss: 0.2244 - val_accuracy: 0.9231\n",
            "Epoch 463/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1684 - accuracy: 0.9643 - val_loss: 0.2250 - val_accuracy: 0.9231\n",
            "Epoch 464/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1681 - accuracy: 0.9643 - val_loss: 0.2263 - val_accuracy: 0.9231\n",
            "Epoch 465/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1681 - accuracy: 0.9643 - val_loss: 0.2281 - val_accuracy: 0.9231\n",
            "Epoch 466/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1679 - accuracy: 0.9643 - val_loss: 0.2254 - val_accuracy: 0.9231\n",
            "Epoch 467/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1683 - accuracy: 0.9615 - val_loss: 0.2223 - val_accuracy: 0.9231\n",
            "Epoch 468/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1678 - accuracy: 0.9643 - val_loss: 0.2231 - val_accuracy: 0.9231\n",
            "Epoch 469/500\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.1678 - accuracy: 0.9643 - val_loss: 0.2240 - val_accuracy: 0.9231\n",
            "Epoch 470/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1677 - accuracy: 0.9615 - val_loss: 0.2223 - val_accuracy: 0.9231\n",
            "Epoch 471/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1678 - accuracy: 0.9643 - val_loss: 0.2229 - val_accuracy: 0.9231\n",
            "Epoch 472/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1700 - accuracy: 0.9643 - val_loss: 0.2248 - val_accuracy: 0.9231\n",
            "Epoch 473/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1675 - accuracy: 0.9670 - val_loss: 0.2211 - val_accuracy: 0.9231\n",
            "Epoch 474/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1683 - accuracy: 0.9643 - val_loss: 0.2173 - val_accuracy: 0.9231\n",
            "Epoch 475/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1671 - accuracy: 0.9643 - val_loss: 0.2186 - val_accuracy: 0.9231\n",
            "Epoch 476/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1664 - accuracy: 0.9643 - val_loss: 0.2184 - val_accuracy: 0.9231\n",
            "Epoch 477/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1666 - accuracy: 0.9643 - val_loss: 0.2200 - val_accuracy: 0.9231\n",
            "Epoch 478/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1662 - accuracy: 0.9643 - val_loss: 0.2199 - val_accuracy: 0.9231\n",
            "Epoch 479/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1654 - accuracy: 0.9643 - val_loss: 0.2212 - val_accuracy: 0.9231\n",
            "Epoch 480/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1658 - accuracy: 0.9643 - val_loss: 0.2220 - val_accuracy: 0.9231\n",
            "Epoch 481/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1658 - accuracy: 0.9643 - val_loss: 0.2227 - val_accuracy: 0.9231\n",
            "Epoch 482/500\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.1655 - accuracy: 0.9615 - val_loss: 0.2180 - val_accuracy: 0.9231\n",
            "Epoch 483/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1678 - accuracy: 0.9643 - val_loss: 0.2153 - val_accuracy: 0.9231\n",
            "Epoch 484/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1652 - accuracy: 0.9643 - val_loss: 0.2145 - val_accuracy: 0.9341\n",
            "Epoch 485/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1661 - accuracy: 0.9643 - val_loss: 0.2136 - val_accuracy: 0.9341\n",
            "Epoch 486/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1647 - accuracy: 0.9643 - val_loss: 0.2169 - val_accuracy: 0.9231\n",
            "Epoch 487/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1654 - accuracy: 0.9643 - val_loss: 0.2195 - val_accuracy: 0.9231\n",
            "Epoch 488/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1643 - accuracy: 0.9643 - val_loss: 0.2204 - val_accuracy: 0.9231\n",
            "Epoch 489/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1650 - accuracy: 0.9643 - val_loss: 0.2212 - val_accuracy: 0.9231\n",
            "Epoch 490/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1652 - accuracy: 0.9615 - val_loss: 0.2199 - val_accuracy: 0.9231\n",
            "Epoch 491/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1644 - accuracy: 0.9615 - val_loss: 0.2186 - val_accuracy: 0.9231\n",
            "Epoch 492/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1641 - accuracy: 0.9643 - val_loss: 0.2170 - val_accuracy: 0.9231\n",
            "Epoch 493/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1638 - accuracy: 0.9643 - val_loss: 0.2185 - val_accuracy: 0.9231\n",
            "Epoch 494/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1638 - accuracy: 0.9615 - val_loss: 0.2182 - val_accuracy: 0.9231\n",
            "Epoch 495/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1638 - accuracy: 0.9615 - val_loss: 0.2201 - val_accuracy: 0.9231\n",
            "Epoch 496/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1633 - accuracy: 0.9643 - val_loss: 0.2192 - val_accuracy: 0.9231\n",
            "Epoch 497/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1632 - accuracy: 0.9643 - val_loss: 0.2183 - val_accuracy: 0.9231\n",
            "Epoch 498/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1631 - accuracy: 0.9643 - val_loss: 0.2163 - val_accuracy: 0.9231\n",
            "Epoch 499/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1635 - accuracy: 0.9643 - val_loss: 0.2191 - val_accuracy: 0.9231\n",
            "Epoch 500/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1634 - accuracy: 0.9643 - val_loss: 0.2199 - val_accuracy: 0.9231\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8a64e9bbe0>"
            ]
          },
          "metadata": {},
          "execution_count": 257
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#y_pred_DNN = (model.predict(DNNX) > 0.5).astype(\"int32\")\n",
        "DTr = model.evaluate(DX_train, Dy_train,verbose=0)[1]\n",
        "DTe = model.evaluate(DX_test, Dy_test,verbose=0)[1]\n",
        "DTr,DTe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhG0YCbhASH9",
        "outputId": "59432139-2233-4db9-8ace-bfbedc5613a0"
      },
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9560439586639404, 0.9035087823867798)"
            ]
          },
          "metadata": {},
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = pd.DataFrame(\n",
        "    {\n",
        "    \"SVM\":[STr,STe],\n",
        "    \"KNN\":[KTr,KTe],\n",
        "    \"RF\" :[RTr,RTe],\n",
        "    \"LR\" :[LTr,LTe],\n",
        "    \"ANN\":[ATr,ATe],\n",
        "    \"XGB\":[XTr,XTe],\n",
        "    \"DNN\":[DTr,DTe]})\n",
        "acc.index = [\"train\", \"test\"]\n",
        "acc = acc.T\n",
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "v_YjlCdOO1JY",
        "outputId": "a7a46b55-25e4-4d2d-ac2f-6407d8eb953f"
      },
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        train      test\n",
              "SVM  0.951648  0.956140\n",
              "KNN  0.980220  0.991228\n",
              "RF   0.975824  0.991228\n",
              "LR   0.980220  0.973684\n",
              "ANN  0.958333  0.902655\n",
              "XGB  0.989011  0.982456\n",
              "DNN  0.956044  0.903509"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a7454fb-8fe3-4ed7-abc0-b253122ee6bc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>0.951648</td>\n",
              "      <td>0.956140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>0.980220</td>\n",
              "      <td>0.991228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>0.975824</td>\n",
              "      <td>0.991228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LR</th>\n",
              "      <td>0.980220</td>\n",
              "      <td>0.973684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ANN</th>\n",
              "      <td>0.958333</td>\n",
              "      <td>0.902655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGB</th>\n",
              "      <td>0.989011</td>\n",
              "      <td>0.982456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DNN</th>\n",
              "      <td>0.956044</td>\n",
              "      <td>0.903509</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a7454fb-8fe3-4ed7-abc0-b253122ee6bc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6a7454fb-8fe3-4ed7-abc0-b253122ee6bc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6a7454fb-8fe3-4ed7-abc0-b253122ee6bc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **AutoML Individual and AutoML DNN**"
      ],
      "metadata": {
        "id": "nJaAMLDKKfKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#H2O AutoML"
      ],
      "metadata": {
        "id": "EhNt_UkjDKcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h2o\n",
        "import h2o\n",
        "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
        "h2o.init()\n",
        "from h2o.model.segment_models import H2OFrame\n",
        "from h2o.automl import H2OAutoML\n",
        "print(\"All Library Loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "iwMF9ROeDOzF",
        "outputId": "81be0e11-d5fc-4af3-826d-95ca9a9e5ff4"
      },
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: h2o in /usr/local/lib/python3.10/dist-packages (3.40.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from h2o) (2.27.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from h2o) (0.8.10)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from h2o) (0.18.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (3.4)\n",
            "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "--------------------------  -----------------------------------------------------------------------------------------\n",
              "H2O_cluster_uptime:         3 hours 9 mins\n",
              "H2O_cluster_timezone:       Etc/UTC\n",
              "H2O_data_parsing_timezone:  UTC\n",
              "H2O_cluster_version:        3.40.0.4\n",
              "H2O_cluster_version_age:    1 month and 24 days\n",
              "H2O_cluster_name:           H2O_from_python_unknownUser_o56uxp\n",
              "H2O_cluster_total_nodes:    1\n",
              "H2O_cluster_free_memory:    3.156 Gb\n",
              "H2O_cluster_total_cores:    2\n",
              "H2O_cluster_allowed_cores:  2\n",
              "H2O_cluster_status:         locked, healthy\n",
              "H2O_connection_url:         http://localhost:54321\n",
              "H2O_connection_proxy:       {\"http\": null, \"https\": null, \"colab_language_server\": \"/usr/colab/bin/language_service\"}\n",
              "H2O_internal_security:      False\n",
              "Python_version:             3.10.12 final\n",
              "--------------------------  -----------------------------------------------------------------------------------------"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "#h2o-table-28.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-28 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-28 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-28 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-28 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-28 .h2o-table th,\n",
              "#h2o-table-28 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-28 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-28\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption></caption>\n",
              "    <thead></thead>\n",
              "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
              "<td>3 hours 9 mins</td></tr>\n",
              "<tr><td>H2O_cluster_timezone:</td>\n",
              "<td>Etc/UTC</td></tr>\n",
              "<tr><td>H2O_data_parsing_timezone:</td>\n",
              "<td>UTC</td></tr>\n",
              "<tr><td>H2O_cluster_version:</td>\n",
              "<td>3.40.0.4</td></tr>\n",
              "<tr><td>H2O_cluster_version_age:</td>\n",
              "<td>1 month and 24 days</td></tr>\n",
              "<tr><td>H2O_cluster_name:</td>\n",
              "<td>H2O_from_python_unknownUser_o56uxp</td></tr>\n",
              "<tr><td>H2O_cluster_total_nodes:</td>\n",
              "<td>1</td></tr>\n",
              "<tr><td>H2O_cluster_free_memory:</td>\n",
              "<td>3.156 Gb</td></tr>\n",
              "<tr><td>H2O_cluster_total_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_allowed_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_status:</td>\n",
              "<td>locked, healthy</td></tr>\n",
              "<tr><td>H2O_connection_url:</td>\n",
              "<td>http://localhost:54321</td></tr>\n",
              "<tr><td>H2O_connection_proxy:</td>\n",
              "<td>{\"http\": null, \"https\": null, \"colab_language_server\": \"/usr/colab/bin/language_service\"}</td></tr>\n",
              "<tr><td>H2O_internal_security:</td>\n",
              "<td>False</td></tr>\n",
              "<tr><td>Python_version:</td>\n",
              "<td>3.10.12 final</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Library Loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hdf = h2o.H2OFrame(df)\n",
        "hdf[\"diagnosis\"] = hdf[\"diagnosis\"].asfactor()\n",
        "hdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "kWdoOLbsF2qs",
        "outputId": "2fcf4191-419f-4487-888c-200a3a276cf8"
      },
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "diagnosis      radius_mean    texture_mean    perimeter_mean    area_mean    smoothness_mean    compactness_mean    concavity_mean    concave points_mean    symmetry_mean    fractal_dimension_mean    radius_se    texture_se    perimeter_se    area_se    smoothness_se    compactness_se    concavity_se    concave points_se    symmetry_se    fractal_dimension_se    radius_worst    texture_worst    perimeter_worst    area_worst    smoothness_worst    compactness_worst    concavity_worst    concave points_worst    symmetry_worst    fractal_dimension_worst\n",
              "-----------  -------------  --------------  ----------------  -----------  -----------------  ------------------  ----------------  ---------------------  ---------------  ------------------------  -----------  ------------  --------------  ---------  ---------------  ----------------  --------------  -------------------  -------------  ----------------------  --------------  ---------------  -----------------  ------------  ------------------  -------------------  -----------------  ----------------------  ----------------  -------------------------\n",
              "M                    17.99           10.38            122.8        1001              0.1184              0.2776            0.3001                 0.1471            0.2419                   0.07871       1.095         0.9053           8.589     153.4          0.006399           0.04904         0.05373              0.01587        0.03003                0.006193           25.38            17.33             184.6         2019                0.1622               0.6656             0.7119                  0.2654            0.4601                    0.1189\n",
              "M                    20.57           17.77            132.9        1326              0.08474             0.07864           0.0869                 0.07017           0.1812                   0.05667       0.5435        0.7339           3.398      74.08         0.005225           0.01308         0.0186               0.0134         0.01389                0.003532           24.99            23.41             158.8         1956                0.1238               0.1866             0.2416                  0.186             0.275                     0.08902\n",
              "M                    19.69           21.25            130          1203              0.1096              0.1599            0.1974                 0.1279            0.2069                   0.05999       0.7456        0.7869           4.585      94.03         0.00615            0.04006         0.03832              0.02058        0.0225                 0.004571           23.57            25.53             152.5         1709                0.1444               0.4245             0.4504                  0.243             0.3613                    0.08758\n",
              "M                    11.42           20.38             77.58        386.1            0.1425              0.2839            0.2414                 0.1052            0.2597                   0.09744       0.4956        1.156            3.445      27.23         0.00911            0.07458         0.05661              0.01867        0.05963                0.009208           14.91            26.5               98.87         567.7              0.2098               0.8663             0.6869                  0.2575            0.6638                    0.173\n",
              "M                    20.29           14.34            135.1        1297              0.1003              0.1328            0.198                  0.1043            0.1809                   0.05883       0.7572        0.7813           5.438      94.44         0.01149            0.02461         0.05688              0.01885        0.01756                0.005115           22.54            16.67             152.2         1575                0.1374               0.205              0.4                     0.1625            0.2364                    0.07678\n",
              "M                    12.45           15.7              82.57        477.1            0.1278              0.17              0.1578                 0.08089           0.2087                   0.07613       0.3345        0.8902           2.217      27.19         0.00751            0.03345         0.03672              0.01137        0.02165                0.005082           15.47            23.75             103.4          741.6              0.1791               0.5249             0.5355                  0.1741            0.3985                    0.1244\n",
              "M                    18.25           19.98            119.6        1040              0.09463             0.109             0.1127                 0.074             0.1794                   0.05742       0.4467        0.7732           3.18       53.91         0.004314           0.01382         0.02254              0.01039        0.01369                0.002179           22.88            27.66             153.2         1606                0.1442               0.2576             0.3784                  0.1932            0.3063                    0.08368\n",
              "M                    13.71           20.83             90.2         577.9            0.1189              0.1645            0.09366                0.05985           0.2196                   0.07451       0.5835        1.377            3.856      50.96         0.008805           0.03029         0.02488              0.01448        0.01486                0.005412           17.06            28.14             110.6          897                0.1654               0.3682             0.2678                  0.1556            0.3196                    0.1151\n",
              "M                    13              21.82             87.5         519.8            0.1273              0.1932            0.1859                 0.09353           0.235                    0.07389       0.3063        1.002            2.406      24.32         0.005731           0.03502         0.03553              0.01226        0.02143                0.003749           15.49            30.73             106.2          739.3              0.1703               0.5401             0.539                   0.206             0.4378                    0.1072\n",
              "M                    12.46           24.04             83.97        475.9            0.1186              0.2396            0.2273                 0.08543           0.203                    0.08243       0.2976        1.599            2.039      23.94         0.007149           0.07217         0.07743              0.01432        0.01789                0.01008            15.09            40.68              97.65         711.4              0.1853               1.058              1.105                   0.221             0.4366                    0.2075\n",
              "[569 rows x 31 columns]\n"
            ],
            "text/html": [
              "<table class='dataframe'>\n",
              "<thead>\n",
              "<tr><th>diagnosis  </th><th style=\"text-align: right;\">  radius_mean</th><th style=\"text-align: right;\">  texture_mean</th><th style=\"text-align: right;\">  perimeter_mean</th><th style=\"text-align: right;\">  area_mean</th><th style=\"text-align: right;\">  smoothness_mean</th><th style=\"text-align: right;\">  compactness_mean</th><th style=\"text-align: right;\">  concavity_mean</th><th style=\"text-align: right;\">  concave points_mean</th><th style=\"text-align: right;\">  symmetry_mean</th><th style=\"text-align: right;\">  fractal_dimension_mean</th><th style=\"text-align: right;\">  radius_se</th><th style=\"text-align: right;\">  texture_se</th><th style=\"text-align: right;\">  perimeter_se</th><th style=\"text-align: right;\">  area_se</th><th style=\"text-align: right;\">  smoothness_se</th><th style=\"text-align: right;\">  compactness_se</th><th style=\"text-align: right;\">  concavity_se</th><th style=\"text-align: right;\">  concave points_se</th><th style=\"text-align: right;\">  symmetry_se</th><th style=\"text-align: right;\">  fractal_dimension_se</th><th style=\"text-align: right;\">  radius_worst</th><th style=\"text-align: right;\">  texture_worst</th><th style=\"text-align: right;\">  perimeter_worst</th><th style=\"text-align: right;\">  area_worst</th><th style=\"text-align: right;\">  smoothness_worst</th><th style=\"text-align: right;\">  compactness_worst</th><th style=\"text-align: right;\">  concavity_worst</th><th style=\"text-align: right;\">  concave points_worst</th><th style=\"text-align: right;\">  symmetry_worst</th><th style=\"text-align: right;\">  fractal_dimension_worst</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>M          </td><td style=\"text-align: right;\">        17.99</td><td style=\"text-align: right;\">         10.38</td><td style=\"text-align: right;\">          122.8 </td><td style=\"text-align: right;\">     1001  </td><td style=\"text-align: right;\">          0.1184 </td><td style=\"text-align: right;\">           0.2776 </td><td style=\"text-align: right;\">         0.3001 </td><td style=\"text-align: right;\">              0.1471 </td><td style=\"text-align: right;\">         0.2419</td><td style=\"text-align: right;\">                 0.07871</td><td style=\"text-align: right;\">     1.095 </td><td style=\"text-align: right;\">      0.9053</td><td style=\"text-align: right;\">         8.589</td><td style=\"text-align: right;\">   153.4 </td><td style=\"text-align: right;\">       0.006399</td><td style=\"text-align: right;\">         0.04904</td><td style=\"text-align: right;\">       0.05373</td><td style=\"text-align: right;\">            0.01587</td><td style=\"text-align: right;\">      0.03003</td><td style=\"text-align: right;\">              0.006193</td><td style=\"text-align: right;\">         25.38</td><td style=\"text-align: right;\">          17.33</td><td style=\"text-align: right;\">           184.6 </td><td style=\"text-align: right;\">      2019  </td><td style=\"text-align: right;\">            0.1622</td><td style=\"text-align: right;\">             0.6656</td><td style=\"text-align: right;\">           0.7119</td><td style=\"text-align: right;\">                0.2654</td><td style=\"text-align: right;\">          0.4601</td><td style=\"text-align: right;\">                  0.1189 </td></tr>\n",
              "<tr><td>M          </td><td style=\"text-align: right;\">        20.57</td><td style=\"text-align: right;\">         17.77</td><td style=\"text-align: right;\">          132.9 </td><td style=\"text-align: right;\">     1326  </td><td style=\"text-align: right;\">          0.08474</td><td style=\"text-align: right;\">           0.07864</td><td style=\"text-align: right;\">         0.0869 </td><td style=\"text-align: right;\">              0.07017</td><td style=\"text-align: right;\">         0.1812</td><td style=\"text-align: right;\">                 0.05667</td><td style=\"text-align: right;\">     0.5435</td><td style=\"text-align: right;\">      0.7339</td><td style=\"text-align: right;\">         3.398</td><td style=\"text-align: right;\">    74.08</td><td style=\"text-align: right;\">       0.005225</td><td style=\"text-align: right;\">         0.01308</td><td style=\"text-align: right;\">       0.0186 </td><td style=\"text-align: right;\">            0.0134 </td><td style=\"text-align: right;\">      0.01389</td><td style=\"text-align: right;\">              0.003532</td><td style=\"text-align: right;\">         24.99</td><td style=\"text-align: right;\">          23.41</td><td style=\"text-align: right;\">           158.8 </td><td style=\"text-align: right;\">      1956  </td><td style=\"text-align: right;\">            0.1238</td><td style=\"text-align: right;\">             0.1866</td><td style=\"text-align: right;\">           0.2416</td><td style=\"text-align: right;\">                0.186 </td><td style=\"text-align: right;\">          0.275 </td><td style=\"text-align: right;\">                  0.08902</td></tr>\n",
              "<tr><td>M          </td><td style=\"text-align: right;\">        19.69</td><td style=\"text-align: right;\">         21.25</td><td style=\"text-align: right;\">          130   </td><td style=\"text-align: right;\">     1203  </td><td style=\"text-align: right;\">          0.1096 </td><td style=\"text-align: right;\">           0.1599 </td><td style=\"text-align: right;\">         0.1974 </td><td style=\"text-align: right;\">              0.1279 </td><td style=\"text-align: right;\">         0.2069</td><td style=\"text-align: right;\">                 0.05999</td><td style=\"text-align: right;\">     0.7456</td><td style=\"text-align: right;\">      0.7869</td><td style=\"text-align: right;\">         4.585</td><td style=\"text-align: right;\">    94.03</td><td style=\"text-align: right;\">       0.00615 </td><td style=\"text-align: right;\">         0.04006</td><td style=\"text-align: right;\">       0.03832</td><td style=\"text-align: right;\">            0.02058</td><td style=\"text-align: right;\">      0.0225 </td><td style=\"text-align: right;\">              0.004571</td><td style=\"text-align: right;\">         23.57</td><td style=\"text-align: right;\">          25.53</td><td style=\"text-align: right;\">           152.5 </td><td style=\"text-align: right;\">      1709  </td><td style=\"text-align: right;\">            0.1444</td><td style=\"text-align: right;\">             0.4245</td><td style=\"text-align: right;\">           0.4504</td><td style=\"text-align: right;\">                0.243 </td><td style=\"text-align: right;\">          0.3613</td><td style=\"text-align: right;\">                  0.08758</td></tr>\n",
              "<tr><td>M          </td><td style=\"text-align: right;\">        11.42</td><td style=\"text-align: right;\">         20.38</td><td style=\"text-align: right;\">           77.58</td><td style=\"text-align: right;\">      386.1</td><td style=\"text-align: right;\">          0.1425 </td><td style=\"text-align: right;\">           0.2839 </td><td style=\"text-align: right;\">         0.2414 </td><td style=\"text-align: right;\">              0.1052 </td><td style=\"text-align: right;\">         0.2597</td><td style=\"text-align: right;\">                 0.09744</td><td style=\"text-align: right;\">     0.4956</td><td style=\"text-align: right;\">      1.156 </td><td style=\"text-align: right;\">         3.445</td><td style=\"text-align: right;\">    27.23</td><td style=\"text-align: right;\">       0.00911 </td><td style=\"text-align: right;\">         0.07458</td><td style=\"text-align: right;\">       0.05661</td><td style=\"text-align: right;\">            0.01867</td><td style=\"text-align: right;\">      0.05963</td><td style=\"text-align: right;\">              0.009208</td><td style=\"text-align: right;\">         14.91</td><td style=\"text-align: right;\">          26.5 </td><td style=\"text-align: right;\">            98.87</td><td style=\"text-align: right;\">       567.7</td><td style=\"text-align: right;\">            0.2098</td><td style=\"text-align: right;\">             0.8663</td><td style=\"text-align: right;\">           0.6869</td><td style=\"text-align: right;\">                0.2575</td><td style=\"text-align: right;\">          0.6638</td><td style=\"text-align: right;\">                  0.173  </td></tr>\n",
              "<tr><td>M          </td><td style=\"text-align: right;\">        20.29</td><td style=\"text-align: right;\">         14.34</td><td style=\"text-align: right;\">          135.1 </td><td style=\"text-align: right;\">     1297  </td><td style=\"text-align: right;\">          0.1003 </td><td style=\"text-align: right;\">           0.1328 </td><td style=\"text-align: right;\">         0.198  </td><td style=\"text-align: right;\">              0.1043 </td><td style=\"text-align: right;\">         0.1809</td><td style=\"text-align: right;\">                 0.05883</td><td style=\"text-align: right;\">     0.7572</td><td style=\"text-align: right;\">      0.7813</td><td style=\"text-align: right;\">         5.438</td><td style=\"text-align: right;\">    94.44</td><td style=\"text-align: right;\">       0.01149 </td><td style=\"text-align: right;\">         0.02461</td><td style=\"text-align: right;\">       0.05688</td><td style=\"text-align: right;\">            0.01885</td><td style=\"text-align: right;\">      0.01756</td><td style=\"text-align: right;\">              0.005115</td><td style=\"text-align: right;\">         22.54</td><td style=\"text-align: right;\">          16.67</td><td style=\"text-align: right;\">           152.2 </td><td style=\"text-align: right;\">      1575  </td><td style=\"text-align: right;\">            0.1374</td><td style=\"text-align: right;\">             0.205 </td><td style=\"text-align: right;\">           0.4   </td><td style=\"text-align: right;\">                0.1625</td><td style=\"text-align: right;\">          0.2364</td><td style=\"text-align: right;\">                  0.07678</td></tr>\n",
              "<tr><td>M          </td><td style=\"text-align: right;\">        12.45</td><td style=\"text-align: right;\">         15.7 </td><td style=\"text-align: right;\">           82.57</td><td style=\"text-align: right;\">      477.1</td><td style=\"text-align: right;\">          0.1278 </td><td style=\"text-align: right;\">           0.17   </td><td style=\"text-align: right;\">         0.1578 </td><td style=\"text-align: right;\">              0.08089</td><td style=\"text-align: right;\">         0.2087</td><td style=\"text-align: right;\">                 0.07613</td><td style=\"text-align: right;\">     0.3345</td><td style=\"text-align: right;\">      0.8902</td><td style=\"text-align: right;\">         2.217</td><td style=\"text-align: right;\">    27.19</td><td style=\"text-align: right;\">       0.00751 </td><td style=\"text-align: right;\">         0.03345</td><td style=\"text-align: right;\">       0.03672</td><td style=\"text-align: right;\">            0.01137</td><td style=\"text-align: right;\">      0.02165</td><td style=\"text-align: right;\">              0.005082</td><td style=\"text-align: right;\">         15.47</td><td style=\"text-align: right;\">          23.75</td><td style=\"text-align: right;\">           103.4 </td><td style=\"text-align: right;\">       741.6</td><td style=\"text-align: right;\">            0.1791</td><td style=\"text-align: right;\">             0.5249</td><td style=\"text-align: right;\">           0.5355</td><td style=\"text-align: right;\">                0.1741</td><td style=\"text-align: right;\">          0.3985</td><td style=\"text-align: right;\">                  0.1244 </td></tr>\n",
              "<tr><td>M          </td><td style=\"text-align: right;\">        18.25</td><td style=\"text-align: right;\">         19.98</td><td style=\"text-align: right;\">          119.6 </td><td style=\"text-align: right;\">     1040  </td><td style=\"text-align: right;\">          0.09463</td><td style=\"text-align: right;\">           0.109  </td><td style=\"text-align: right;\">         0.1127 </td><td style=\"text-align: right;\">              0.074  </td><td style=\"text-align: right;\">         0.1794</td><td style=\"text-align: right;\">                 0.05742</td><td style=\"text-align: right;\">     0.4467</td><td style=\"text-align: right;\">      0.7732</td><td style=\"text-align: right;\">         3.18 </td><td style=\"text-align: right;\">    53.91</td><td style=\"text-align: right;\">       0.004314</td><td style=\"text-align: right;\">         0.01382</td><td style=\"text-align: right;\">       0.02254</td><td style=\"text-align: right;\">            0.01039</td><td style=\"text-align: right;\">      0.01369</td><td style=\"text-align: right;\">              0.002179</td><td style=\"text-align: right;\">         22.88</td><td style=\"text-align: right;\">          27.66</td><td style=\"text-align: right;\">           153.2 </td><td style=\"text-align: right;\">      1606  </td><td style=\"text-align: right;\">            0.1442</td><td style=\"text-align: right;\">             0.2576</td><td style=\"text-align: right;\">           0.3784</td><td style=\"text-align: right;\">                0.1932</td><td style=\"text-align: right;\">          0.3063</td><td style=\"text-align: right;\">                  0.08368</td></tr>\n",
              "<tr><td>M          </td><td style=\"text-align: right;\">        13.71</td><td style=\"text-align: right;\">         20.83</td><td style=\"text-align: right;\">           90.2 </td><td style=\"text-align: right;\">      577.9</td><td style=\"text-align: right;\">          0.1189 </td><td style=\"text-align: right;\">           0.1645 </td><td style=\"text-align: right;\">         0.09366</td><td style=\"text-align: right;\">              0.05985</td><td style=\"text-align: right;\">         0.2196</td><td style=\"text-align: right;\">                 0.07451</td><td style=\"text-align: right;\">     0.5835</td><td style=\"text-align: right;\">      1.377 </td><td style=\"text-align: right;\">         3.856</td><td style=\"text-align: right;\">    50.96</td><td style=\"text-align: right;\">       0.008805</td><td style=\"text-align: right;\">         0.03029</td><td style=\"text-align: right;\">       0.02488</td><td style=\"text-align: right;\">            0.01448</td><td style=\"text-align: right;\">      0.01486</td><td style=\"text-align: right;\">              0.005412</td><td style=\"text-align: right;\">         17.06</td><td style=\"text-align: right;\">          28.14</td><td style=\"text-align: right;\">           110.6 </td><td style=\"text-align: right;\">       897  </td><td style=\"text-align: right;\">            0.1654</td><td style=\"text-align: right;\">             0.3682</td><td style=\"text-align: right;\">           0.2678</td><td style=\"text-align: right;\">                0.1556</td><td style=\"text-align: right;\">          0.3196</td><td style=\"text-align: right;\">                  0.1151 </td></tr>\n",
              "<tr><td>M          </td><td style=\"text-align: right;\">        13   </td><td style=\"text-align: right;\">         21.82</td><td style=\"text-align: right;\">           87.5 </td><td style=\"text-align: right;\">      519.8</td><td style=\"text-align: right;\">          0.1273 </td><td style=\"text-align: right;\">           0.1932 </td><td style=\"text-align: right;\">         0.1859 </td><td style=\"text-align: right;\">              0.09353</td><td style=\"text-align: right;\">         0.235 </td><td style=\"text-align: right;\">                 0.07389</td><td style=\"text-align: right;\">     0.3063</td><td style=\"text-align: right;\">      1.002 </td><td style=\"text-align: right;\">         2.406</td><td style=\"text-align: right;\">    24.32</td><td style=\"text-align: right;\">       0.005731</td><td style=\"text-align: right;\">         0.03502</td><td style=\"text-align: right;\">       0.03553</td><td style=\"text-align: right;\">            0.01226</td><td style=\"text-align: right;\">      0.02143</td><td style=\"text-align: right;\">              0.003749</td><td style=\"text-align: right;\">         15.49</td><td style=\"text-align: right;\">          30.73</td><td style=\"text-align: right;\">           106.2 </td><td style=\"text-align: right;\">       739.3</td><td style=\"text-align: right;\">            0.1703</td><td style=\"text-align: right;\">             0.5401</td><td style=\"text-align: right;\">           0.539 </td><td style=\"text-align: right;\">                0.206 </td><td style=\"text-align: right;\">          0.4378</td><td style=\"text-align: right;\">                  0.1072 </td></tr>\n",
              "<tr><td>M          </td><td style=\"text-align: right;\">        12.46</td><td style=\"text-align: right;\">         24.04</td><td style=\"text-align: right;\">           83.97</td><td style=\"text-align: right;\">      475.9</td><td style=\"text-align: right;\">          0.1186 </td><td style=\"text-align: right;\">           0.2396 </td><td style=\"text-align: right;\">         0.2273 </td><td style=\"text-align: right;\">              0.08543</td><td style=\"text-align: right;\">         0.203 </td><td style=\"text-align: right;\">                 0.08243</td><td style=\"text-align: right;\">     0.2976</td><td style=\"text-align: right;\">      1.599 </td><td style=\"text-align: right;\">         2.039</td><td style=\"text-align: right;\">    23.94</td><td style=\"text-align: right;\">       0.007149</td><td style=\"text-align: right;\">         0.07217</td><td style=\"text-align: right;\">       0.07743</td><td style=\"text-align: right;\">            0.01432</td><td style=\"text-align: right;\">      0.01789</td><td style=\"text-align: right;\">              0.01008 </td><td style=\"text-align: right;\">         15.09</td><td style=\"text-align: right;\">          40.68</td><td style=\"text-align: right;\">            97.65</td><td style=\"text-align: right;\">       711.4</td><td style=\"text-align: right;\">            0.1853</td><td style=\"text-align: right;\">             1.058 </td><td style=\"text-align: right;\">           1.105 </td><td style=\"text-align: right;\">                0.221 </td><td style=\"text-align: right;\">          0.4366</td><td style=\"text-align: right;\">                  0.2075 </td></tr>\n",
              "</tbody>\n",
              "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[569 rows x 31 columns]</pre>"
            ]
          },
          "metadata": {},
          "execution_count": 269
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hy = \"diagnosis\"\n",
        "hx = hdf.columns\n",
        "hx.remove(hy)"
      ],
      "metadata": {
        "id": "X-QiglXeF_XE"
      },
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, valid = hdf.split_frame(ratios=[.8], seed=123)"
      ],
      "metadata": {
        "id": "NVoFNbYCGxGh"
      },
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aml = H2OAutoML(max_models = 10, seed = 123, verbosity=\"info\", nfolds=10, sort_metric='accuracy')"
      ],
      "metadata": {
        "id": "7JNO6XnVHH5P"
      },
      "execution_count": 273,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aml.train(x = hx, y = hy, training_frame = train, validation_frame = valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Lbo606kFH4Zc",
        "outputId": "b8a9873e-4adf-4505-aede-52bbc71f315a"
      },
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoML progress: |\n",
            "21:45:24.978: Project: AutoML_2_20230621_214524\n",
            "21:45:24.978: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n",
            "21:45:24.978: Setting stopping tolerance adaptively based on the training frame: 0.04714045207910317\n",
            "21:45:24.978: Build control seed: 123\n",
            "21:45:24.979: training frame: Frame key: AutoML_2_20230621_214524_training_py_14_sid_b943    cols: 31    rows: 450  chunks: 1    size: 40099  checksum: 6449846279590894544\n",
            "21:45:24.979: validation frame: Frame key: py_15_sid_b943    cols: 31    rows: 119  chunks: 1    size: 12439  checksum: -3700575018798051096\n",
            "21:45:24.979: leaderboard frame: NULL\n",
            "21:45:24.979: blending frame: NULL\n",
            "21:45:24.979: response column: diagnosis\n",
            "21:45:24.979: fold column: null\n",
            "21:45:24.979: weights column: null\n",
            "21:45:24.989: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (7g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (7g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (6g, 60w)]}, {StackedEnsemble : [monotonic (9g, 10w), best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
            "21:45:25.0: AutoML job created: 2023.06.21 21:45:24.963\n",
            "21:45:25.3: AutoML build started: 2023.06.21 21:45:25.3\n",
            "21:45:25.10: AutoML: starting XGBoost_1_AutoML_2_20230621_214524 model training\n",
            "\n",
            "█\n",
            "21:45:30.206: New leader: XGBoost_1_AutoML_2_20230621_214524, accuracy: 0.9422222222222222\n",
            "21:45:30.207: AutoML: starting GLM_1_AutoML_2_20230621_214524 model training\n",
            "\n",
            "█\n",
            "21:45:32.52: AutoML: starting GBM_1_AutoML_2_20230621_214524 model training\n",
            "\n",
            "███\n",
            "21:45:39.590: AutoML: starting XGBoost_2_AutoML_2_20230621_214524 model training\n",
            "\n",
            "█\n",
            "21:45:43.28: AutoML: starting DRF_1_AutoML_2_20230621_214524 model training\n",
            "\n",
            "\n",
            "21:45:45.906: AutoML: starting GBM_2_AutoML_2_20230621_214524 model training\n",
            "\n",
            "███\n",
            "21:45:56.621: AutoML: starting GBM_3_AutoML_2_20230621_214524 model training\n",
            "\n",
            "█\n",
            "21:46:07.654: AutoML: starting GBM_4_AutoML_2_20230621_214524 model training\n",
            "\n",
            "██\n",
            "21:46:19.578: AutoML: starting XGBoost_3_AutoML_2_20230621_214524 model training\n",
            "\n",
            "\n",
            "21:46:22.908: AutoML: starting XRT_1_AutoML_2_20230621_214524 model training\n",
            "\n",
            "█\n",
            "21:46:26.375: No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'monotonic'.\n",
            "21:46:26.376: AutoML: starting StackedEnsemble_BestOfFamily_1_AutoML_2_20230621_214524 model training\n",
            "\n",
            "██\n",
            "21:46:29.644: AutoML: starting StackedEnsemble_AllModels_1_AutoML_2_20230621_214524 model training\n",
            "\n",
            "████████████████████████████████████████████████| (done) 100%\n",
            "\n",
            "21:46:32.355: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GLM : [def_1 (1g, 10w)]}, {GBM : [def_5 (1g, 10w)]}, {XGBoost : [def_1 (2g, 10w)]}, {DRF : [def_1 (2g, 10w)]}, {GBM : [def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w)]}, {XGBoost : [def_3 (3g, 10w)]}, {DRF : [XRT (3g, 10w)]}, {StackedEnsemble : [best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
            "21:46:32.355: AutoML build stopped: 2023.06.21 21:46:32.355\n",
            "21:46:32.355: AutoML build done: built 10 models\n",
            "21:46:32.355: AutoML duration:  1 min  7.352 sec\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model Details\n",
              "=============\n",
              "H2OXGBoostEstimator : XGBoost\n",
              "Model Key: XGBoost_1_AutoML_2_20230621_214524\n",
              "\n",
              "\n",
              "Model Summary: \n",
              "    number_of_trees\n",
              "--  -----------------\n",
              "    44\n",
              "\n",
              "ModelMetricsBinomial: xgboost\n",
              "** Reported on train data. **\n",
              "\n",
              "MSE: 0.029130112207480154\n",
              "RMSE: 0.17067545871472017\n",
              "LogLoss: 0.12240138558277379\n",
              "Mean Per-Class Error: 0.03565096251266464\n",
              "AUC: 0.9911136440391759\n",
              "AUCPR: 0.989398055584699\n",
              "Gini: 0.9822272880783518\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4297827184200287\n",
              "       B    M    Error    Rate\n",
              "-----  ---  ---  -------  ------------\n",
              "B      277  5    0.0177   (5.0/282.0)\n",
              "M      9    159  0.0536   (9.0/168.0)\n",
              "Total  286  164  0.0311   (14.0/450.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.429783     0.957831  47\n",
              "max f2                       0.292471     0.963572  59\n",
              "max f0point5                 0.574773     0.977157  40\n",
              "max accuracy                 0.516256     0.968889  45\n",
              "max precision                0.97564      1         0\n",
              "max recall                   0.0439371    1         113\n",
              "max specificity              0.97564      1         0\n",
              "max absolute_mcc             0.516256     0.933412  45\n",
              "max min_per_class_accuracy   0.349176     0.960993  53\n",
              "max mean_per_class_accuracy  0.341069     0.965616  54\n",
              "max tns                      0.97564      282       0\n",
              "max fns                      0.97564      107       0\n",
              "max fps                      0.0141261    282       139\n",
              "max tps                      0.0439371    168       113\n",
              "max tnr                      0.97564      1         0\n",
              "max fnr                      0.97564      0.636905  0\n",
              "max fpr                      0.0141261    1         139\n",
              "max tpr                      0.0439371    1         113\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 37.33 %, avg score: 37.00 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.135556                    0.97564            2.67857    2.67857            1                0.97564    1                           0.97564             0.363095        0.363095                   167.857   167.857            0.363095\n",
              "2        0.155556                    0.965855           2.67857    2.67857            1                0.965936   1                           0.974393            0.0535714       0.416667                   167.857   167.857            0.416667\n",
              "3        0.202222                    0.949678           2.67857    2.67857            1                0.959372   1                           0.970926            0.125           0.541667                   167.857   167.857            0.541667\n",
              "4        0.3                         0.815279           2.67857    2.67857            1                0.915144   1                           0.952745            0.261905        0.803571                   167.857   167.857            0.803571\n",
              "5        0.4                         0.276934           1.72619    2.44048            0.644444         0.54826    0.911111                    0.851624            0.172619        0.97619                    72.619    144.048            0.919453\n",
              "6        0.5                         0.0818321          0.0595238  1.96429            0.0222222        0.134368   0.733333                    0.708173            0.00595238      0.982143                   -94.0476  96.4286            0.769377\n",
              "7        0.6                         0.060137           0.119048   1.65675            0.0444444        0.0681423  0.618519                    0.601501            0.0119048       0.994048                   -88.0952  65.6746            0.628799\n",
              "8        0.708889                    0.0255055          0.0546647  1.41066            0.0204082        0.0402448  0.526646                    0.515289            0.00595238      1                          -94.5335  41.0658            0.464539\n",
              "9        0.817778                    0.017118           0          1.22283            0                0.019577   0.456522                    0.449284            0               1                          -100      22.2826            0.29078\n",
              "10       1                           0.0141261          0          1                  0                0.0141261  0.373333                    0.369989            0               1                          -100      0                  0\n",
              "\n",
              "ModelMetricsBinomial: xgboost\n",
              "** Reported on validation data. **\n",
              "\n",
              "MSE: 0.026133884441954087\n",
              "RMSE: 0.16165977991434383\n",
              "LogLoss: 0.11356345603286226\n",
              "Mean Per-Class Error: 0.024696969696969696\n",
              "AUC: 0.9974242424242425\n",
              "AUCPR: 0.9957667052093674\n",
              "Gini: 0.9948484848484851\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.47318321466445923\n",
              "       B    M    Error    Rate\n",
              "-----  ---  ---  -------  -----------\n",
              "B      73   2    0.0267   (2.0/75.0)\n",
              "M      1    43   0.0227   (1.0/44.0)\n",
              "Total  74   45   0.0252   (3.0/119.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.473183     0.966292  20\n",
              "max f2                       0.291518     0.977778  23\n",
              "max f0point5                 0.615323     0.980392  15\n",
              "max accuracy                 0.509488     0.97479   18\n",
              "max precision                0.97564      1         0\n",
              "max recall                   0.291518     1         23\n",
              "max specificity              0.97564      1         0\n",
              "max absolute_mcc             0.473183     0.946314  20\n",
              "max min_per_class_accuracy   0.473183     0.973333  20\n",
              "max mean_per_class_accuracy  0.473183     0.975303  20\n",
              "max tns                      0.97564      75        0\n",
              "max fns                      0.97564      29        0\n",
              "max fps                      0.0141261    75        61\n",
              "max tps                      0.291518     44        23\n",
              "max tnr                      0.97564      1         0\n",
              "max fnr                      0.97564      0.659091  0\n",
              "max fpr                      0.0141261    1         61\n",
              "max tpr                      0.291518     1         23\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 36.97 %, avg score: 37.32 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  -------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------\n",
              "1        0.12605                     0.97564            2.70455  2.70455            1                0.97564    1                           0.97564             0.340909        0.340909                   170.455  170.455            0.340909\n",
              "2        0.151261                    0.947632           2.70455  2.70455            1                0.959285   1                           0.972915            0.0681818       0.409091                   170.455  170.455            0.409091\n",
              "3        0.235294                    0.926242           2.70455  2.70455            1                0.929826   1                           0.957526            0.227273        0.636364                   170.455  170.455            0.636364\n",
              "4        0.319328                    0.811291           2.70455  2.70455            1                0.865185   1                           0.933226            0.227273        0.863636                   170.455  170.455            0.863636\n",
              "5        0.411765                    0.291518           1.47521  2.42857            0.545455         0.483095   0.897959                    0.832176            0.136364        1                          47.5207  142.857            0.933333\n",
              "6        0.504202                    0.0890782          0        1.98333            0                0.163798   0.733333                    0.70964             0               1                          -100     98.3333            0.786667\n",
              "7        0.596639                    0.0469845          0        1.67606            0                0.0708849  0.619718                    0.610678            0               1                          -100     67.6056            0.64\n",
              "8        0.697479                    0.0275775          0        1.43373            0                0.0362935  0.53012                     0.527634            0               1                          -100     43.3735            0.48\n",
              "9        0.798319                    0.0184387          0        1.25263            0                0.0209517  0.463158                    0.463632            0               1                          -100     25.2632            0.32\n",
              "10       1                           0.0141261          0        1                  0                0.015323   0.369748                    0.373217            0               1                          -100     0                  0\n",
              "\n",
              "ModelMetricsBinomial: xgboost\n",
              "** Reported on cross-validation data. **\n",
              "\n",
              "MSE: 0.04456220211816163\n",
              "RMSE: 0.21109761277229458\n",
              "LogLoss: 0.16800715284467554\n",
              "Mean Per-Class Error: 0.05933383991894631\n",
              "AUC: 0.982364488348531\n",
              "AUCPR: 0.9779680523587579\n",
              "Gini: 0.9647289766970619\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4053971767425537\n",
              "       B    M    Error    Rate\n",
              "-----  ---  ---  -------  ------------\n",
              "B      267  15   0.0532   (15.0/282.0)\n",
              "M      11   157  0.0655   (11.0/168.0)\n",
              "Total  278  172  0.0578   (26.0/450.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.405397     0.923529  94\n",
              "max f2                       0.346213     0.94152   105\n",
              "max f0point5                 0.692823     0.951087  64\n",
              "max accuracy                 0.405397     0.942222  94\n",
              "max precision                0.972643     1         0\n",
              "max recall                   0.0375161    1         217\n",
              "max specificity              0.972643     1         0\n",
              "max absolute_mcc             0.405397     0.877268  94\n",
              "max min_per_class_accuracy   0.379142     0.93617   98\n",
              "max mean_per_class_accuracy  0.405397     0.940666  94\n",
              "max tns                      0.972643     282       0\n",
              "max fns                      0.972643     160       0\n",
              "max fps                      0.0176464    282       265\n",
              "max tps                      0.0375161    168       217\n",
              "max tnr                      0.972643     1         0\n",
              "max fnr                      0.972643     0.952381  0\n",
              "max fpr                      0.0176464    1         265\n",
              "max tpr                      0.0375161    1         217\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 37.33 %, avg score: 37.50 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  --------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.0177778                   0.972643           2.67857   2.67857            1                0.972643   1                           0.972643            0.047619        0.047619                   167.857   167.857            0.047619\n",
              "2        0.0333333                   0.969649           2.67857   2.67857            1                0.969649   1                           0.971246            0.0416667       0.0892857                  167.857   167.857            0.0892857\n",
              "3        0.0488889                   0.966778           2.67857   2.67857            1                0.967138   1                           0.969939            0.0416667       0.130952                   167.857   167.857            0.130952\n",
              "4        0.0666667                   0.966353           2.67857   2.67857            1                0.966353   1                           0.968983            0.047619        0.178571                   167.857   167.857            0.178571\n",
              "5        0.102222                    0.959761           2.67857   2.67857            1                0.961971   1                           0.966544            0.0952381       0.27381                    167.857   167.857            0.27381\n",
              "6        0.16                        0.952606           2.67857   2.67857            1                0.955511   1                           0.96256             0.154762        0.428571                   167.857   167.857            0.428571\n",
              "7        0.2                         0.935707           2.67857   2.67857            1                0.944104   1                           0.958869            0.107143        0.535714                   167.857   167.857            0.535714\n",
              "8        0.3                         0.781871           2.55952   2.63889            0.955556         0.901003   0.985185                    0.93958             0.255952        0.791667                   155.952   163.889            0.784574\n",
              "9        0.4                         0.35034            1.54762   2.36607            0.577778         0.54105    0.883333                    0.839948            0.154762        0.946429                   54.7619   136.607            0.87196\n",
              "10       0.5                         0.099627           0.297619  1.95238            0.111111         0.185644   0.728889                    0.709087            0.0297619       0.97619                    -70.2381  95.2381            0.759878\n",
              "11       0.604444                    0.0597624          0.113982  1.63472            0.0425532        0.0731328  0.610294                    0.599198            0.0119048       0.988095                   -88.6018  63.4716            0.612209\n",
              "12       0.7                         0.0389057          0         1.41156            0                0.048439   0.526984                    0.524015            0               0.988095                   -100      41.1565            0.459726\n",
              "13       0.802222                    0.029383           0.11646   1.24654            0.0434783        0.034212   0.465374                    0.461602            0.0119048       1                          -88.354   24.6537            0.315603\n",
              "14       0.902222                    0.024317           0         1.10837            0                0.0259154  0.413793                    0.413312            0               1                          -100      10.8374            0.156028\n",
              "15       1                           0.0176464          0         1                  0                0.0210691  0.373333                    0.374959            0               1                          -100      0                  0\n",
              "\n",
              "Cross-Validation Metrics Summary: \n",
              "                         mean       sd         cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid    cv_6_valid    cv_7_valid    cv_8_valid    cv_9_valid    cv_10_valid\n",
              "-----------------------  ---------  ---------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  -------------\n",
              "accuracy                 0.964444   0.0214687  0.955556      1             0.977778      0.933333      0.977778      0.955556      0.977778      0.933333      0.955556      0.977778\n",
              "auc                      0.985334   0.0191174  0.99177       1             0.997976      0.936         0.982222      0.993927      0.993827      0.972672      0.989224      0.995726\n",
              "err                      0.0355556  0.0214687  0.0444444     0             0.0222222     0.0666667     0.0222222     0.0444444     0.0222222     0.0666667     0.0444444     0.0222222\n",
              "err_count                1.6        0.966092   2             0             1             3             1             2             1             3             2             1\n",
              "f0point5                 0.943507   0.0340338  0.918367      1             0.959596      0.9375        0.985915      0.92233       0.957447      0.934066      0.9375        0.882353\n",
              "f1                       0.951279   0.0267176  0.947368      1             0.974359      0.923077      0.965517      0.95          0.972973      0.918919      0.9375        0.923077\n",
              "f2                       0.960077   0.0341382  0.978261      1             0.989583      0.909091      0.945946      0.979381      0.989011      0.904255      0.9375        0.967742\n",
              "lift_top_group           3.01678    1.59135    2.5           2.5           2.36842       2.25          3             2.36842       2.5           2.36842       2.8125        7.5\n",
              "logloss                  0.168007   0.0536355  0.141224      0.109406      0.140843      0.287477      0.169976      0.165738      0.163844      0.21237       0.187247      0.101947\n",
              "max_per_class_error      0.0586567  0.0332292  0.0740741     0             0.0384615     0.1           0.0666667     0.0769231     0.037037      0.105263      0.0625        0.025641\n",
              "mcc                      0.92334    0.0426305  0.912871      1             0.955752      0.865207      0.950382      0.913874      0.955134      0.863294      0.903017      0.913874\n",
              "mean_per_class_accuracy  0.965024   0.023622   0.962963      1             0.980769      0.93          0.966667      0.961538      0.981482      0.928138      0.951509      0.987179\n",
              "mean_per_class_error     0.0349755  0.023622   0.037037      0             0.0192308     0.07          0.0333333     0.0384615     0.0185185     0.0718624     0.0484914     0.0128205\n",
              "mse                      0.0445622  0.0161211  0.037262      0.0255396     0.0351779     0.0772335     0.0445828     0.0448035     0.0417654     0.0617108     0.0529047     0.0246418\n",
              "pr_auc                   0.981783   0.0155081  0.988293      1             0.9973        0.948117      0.976292      0.992019      0.990453      0.969532      0.981517      0.974308\n",
              "precision                0.938859   0.0436254  0.9           1             0.95          0.947368      1             0.904762      0.947368      0.944444      0.9375        0.857143\n",
              "r2                       0.802593   0.0590727  0.844742      0.893585      0.855799      0.687204      0.799377      0.816342      0.825977      0.747036      0.769112      0.786754\n",
              "recall                   0.966557   0.0450268  1             1             1             0.9           0.933333      1             1             0.894737      0.9375        1\n",
              "rmse                     0.20809    0.0374301  0.193034      0.159811      0.187558      0.277909      0.211146      0.211668      0.204366      0.248417      0.23001       0.156977\n",
              "specificity              0.963492   0.0255007  0.925926      1             0.961538      0.96          1             0.923077      0.962963      0.961538      0.965517      0.974359\n",
              "\n",
              "Scoring History: \n",
              "    timestamp            duration    number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
              "--  -------------------  ----------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ----------------  -------------------  -----------------  ---------------------------------\n",
              "    2023-06-21 21:45:29  4.870 sec   0                  0.5              0.693147            0.5             0.373333           1                0.626667                         0.5                0.693147              0.5               0.369748             1                  0.630252\n",
              "    2023-06-21 21:45:29  4.897 sec   5                  0.22969          0.226667            0.986934        0.982173           2.67857          0.0555556                        0.236996           0.235786              0.988939          0.980655             2.70455            0.0504202\n",
              "    2023-06-21 21:45:29  4.921 sec   10                 0.183882         0.143713            0.992317        0.98965            2.67857          0.0333333                        0.194435           0.152695              0.99197           0.986434             2.70455            0.0420168\n",
              "    2023-06-21 21:45:29  4.938 sec   15                 0.176657         0.131826            0.991831        0.989632           2.67857          0.0311111                        0.179833           0.13377               0.995             0.991882             2.70455            0.0336134\n",
              "    2023-06-21 21:45:29  4.960 sec   20                 0.173072         0.127836            0.991515        0.989782           2.67857          0.0311111                        0.172738           0.12622               0.996515          0.994173             2.70455            0.0252101\n",
              "    2023-06-21 21:45:29  4.988 sec   25                 0.172723         0.127706            0.991515        0.989782           2.67857          0.0311111                        0.1726             0.126394              0.996515          0.994173             2.70455            0.0252101\n",
              "    2023-06-21 21:45:30  5.026 sec   30                 0.172738         0.127708            0.991515        0.989782           2.67857          0.0311111                        0.172602           0.126379              0.996515          0.994173             2.70455            0.0252101\n",
              "    2023-06-21 21:45:30  5.051 sec   35                 0.173271         0.127943            0.991515        0.989782           2.67857          0.0311111                        0.172859           0.126204              0.996515          0.994173             2.70455            0.0252101\n",
              "    2023-06-21 21:45:30  5.080 sec   40                 0.170592         0.122358            0.991114        0.989398           2.67857          0.0311111                        0.161652           0.113623              0.997424          0.995767             2.70455            0.0252101\n",
              "    2023-06-21 21:45:30  5.111 sec   44                 0.170675         0.122401            0.991114        0.989398           2.67857          0.0311111                        0.16166            0.113563              0.997424          0.995767             2.70455            0.0252101\n",
              "\n",
              "Variable Importances: \n",
              "variable              relative_importance    scaled_importance    percentage\n",
              "--------------------  ---------------------  -------------------  ------------\n",
              "perimeter_worst       335.855                1                    0.559163\n",
              "concave points_worst  156.842                0.466992             0.261125\n",
              "concave points_mean   25.2143                0.0750751            0.0419793\n",
              "texture_worst         23.8098                0.0708931            0.0396408\n",
              "area_worst            17.7388                0.052817             0.0295333\n",
              "area_se               17.3529                0.0516679            0.0288908\n",
              "texture_mean          12.4471                0.0370608            0.020723\n",
              "concavity_mean        7.08558                0.0210971            0.0117967\n",
              "radius_se             4.2931                 0.0127826            0.00714757\n",
              "\n",
              "[tips]\n",
              "Use `model.explain()` to inspect the model.\n",
              "--\n",
              "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
            ],
            "text/html": [
              "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
              "=============\n",
              "H2OXGBoostEstimator : XGBoost\n",
              "Model Key: XGBoost_1_AutoML_2_20230621_214524\n",
              "</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-29.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-29 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-29 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-29 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-29 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-29 .h2o-table th,\n",
              "#h2o-table-29 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-29 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-29\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Model Summary: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>number_of_trees</th></tr></thead>\n",
              "    <tbody><tr><td></td>\n",
              "<td>44.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: xgboost\n",
              "** Reported on train data. **\n",
              "\n",
              "MSE: 0.029130112207480154\n",
              "RMSE: 0.17067545871472017\n",
              "LogLoss: 0.12240138558277379\n",
              "Mean Per-Class Error: 0.03565096251266464\n",
              "AUC: 0.9911136440391759\n",
              "AUCPR: 0.989398055584699\n",
              "Gini: 0.9822272880783518</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-30.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-30 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-30 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-30 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-30 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-30 .h2o-table th,\n",
              "#h2o-table-30 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-30 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-30\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4297827184200287</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>B</th>\n",
              "<th>M</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>B</td>\n",
              "<td>277.0</td>\n",
              "<td>5.0</td>\n",
              "<td>0.0177</td>\n",
              "<td> (5.0/282.0)</td></tr>\n",
              "<tr><td>M</td>\n",
              "<td>9.0</td>\n",
              "<td>159.0</td>\n",
              "<td>0.0536</td>\n",
              "<td> (9.0/168.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>286.0</td>\n",
              "<td>164.0</td>\n",
              "<td>0.0311</td>\n",
              "<td> (14.0/450.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-31.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-31 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-31 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-31 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-31 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-31 .h2o-table th,\n",
              "#h2o-table-31 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-31 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-31\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.4297827</td>\n",
              "<td>0.9578313</td>\n",
              "<td>47.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.2924710</td>\n",
              "<td>0.9635723</td>\n",
              "<td>59.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.5747734</td>\n",
              "<td>0.9771574</td>\n",
              "<td>40.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.5162559</td>\n",
              "<td>0.9688889</td>\n",
              "<td>45.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>0.9756404</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0439371</td>\n",
              "<td>1.0</td>\n",
              "<td>113.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>0.9756404</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.5162559</td>\n",
              "<td>0.9334117</td>\n",
              "<td>45.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.3491756</td>\n",
              "<td>0.9609929</td>\n",
              "<td>53.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.3410693</td>\n",
              "<td>0.9656155</td>\n",
              "<td>54.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>0.9756404</td>\n",
              "<td>282.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>0.9756404</td>\n",
              "<td>107.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0141261</td>\n",
              "<td>282.0</td>\n",
              "<td>139.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0439371</td>\n",
              "<td>168.0</td>\n",
              "<td>113.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>0.9756404</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>0.9756404</td>\n",
              "<td>0.6369048</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0141261</td>\n",
              "<td>1.0</td>\n",
              "<td>139.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0439371</td>\n",
              "<td>1.0</td>\n",
              "<td>113.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-32.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-32 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-32 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-32 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-32 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-32 .h2o-table th,\n",
              "#h2o-table-32 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-32 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-32\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 37.33 %, avg score: 37.00 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.1355556</td>\n",
              "<td>0.9756404</td>\n",
              "<td>2.6785714</td>\n",
              "<td>2.6785714</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9756404</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9756404</td>\n",
              "<td>0.3630952</td>\n",
              "<td>0.3630952</td>\n",
              "<td>167.8571429</td>\n",
              "<td>167.8571429</td>\n",
              "<td>0.3630952</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.1555556</td>\n",
              "<td>0.9658545</td>\n",
              "<td>2.6785714</td>\n",
              "<td>2.6785714</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9659363</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9743927</td>\n",
              "<td>0.0535714</td>\n",
              "<td>0.4166667</td>\n",
              "<td>167.8571429</td>\n",
              "<td>167.8571429</td>\n",
              "<td>0.4166667</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.2022222</td>\n",
              "<td>0.9496785</td>\n",
              "<td>2.6785714</td>\n",
              "<td>2.6785714</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9593723</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9709265</td>\n",
              "<td>0.125</td>\n",
              "<td>0.5416667</td>\n",
              "<td>167.8571429</td>\n",
              "<td>167.8571429</td>\n",
              "<td>0.5416667</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.3</td>\n",
              "<td>0.8152791</td>\n",
              "<td>2.6785714</td>\n",
              "<td>2.6785714</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9151439</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9527455</td>\n",
              "<td>0.2619048</td>\n",
              "<td>0.8035714</td>\n",
              "<td>167.8571429</td>\n",
              "<td>167.8571429</td>\n",
              "<td>0.8035714</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.4</td>\n",
              "<td>0.2769342</td>\n",
              "<td>1.7261905</td>\n",
              "<td>2.4404762</td>\n",
              "<td>0.6444444</td>\n",
              "<td>0.5482601</td>\n",
              "<td>0.9111111</td>\n",
              "<td>0.8516241</td>\n",
              "<td>0.1726190</td>\n",
              "<td>0.9761905</td>\n",
              "<td>72.6190476</td>\n",
              "<td>144.0476190</td>\n",
              "<td>0.9194529</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.5</td>\n",
              "<td>0.0818321</td>\n",
              "<td>0.0595238</td>\n",
              "<td>1.9642857</td>\n",
              "<td>0.0222222</td>\n",
              "<td>0.1343683</td>\n",
              "<td>0.7333333</td>\n",
              "<td>0.7081730</td>\n",
              "<td>0.0059524</td>\n",
              "<td>0.9821429</td>\n",
              "<td>-94.0476190</td>\n",
              "<td>96.4285714</td>\n",
              "<td>0.7693769</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>0.6</td>\n",
              "<td>0.0601370</td>\n",
              "<td>0.1190476</td>\n",
              "<td>1.6567460</td>\n",
              "<td>0.0444444</td>\n",
              "<td>0.0681423</td>\n",
              "<td>0.6185185</td>\n",
              "<td>0.6015012</td>\n",
              "<td>0.0119048</td>\n",
              "<td>0.9940476</td>\n",
              "<td>-88.0952381</td>\n",
              "<td>65.6746032</td>\n",
              "<td>0.6287994</td></tr>\n",
              "<tr><td>8</td>\n",
              "<td>0.7088889</td>\n",
              "<td>0.0255055</td>\n",
              "<td>0.0546647</td>\n",
              "<td>1.4106583</td>\n",
              "<td>0.0204082</td>\n",
              "<td>0.0402448</td>\n",
              "<td>0.5266458</td>\n",
              "<td>0.5152894</td>\n",
              "<td>0.0059524</td>\n",
              "<td>1.0</td>\n",
              "<td>-94.5335277</td>\n",
              "<td>41.0658307</td>\n",
              "<td>0.4645390</td></tr>\n",
              "<tr><td>9</td>\n",
              "<td>0.8177778</td>\n",
              "<td>0.0171180</td>\n",
              "<td>0.0</td>\n",
              "<td>1.2228261</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0195770</td>\n",
              "<td>0.4565217</td>\n",
              "<td>0.4492842</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>22.2826087</td>\n",
              "<td>0.2907801</td></tr>\n",
              "<tr><td>10</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0141261</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0141261</td>\n",
              "<td>0.3733333</td>\n",
              "<td>0.3699887</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: xgboost\n",
              "** Reported on validation data. **\n",
              "\n",
              "MSE: 0.026133884441954087\n",
              "RMSE: 0.16165977991434383\n",
              "LogLoss: 0.11356345603286226\n",
              "Mean Per-Class Error: 0.024696969696969696\n",
              "AUC: 0.9974242424242425\n",
              "AUCPR: 0.9957667052093674\n",
              "Gini: 0.9948484848484851</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-33.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-33 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-33 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-33 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-33 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-33 .h2o-table th,\n",
              "#h2o-table-33 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-33 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-33\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.47318321466445923</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>B</th>\n",
              "<th>M</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>B</td>\n",
              "<td>73.0</td>\n",
              "<td>2.0</td>\n",
              "<td>0.0267</td>\n",
              "<td> (2.0/75.0)</td></tr>\n",
              "<tr><td>M</td>\n",
              "<td>1.0</td>\n",
              "<td>43.0</td>\n",
              "<td>0.0227</td>\n",
              "<td> (1.0/44.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>74.0</td>\n",
              "<td>45.0</td>\n",
              "<td>0.0252</td>\n",
              "<td> (3.0/119.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-34.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-34 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-34 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-34 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-34 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-34 .h2o-table th,\n",
              "#h2o-table-34 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-34 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-34\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.4731832</td>\n",
              "<td>0.9662921</td>\n",
              "<td>20.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.2915184</td>\n",
              "<td>0.9777778</td>\n",
              "<td>23.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.6153226</td>\n",
              "<td>0.9803922</td>\n",
              "<td>15.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.5094880</td>\n",
              "<td>0.9747899</td>\n",
              "<td>18.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>0.9756404</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.2915184</td>\n",
              "<td>1.0</td>\n",
              "<td>23.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>0.9756404</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.4731832</td>\n",
              "<td>0.9463144</td>\n",
              "<td>20.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.4731832</td>\n",
              "<td>0.9733333</td>\n",
              "<td>20.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.4731832</td>\n",
              "<td>0.9753030</td>\n",
              "<td>20.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>0.9756404</td>\n",
              "<td>75.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>0.9756404</td>\n",
              "<td>29.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0141261</td>\n",
              "<td>75.0</td>\n",
              "<td>61.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.2915184</td>\n",
              "<td>44.0</td>\n",
              "<td>23.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>0.9756404</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>0.9756404</td>\n",
              "<td>0.6590909</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0141261</td>\n",
              "<td>1.0</td>\n",
              "<td>61.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.2915184</td>\n",
              "<td>1.0</td>\n",
              "<td>23.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-35.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-35 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-35 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-35 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-35 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-35 .h2o-table th,\n",
              "#h2o-table-35 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-35 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-35\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 36.97 %, avg score: 37.32 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.1260504</td>\n",
              "<td>0.9756404</td>\n",
              "<td>2.7045455</td>\n",
              "<td>2.7045455</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9756404</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9756404</td>\n",
              "<td>0.3409091</td>\n",
              "<td>0.3409091</td>\n",
              "<td>170.4545455</td>\n",
              "<td>170.4545455</td>\n",
              "<td>0.3409091</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.1512605</td>\n",
              "<td>0.9476320</td>\n",
              "<td>2.7045455</td>\n",
              "<td>2.7045455</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9592851</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9729145</td>\n",
              "<td>0.0681818</td>\n",
              "<td>0.4090909</td>\n",
              "<td>170.4545455</td>\n",
              "<td>170.4545455</td>\n",
              "<td>0.4090909</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.2352941</td>\n",
              "<td>0.9262424</td>\n",
              "<td>2.7045455</td>\n",
              "<td>2.7045455</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9298264</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9575259</td>\n",
              "<td>0.2272727</td>\n",
              "<td>0.6363636</td>\n",
              "<td>170.4545455</td>\n",
              "<td>170.4545455</td>\n",
              "<td>0.6363636</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.3193277</td>\n",
              "<td>0.8112912</td>\n",
              "<td>2.7045455</td>\n",
              "<td>2.7045455</td>\n",
              "<td>1.0</td>\n",
              "<td>0.8651847</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9332256</td>\n",
              "<td>0.2272727</td>\n",
              "<td>0.8636364</td>\n",
              "<td>170.4545455</td>\n",
              "<td>170.4545455</td>\n",
              "<td>0.8636364</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.4117647</td>\n",
              "<td>0.2915184</td>\n",
              "<td>1.4752066</td>\n",
              "<td>2.4285714</td>\n",
              "<td>0.5454545</td>\n",
              "<td>0.4830952</td>\n",
              "<td>0.8979592</td>\n",
              "<td>0.8321759</td>\n",
              "<td>0.1363636</td>\n",
              "<td>1.0</td>\n",
              "<td>47.5206612</td>\n",
              "<td>142.8571429</td>\n",
              "<td>0.9333333</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.5042017</td>\n",
              "<td>0.0890782</td>\n",
              "<td>0.0</td>\n",
              "<td>1.9833333</td>\n",
              "<td>0.0</td>\n",
              "<td>0.1637983</td>\n",
              "<td>0.7333333</td>\n",
              "<td>0.7096400</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>98.3333333</td>\n",
              "<td>0.7866667</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>0.5966387</td>\n",
              "<td>0.0469845</td>\n",
              "<td>0.0</td>\n",
              "<td>1.6760563</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0708849</td>\n",
              "<td>0.6197183</td>\n",
              "<td>0.6106780</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>67.6056338</td>\n",
              "<td>0.64</td></tr>\n",
              "<tr><td>8</td>\n",
              "<td>0.6974790</td>\n",
              "<td>0.0275775</td>\n",
              "<td>0.0</td>\n",
              "<td>1.4337349</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0362935</td>\n",
              "<td>0.5301205</td>\n",
              "<td>0.5276344</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>43.3734940</td>\n",
              "<td>0.48</td></tr>\n",
              "<tr><td>9</td>\n",
              "<td>0.7983193</td>\n",
              "<td>0.0184387</td>\n",
              "<td>0.0</td>\n",
              "<td>1.2526316</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0209517</td>\n",
              "<td>0.4631579</td>\n",
              "<td>0.4636324</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>25.2631579</td>\n",
              "<td>0.3200000</td></tr>\n",
              "<tr><td>10</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0141261</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0153230</td>\n",
              "<td>0.3697479</td>\n",
              "<td>0.3732170</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: xgboost\n",
              "** Reported on cross-validation data. **\n",
              "\n",
              "MSE: 0.04456220211816163\n",
              "RMSE: 0.21109761277229458\n",
              "LogLoss: 0.16800715284467554\n",
              "Mean Per-Class Error: 0.05933383991894631\n",
              "AUC: 0.982364488348531\n",
              "AUCPR: 0.9779680523587579\n",
              "Gini: 0.9647289766970619</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-36.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-36 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-36 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-36 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-36 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-36 .h2o-table th,\n",
              "#h2o-table-36 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-36 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-36\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4053971767425537</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>B</th>\n",
              "<th>M</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>B</td>\n",
              "<td>267.0</td>\n",
              "<td>15.0</td>\n",
              "<td>0.0532</td>\n",
              "<td> (15.0/282.0)</td></tr>\n",
              "<tr><td>M</td>\n",
              "<td>11.0</td>\n",
              "<td>157.0</td>\n",
              "<td>0.0655</td>\n",
              "<td> (11.0/168.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>278.0</td>\n",
              "<td>172.0</td>\n",
              "<td>0.0578</td>\n",
              "<td> (26.0/450.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-37.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-37 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-37 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-37 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-37 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-37 .h2o-table th,\n",
              "#h2o-table-37 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-37 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-37\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.4053972</td>\n",
              "<td>0.9235294</td>\n",
              "<td>94.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.3462134</td>\n",
              "<td>0.9415205</td>\n",
              "<td>105.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.6928228</td>\n",
              "<td>0.9510870</td>\n",
              "<td>64.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.4053972</td>\n",
              "<td>0.9422222</td>\n",
              "<td>94.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>0.9726430</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0375161</td>\n",
              "<td>1.0</td>\n",
              "<td>217.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>0.9726430</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.4053972</td>\n",
              "<td>0.8772680</td>\n",
              "<td>94.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.3791416</td>\n",
              "<td>0.9361702</td>\n",
              "<td>98.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.4053972</td>\n",
              "<td>0.9406662</td>\n",
              "<td>94.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>0.9726430</td>\n",
              "<td>282.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>0.9726430</td>\n",
              "<td>160.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0176464</td>\n",
              "<td>282.0</td>\n",
              "<td>265.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0375161</td>\n",
              "<td>168.0</td>\n",
              "<td>217.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>0.9726430</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>0.9726430</td>\n",
              "<td>0.9523810</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0176464</td>\n",
              "<td>1.0</td>\n",
              "<td>265.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0375161</td>\n",
              "<td>1.0</td>\n",
              "<td>217.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-38.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-38 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-38 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-38 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-38 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-38 .h2o-table th,\n",
              "#h2o-table-38 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-38 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-38\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 37.33 %, avg score: 37.50 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.0177778</td>\n",
              "<td>0.9726430</td>\n",
              "<td>2.6785714</td>\n",
              "<td>2.6785714</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9726430</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9726430</td>\n",
              "<td>0.0476190</td>\n",
              "<td>0.0476190</td>\n",
              "<td>167.8571429</td>\n",
              "<td>167.8571429</td>\n",
              "<td>0.0476190</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.0333333</td>\n",
              "<td>0.9696493</td>\n",
              "<td>2.6785714</td>\n",
              "<td>2.6785714</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9696493</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9712459</td>\n",
              "<td>0.0416667</td>\n",
              "<td>0.0892857</td>\n",
              "<td>167.8571429</td>\n",
              "<td>167.8571429</td>\n",
              "<td>0.0892857</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.0488889</td>\n",
              "<td>0.9667782</td>\n",
              "<td>2.6785714</td>\n",
              "<td>2.6785714</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9671381</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9699389</td>\n",
              "<td>0.0416667</td>\n",
              "<td>0.1309524</td>\n",
              "<td>167.8571429</td>\n",
              "<td>167.8571429</td>\n",
              "<td>0.1309524</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.0666667</td>\n",
              "<td>0.9663531</td>\n",
              "<td>2.6785714</td>\n",
              "<td>2.6785714</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9663531</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9689827</td>\n",
              "<td>0.0476190</td>\n",
              "<td>0.1785714</td>\n",
              "<td>167.8571429</td>\n",
              "<td>167.8571429</td>\n",
              "<td>0.1785714</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.1022222</td>\n",
              "<td>0.9597611</td>\n",
              "<td>2.6785714</td>\n",
              "<td>2.6785714</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9619714</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9665440</td>\n",
              "<td>0.0952381</td>\n",
              "<td>0.2738095</td>\n",
              "<td>167.8571429</td>\n",
              "<td>167.8571429</td>\n",
              "<td>0.2738095</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.16</td>\n",
              "<td>0.9526056</td>\n",
              "<td>2.6785714</td>\n",
              "<td>2.6785714</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9555109</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9625598</td>\n",
              "<td>0.1547619</td>\n",
              "<td>0.4285714</td>\n",
              "<td>167.8571429</td>\n",
              "<td>167.8571429</td>\n",
              "<td>0.4285714</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>0.2</td>\n",
              "<td>0.9357066</td>\n",
              "<td>2.6785714</td>\n",
              "<td>2.6785714</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9441041</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9588687</td>\n",
              "<td>0.1071429</td>\n",
              "<td>0.5357143</td>\n",
              "<td>167.8571429</td>\n",
              "<td>167.8571429</td>\n",
              "<td>0.5357143</td></tr>\n",
              "<tr><td>8</td>\n",
              "<td>0.3</td>\n",
              "<td>0.7818707</td>\n",
              "<td>2.5595238</td>\n",
              "<td>2.6388889</td>\n",
              "<td>0.9555556</td>\n",
              "<td>0.9010030</td>\n",
              "<td>0.9851852</td>\n",
              "<td>0.9395801</td>\n",
              "<td>0.2559524</td>\n",
              "<td>0.7916667</td>\n",
              "<td>155.9523810</td>\n",
              "<td>163.8888889</td>\n",
              "<td>0.7845745</td></tr>\n",
              "<tr><td>9</td>\n",
              "<td>0.4</td>\n",
              "<td>0.3503399</td>\n",
              "<td>1.5476190</td>\n",
              "<td>2.3660714</td>\n",
              "<td>0.5777778</td>\n",
              "<td>0.5410498</td>\n",
              "<td>0.8833333</td>\n",
              "<td>0.8399475</td>\n",
              "<td>0.1547619</td>\n",
              "<td>0.9464286</td>\n",
              "<td>54.7619048</td>\n",
              "<td>136.6071429</td>\n",
              "<td>0.8719605</td></tr>\n",
              "<tr><td>10</td>\n",
              "<td>0.5</td>\n",
              "<td>0.0996270</td>\n",
              "<td>0.2976190</td>\n",
              "<td>1.9523810</td>\n",
              "<td>0.1111111</td>\n",
              "<td>0.1856441</td>\n",
              "<td>0.7288889</td>\n",
              "<td>0.7090868</td>\n",
              "<td>0.0297619</td>\n",
              "<td>0.9761905</td>\n",
              "<td>-70.2380952</td>\n",
              "<td>95.2380952</td>\n",
              "<td>0.7598784</td></tr>\n",
              "<tr><td>11</td>\n",
              "<td>0.6044444</td>\n",
              "<td>0.0597624</td>\n",
              "<td>0.1139818</td>\n",
              "<td>1.6347164</td>\n",
              "<td>0.0425532</td>\n",
              "<td>0.0731328</td>\n",
              "<td>0.6102941</td>\n",
              "<td>0.5991977</td>\n",
              "<td>0.0119048</td>\n",
              "<td>0.9880952</td>\n",
              "<td>-88.6018237</td>\n",
              "<td>63.4716387</td>\n",
              "<td>0.6122087</td></tr>\n",
              "<tr><td>12</td>\n",
              "<td>0.7</td>\n",
              "<td>0.0389057</td>\n",
              "<td>0.0</td>\n",
              "<td>1.4115646</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0484390</td>\n",
              "<td>0.5269841</td>\n",
              "<td>0.5240148</td>\n",
              "<td>0.0</td>\n",
              "<td>0.9880952</td>\n",
              "<td>-100.0</td>\n",
              "<td>41.1564626</td>\n",
              "<td>0.4597264</td></tr>\n",
              "<tr><td>13</td>\n",
              "<td>0.8022222</td>\n",
              "<td>0.0293830</td>\n",
              "<td>0.1164596</td>\n",
              "<td>1.2465374</td>\n",
              "<td>0.0434783</td>\n",
              "<td>0.0342120</td>\n",
              "<td>0.4653740</td>\n",
              "<td>0.4616022</td>\n",
              "<td>0.0119048</td>\n",
              "<td>1.0</td>\n",
              "<td>-88.3540373</td>\n",
              "<td>24.6537396</td>\n",
              "<td>0.3156028</td></tr>\n",
              "<tr><td>14</td>\n",
              "<td>0.9022222</td>\n",
              "<td>0.0243170</td>\n",
              "<td>0.0</td>\n",
              "<td>1.1083744</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0259154</td>\n",
              "<td>0.4137931</td>\n",
              "<td>0.4133118</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>10.8374384</td>\n",
              "<td>0.1560284</td></tr>\n",
              "<tr><td>15</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0176464</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0210691</td>\n",
              "<td>0.3733333</td>\n",
              "<td>0.3749592</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-39.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-39 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-39 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-39 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-39 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-39 .h2o-table th,\n",
              "#h2o-table-39 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-39 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-39\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Cross-Validation Metrics Summary: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>mean</th>\n",
              "<th>sd</th>\n",
              "<th>cv_1_valid</th>\n",
              "<th>cv_2_valid</th>\n",
              "<th>cv_3_valid</th>\n",
              "<th>cv_4_valid</th>\n",
              "<th>cv_5_valid</th>\n",
              "<th>cv_6_valid</th>\n",
              "<th>cv_7_valid</th>\n",
              "<th>cv_8_valid</th>\n",
              "<th>cv_9_valid</th>\n",
              "<th>cv_10_valid</th></tr></thead>\n",
              "    <tbody><tr><td>accuracy</td>\n",
              "<td>0.9644445</td>\n",
              "<td>0.0214687</td>\n",
              "<td>0.9555556</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9777778</td>\n",
              "<td>0.9333333</td>\n",
              "<td>0.9777778</td>\n",
              "<td>0.9555556</td>\n",
              "<td>0.9777778</td>\n",
              "<td>0.9333333</td>\n",
              "<td>0.9555556</td>\n",
              "<td>0.9777778</td></tr>\n",
              "<tr><td>auc</td>\n",
              "<td>0.9853345</td>\n",
              "<td>0.0191174</td>\n",
              "<td>0.9917695</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9979757</td>\n",
              "<td>0.936</td>\n",
              "<td>0.9822222</td>\n",
              "<td>0.9939271</td>\n",
              "<td>0.9938272</td>\n",
              "<td>0.9726721</td>\n",
              "<td>0.9892241</td>\n",
              "<td>0.9957265</td></tr>\n",
              "<tr><td>err</td>\n",
              "<td>0.0355556</td>\n",
              "<td>0.0214687</td>\n",
              "<td>0.0444444</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0222222</td>\n",
              "<td>0.0666667</td>\n",
              "<td>0.0222222</td>\n",
              "<td>0.0444444</td>\n",
              "<td>0.0222222</td>\n",
              "<td>0.0666667</td>\n",
              "<td>0.0444444</td>\n",
              "<td>0.0222222</td></tr>\n",
              "<tr><td>err_count</td>\n",
              "<td>1.6</td>\n",
              "<td>0.9660918</td>\n",
              "<td>2.0</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>3.0</td>\n",
              "<td>1.0</td>\n",
              "<td>2.0</td>\n",
              "<td>1.0</td>\n",
              "<td>3.0</td>\n",
              "<td>2.0</td>\n",
              "<td>1.0</td></tr>\n",
              "<tr><td>f0point5</td>\n",
              "<td>0.9435074</td>\n",
              "<td>0.0340338</td>\n",
              "<td>0.9183673</td>\n",
              "<td>1.0</td>\n",
              "<td>0.959596</td>\n",
              "<td>0.9375</td>\n",
              "<td>0.9859155</td>\n",
              "<td>0.9223301</td>\n",
              "<td>0.9574468</td>\n",
              "<td>0.9340659</td>\n",
              "<td>0.9375</td>\n",
              "<td>0.8823530</td></tr>\n",
              "<tr><td>f1</td>\n",
              "<td>0.9512790</td>\n",
              "<td>0.0267176</td>\n",
              "<td>0.9473684</td>\n",
              "<td>1.0</td>\n",
              "<td>0.974359</td>\n",
              "<td>0.9230769</td>\n",
              "<td>0.9655172</td>\n",
              "<td>0.95</td>\n",
              "<td>0.972973</td>\n",
              "<td>0.9189189</td>\n",
              "<td>0.9375</td>\n",
              "<td>0.9230769</td></tr>\n",
              "<tr><td>f2</td>\n",
              "<td>0.9600770</td>\n",
              "<td>0.0341382</td>\n",
              "<td>0.9782609</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9895833</td>\n",
              "<td>0.9090909</td>\n",
              "<td>0.9459459</td>\n",
              "<td>0.9793814</td>\n",
              "<td>0.989011</td>\n",
              "<td>0.9042553</td>\n",
              "<td>0.9375</td>\n",
              "<td>0.9677419</td></tr>\n",
              "<tr><td>lift_top_group</td>\n",
              "<td>3.0167763</td>\n",
              "<td>1.5913488</td>\n",
              "<td>2.5</td>\n",
              "<td>2.5</td>\n",
              "<td>2.368421</td>\n",
              "<td>2.25</td>\n",
              "<td>3.0</td>\n",
              "<td>2.368421</td>\n",
              "<td>2.5</td>\n",
              "<td>2.368421</td>\n",
              "<td>2.8125</td>\n",
              "<td>7.5</td></tr>\n",
              "<tr><td>logloss</td>\n",
              "<td>0.1680071</td>\n",
              "<td>0.0536355</td>\n",
              "<td>0.1412243</td>\n",
              "<td>0.1094058</td>\n",
              "<td>0.1408426</td>\n",
              "<td>0.2874768</td>\n",
              "<td>0.1699757</td>\n",
              "<td>0.1657380</td>\n",
              "<td>0.1638442</td>\n",
              "<td>0.2123703</td>\n",
              "<td>0.1872467</td>\n",
              "<td>0.1019470</td></tr>\n",
              "<tr><td>max_per_class_error</td>\n",
              "<td>0.0586567</td>\n",
              "<td>0.0332292</td>\n",
              "<td>0.0740741</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0384615</td>\n",
              "<td>0.1</td>\n",
              "<td>0.0666667</td>\n",
              "<td>0.0769231</td>\n",
              "<td>0.0370370</td>\n",
              "<td>0.1052632</td>\n",
              "<td>0.0625</td>\n",
              "<td>0.0256410</td></tr>\n",
              "<tr><td>mcc</td>\n",
              "<td>0.9233404</td>\n",
              "<td>0.0426305</td>\n",
              "<td>0.9128709</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9557518</td>\n",
              "<td>0.8652069</td>\n",
              "<td>0.9503819</td>\n",
              "<td>0.9138736</td>\n",
              "<td>0.9551339</td>\n",
              "<td>0.8632941</td>\n",
              "<td>0.9030172</td>\n",
              "<td>0.9138736</td></tr>\n",
              "<tr><td>mean_per_class_accuracy</td>\n",
              "<td>0.9650245</td>\n",
              "<td>0.0236220</td>\n",
              "<td>0.962963</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9807692</td>\n",
              "<td>0.93</td>\n",
              "<td>0.9666666</td>\n",
              "<td>0.9615384</td>\n",
              "<td>0.9814815</td>\n",
              "<td>0.9281377</td>\n",
              "<td>0.9515086</td>\n",
              "<td>0.9871795</td></tr>\n",
              "<tr><td>mean_per_class_error</td>\n",
              "<td>0.0349755</td>\n",
              "<td>0.0236220</td>\n",
              "<td>0.0370370</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0192308</td>\n",
              "<td>0.07</td>\n",
              "<td>0.0333333</td>\n",
              "<td>0.0384615</td>\n",
              "<td>0.0185185</td>\n",
              "<td>0.0718624</td>\n",
              "<td>0.0484914</td>\n",
              "<td>0.0128205</td></tr>\n",
              "<tr><td>mse</td>\n",
              "<td>0.0445622</td>\n",
              "<td>0.0161211</td>\n",
              "<td>0.0372620</td>\n",
              "<td>0.0255396</td>\n",
              "<td>0.0351779</td>\n",
              "<td>0.0772335</td>\n",
              "<td>0.0445828</td>\n",
              "<td>0.0448035</td>\n",
              "<td>0.0417654</td>\n",
              "<td>0.0617108</td>\n",
              "<td>0.0529047</td>\n",
              "<td>0.0246418</td></tr>\n",
              "<tr><td>pr_auc</td>\n",
              "<td>0.9817832</td>\n",
              "<td>0.0155081</td>\n",
              "<td>0.9882933</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9973003</td>\n",
              "<td>0.9481173</td>\n",
              "<td>0.9762924</td>\n",
              "<td>0.9920185</td>\n",
              "<td>0.9904528</td>\n",
              "<td>0.9695324</td>\n",
              "<td>0.9815167</td>\n",
              "<td>0.9743082</td></tr>\n",
              "<tr><td>precision</td>\n",
              "<td>0.9388586</td>\n",
              "<td>0.0436254</td>\n",
              "<td>0.9</td>\n",
              "<td>1.0</td>\n",
              "<td>0.95</td>\n",
              "<td>0.9473684</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9047619</td>\n",
              "<td>0.9473684</td>\n",
              "<td>0.9444444</td>\n",
              "<td>0.9375</td>\n",
              "<td>0.8571429</td></tr>\n",
              "<tr><td>r2</td>\n",
              "<td>0.8025928</td>\n",
              "<td>0.0590727</td>\n",
              "<td>0.8447416</td>\n",
              "<td>0.8935852</td>\n",
              "<td>0.8557991</td>\n",
              "<td>0.6872043</td>\n",
              "<td>0.7993774</td>\n",
              "<td>0.816342</td>\n",
              "<td>0.8259773</td>\n",
              "<td>0.7470357</td>\n",
              "<td>0.7691118</td>\n",
              "<td>0.7867540</td></tr>\n",
              "<tr><td>recall</td>\n",
              "<td>0.966557</td>\n",
              "<td>0.0450268</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9</td>\n",
              "<td>0.9333333</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.8947368</td>\n",
              "<td>0.9375</td>\n",
              "<td>1.0</td></tr>\n",
              "<tr><td>rmse</td>\n",
              "<td>0.2080896</td>\n",
              "<td>0.0374301</td>\n",
              "<td>0.1930337</td>\n",
              "<td>0.1598110</td>\n",
              "<td>0.1875577</td>\n",
              "<td>0.2779092</td>\n",
              "<td>0.2111464</td>\n",
              "<td>0.2116683</td>\n",
              "<td>0.2043660</td>\n",
              "<td>0.2484166</td>\n",
              "<td>0.2300103</td>\n",
              "<td>0.1569770</td></tr>\n",
              "<tr><td>specificity</td>\n",
              "<td>0.9634919</td>\n",
              "<td>0.0255007</td>\n",
              "<td>0.9259259</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9615384</td>\n",
              "<td>0.96</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9230769</td>\n",
              "<td>0.962963</td>\n",
              "<td>0.9615384</td>\n",
              "<td>0.9655172</td>\n",
              "<td>0.974359</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-40.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-40 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-40 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-40 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-40 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-40 .h2o-table th,\n",
              "#h2o-table-40 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-40 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-40\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Scoring History: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>timestamp</th>\n",
              "<th>duration</th>\n",
              "<th>number_of_trees</th>\n",
              "<th>training_rmse</th>\n",
              "<th>training_logloss</th>\n",
              "<th>training_auc</th>\n",
              "<th>training_pr_auc</th>\n",
              "<th>training_lift</th>\n",
              "<th>training_classification_error</th>\n",
              "<th>validation_rmse</th>\n",
              "<th>validation_logloss</th>\n",
              "<th>validation_auc</th>\n",
              "<th>validation_pr_auc</th>\n",
              "<th>validation_lift</th>\n",
              "<th>validation_classification_error</th></tr></thead>\n",
              "    <tbody><tr><td></td>\n",
              "<td>2023-06-21 21:45:29</td>\n",
              "<td> 4.870 sec</td>\n",
              "<td>0.0</td>\n",
              "<td>0.5</td>\n",
              "<td>0.6931472</td>\n",
              "<td>0.5</td>\n",
              "<td>0.3733333</td>\n",
              "<td>1.0</td>\n",
              "<td>0.6266667</td>\n",
              "<td>0.5</td>\n",
              "<td>0.6931472</td>\n",
              "<td>0.5</td>\n",
              "<td>0.3697479</td>\n",
              "<td>1.0</td>\n",
              "<td>0.6302521</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 21:45:29</td>\n",
              "<td> 4.897 sec</td>\n",
              "<td>5.0</td>\n",
              "<td>0.2296900</td>\n",
              "<td>0.2266673</td>\n",
              "<td>0.9869343</td>\n",
              "<td>0.9821729</td>\n",
              "<td>2.6785714</td>\n",
              "<td>0.0555556</td>\n",
              "<td>0.2369959</td>\n",
              "<td>0.2357856</td>\n",
              "<td>0.9889394</td>\n",
              "<td>0.9806550</td>\n",
              "<td>2.7045455</td>\n",
              "<td>0.0504202</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 21:45:29</td>\n",
              "<td> 4.921 sec</td>\n",
              "<td>10.0</td>\n",
              "<td>0.1838817</td>\n",
              "<td>0.1437128</td>\n",
              "<td>0.9923168</td>\n",
              "<td>0.9896504</td>\n",
              "<td>2.6785714</td>\n",
              "<td>0.0333333</td>\n",
              "<td>0.1944354</td>\n",
              "<td>0.1526950</td>\n",
              "<td>0.9919697</td>\n",
              "<td>0.9864338</td>\n",
              "<td>2.7045455</td>\n",
              "<td>0.0420168</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 21:45:29</td>\n",
              "<td> 4.938 sec</td>\n",
              "<td>15.0</td>\n",
              "<td>0.1766573</td>\n",
              "<td>0.1318257</td>\n",
              "<td>0.9918313</td>\n",
              "<td>0.9896319</td>\n",
              "<td>2.6785714</td>\n",
              "<td>0.0311111</td>\n",
              "<td>0.1798334</td>\n",
              "<td>0.1337698</td>\n",
              "<td>0.995</td>\n",
              "<td>0.9918816</td>\n",
              "<td>2.7045455</td>\n",
              "<td>0.0336134</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 21:45:29</td>\n",
              "<td> 4.960 sec</td>\n",
              "<td>20.0</td>\n",
              "<td>0.1730721</td>\n",
              "<td>0.1278360</td>\n",
              "<td>0.9915147</td>\n",
              "<td>0.9897823</td>\n",
              "<td>2.6785714</td>\n",
              "<td>0.0311111</td>\n",
              "<td>0.1727378</td>\n",
              "<td>0.1262197</td>\n",
              "<td>0.9965152</td>\n",
              "<td>0.9941734</td>\n",
              "<td>2.7045455</td>\n",
              "<td>0.0252101</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 21:45:29</td>\n",
              "<td> 4.988 sec</td>\n",
              "<td>25.0</td>\n",
              "<td>0.1727234</td>\n",
              "<td>0.1277058</td>\n",
              "<td>0.9915147</td>\n",
              "<td>0.9897823</td>\n",
              "<td>2.6785714</td>\n",
              "<td>0.0311111</td>\n",
              "<td>0.1726003</td>\n",
              "<td>0.1263937</td>\n",
              "<td>0.9965152</td>\n",
              "<td>0.9941734</td>\n",
              "<td>2.7045455</td>\n",
              "<td>0.0252101</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 21:45:30</td>\n",
              "<td> 5.026 sec</td>\n",
              "<td>30.0</td>\n",
              "<td>0.1727376</td>\n",
              "<td>0.1277083</td>\n",
              "<td>0.9915147</td>\n",
              "<td>0.9897823</td>\n",
              "<td>2.6785714</td>\n",
              "<td>0.0311111</td>\n",
              "<td>0.1726023</td>\n",
              "<td>0.1263794</td>\n",
              "<td>0.9965152</td>\n",
              "<td>0.9941734</td>\n",
              "<td>2.7045455</td>\n",
              "<td>0.0252101</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 21:45:30</td>\n",
              "<td> 5.051 sec</td>\n",
              "<td>35.0</td>\n",
              "<td>0.1732714</td>\n",
              "<td>0.1279432</td>\n",
              "<td>0.9915147</td>\n",
              "<td>0.9897823</td>\n",
              "<td>2.6785714</td>\n",
              "<td>0.0311111</td>\n",
              "<td>0.1728585</td>\n",
              "<td>0.1262045</td>\n",
              "<td>0.9965152</td>\n",
              "<td>0.9941734</td>\n",
              "<td>2.7045455</td>\n",
              "<td>0.0252101</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 21:45:30</td>\n",
              "<td> 5.080 sec</td>\n",
              "<td>40.0</td>\n",
              "<td>0.1705924</td>\n",
              "<td>0.1223583</td>\n",
              "<td>0.9911136</td>\n",
              "<td>0.9893981</td>\n",
              "<td>2.6785714</td>\n",
              "<td>0.0311111</td>\n",
              "<td>0.1616518</td>\n",
              "<td>0.1136228</td>\n",
              "<td>0.9974242</td>\n",
              "<td>0.9957667</td>\n",
              "<td>2.7045455</td>\n",
              "<td>0.0252101</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 21:45:30</td>\n",
              "<td> 5.111 sec</td>\n",
              "<td>44.0</td>\n",
              "<td>0.1706755</td>\n",
              "<td>0.1224014</td>\n",
              "<td>0.9911136</td>\n",
              "<td>0.9893981</td>\n",
              "<td>2.6785714</td>\n",
              "<td>0.0311111</td>\n",
              "<td>0.1616598</td>\n",
              "<td>0.1135635</td>\n",
              "<td>0.9974242</td>\n",
              "<td>0.9957667</td>\n",
              "<td>2.7045455</td>\n",
              "<td>0.0252101</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-41.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-41 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-41 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-41 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-41 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-41 .h2o-table th,\n",
              "#h2o-table-41 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-41 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-41\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Variable Importances: </caption>\n",
              "    <thead><tr><th>variable</th>\n",
              "<th>relative_importance</th>\n",
              "<th>scaled_importance</th>\n",
              "<th>percentage</th></tr></thead>\n",
              "    <tbody><tr><td>perimeter_worst</td>\n",
              "<td>335.8549194</td>\n",
              "<td>1.0</td>\n",
              "<td>0.5591635</td></tr>\n",
              "<tr><td>concave points_worst</td>\n",
              "<td>156.8416138</td>\n",
              "<td>0.4669922</td>\n",
              "<td>0.2611250</td></tr>\n",
              "<tr><td>concave points_mean</td>\n",
              "<td>25.2143497</td>\n",
              "<td>0.0750751</td>\n",
              "<td>0.0419793</td></tr>\n",
              "<tr><td>texture_worst</td>\n",
              "<td>23.8097916</td>\n",
              "<td>0.0708931</td>\n",
              "<td>0.0396408</td></tr>\n",
              "<tr><td>area_worst</td>\n",
              "<td>17.7388382</td>\n",
              "<td>0.0528170</td>\n",
              "<td>0.0295333</td></tr>\n",
              "<tr><td>area_se</td>\n",
              "<td>17.3529110</td>\n",
              "<td>0.0516679</td>\n",
              "<td>0.0288908</td></tr>\n",
              "<tr><td>texture_mean</td>\n",
              "<td>12.4470520</td>\n",
              "<td>0.0370608</td>\n",
              "<td>0.0207230</td></tr>\n",
              "<tr><td>concavity_mean</td>\n",
              "<td>7.0855765</td>\n",
              "<td>0.0210971</td>\n",
              "<td>0.0117967</td></tr>\n",
              "<tr><td>radius_se</td>\n",
              "<td>4.2931023</td>\n",
              "<td>0.0127826</td>\n",
              "<td>0.0071476</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
              "\n",
              "[tips]\n",
              "Use `model.explain()` to inspect the model.\n",
              "--\n",
              "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
            ]
          },
          "metadata": {},
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lb = aml.leaderboard\n",
        "lb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "gmCXw_D_4y1D",
        "outputId": "e2cb614d-704c-493c-be8c-cb470e4ac370"
      },
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model_id                                                accuracy       auc    logloss     aucpr    mean_per_class_error      rmse        mse\n",
              "----------------------------------------------------  ----------  --------  ---------  --------  ----------------------  --------  ---------\n",
              "XGBoost_1_AutoML_2_20230621_214524                      0.942222  0.982364  0.168007   0.977968               0.0593338  0.211098  0.0445622\n",
              "XRT_1_AutoML_2_20230621_214524                          0.953333  0.986132  0.19872    0.983085               0.0480623  0.195467  0.0382072\n",
              "DRF_1_AutoML_2_20230621_214524                          0.955556  0.984845  0.262059   0.982697               0.0462893  0.191936  0.0368395\n",
              "GBM_1_AutoML_2_20230621_214524                          0.955556  0.98913   0.123639   0.985234               0.0571175  0.188424  0.0355036\n",
              "GBM_3_AutoML_2_20230621_214524                          0.957778  0.989847  0.126098   0.985796               0.0469225  0.18951   0.0359142\n",
              "GBM_2_AutoML_2_20230621_214524                          0.96      0.988285  0.12614    0.985199               0.0475557  0.186837  0.034908\n",
              "XGBoost_3_AutoML_2_20230621_214524                      0.962222  0.984665  0.126896   0.983236               0.0409701  0.17997   0.0323891\n",
              "GBM_4_AutoML_2_20230621_214524                          0.964444  0.991451  0.114397   0.98824                0.0440096  0.177731  0.0315885\n",
              "XGBoost_2_AutoML_2_20230621_214524                      0.964444  0.9878    0.123176   0.985575               0.0416033  0.182435  0.0332825\n",
              "StackedEnsemble_AllModels_1_AutoML_2_20230621_214524    0.973333  0.991198  0.0933805  0.990267               0.0272923  0.154152  0.0237627\n",
              "[12 rows x 8 columns]\n"
            ],
            "text/html": [
              "<table class='dataframe'>\n",
              "<thead>\n",
              "<tr><th>model_id                                            </th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">      mse</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>XGBoost_1_AutoML_2_20230621_214524                  </td><td style=\"text-align: right;\">  0.942222</td><td style=\"text-align: right;\">0.982364</td><td style=\"text-align: right;\">0.168007 </td><td style=\"text-align: right;\">0.977968</td><td style=\"text-align: right;\">             0.0593338</td><td style=\"text-align: right;\">0.211098</td><td style=\"text-align: right;\">0.0445622</td></tr>\n",
              "<tr><td>XRT_1_AutoML_2_20230621_214524                      </td><td style=\"text-align: right;\">  0.953333</td><td style=\"text-align: right;\">0.986132</td><td style=\"text-align: right;\">0.19872  </td><td style=\"text-align: right;\">0.983085</td><td style=\"text-align: right;\">             0.0480623</td><td style=\"text-align: right;\">0.195467</td><td style=\"text-align: right;\">0.0382072</td></tr>\n",
              "<tr><td>DRF_1_AutoML_2_20230621_214524                      </td><td style=\"text-align: right;\">  0.955556</td><td style=\"text-align: right;\">0.984845</td><td style=\"text-align: right;\">0.262059 </td><td style=\"text-align: right;\">0.982697</td><td style=\"text-align: right;\">             0.0462893</td><td style=\"text-align: right;\">0.191936</td><td style=\"text-align: right;\">0.0368395</td></tr>\n",
              "<tr><td>GBM_1_AutoML_2_20230621_214524                      </td><td style=\"text-align: right;\">  0.955556</td><td style=\"text-align: right;\">0.98913 </td><td style=\"text-align: right;\">0.123639 </td><td style=\"text-align: right;\">0.985234</td><td style=\"text-align: right;\">             0.0571175</td><td style=\"text-align: right;\">0.188424</td><td style=\"text-align: right;\">0.0355036</td></tr>\n",
              "<tr><td>GBM_3_AutoML_2_20230621_214524                      </td><td style=\"text-align: right;\">  0.957778</td><td style=\"text-align: right;\">0.989847</td><td style=\"text-align: right;\">0.126098 </td><td style=\"text-align: right;\">0.985796</td><td style=\"text-align: right;\">             0.0469225</td><td style=\"text-align: right;\">0.18951 </td><td style=\"text-align: right;\">0.0359142</td></tr>\n",
              "<tr><td>GBM_2_AutoML_2_20230621_214524                      </td><td style=\"text-align: right;\">  0.96    </td><td style=\"text-align: right;\">0.988285</td><td style=\"text-align: right;\">0.12614  </td><td style=\"text-align: right;\">0.985199</td><td style=\"text-align: right;\">             0.0475557</td><td style=\"text-align: right;\">0.186837</td><td style=\"text-align: right;\">0.034908 </td></tr>\n",
              "<tr><td>XGBoost_3_AutoML_2_20230621_214524                  </td><td style=\"text-align: right;\">  0.962222</td><td style=\"text-align: right;\">0.984665</td><td style=\"text-align: right;\">0.126896 </td><td style=\"text-align: right;\">0.983236</td><td style=\"text-align: right;\">             0.0409701</td><td style=\"text-align: right;\">0.17997 </td><td style=\"text-align: right;\">0.0323891</td></tr>\n",
              "<tr><td>GBM_4_AutoML_2_20230621_214524                      </td><td style=\"text-align: right;\">  0.964444</td><td style=\"text-align: right;\">0.991451</td><td style=\"text-align: right;\">0.114397 </td><td style=\"text-align: right;\">0.98824 </td><td style=\"text-align: right;\">             0.0440096</td><td style=\"text-align: right;\">0.177731</td><td style=\"text-align: right;\">0.0315885</td></tr>\n",
              "<tr><td>XGBoost_2_AutoML_2_20230621_214524                  </td><td style=\"text-align: right;\">  0.964444</td><td style=\"text-align: right;\">0.9878  </td><td style=\"text-align: right;\">0.123176 </td><td style=\"text-align: right;\">0.985575</td><td style=\"text-align: right;\">             0.0416033</td><td style=\"text-align: right;\">0.182435</td><td style=\"text-align: right;\">0.0332825</td></tr>\n",
              "<tr><td>StackedEnsemble_AllModels_1_AutoML_2_20230621_214524</td><td style=\"text-align: right;\">  0.973333</td><td style=\"text-align: right;\">0.991198</td><td style=\"text-align: right;\">0.0933805</td><td style=\"text-align: right;\">0.990267</td><td style=\"text-align: right;\">             0.0272923</td><td style=\"text-align: right;\">0.154152</td><td style=\"text-align: right;\">0.0237627</td></tr>\n",
              "</tbody>\n",
              "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[12 rows x 8 columns]</pre>"
            ]
          },
          "metadata": {},
          "execution_count": 275
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = aml.get_best_model()\n",
        "best_model"
      ],
      "metadata": {
        "id": "vlH8zwtisQU1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "547bf823-95f9-4cd7-cf47-26f91ea85cca"
      },
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model Details\n",
              "=============\n",
              "H2OXGBoostEstimator : XGBoost\n",
              "Model Key: XGBoost_1_AutoML_2_20230621_214524\n",
              "\n",
              "\n",
              "Model Summary: \n",
              "    number_of_trees\n",
              "--  -----------------\n",
              "    44\n",
              "\n",
              "ModelMetricsBinomial: xgboost\n",
              "** Reported on train data. **\n",
              "\n",
              "MSE: 0.029130112207480154\n",
              "RMSE: 0.17067545871472017\n",
              "LogLoss: 0.12240138558277379\n",
              "Mean Per-Class Error: 0.03565096251266464\n",
              "AUC: 0.9911136440391759\n",
              "AUCPR: 0.989398055584699\n",
              "Gini: 0.9822272880783518\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4297827184200287\n",
              "       B    M    Error    Rate\n",
              "-----  ---  ---  -------  ------------\n",
              "B      277  5    0.0177   (5.0/282.0)\n",
              "M      9    159  0.0536   (9.0/168.0)\n",
              "Total  286  164  0.0311   (14.0/450.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.429783     0.957831  47\n",
              "max f2                       0.292471     0.963572  59\n",
              "max f0point5                 0.574773     0.977157  40\n",
              "max accuracy                 0.516256     0.968889  45\n",
              "max precision                0.97564      1         0\n",
              "max recall                   0.0439371    1         113\n",
              "max specificity              0.97564      1         0\n",
              "max absolute_mcc             0.516256     0.933412  45\n",
              "max min_per_class_accuracy   0.349176     0.960993  53\n",
              "max mean_per_class_accuracy  0.341069     0.965616  54\n",
              "max tns                      0.97564      282       0\n",
              "max fns                      0.97564      107       0\n",
              "max fps                      0.0141261    282       139\n",
              "max tps                      0.0439371    168       113\n",
              "max tnr                      0.97564      1         0\n",
              "max fnr                      0.97564      0.636905  0\n",
              "max fpr                      0.0141261    1         139\n",
              "max tpr                      0.0439371    1         113\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 37.33 %, avg score: 37.00 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.135556                    0.97564            2.67857    2.67857            1                0.97564    1                           0.97564             0.363095        0.363095                   167.857   167.857            0.363095\n",
              "2        0.155556                    0.965855           2.67857    2.67857            1                0.965936   1                           0.974393            0.0535714       0.416667                   167.857   167.857            0.416667\n",
              "3        0.202222                    0.949678           2.67857    2.67857            1                0.959372   1                           0.970926            0.125           0.541667                   167.857   167.857            0.541667\n",
              "4        0.3                         0.815279           2.67857    2.67857            1                0.915144   1                           0.952745            0.261905        0.803571                   167.857   167.857            0.803571\n",
              "5        0.4                         0.276934           1.72619    2.44048            0.644444         0.54826    0.911111                    0.851624            0.172619        0.97619                    72.619    144.048            0.919453\n",
              "6        0.5                         0.0818321          0.0595238  1.96429            0.0222222        0.134368   0.733333                    0.708173            0.00595238      0.982143                   -94.0476  96.4286            0.769377\n",
              "7        0.6                         0.060137           0.119048   1.65675            0.0444444        0.0681423  0.618519                    0.601501            0.0119048       0.994048                   -88.0952  65.6746            0.628799\n",
              "8        0.708889                    0.0255055          0.0546647  1.41066            0.0204082        0.0402448  0.526646                    0.515289            0.00595238      1                          -94.5335  41.0658            0.464539\n",
              "9        0.817778                    0.017118           0          1.22283            0                0.019577   0.456522                    0.449284            0               1                          -100      22.2826            0.29078\n",
              "10       1                           0.0141261          0          1                  0                0.0141261  0.373333                    0.369989            0               1                          -100      0                  0\n",
              "\n",
              "ModelMetricsBinomial: xgboost\n",
              "** Reported on validation data. **\n",
              "\n",
              "MSE: 0.026133884441954087\n",
              "RMSE: 0.16165977991434383\n",
              "LogLoss: 0.11356345603286226\n",
              "Mean Per-Class Error: 0.024696969696969696\n",
              "AUC: 0.9974242424242425\n",
              "AUCPR: 0.9957667052093674\n",
              "Gini: 0.9948484848484851\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.47318321466445923\n",
              "       B    M    Error    Rate\n",
              "-----  ---  ---  -------  -----------\n",
              "B      73   2    0.0267   (2.0/75.0)\n",
              "M      1    43   0.0227   (1.0/44.0)\n",
              "Total  74   45   0.0252   (3.0/119.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.473183     0.966292  20\n",
              "max f2                       0.291518     0.977778  23\n",
              "max f0point5                 0.615323     0.980392  15\n",
              "max accuracy                 0.509488     0.97479   18\n",
              "max precision                0.97564      1         0\n",
              "max recall                   0.291518     1         23\n",
              "max specificity              0.97564      1         0\n",
              "max absolute_mcc             0.473183     0.946314  20\n",
              "max min_per_class_accuracy   0.473183     0.973333  20\n",
              "max mean_per_class_accuracy  0.473183     0.975303  20\n",
              "max tns                      0.97564      75        0\n",
              "max fns                      0.97564      29        0\n",
              "max fps                      0.0141261    75        61\n",
              "max tps                      0.291518     44        23\n",
              "max tnr                      0.97564      1         0\n",
              "max fnr                      0.97564      0.659091  0\n",
              "max fpr                      0.0141261    1         61\n",
              "max tpr                      0.291518     1         23\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 36.97 %, avg score: 37.32 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  -------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------\n",
              "1        0.12605                     0.97564            2.70455  2.70455            1                0.97564    1                           0.97564             0.340909        0.340909                   170.455  170.455            0.340909\n",
              "2        0.151261                    0.947632           2.70455  2.70455            1                0.959285   1                           0.972915            0.0681818       0.409091                   170.455  170.455            0.409091\n",
              "3        0.235294                    0.926242           2.70455  2.70455            1                0.929826   1                           0.957526            0.227273        0.636364                   170.455  170.455            0.636364\n",
              "4        0.319328                    0.811291           2.70455  2.70455            1                0.865185   1                           0.933226            0.227273        0.863636                   170.455  170.455            0.863636\n",
              "5        0.411765                    0.291518           1.47521  2.42857            0.545455         0.483095   0.897959                    0.832176            0.136364        1                          47.5207  142.857            0.933333\n",
              "6        0.504202                    0.0890782          0        1.98333            0                0.163798   0.733333                    0.70964             0               1                          -100     98.3333            0.786667\n",
              "7        0.596639                    0.0469845          0        1.67606            0                0.0708849  0.619718                    0.610678            0               1                          -100     67.6056            0.64\n",
              "8        0.697479                    0.0275775          0        1.43373            0                0.0362935  0.53012                     0.527634            0               1                          -100     43.3735            0.48\n",
              "9        0.798319                    0.0184387          0        1.25263            0                0.0209517  0.463158                    0.463632            0               1                          -100     25.2632            0.32\n",
              "10       1                           0.0141261          0        1                  0                0.015323   0.369748                    0.373217            0               1                          -100     0                  0\n",
              "\n",
              "ModelMetricsBinomial: xgboost\n",
              "** Reported on cross-validation data. **\n",
              "\n",
              "MSE: 0.04456220211816163\n",
              "RMSE: 0.21109761277229458\n",
              "LogLoss: 0.16800715284467554\n",
              "Mean Per-Class Error: 0.05933383991894631\n",
              "AUC: 0.982364488348531\n",
              "AUCPR: 0.9779680523587579\n",
              "Gini: 0.9647289766970619\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4053971767425537\n",
              "       B    M    Error    Rate\n",
              "-----  ---  ---  -------  ------------\n",
              "B      267  15   0.0532   (15.0/282.0)\n",
              "M      11   157  0.0655   (11.0/168.0)\n",
              "Total  278  172  0.0578   (26.0/450.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.405397     0.923529  94\n",
              "max f2                       0.346213     0.94152   105\n",
              "max f0point5                 0.692823     0.951087  64\n",
              "max accuracy                 0.405397     0.942222  94\n",
              "max precision                0.972643     1         0\n",
              "max recall                   0.0375161    1         217\n",
              "max specificity              0.972643     1         0\n",
              "max absolute_mcc             0.405397     0.877268  94\n",
              "max min_per_class_accuracy   0.379142     0.93617   98\n",
              "max mean_per_class_accuracy  0.405397     0.940666  94\n",
              "max tns                      0.972643     282       0\n",
              "max fns                      0.972643     160       0\n",
              "max fps                      0.0176464    282       265\n",
              "max tps                      0.0375161    168       217\n",
              "max tnr                      0.972643     1         0\n",
              "max fnr                      0.972643     0.952381  0\n",
              "max fpr                      0.0176464    1         265\n",
              "max tpr                      0.0375161    1         217\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 37.33 %, avg score: 37.50 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  --------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.0177778                   0.972643           2.67857   2.67857            1                0.972643   1                           0.972643            0.047619        0.047619                   167.857   167.857            0.047619\n",
              "2        0.0333333                   0.969649           2.67857   2.67857            1                0.969649   1                           0.971246            0.0416667       0.0892857                  167.857   167.857            0.0892857\n",
              "3        0.0488889                   0.966778           2.67857   2.67857            1                0.967138   1                           0.969939            0.0416667       0.130952                   167.857   167.857            0.130952\n",
              "4        0.0666667                   0.966353           2.67857   2.67857            1                0.966353   1                           0.968983            0.047619        0.178571                   167.857   167.857            0.178571\n",
              "5        0.102222                    0.959761           2.67857   2.67857            1                0.961971   1                           0.966544            0.0952381       0.27381                    167.857   167.857            0.27381\n",
              "6        0.16                        0.952606           2.67857   2.67857            1                0.955511   1                           0.96256             0.154762        0.428571                   167.857   167.857            0.428571\n",
              "7        0.2                         0.935707           2.67857   2.67857            1                0.944104   1                           0.958869            0.107143        0.535714                   167.857   167.857            0.535714\n",
              "8        0.3                         0.781871           2.55952   2.63889            0.955556         0.901003   0.985185                    0.93958             0.255952        0.791667                   155.952   163.889            0.784574\n",
              "9        0.4                         0.35034            1.54762   2.36607            0.577778         0.54105    0.883333                    0.839948            0.154762        0.946429                   54.7619   136.607            0.87196\n",
              "10       0.5                         0.099627           0.297619  1.95238            0.111111         0.185644   0.728889                    0.709087            0.0297619       0.97619                    -70.2381  95.2381            0.759878\n",
              "11       0.604444                    0.0597624          0.113982  1.63472            0.0425532        0.0731328  0.610294                    0.599198            0.0119048       0.988095                   -88.6018  63.4716            0.612209\n",
              "12       0.7                         0.0389057          0         1.41156            0                0.048439   0.526984                    0.524015            0               0.988095                   -100      41.1565            0.459726\n",
              "13       0.802222                    0.029383           0.11646   1.24654            0.0434783        0.034212   0.465374                    0.461602            0.0119048       1                          -88.354   24.6537            0.315603\n",
              "14       0.902222                    0.024317           0         1.10837            0                0.0259154  0.413793                    0.413312            0               1                          -100      10.8374            0.156028\n",
              "15       1                           0.0176464          0         1                  0                0.0210691  0.373333                    0.374959            0               1                          -100      0                  0\n",
              "\n",
              "Cross-Validation Metrics Summary: \n",
              "                         mean       sd         cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid    cv_6_valid    cv_7_valid    cv_8_valid    cv_9_valid    cv_10_valid\n",
              "-----------------------  ---------  ---------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  -------------\n",
              "accuracy                 0.964444   0.0214687  0.955556      1             0.977778      0.933333      0.977778      0.955556      0.977778      0.933333      0.955556      0.977778\n",
              "auc                      0.985334   0.0191174  0.99177       1             0.997976      0.936         0.982222      0.993927      0.993827      0.972672      0.989224      0.995726\n",
              "err                      0.0355556  0.0214687  0.0444444     0             0.0222222     0.0666667     0.0222222     0.0444444     0.0222222     0.0666667     0.0444444     0.0222222\n",
              "err_count                1.6        0.966092   2             0             1             3             1             2             1             3             2             1\n",
              "f0point5                 0.943507   0.0340338  0.918367      1             0.959596      0.9375        0.985915      0.92233       0.957447      0.934066      0.9375        0.882353\n",
              "f1                       0.951279   0.0267176  0.947368      1             0.974359      0.923077      0.965517      0.95          0.972973      0.918919      0.9375        0.923077\n",
              "f2                       0.960077   0.0341382  0.978261      1             0.989583      0.909091      0.945946      0.979381      0.989011      0.904255      0.9375        0.967742\n",
              "lift_top_group           3.01678    1.59135    2.5           2.5           2.36842       2.25          3             2.36842       2.5           2.36842       2.8125        7.5\n",
              "logloss                  0.168007   0.0536355  0.141224      0.109406      0.140843      0.287477      0.169976      0.165738      0.163844      0.21237       0.187247      0.101947\n",
              "max_per_class_error      0.0586567  0.0332292  0.0740741     0             0.0384615     0.1           0.0666667     0.0769231     0.037037      0.105263      0.0625        0.025641\n",
              "mcc                      0.92334    0.0426305  0.912871      1             0.955752      0.865207      0.950382      0.913874      0.955134      0.863294      0.903017      0.913874\n",
              "mean_per_class_accuracy  0.965024   0.023622   0.962963      1             0.980769      0.93          0.966667      0.961538      0.981482      0.928138      0.951509      0.987179\n",
              "mean_per_class_error     0.0349755  0.023622   0.037037      0             0.0192308     0.07          0.0333333     0.0384615     0.0185185     0.0718624     0.0484914     0.0128205\n",
              "mse                      0.0445622  0.0161211  0.037262      0.0255396     0.0351779     0.0772335     0.0445828     0.0448035     0.0417654     0.0617108     0.0529047     0.0246418\n",
              "pr_auc                   0.981783   0.0155081  0.988293      1             0.9973        0.948117      0.976292      0.992019      0.990453      0.969532      0.981517      0.974308\n",
              "precision                0.938859   0.0436254  0.9           1             0.95          0.947368      1             0.904762      0.947368      0.944444      0.9375        0.857143\n",
              "r2                       0.802593   0.0590727  0.844742      0.893585      0.855799      0.687204      0.799377      0.816342      0.825977      0.747036      0.769112      0.786754\n",
              "recall                   0.966557   0.0450268  1             1             1             0.9           0.933333      1             1             0.894737      0.9375        1\n",
              "rmse                     0.20809    0.0374301  0.193034      0.159811      0.187558      0.277909      0.211146      0.211668      0.204366      0.248417      0.23001       0.156977\n",
              "specificity              0.963492   0.0255007  0.925926      1             0.961538      0.96          1             0.923077      0.962963      0.961538      0.965517      0.974359\n",
              "\n",
              "Scoring History: \n",
              "    timestamp            duration    number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
              "--  -------------------  ----------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ----------------  -------------------  -----------------  ---------------------------------\n",
              "    2023-06-21 21:45:29  4.870 sec   0                  0.5              0.693147            0.5             0.373333           1                0.626667                         0.5                0.693147              0.5               0.369748             1                  0.630252\n",
              "    2023-06-21 21:45:29  4.897 sec   5                  0.22969          0.226667            0.986934        0.982173           2.67857          0.0555556                        0.236996           0.235786              0.988939          0.980655             2.70455            0.0504202\n",
              "    2023-06-21 21:45:29  4.921 sec   10                 0.183882         0.143713            0.992317        0.98965            2.67857          0.0333333                        0.194435           0.152695              0.99197           0.986434             2.70455            0.0420168\n",
              "    2023-06-21 21:45:29  4.938 sec   15                 0.176657         0.131826            0.991831        0.989632           2.67857          0.0311111                        0.179833           0.13377               0.995             0.991882             2.70455            0.0336134\n",
              "    2023-06-21 21:45:29  4.960 sec   20                 0.173072         0.127836            0.991515        0.989782           2.67857          0.0311111                        0.172738           0.12622               0.996515          0.994173             2.70455            0.0252101\n",
              "    2023-06-21 21:45:29  4.988 sec   25                 0.172723         0.127706            0.991515        0.989782           2.67857          0.0311111                        0.1726             0.126394              0.996515          0.994173             2.70455            0.0252101\n",
              "    2023-06-21 21:45:30  5.026 sec   30                 0.172738         0.127708            0.991515        0.989782           2.67857          0.0311111                        0.172602           0.126379              0.996515          0.994173             2.70455            0.0252101\n",
              "    2023-06-21 21:45:30  5.051 sec   35                 0.173271         0.127943            0.991515        0.989782           2.67857          0.0311111                        0.172859           0.126204              0.996515          0.994173             2.70455            0.0252101\n",
              "    2023-06-21 21:45:30  5.080 sec   40                 0.170592         0.122358            0.991114        0.989398           2.67857          0.0311111                        0.161652           0.113623              0.997424          0.995767             2.70455            0.0252101\n",
              "    2023-06-21 21:45:30  5.111 sec   44                 0.170675         0.122401            0.991114        0.989398           2.67857          0.0311111                        0.16166            0.113563              0.997424          0.995767             2.70455            0.0252101\n",
              "\n",
              "Variable Importances: \n",
              "variable              relative_importance    scaled_importance    percentage\n",
              "--------------------  ---------------------  -------------------  ------------\n",
              "perimeter_worst       335.855                1                    0.559163\n",
              "concave points_worst  156.842                0.466992             0.261125\n",
              "concave points_mean   25.2143                0.0750751            0.0419793\n",
              "texture_worst         23.8098                0.0708931            0.0396408\n",
              "area_worst            17.7388                0.052817             0.0295333\n",
              "area_se               17.3529                0.0516679            0.0288908\n",
              "texture_mean          12.4471                0.0370608            0.020723\n",
              "concavity_mean        7.08558                0.0210971            0.0117967\n",
              "radius_se             4.2931                 0.0127826            0.00714757\n",
              "\n",
              "[tips]\n",
              "Use `model.explain()` to inspect the model.\n",
              "--\n",
              "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
            ],
            "text/html": [
              "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
              "=============\n",
              "H2OXGBoostEstimator : XGBoost\n",
              "Model Key: XGBoost_1_AutoML_2_20230621_214524\n",
              "</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-42.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-42 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-42 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-42 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-42 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-42 .h2o-table th,\n",
              "#h2o-table-42 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-42 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-42\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Model Summary: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>number_of_trees</th></tr></thead>\n",
              "    <tbody><tr><td></td>\n",
              "<td>44.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: xgboost\n",
              "** Reported on train data. **\n",
              "\n",
              "MSE: 0.029130112207480154\n",
              "RMSE: 0.17067545871472017\n",
              "LogLoss: 0.12240138558277379\n",
              "Mean Per-Class Error: 0.03565096251266464\n",
              "AUC: 0.9911136440391759\n",
              "AUCPR: 0.989398055584699\n",
              "Gini: 0.9822272880783518</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-43.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-43 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-43 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-43 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-43 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-43 .h2o-table th,\n",
              "#h2o-table-43 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-43 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-43\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4297827184200287</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>B</th>\n",
              "<th>M</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>B</td>\n",
              "<td>277.0</td>\n",
              "<td>5.0</td>\n",
              "<td>0.0177</td>\n",
              "<td> (5.0/282.0)</td></tr>\n",
              "<tr><td>M</td>\n",
              "<td>9.0</td>\n",
              "<td>159.0</td>\n",
              "<td>0.0536</td>\n",
              "<td> (9.0/168.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>286.0</td>\n",
              "<td>164.0</td>\n",
              "<td>0.0311</td>\n",
              "<td> (14.0/450.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-44.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-44 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-44 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-44 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-44 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-44 .h2o-table th,\n",
              "#h2o-table-44 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-44 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-44\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.4297827</td>\n",
              "<td>0.9578313</td>\n",
              "<td>47.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.2924710</td>\n",
              "<td>0.9635723</td>\n",
              "<td>59.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.5747734</td>\n",
              "<td>0.9771574</td>\n",
              "<td>40.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.5162559</td>\n",
              "<td>0.9688889</td>\n",
              "<td>45.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>0.9756404</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0439371</td>\n",
              "<td>1.0</td>\n",
              "<td>113.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>0.9756404</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.5162559</td>\n",
              "<td>0.9334117</td>\n",
              "<td>45.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.3491756</td>\n",
              "<td>0.9609929</td>\n",
              "<td>53.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.3410693</td>\n",
              "<td>0.9656155</td>\n",
              "<td>54.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>0.9756404</td>\n",
              "<td>282.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>0.9756404</td>\n",
              "<td>107.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0141261</td>\n",
              "<td>282.0</td>\n",
              "<td>139.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0439371</td>\n",
              "<td>168.0</td>\n",
              "<td>113.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>0.9756404</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>0.9756404</td>\n",
              "<td>0.6369048</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0141261</td>\n",
              "<td>1.0</td>\n",
              "<td>139.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0439371</td>\n",
              "<td>1.0</td>\n",
              "<td>113.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-45.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-45 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-45 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-45 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-45 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-45 .h2o-table th,\n",
              "#h2o-table-45 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-45 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-45\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 37.33 %, avg score: 37.00 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.1355556</td>\n",
              "<td>0.9756404</td>\n",
              "<td>2.6785714</td>\n",
              "<td>2.6785714</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9756404</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9756404</td>\n",
              "<td>0.3630952</td>\n",
              "<td>0.3630952</td>\n",
              "<td>167.8571429</td>\n",
              "<td>167.8571429</td>\n",
              "<td>0.3630952</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.1555556</td>\n",
              "<td>0.9658545</td>\n",
              "<td>2.6785714</td>\n",
              "<td>2.6785714</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9659363</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9743927</td>\n",
              "<td>0.0535714</td>\n",
              "<td>0.4166667</td>\n",
              "<td>167.8571429</td>\n",
              "<td>167.8571429</td>\n",
              "<td>0.4166667</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.2022222</td>\n",
              "<td>0.9496785</td>\n",
              "<td>2.6785714</td>\n",
              "<td>2.6785714</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9593723</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9709265</td>\n",
              "<td>0.125</td>\n",
              "<td>0.5416667</td>\n",
              "<td>167.8571429</td>\n",
              "<td>167.8571429</td>\n",
              "<td>0.5416667</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.3</td>\n",
              "<td>0.8152791</td>\n",
              "<td>2.6785714</td>\n",
              "<td>2.6785714</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9151439</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9527455</td>\n",
              "<td>0.2619048</td>\n",
              "<td>0.8035714</td>\n",
              "<td>167.8571429</td>\n",
              "<td>167.8571429</td>\n",
              "<td>0.8035714</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.4</td>\n",
              "<td>0.2769342</td>\n",
              "<td>1.7261905</td>\n",
              "<td>2.4404762</td>\n",
              "<td>0.6444444</td>\n",
              "<td>0.5482601</td>\n",
              "<td>0.9111111</td>\n",
              "<td>0.8516241</td>\n",
              "<td>0.1726190</td>\n",
              "<td>0.9761905</td>\n",
              "<td>72.6190476</td>\n",
              "<td>144.0476190</td>\n",
              "<td>0.9194529</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.5</td>\n",
              "<td>0.0818321</td>\n",
              "<td>0.0595238</td>\n",
              "<td>1.9642857</td>\n",
              "<td>0.0222222</td>\n",
              "<td>0.1343683</td>\n",
              "<td>0.7333333</td>\n",
              "<td>0.7081730</td>\n",
              "<td>0.0059524</td>\n",
              "<td>0.9821429</td>\n",
              "<td>-94.0476190</td>\n",
              "<td>96.4285714</td>\n",
              "<td>0.7693769</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>0.6</td>\n",
              "<td>0.0601370</td>\n",
              "<td>0.1190476</td>\n",
              "<td>1.6567460</td>\n",
              "<td>0.0444444</td>\n",
              "<td>0.0681423</td>\n",
              "<td>0.6185185</td>\n",
              "<td>0.6015012</td>\n",
              "<td>0.0119048</td>\n",
              "<td>0.9940476</td>\n",
              "<td>-88.0952381</td>\n",
              "<td>65.6746032</td>\n",
              "<td>0.6287994</td></tr>\n",
              "<tr><td>8</td>\n",
              "<td>0.7088889</td>\n",
              "<td>0.0255055</td>\n",
              "<td>0.0546647</td>\n",
              "<td>1.4106583</td>\n",
              "<td>0.0204082</td>\n",
              "<td>0.0402448</td>\n",
              "<td>0.5266458</td>\n",
              "<td>0.5152894</td>\n",
              "<td>0.0059524</td>\n",
              "<td>1.0</td>\n",
              "<td>-94.5335277</td>\n",
              "<td>41.0658307</td>\n",
              "<td>0.4645390</td></tr>\n",
              "<tr><td>9</td>\n",
              "<td>0.8177778</td>\n",
              "<td>0.0171180</td>\n",
              "<td>0.0</td>\n",
              "<td>1.2228261</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0195770</td>\n",
              "<td>0.4565217</td>\n",
              "<td>0.4492842</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>22.2826087</td>\n",
              "<td>0.2907801</td></tr>\n",
              "<tr><td>10</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0141261</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0141261</td>\n",
              "<td>0.3733333</td>\n",
              "<td>0.3699887</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: xgboost\n",
              "** Reported on validation data. **\n",
              "\n",
              "MSE: 0.026133884441954087\n",
              "RMSE: 0.16165977991434383\n",
              "LogLoss: 0.11356345603286226\n",
              "Mean Per-Class Error: 0.024696969696969696\n",
              "AUC: 0.9974242424242425\n",
              "AUCPR: 0.9957667052093674\n",
              "Gini: 0.9948484848484851</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-46.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-46 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-46 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-46 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-46 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-46 .h2o-table th,\n",
              "#h2o-table-46 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-46 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-46\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.47318321466445923</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>B</th>\n",
              "<th>M</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>B</td>\n",
              "<td>73.0</td>\n",
              "<td>2.0</td>\n",
              "<td>0.0267</td>\n",
              "<td> (2.0/75.0)</td></tr>\n",
              "<tr><td>M</td>\n",
              "<td>1.0</td>\n",
              "<td>43.0</td>\n",
              "<td>0.0227</td>\n",
              "<td> (1.0/44.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>74.0</td>\n",
              "<td>45.0</td>\n",
              "<td>0.0252</td>\n",
              "<td> (3.0/119.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-47.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-47 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-47 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-47 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-47 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-47 .h2o-table th,\n",
              "#h2o-table-47 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-47 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-47\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.4731832</td>\n",
              "<td>0.9662921</td>\n",
              "<td>20.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.2915184</td>\n",
              "<td>0.9777778</td>\n",
              "<td>23.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.6153226</td>\n",
              "<td>0.9803922</td>\n",
              "<td>15.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.5094880</td>\n",
              "<td>0.9747899</td>\n",
              "<td>18.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>0.9756404</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.2915184</td>\n",
              "<td>1.0</td>\n",
              "<td>23.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>0.9756404</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.4731832</td>\n",
              "<td>0.9463144</td>\n",
              "<td>20.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.4731832</td>\n",
              "<td>0.9733333</td>\n",
              "<td>20.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.4731832</td>\n",
              "<td>0.9753030</td>\n",
              "<td>20.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>0.9756404</td>\n",
              "<td>75.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>0.9756404</td>\n",
              "<td>29.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0141261</td>\n",
              "<td>75.0</td>\n",
              "<td>61.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.2915184</td>\n",
              "<td>44.0</td>\n",
              "<td>23.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>0.9756404</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>0.9756404</td>\n",
              "<td>0.6590909</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0141261</td>\n",
              "<td>1.0</td>\n",
              "<td>61.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.2915184</td>\n",
              "<td>1.0</td>\n",
              "<td>23.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-48.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-48 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-48 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-48 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-48 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-48 .h2o-table th,\n",
              "#h2o-table-48 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-48 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-48\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 36.97 %, avg score: 37.32 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.1260504</td>\n",
              "<td>0.9756404</td>\n",
              "<td>2.7045455</td>\n",
              "<td>2.7045455</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9756404</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9756404</td>\n",
              "<td>0.3409091</td>\n",
              "<td>0.3409091</td>\n",
              "<td>170.4545455</td>\n",
              "<td>170.4545455</td>\n",
              "<td>0.3409091</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.1512605</td>\n",
              "<td>0.9476320</td>\n",
              "<td>2.7045455</td>\n",
              "<td>2.7045455</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9592851</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9729145</td>\n",
              "<td>0.0681818</td>\n",
              "<td>0.4090909</td>\n",
              "<td>170.4545455</td>\n",
              "<td>170.4545455</td>\n",
              "<td>0.4090909</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.2352941</td>\n",
              "<td>0.9262424</td>\n",
              "<td>2.7045455</td>\n",
              "<td>2.7045455</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9298264</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9575259</td>\n",
              "<td>0.2272727</td>\n",
              "<td>0.6363636</td>\n",
              "<td>170.4545455</td>\n",
              "<td>170.4545455</td>\n",
              "<td>0.6363636</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.3193277</td>\n",
              "<td>0.8112912</td>\n",
              "<td>2.7045455</td>\n",
              "<td>2.7045455</td>\n",
              "<td>1.0</td>\n",
              "<td>0.8651847</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9332256</td>\n",
              "<td>0.2272727</td>\n",
              "<td>0.8636364</td>\n",
              "<td>170.4545455</td>\n",
              "<td>170.4545455</td>\n",
              "<td>0.8636364</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.4117647</td>\n",
              "<td>0.2915184</td>\n",
              "<td>1.4752066</td>\n",
              "<td>2.4285714</td>\n",
              "<td>0.5454545</td>\n",
              "<td>0.4830952</td>\n",
              "<td>0.8979592</td>\n",
              "<td>0.8321759</td>\n",
              "<td>0.1363636</td>\n",
              "<td>1.0</td>\n",
              "<td>47.5206612</td>\n",
              "<td>142.8571429</td>\n",
              "<td>0.9333333</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.5042017</td>\n",
              "<td>0.0890782</td>\n",
              "<td>0.0</td>\n",
              "<td>1.9833333</td>\n",
              "<td>0.0</td>\n",
              "<td>0.1637983</td>\n",
              "<td>0.7333333</td>\n",
              "<td>0.7096400</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>98.3333333</td>\n",
              "<td>0.7866667</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>0.5966387</td>\n",
              "<td>0.0469845</td>\n",
              "<td>0.0</td>\n",
              "<td>1.6760563</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0708849</td>\n",
              "<td>0.6197183</td>\n",
              "<td>0.6106780</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>67.6056338</td>\n",
              "<td>0.64</td></tr>\n",
              "<tr><td>8</td>\n",
              "<td>0.6974790</td>\n",
              "<td>0.0275775</td>\n",
              "<td>0.0</td>\n",
              "<td>1.4337349</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0362935</td>\n",
              "<td>0.5301205</td>\n",
              "<td>0.5276344</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>43.3734940</td>\n",
              "<td>0.48</td></tr>\n",
              "<tr><td>9</td>\n",
              "<td>0.7983193</td>\n",
              "<td>0.0184387</td>\n",
              "<td>0.0</td>\n",
              "<td>1.2526316</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0209517</td>\n",
              "<td>0.4631579</td>\n",
              "<td>0.4636324</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>25.2631579</td>\n",
              "<td>0.3200000</td></tr>\n",
              "<tr><td>10</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0141261</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0153230</td>\n",
              "<td>0.3697479</td>\n",
              "<td>0.3732170</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: xgboost\n",
              "** Reported on cross-validation data. **\n",
              "\n",
              "MSE: 0.04456220211816163\n",
              "RMSE: 0.21109761277229458\n",
              "LogLoss: 0.16800715284467554\n",
              "Mean Per-Class Error: 0.05933383991894631\n",
              "AUC: 0.982364488348531\n",
              "AUCPR: 0.9779680523587579\n",
              "Gini: 0.9647289766970619</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-49.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-49 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-49 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-49 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-49 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-49 .h2o-table th,\n",
              "#h2o-table-49 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-49 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-49\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4053971767425537</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>B</th>\n",
              "<th>M</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>B</td>\n",
              "<td>267.0</td>\n",
              "<td>15.0</td>\n",
              "<td>0.0532</td>\n",
              "<td> (15.0/282.0)</td></tr>\n",
              "<tr><td>M</td>\n",
              "<td>11.0</td>\n",
              "<td>157.0</td>\n",
              "<td>0.0655</td>\n",
              "<td> (11.0/168.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>278.0</td>\n",
              "<td>172.0</td>\n",
              "<td>0.0578</td>\n",
              "<td> (26.0/450.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-50.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-50 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-50 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-50 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-50 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-50 .h2o-table th,\n",
              "#h2o-table-50 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-50 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-50\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.4053972</td>\n",
              "<td>0.9235294</td>\n",
              "<td>94.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.3462134</td>\n",
              "<td>0.9415205</td>\n",
              "<td>105.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.6928228</td>\n",
              "<td>0.9510870</td>\n",
              "<td>64.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.4053972</td>\n",
              "<td>0.9422222</td>\n",
              "<td>94.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>0.9726430</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0375161</td>\n",
              "<td>1.0</td>\n",
              "<td>217.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>0.9726430</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.4053972</td>\n",
              "<td>0.8772680</td>\n",
              "<td>94.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.3791416</td>\n",
              "<td>0.9361702</td>\n",
              "<td>98.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.4053972</td>\n",
              "<td>0.9406662</td>\n",
              "<td>94.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>0.9726430</td>\n",
              "<td>282.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>0.9726430</td>\n",
              "<td>160.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0176464</td>\n",
              "<td>282.0</td>\n",
              "<td>265.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0375161</td>\n",
              "<td>168.0</td>\n",
              "<td>217.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>0.9726430</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>0.9726430</td>\n",
              "<td>0.9523810</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0176464</td>\n",
              "<td>1.0</td>\n",
              "<td>265.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0375161</td>\n",
              "<td>1.0</td>\n",
              "<td>217.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-51.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-51 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-51 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-51 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-51 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-51 .h2o-table th,\n",
              "#h2o-table-51 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-51 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-51\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 37.33 %, avg score: 37.50 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.0177778</td>\n",
              "<td>0.9726430</td>\n",
              "<td>2.6785714</td>\n",
              "<td>2.6785714</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9726430</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9726430</td>\n",
              "<td>0.0476190</td>\n",
              "<td>0.0476190</td>\n",
              "<td>167.8571429</td>\n",
              "<td>167.8571429</td>\n",
              "<td>0.0476190</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.0333333</td>\n",
              "<td>0.9696493</td>\n",
              "<td>2.6785714</td>\n",
              "<td>2.6785714</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9696493</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9712459</td>\n",
              "<td>0.0416667</td>\n",
              "<td>0.0892857</td>\n",
              "<td>167.8571429</td>\n",
              "<td>167.8571429</td>\n",
              "<td>0.0892857</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.0488889</td>\n",
              "<td>0.9667782</td>\n",
              "<td>2.6785714</td>\n",
              "<td>2.6785714</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9671381</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9699389</td>\n",
              "<td>0.0416667</td>\n",
              "<td>0.1309524</td>\n",
              "<td>167.8571429</td>\n",
              "<td>167.8571429</td>\n",
              "<td>0.1309524</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.0666667</td>\n",
              "<td>0.9663531</td>\n",
              "<td>2.6785714</td>\n",
              "<td>2.6785714</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9663531</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9689827</td>\n",
              "<td>0.0476190</td>\n",
              "<td>0.1785714</td>\n",
              "<td>167.8571429</td>\n",
              "<td>167.8571429</td>\n",
              "<td>0.1785714</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.1022222</td>\n",
              "<td>0.9597611</td>\n",
              "<td>2.6785714</td>\n",
              "<td>2.6785714</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9619714</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9665440</td>\n",
              "<td>0.0952381</td>\n",
              "<td>0.2738095</td>\n",
              "<td>167.8571429</td>\n",
              "<td>167.8571429</td>\n",
              "<td>0.2738095</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.16</td>\n",
              "<td>0.9526056</td>\n",
              "<td>2.6785714</td>\n",
              "<td>2.6785714</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9555109</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9625598</td>\n",
              "<td>0.1547619</td>\n",
              "<td>0.4285714</td>\n",
              "<td>167.8571429</td>\n",
              "<td>167.8571429</td>\n",
              "<td>0.4285714</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>0.2</td>\n",
              "<td>0.9357066</td>\n",
              "<td>2.6785714</td>\n",
              "<td>2.6785714</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9441041</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9588687</td>\n",
              "<td>0.1071429</td>\n",
              "<td>0.5357143</td>\n",
              "<td>167.8571429</td>\n",
              "<td>167.8571429</td>\n",
              "<td>0.5357143</td></tr>\n",
              "<tr><td>8</td>\n",
              "<td>0.3</td>\n",
              "<td>0.7818707</td>\n",
              "<td>2.5595238</td>\n",
              "<td>2.6388889</td>\n",
              "<td>0.9555556</td>\n",
              "<td>0.9010030</td>\n",
              "<td>0.9851852</td>\n",
              "<td>0.9395801</td>\n",
              "<td>0.2559524</td>\n",
              "<td>0.7916667</td>\n",
              "<td>155.9523810</td>\n",
              "<td>163.8888889</td>\n",
              "<td>0.7845745</td></tr>\n",
              "<tr><td>9</td>\n",
              "<td>0.4</td>\n",
              "<td>0.3503399</td>\n",
              "<td>1.5476190</td>\n",
              "<td>2.3660714</td>\n",
              "<td>0.5777778</td>\n",
              "<td>0.5410498</td>\n",
              "<td>0.8833333</td>\n",
              "<td>0.8399475</td>\n",
              "<td>0.1547619</td>\n",
              "<td>0.9464286</td>\n",
              "<td>54.7619048</td>\n",
              "<td>136.6071429</td>\n",
              "<td>0.8719605</td></tr>\n",
              "<tr><td>10</td>\n",
              "<td>0.5</td>\n",
              "<td>0.0996270</td>\n",
              "<td>0.2976190</td>\n",
              "<td>1.9523810</td>\n",
              "<td>0.1111111</td>\n",
              "<td>0.1856441</td>\n",
              "<td>0.7288889</td>\n",
              "<td>0.7090868</td>\n",
              "<td>0.0297619</td>\n",
              "<td>0.9761905</td>\n",
              "<td>-70.2380952</td>\n",
              "<td>95.2380952</td>\n",
              "<td>0.7598784</td></tr>\n",
              "<tr><td>11</td>\n",
              "<td>0.6044444</td>\n",
              "<td>0.0597624</td>\n",
              "<td>0.1139818</td>\n",
              "<td>1.6347164</td>\n",
              "<td>0.0425532</td>\n",
              "<td>0.0731328</td>\n",
              "<td>0.6102941</td>\n",
              "<td>0.5991977</td>\n",
              "<td>0.0119048</td>\n",
              "<td>0.9880952</td>\n",
              "<td>-88.6018237</td>\n",
              "<td>63.4716387</td>\n",
              "<td>0.6122087</td></tr>\n",
              "<tr><td>12</td>\n",
              "<td>0.7</td>\n",
              "<td>0.0389057</td>\n",
              "<td>0.0</td>\n",
              "<td>1.4115646</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0484390</td>\n",
              "<td>0.5269841</td>\n",
              "<td>0.5240148</td>\n",
              "<td>0.0</td>\n",
              "<td>0.9880952</td>\n",
              "<td>-100.0</td>\n",
              "<td>41.1564626</td>\n",
              "<td>0.4597264</td></tr>\n",
              "<tr><td>13</td>\n",
              "<td>0.8022222</td>\n",
              "<td>0.0293830</td>\n",
              "<td>0.1164596</td>\n",
              "<td>1.2465374</td>\n",
              "<td>0.0434783</td>\n",
              "<td>0.0342120</td>\n",
              "<td>0.4653740</td>\n",
              "<td>0.4616022</td>\n",
              "<td>0.0119048</td>\n",
              "<td>1.0</td>\n",
              "<td>-88.3540373</td>\n",
              "<td>24.6537396</td>\n",
              "<td>0.3156028</td></tr>\n",
              "<tr><td>14</td>\n",
              "<td>0.9022222</td>\n",
              "<td>0.0243170</td>\n",
              "<td>0.0</td>\n",
              "<td>1.1083744</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0259154</td>\n",
              "<td>0.4137931</td>\n",
              "<td>0.4133118</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>10.8374384</td>\n",
              "<td>0.1560284</td></tr>\n",
              "<tr><td>15</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0176464</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0210691</td>\n",
              "<td>0.3733333</td>\n",
              "<td>0.3749592</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-52.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-52 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-52 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-52 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-52 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-52 .h2o-table th,\n",
              "#h2o-table-52 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-52 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-52\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Cross-Validation Metrics Summary: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>mean</th>\n",
              "<th>sd</th>\n",
              "<th>cv_1_valid</th>\n",
              "<th>cv_2_valid</th>\n",
              "<th>cv_3_valid</th>\n",
              "<th>cv_4_valid</th>\n",
              "<th>cv_5_valid</th>\n",
              "<th>cv_6_valid</th>\n",
              "<th>cv_7_valid</th>\n",
              "<th>cv_8_valid</th>\n",
              "<th>cv_9_valid</th>\n",
              "<th>cv_10_valid</th></tr></thead>\n",
              "    <tbody><tr><td>accuracy</td>\n",
              "<td>0.9644445</td>\n",
              "<td>0.0214687</td>\n",
              "<td>0.9555556</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9777778</td>\n",
              "<td>0.9333333</td>\n",
              "<td>0.9777778</td>\n",
              "<td>0.9555556</td>\n",
              "<td>0.9777778</td>\n",
              "<td>0.9333333</td>\n",
              "<td>0.9555556</td>\n",
              "<td>0.9777778</td></tr>\n",
              "<tr><td>auc</td>\n",
              "<td>0.9853345</td>\n",
              "<td>0.0191174</td>\n",
              "<td>0.9917695</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9979757</td>\n",
              "<td>0.936</td>\n",
              "<td>0.9822222</td>\n",
              "<td>0.9939271</td>\n",
              "<td>0.9938272</td>\n",
              "<td>0.9726721</td>\n",
              "<td>0.9892241</td>\n",
              "<td>0.9957265</td></tr>\n",
              "<tr><td>err</td>\n",
              "<td>0.0355556</td>\n",
              "<td>0.0214687</td>\n",
              "<td>0.0444444</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0222222</td>\n",
              "<td>0.0666667</td>\n",
              "<td>0.0222222</td>\n",
              "<td>0.0444444</td>\n",
              "<td>0.0222222</td>\n",
              "<td>0.0666667</td>\n",
              "<td>0.0444444</td>\n",
              "<td>0.0222222</td></tr>\n",
              "<tr><td>err_count</td>\n",
              "<td>1.6</td>\n",
              "<td>0.9660918</td>\n",
              "<td>2.0</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>3.0</td>\n",
              "<td>1.0</td>\n",
              "<td>2.0</td>\n",
              "<td>1.0</td>\n",
              "<td>3.0</td>\n",
              "<td>2.0</td>\n",
              "<td>1.0</td></tr>\n",
              "<tr><td>f0point5</td>\n",
              "<td>0.9435074</td>\n",
              "<td>0.0340338</td>\n",
              "<td>0.9183673</td>\n",
              "<td>1.0</td>\n",
              "<td>0.959596</td>\n",
              "<td>0.9375</td>\n",
              "<td>0.9859155</td>\n",
              "<td>0.9223301</td>\n",
              "<td>0.9574468</td>\n",
              "<td>0.9340659</td>\n",
              "<td>0.9375</td>\n",
              "<td>0.8823530</td></tr>\n",
              "<tr><td>f1</td>\n",
              "<td>0.9512790</td>\n",
              "<td>0.0267176</td>\n",
              "<td>0.9473684</td>\n",
              "<td>1.0</td>\n",
              "<td>0.974359</td>\n",
              "<td>0.9230769</td>\n",
              "<td>0.9655172</td>\n",
              "<td>0.95</td>\n",
              "<td>0.972973</td>\n",
              "<td>0.9189189</td>\n",
              "<td>0.9375</td>\n",
              "<td>0.9230769</td></tr>\n",
              "<tr><td>f2</td>\n",
              "<td>0.9600770</td>\n",
              "<td>0.0341382</td>\n",
              "<td>0.9782609</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9895833</td>\n",
              "<td>0.9090909</td>\n",
              "<td>0.9459459</td>\n",
              "<td>0.9793814</td>\n",
              "<td>0.989011</td>\n",
              "<td>0.9042553</td>\n",
              "<td>0.9375</td>\n",
              "<td>0.9677419</td></tr>\n",
              "<tr><td>lift_top_group</td>\n",
              "<td>3.0167763</td>\n",
              "<td>1.5913488</td>\n",
              "<td>2.5</td>\n",
              "<td>2.5</td>\n",
              "<td>2.368421</td>\n",
              "<td>2.25</td>\n",
              "<td>3.0</td>\n",
              "<td>2.368421</td>\n",
              "<td>2.5</td>\n",
              "<td>2.368421</td>\n",
              "<td>2.8125</td>\n",
              "<td>7.5</td></tr>\n",
              "<tr><td>logloss</td>\n",
              "<td>0.1680071</td>\n",
              "<td>0.0536355</td>\n",
              "<td>0.1412243</td>\n",
              "<td>0.1094058</td>\n",
              "<td>0.1408426</td>\n",
              "<td>0.2874768</td>\n",
              "<td>0.1699757</td>\n",
              "<td>0.1657380</td>\n",
              "<td>0.1638442</td>\n",
              "<td>0.2123703</td>\n",
              "<td>0.1872467</td>\n",
              "<td>0.1019470</td></tr>\n",
              "<tr><td>max_per_class_error</td>\n",
              "<td>0.0586567</td>\n",
              "<td>0.0332292</td>\n",
              "<td>0.0740741</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0384615</td>\n",
              "<td>0.1</td>\n",
              "<td>0.0666667</td>\n",
              "<td>0.0769231</td>\n",
              "<td>0.0370370</td>\n",
              "<td>0.1052632</td>\n",
              "<td>0.0625</td>\n",
              "<td>0.0256410</td></tr>\n",
              "<tr><td>mcc</td>\n",
              "<td>0.9233404</td>\n",
              "<td>0.0426305</td>\n",
              "<td>0.9128709</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9557518</td>\n",
              "<td>0.8652069</td>\n",
              "<td>0.9503819</td>\n",
              "<td>0.9138736</td>\n",
              "<td>0.9551339</td>\n",
              "<td>0.8632941</td>\n",
              "<td>0.9030172</td>\n",
              "<td>0.9138736</td></tr>\n",
              "<tr><td>mean_per_class_accuracy</td>\n",
              "<td>0.9650245</td>\n",
              "<td>0.0236220</td>\n",
              "<td>0.962963</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9807692</td>\n",
              "<td>0.93</td>\n",
              "<td>0.9666666</td>\n",
              "<td>0.9615384</td>\n",
              "<td>0.9814815</td>\n",
              "<td>0.9281377</td>\n",
              "<td>0.9515086</td>\n",
              "<td>0.9871795</td></tr>\n",
              "<tr><td>mean_per_class_error</td>\n",
              "<td>0.0349755</td>\n",
              "<td>0.0236220</td>\n",
              "<td>0.0370370</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0192308</td>\n",
              "<td>0.07</td>\n",
              "<td>0.0333333</td>\n",
              "<td>0.0384615</td>\n",
              "<td>0.0185185</td>\n",
              "<td>0.0718624</td>\n",
              "<td>0.0484914</td>\n",
              "<td>0.0128205</td></tr>\n",
              "<tr><td>mse</td>\n",
              "<td>0.0445622</td>\n",
              "<td>0.0161211</td>\n",
              "<td>0.0372620</td>\n",
              "<td>0.0255396</td>\n",
              "<td>0.0351779</td>\n",
              "<td>0.0772335</td>\n",
              "<td>0.0445828</td>\n",
              "<td>0.0448035</td>\n",
              "<td>0.0417654</td>\n",
              "<td>0.0617108</td>\n",
              "<td>0.0529047</td>\n",
              "<td>0.0246418</td></tr>\n",
              "<tr><td>pr_auc</td>\n",
              "<td>0.9817832</td>\n",
              "<td>0.0155081</td>\n",
              "<td>0.9882933</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9973003</td>\n",
              "<td>0.9481173</td>\n",
              "<td>0.9762924</td>\n",
              "<td>0.9920185</td>\n",
              "<td>0.9904528</td>\n",
              "<td>0.9695324</td>\n",
              "<td>0.9815167</td>\n",
              "<td>0.9743082</td></tr>\n",
              "<tr><td>precision</td>\n",
              "<td>0.9388586</td>\n",
              "<td>0.0436254</td>\n",
              "<td>0.9</td>\n",
              "<td>1.0</td>\n",
              "<td>0.95</td>\n",
              "<td>0.9473684</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9047619</td>\n",
              "<td>0.9473684</td>\n",
              "<td>0.9444444</td>\n",
              "<td>0.9375</td>\n",
              "<td>0.8571429</td></tr>\n",
              "<tr><td>r2</td>\n",
              "<td>0.8025928</td>\n",
              "<td>0.0590727</td>\n",
              "<td>0.8447416</td>\n",
              "<td>0.8935852</td>\n",
              "<td>0.8557991</td>\n",
              "<td>0.6872043</td>\n",
              "<td>0.7993774</td>\n",
              "<td>0.816342</td>\n",
              "<td>0.8259773</td>\n",
              "<td>0.7470357</td>\n",
              "<td>0.7691118</td>\n",
              "<td>0.7867540</td></tr>\n",
              "<tr><td>recall</td>\n",
              "<td>0.966557</td>\n",
              "<td>0.0450268</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9</td>\n",
              "<td>0.9333333</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.8947368</td>\n",
              "<td>0.9375</td>\n",
              "<td>1.0</td></tr>\n",
              "<tr><td>rmse</td>\n",
              "<td>0.2080896</td>\n",
              "<td>0.0374301</td>\n",
              "<td>0.1930337</td>\n",
              "<td>0.1598110</td>\n",
              "<td>0.1875577</td>\n",
              "<td>0.2779092</td>\n",
              "<td>0.2111464</td>\n",
              "<td>0.2116683</td>\n",
              "<td>0.2043660</td>\n",
              "<td>0.2484166</td>\n",
              "<td>0.2300103</td>\n",
              "<td>0.1569770</td></tr>\n",
              "<tr><td>specificity</td>\n",
              "<td>0.9634919</td>\n",
              "<td>0.0255007</td>\n",
              "<td>0.9259259</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9615384</td>\n",
              "<td>0.96</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9230769</td>\n",
              "<td>0.962963</td>\n",
              "<td>0.9615384</td>\n",
              "<td>0.9655172</td>\n",
              "<td>0.974359</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-53.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-53 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-53 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-53 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-53 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-53 .h2o-table th,\n",
              "#h2o-table-53 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-53 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-53\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Scoring History: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>timestamp</th>\n",
              "<th>duration</th>\n",
              "<th>number_of_trees</th>\n",
              "<th>training_rmse</th>\n",
              "<th>training_logloss</th>\n",
              "<th>training_auc</th>\n",
              "<th>training_pr_auc</th>\n",
              "<th>training_lift</th>\n",
              "<th>training_classification_error</th>\n",
              "<th>validation_rmse</th>\n",
              "<th>validation_logloss</th>\n",
              "<th>validation_auc</th>\n",
              "<th>validation_pr_auc</th>\n",
              "<th>validation_lift</th>\n",
              "<th>validation_classification_error</th></tr></thead>\n",
              "    <tbody><tr><td></td>\n",
              "<td>2023-06-21 21:45:29</td>\n",
              "<td> 4.870 sec</td>\n",
              "<td>0.0</td>\n",
              "<td>0.5</td>\n",
              "<td>0.6931472</td>\n",
              "<td>0.5</td>\n",
              "<td>0.3733333</td>\n",
              "<td>1.0</td>\n",
              "<td>0.6266667</td>\n",
              "<td>0.5</td>\n",
              "<td>0.6931472</td>\n",
              "<td>0.5</td>\n",
              "<td>0.3697479</td>\n",
              "<td>1.0</td>\n",
              "<td>0.6302521</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 21:45:29</td>\n",
              "<td> 4.897 sec</td>\n",
              "<td>5.0</td>\n",
              "<td>0.2296900</td>\n",
              "<td>0.2266673</td>\n",
              "<td>0.9869343</td>\n",
              "<td>0.9821729</td>\n",
              "<td>2.6785714</td>\n",
              "<td>0.0555556</td>\n",
              "<td>0.2369959</td>\n",
              "<td>0.2357856</td>\n",
              "<td>0.9889394</td>\n",
              "<td>0.9806550</td>\n",
              "<td>2.7045455</td>\n",
              "<td>0.0504202</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 21:45:29</td>\n",
              "<td> 4.921 sec</td>\n",
              "<td>10.0</td>\n",
              "<td>0.1838817</td>\n",
              "<td>0.1437128</td>\n",
              "<td>0.9923168</td>\n",
              "<td>0.9896504</td>\n",
              "<td>2.6785714</td>\n",
              "<td>0.0333333</td>\n",
              "<td>0.1944354</td>\n",
              "<td>0.1526950</td>\n",
              "<td>0.9919697</td>\n",
              "<td>0.9864338</td>\n",
              "<td>2.7045455</td>\n",
              "<td>0.0420168</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 21:45:29</td>\n",
              "<td> 4.938 sec</td>\n",
              "<td>15.0</td>\n",
              "<td>0.1766573</td>\n",
              "<td>0.1318257</td>\n",
              "<td>0.9918313</td>\n",
              "<td>0.9896319</td>\n",
              "<td>2.6785714</td>\n",
              "<td>0.0311111</td>\n",
              "<td>0.1798334</td>\n",
              "<td>0.1337698</td>\n",
              "<td>0.995</td>\n",
              "<td>0.9918816</td>\n",
              "<td>2.7045455</td>\n",
              "<td>0.0336134</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 21:45:29</td>\n",
              "<td> 4.960 sec</td>\n",
              "<td>20.0</td>\n",
              "<td>0.1730721</td>\n",
              "<td>0.1278360</td>\n",
              "<td>0.9915147</td>\n",
              "<td>0.9897823</td>\n",
              "<td>2.6785714</td>\n",
              "<td>0.0311111</td>\n",
              "<td>0.1727378</td>\n",
              "<td>0.1262197</td>\n",
              "<td>0.9965152</td>\n",
              "<td>0.9941734</td>\n",
              "<td>2.7045455</td>\n",
              "<td>0.0252101</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 21:45:29</td>\n",
              "<td> 4.988 sec</td>\n",
              "<td>25.0</td>\n",
              "<td>0.1727234</td>\n",
              "<td>0.1277058</td>\n",
              "<td>0.9915147</td>\n",
              "<td>0.9897823</td>\n",
              "<td>2.6785714</td>\n",
              "<td>0.0311111</td>\n",
              "<td>0.1726003</td>\n",
              "<td>0.1263937</td>\n",
              "<td>0.9965152</td>\n",
              "<td>0.9941734</td>\n",
              "<td>2.7045455</td>\n",
              "<td>0.0252101</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 21:45:30</td>\n",
              "<td> 5.026 sec</td>\n",
              "<td>30.0</td>\n",
              "<td>0.1727376</td>\n",
              "<td>0.1277083</td>\n",
              "<td>0.9915147</td>\n",
              "<td>0.9897823</td>\n",
              "<td>2.6785714</td>\n",
              "<td>0.0311111</td>\n",
              "<td>0.1726023</td>\n",
              "<td>0.1263794</td>\n",
              "<td>0.9965152</td>\n",
              "<td>0.9941734</td>\n",
              "<td>2.7045455</td>\n",
              "<td>0.0252101</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 21:45:30</td>\n",
              "<td> 5.051 sec</td>\n",
              "<td>35.0</td>\n",
              "<td>0.1732714</td>\n",
              "<td>0.1279432</td>\n",
              "<td>0.9915147</td>\n",
              "<td>0.9897823</td>\n",
              "<td>2.6785714</td>\n",
              "<td>0.0311111</td>\n",
              "<td>0.1728585</td>\n",
              "<td>0.1262045</td>\n",
              "<td>0.9965152</td>\n",
              "<td>0.9941734</td>\n",
              "<td>2.7045455</td>\n",
              "<td>0.0252101</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 21:45:30</td>\n",
              "<td> 5.080 sec</td>\n",
              "<td>40.0</td>\n",
              "<td>0.1705924</td>\n",
              "<td>0.1223583</td>\n",
              "<td>0.9911136</td>\n",
              "<td>0.9893981</td>\n",
              "<td>2.6785714</td>\n",
              "<td>0.0311111</td>\n",
              "<td>0.1616518</td>\n",
              "<td>0.1136228</td>\n",
              "<td>0.9974242</td>\n",
              "<td>0.9957667</td>\n",
              "<td>2.7045455</td>\n",
              "<td>0.0252101</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-06-21 21:45:30</td>\n",
              "<td> 5.111 sec</td>\n",
              "<td>44.0</td>\n",
              "<td>0.1706755</td>\n",
              "<td>0.1224014</td>\n",
              "<td>0.9911136</td>\n",
              "<td>0.9893981</td>\n",
              "<td>2.6785714</td>\n",
              "<td>0.0311111</td>\n",
              "<td>0.1616598</td>\n",
              "<td>0.1135635</td>\n",
              "<td>0.9974242</td>\n",
              "<td>0.9957667</td>\n",
              "<td>2.7045455</td>\n",
              "<td>0.0252101</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-54.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-54 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-54 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-54 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-54 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-54 .h2o-table th,\n",
              "#h2o-table-54 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-54 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-54\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Variable Importances: </caption>\n",
              "    <thead><tr><th>variable</th>\n",
              "<th>relative_importance</th>\n",
              "<th>scaled_importance</th>\n",
              "<th>percentage</th></tr></thead>\n",
              "    <tbody><tr><td>perimeter_worst</td>\n",
              "<td>335.8549194</td>\n",
              "<td>1.0</td>\n",
              "<td>0.5591635</td></tr>\n",
              "<tr><td>concave points_worst</td>\n",
              "<td>156.8416138</td>\n",
              "<td>0.4669922</td>\n",
              "<td>0.2611250</td></tr>\n",
              "<tr><td>concave points_mean</td>\n",
              "<td>25.2143497</td>\n",
              "<td>0.0750751</td>\n",
              "<td>0.0419793</td></tr>\n",
              "<tr><td>texture_worst</td>\n",
              "<td>23.8097916</td>\n",
              "<td>0.0708931</td>\n",
              "<td>0.0396408</td></tr>\n",
              "<tr><td>area_worst</td>\n",
              "<td>17.7388382</td>\n",
              "<td>0.0528170</td>\n",
              "<td>0.0295333</td></tr>\n",
              "<tr><td>area_se</td>\n",
              "<td>17.3529110</td>\n",
              "<td>0.0516679</td>\n",
              "<td>0.0288908</td></tr>\n",
              "<tr><td>texture_mean</td>\n",
              "<td>12.4470520</td>\n",
              "<td>0.0370608</td>\n",
              "<td>0.0207230</td></tr>\n",
              "<tr><td>concavity_mean</td>\n",
              "<td>7.0855765</td>\n",
              "<td>0.0210971</td>\n",
              "<td>0.0117967</td></tr>\n",
              "<tr><td>radius_se</td>\n",
              "<td>4.2931023</td>\n",
              "<td>0.0127826</td>\n",
              "<td>0.0071476</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
              "\n",
              "[tips]\n",
              "Use `model.explain()` to inspect the model.\n",
              "--\n",
              "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
            ]
          },
          "metadata": {},
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.model_performance(train).accuracy()"
      ],
      "metadata": {
        "id": "G_PyYFNMs97_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8873b9b3-7759-4a1b-9363-c39102f8d187"
      },
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.5162559151649475, 0.9688888888888889]]"
            ]
          },
          "metadata": {},
          "execution_count": 277
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = aml.get_best_model()\n",
        "HATr  = best_model.model_performance(train)\n",
        "HATe  = best_model.model_performance(valid)"
      ],
      "metadata": {
        "id": "jKquKjVVJBL9"
      },
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uzfosknt7ILF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SFOLD DATA AUTOML\n",
        "\n",
        "shdf = h2o.H2OFrame(newdata)\n",
        "shdf[\"y_test\"] = shdf[\"y_test\"].asfactor()\n",
        "shy = \"y_test\"\n",
        "shx = shdf.columns\n",
        "shx.remove(shy)\n",
        "strain, svalid = shdf.split_frame(ratios=[.8], seed=123)\n",
        "saml = H2OAutoML(max_models = 10, seed = 123, verbosity=\"info\", nfolds=10, sort_metric='accuracy')\n",
        "saml.train(x = shx, y = shy, training_frame = strain, validation_frame = svalid)\n",
        "sbest_model = saml.get_best_model()\n",
        "sHATr  = sbest_model.model_performance(strain)\n",
        "sHATe  = sbest_model.model_performance(svalid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMDqylVK7svS",
        "outputId": "2a016d93-7a97-4c41-c98d-5562f4ff5e54"
      },
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
            "AutoML progress: |\n",
            "21:52:34.4: Project: AutoML_3_20230621_215234\n",
            "21:52:34.4: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n",
            "21:52:34.4: Setting stopping tolerance adaptively based on the training frame: 0.04714045207910317\n",
            "21:52:34.4: Build control seed: 123\n",
            "21:52:34.4: training frame: Frame key: AutoML_3_20230621_215234_training_py_30_sid_b943    cols: 7    rows: 450  chunks: 1    size: 1441  checksum: -2050253062745124720\n",
            "21:52:34.4: validation frame: Frame key: py_31_sid_b943    cols: 7    rows: 119  chunks: 1    size: 1147  checksum: -2050252744822272480\n",
            "21:52:34.4: leaderboard frame: NULL\n",
            "21:52:34.5: blending frame: NULL\n",
            "21:52:34.5: response column: y_test\n",
            "21:52:34.5: fold column: null\n",
            "21:52:34.5: weights column: null\n",
            "21:52:34.6: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (7g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (7g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (6g, 60w)]}, {StackedEnsemble : [monotonic (9g, 10w), best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
            "21:52:34.10: AutoML job created: 2023.06.21 21:52:34.3\n",
            "21:52:34.11: AutoML build started: 2023.06.21 21:52:34.11\n",
            "21:52:34.12: AutoML: starting XGBoost_1_AutoML_3_20230621_215234 model training\n",
            "\n",
            "█\n",
            "21:52:36.347: New leader: XGBoost_1_AutoML_3_20230621_215234, accuracy: 0.9266666666666666\n",
            "21:52:36.348: AutoML: starting GLM_1_AutoML_3_20230621_215234 model training\n",
            "\n",
            "\n",
            "21:52:37.700: New leader: GLM_1_AutoML_3_20230621_215234, accuracy: 0.9244444444444444\n",
            "21:52:37.701: AutoML: starting GBM_1_AutoML_3_20230621_215234 model training\n",
            "\n",
            "██\n",
            "21:52:40.241: AutoML: starting XGBoost_2_AutoML_3_20230621_215234 model training\n",
            "\n",
            "██\n",
            "21:52:41.993: AutoML: starting DRF_1_AutoML_3_20230621_215234 model training\n",
            "21:52:43.486: AutoML: starting GBM_2_AutoML_3_20230621_215234 model training\n",
            "\n",
            "█\n",
            "21:52:44.867: AutoML: starting GBM_3_AutoML_3_20230621_215234 model training\n",
            "\n",
            "█\n",
            "21:52:46.189: AutoML: starting GBM_4_AutoML_3_20230621_215234 model training\n",
            "\n",
            "█\n",
            "21:52:47.598: AutoML: starting XGBoost_3_AutoML_3_20230621_215234 model training\n",
            "\n",
            "██\n",
            "21:52:49.485: New leader: XGBoost_3_AutoML_3_20230621_215234, accuracy: 0.9222222222222223\n",
            "21:52:49.486: AutoML: starting XRT_1_AutoML_3_20230621_215234 model training\n",
            "\n",
            "█\n",
            "21:52:51.151: No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'monotonic'.\n",
            "21:52:51.152: AutoML: starting StackedEnsemble_BestOfFamily_1_AutoML_3_20230621_215234 model training\n",
            "\n",
            "██\n",
            "21:52:53.890: AutoML: starting StackedEnsemble_AllModels_1_AutoML_3_20230621_215234 model training\n",
            "\n",
            "██████████████████████████████████████████████████| (done) 100%\n",
            "\n",
            "21:52:56.490: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GLM : [def_1 (1g, 10w)]}, {GBM : [def_5 (1g, 10w)]}, {XGBoost : [def_1 (2g, 10w)]}, {DRF : [def_1 (2g, 10w)]}, {GBM : [def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w)]}, {XGBoost : [def_3 (3g, 10w)]}, {DRF : [XRT (3g, 10w)]}, {StackedEnsemble : [best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
            "21:52:56.490: AutoML build stopped: 2023.06.21 21:52:56.490\n",
            "21:52:56.490: AutoML build done: built 10 models\n",
            "21:52:56.490: AutoML duration: 22.479 sec\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = pd.DataFrame(\n",
        "    {\n",
        "    \"SVM\":[STr,STe],\n",
        "    \"KNN\":[KTr,KTe],\n",
        "    \"RF\" :[RTr,RTe],\n",
        "    \"LR\" :[LTr,LTe],\n",
        "    \"ANN\":[ATr,ATe],\n",
        "    \"XGB\":[XTr,XTe],\n",
        "    \"DNN\":[DTr,DTe],\n",
        "    \"H_OD\":[HATr.accuracy()[0][1],HATe.accuracy()[0][1]],\n",
        "    \"H_SOD\":[sHATr.accuracy()[0][1],sHATe.accuracy()[0][1]]\n",
        "    })\n",
        "acc.index = [\"train\", \"test\"]\n",
        "acc = acc.T\n",
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "F1gz4fq-6P6o",
        "outputId": "fcc3fac1-526a-4ca6-eb0f-ff910fcb6359"
      },
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          train      test\n",
              "SVM    0.951648  0.956140\n",
              "KNN    0.980220  0.991228\n",
              "RF     0.975824  0.991228\n",
              "LR     0.980220  0.973684\n",
              "ANN    0.958333  0.902655\n",
              "XGB    0.989011  0.982456\n",
              "DNN    0.956044  0.903509\n",
              "H_OD   0.968889  0.974790\n",
              "H_SOD  0.931111  0.949580"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-766bead8-394c-4696-b211-cebc2291c49f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>0.951648</td>\n",
              "      <td>0.956140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>0.980220</td>\n",
              "      <td>0.991228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>0.975824</td>\n",
              "      <td>0.991228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LR</th>\n",
              "      <td>0.980220</td>\n",
              "      <td>0.973684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ANN</th>\n",
              "      <td>0.958333</td>\n",
              "      <td>0.902655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGB</th>\n",
              "      <td>0.989011</td>\n",
              "      <td>0.982456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DNN</th>\n",
              "      <td>0.956044</td>\n",
              "      <td>0.903509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H_OD</th>\n",
              "      <td>0.968889</td>\n",
              "      <td>0.974790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H_SOD</th>\n",
              "      <td>0.931111</td>\n",
              "      <td>0.949580</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-766bead8-394c-4696-b211-cebc2291c49f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-766bead8-394c-4696-b211-cebc2291c49f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-766bead8-394c-4696-b211-cebc2291c49f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.bar(acc.index, acc['train'], color ='black',width = 0.4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "nJrcI3Gn8we2",
        "outputId": "12a27335-237c-4a33-d2ed-e94405b42de7"
      },
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 9 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 288
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAApG0lEQVR4nO3de1RVZf7H8c8BBTQCVBKUOSNeUnM0MC8MdlMHQ6ecLFNyNLxlaY1pdFFMoTRFG2/NaJIGamuG8VY5ZmXjUNiUOE4qU62fl3HUdFRQ0sCwMGH//nBx6sTtHAUeOb5fa+215DnPs8/zhc3h47P32cdmWZYlAAAAQ7xMTwAAAFzbCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjGpgegKuKC0t1YkTJ3T99dfLZrOZng4AAHCBZVk6d+6cWrZsKS+vytc/6kUYOXHihOx2u+lpAACAy3Ds2DH97Gc/q/TxehFGrr/+ekmXigkICDA8GwAA4IrCwkLZ7XbH3/HK1IswUnZqJiAggDACAEA9U90lFlzACgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACj3A4jH330kQYOHKiWLVvKZrNp48aN1Y7JysrSLbfcIl9fX7Vr106rVq26jKkCAABP5HYYKSoqUkREhJYuXepS/8OHD+vuu+9Wnz59lJOTo8mTJ+vhhx/W+++/7/ZkAQCA53H7pmcDBgzQgAEDXO6fmpqq1q1ba8GCBZKkm266SR9//LEWLVqk2NhYd58eAAB4mFq/ZiQ7O1sxMTFObbGxscrOzq50THFxsQoLC502AADgmWo9jOTm5iokJMSpLSQkRIWFhfr2228rHJOSkqLAwEDHxofkAQDgua7Kd9MkJiaqoKDAsR07dsz0lAAAQC2p9Q/KCw0NVV5enlNbXl6eAgIC1KhRowrH+Pr6ytfXt7anBgAArgK1vjISHR2tzMxMp7atW7cqOjq6tp8aAADUA26HkW+++UY5OTnKycmRdOmtuzk5OTp69KikS6dY4uPjHf3Hjx+vQ4cO6dlnn9W+ffv0yiuvaN26dXryySdrpgIAqEM2m63GN+Ba53YY+fTTT9W1a1d17dpVkpSQkKCuXbsqKSlJknTy5ElHMJGk1q1b65133tHWrVsVERGhBQsW6LXXXuNtvQAAQJJksyzLMj2J6hQWFiowMFAFBQUKCAgwPR0A17DaWMmoBy/DwGVx9e93rV/ACjN4waw/amuZnp8XgPriqnxrLwAAuHawMoJ6hRUfAPA8rIwAAACjWBkBAHgkVlLrD1ZGAACAUYQRAABgFGEEAAAYxTUjAGoF5+sBuIowAgDXOG68B9M4TQMAAIy65ldG+B8BAABmsTICAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKOu+bf2AgBQn3ji3Y1ZGQEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGAUYQQAABhFGAEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGAUYQQAABhFGAEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGAUYQQAABhFGAEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARl1WGFm6dKnCw8Pl5+enqKgo7dy5s8r+ixcvVocOHdSoUSPZ7XY9+eST+u677y5rwgAAwLO4HUbWrl2rhIQEJScna/fu3YqIiFBsbKxOnTpVYf+MjAxNnTpVycnJ2rt3r9LS0rR27VpNmzbtiicPAADqP7fDyMKFCzVu3DiNHj1anTp1Umpqqho3bqz09PQK+2/fvl233nqrfvvb3yo8PFx33XWXhg0bVu1qCgAAuDa4FUYuXLigXbt2KSYm5ocdeHkpJiZG2dnZFY7p1auXdu3a5Qgfhw4d0rvvvqtf//rXVzBtAADgKRq40zk/P18lJSUKCQlxag8JCdG+ffsqHPPb3/5W+fn5uu2222RZli5evKjx48dXeZqmuLhYxcXFjq8LCwvdmSYAAKhHav3dNFlZWZozZ45eeeUV7d69W2+++abeeecdzZo1q9IxKSkpCgwMdGx2u722pwkAAAxxa2UkODhY3t7eysvLc2rPy8tTaGhohWNmzJihhx56SA8//LAkqUuXLioqKtIjjzyi5557Tl5e5fNQYmKiEhISHF8XFhYSSAAA8FBurYz4+PioW7duyszMdLSVlpYqMzNT0dHRFY45f/58ucDh7e0tSbIsq8Ixvr6+CggIcNoAAIBncmtlRJISEhI0cuRIde/eXT179tTixYtVVFSk0aNHS5Li4+MVFhamlJQUSdLAgQO1cOFCde3aVVFRUTp48KBmzJihgQMHOkIJAAC4drkdRuLi4nT69GklJSUpNzdXkZGR2rJli+Oi1qNHjzqthEyfPl02m03Tp0/X8ePHdcMNN2jgwIGaPXt2zVUBAADqLZtV2bmSq0hhYaECAwNVUFBQ46dsbDZbje6vjOlva23UZbomyTPr4hh0nemaJM+si2PQdaZrkupXXa7+/eazaQAAgFGEEQAAYBRhBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGAUYQQAABhFGAEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGAUYQQAABhFGAEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGAUYQQAABhFGAEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGAUYQQAABhFGAEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGAUYQQAABhFGAEAAEYRRgAAgFGXFUaWLl2q8PBw+fn5KSoqSjt37qyy/9dff63HH39cLVq0kK+vr9q3b6933333siYMAAA8SwN3B6xdu1YJCQlKTU1VVFSUFi9erNjYWO3fv1/Nmzcv1//ChQvq16+fmjdvrg0bNigsLExffvmlgoKCamL+AACgnrNZlmW5MyAqKko9evTQkiVLJEmlpaWy2+2aOHGipk6dWq5/amqqfv/732vfvn1q2LDhZU2ysLBQgYGBKigoUEBAwGXtozI2m61G91fGzW9rjauNukzXJHlmXRyDrjNdk+SZdXEMus50TVL9qsvVv99unaa5cOGCdu3apZiYmB924OWlmJgYZWdnVzhm06ZNio6O1uOPP66QkBB17txZc+bMUUlJSaXPU1xcrMLCQqcNAAB4JrfCSH5+vkpKShQSEuLUHhISotzc3ArHHDp0SBs2bFBJSYneffddzZgxQwsWLNCLL75Y6fOkpKQoMDDQsdntdnemCQAA6pFafzdNaWmpmjdvruXLl6tbt26Ki4vTc889p9TU1ErHJCYmqqCgwLEdO3astqcJAAAMcesC1uDgYHl7eysvL8+pPS8vT6GhoRWOadGihRo2bChvb29H20033aTc3FxduHBBPj4+5cb4+vrK19fXnakBAIB6yq2VER8fH3Xr1k2ZmZmOttLSUmVmZio6OrrCMbfeeqsOHjyo0tJSR9uBAwfUokWLCoMIAAC4trh9miYhIUErVqzQ6tWrtXfvXk2YMEFFRUUaPXq0JCk+Pl6JiYmO/hMmTNCZM2c0adIkHThwQO+8847mzJmjxx9/vOaqAAAA9Zbb9xmJi4vT6dOnlZSUpNzcXEVGRmrLli2Oi1qPHj0qL68fMo7dbtf777+vJ598UjfffLPCwsI0adIkTZkypeaqAAAA9Zbb9xkxgfuMuK8+vQ/dHZ5YF8eg60zXJHlmXRyDrjNdk1S/6qqV+4wAAADUNMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAoy4rjCxdulTh4eHy8/NTVFSUdu7c6dK4NWvWyGazadCgQZfztAAAwAO5HUbWrl2rhIQEJScna/fu3YqIiFBsbKxOnTpV5bgjR47o6aef1u23337ZkwUAAJ7H7TCycOFCjRs3TqNHj1anTp2Umpqqxo0bKz09vdIxJSUlGj58uF544QW1adPmiiYMAAA8i1th5MKFC9q1a5diYmJ+2IGXl2JiYpSdnV3puJkzZ6p58+YaO3asS89TXFyswsJCpw0AAHgmt8JIfn6+SkpKFBIS4tQeEhKi3NzcCsd8/PHHSktL04oVK1x+npSUFAUGBjo2u93uzjQBAEA9Uqvvpjl37pweeughrVixQsHBwS6PS0xMVEFBgWM7duxYLc4SAACY1MCdzsHBwfL29lZeXp5Te15enkJDQ8v1/+9//6sjR45o4MCBjrbS0tJLT9yggfbv36+2bduWG+fr6ytfX193pgYAAOopt1ZGfHx81K1bN2VmZjraSktLlZmZqejo6HL9O3bsqM8//1w5OTmO7Te/+Y369OmjnJwcTr8AAAD3VkYkKSEhQSNHjlT37t3Vs2dPLV68WEVFRRo9erQkKT4+XmFhYUpJSZGfn586d+7sND4oKEiSyrUDAIBrk9thJC4uTqdPn1ZSUpJyc3MVGRmpLVu2OC5qPXr0qLy8uLErAABwjc2yLMv0JKpTWFiowMBAFRQUKCAgoEb3bbPZanR/ZUx/W2ujLtM1SZ5ZF8eg60zXJHlmXRyDrjNdk1S/6nL17zdLGAAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMuK4wsXbpU4eHh8vPzU1RUlHbu3Flp3xUrVuj2229XkyZN1KRJE8XExFTZHwAAXFvcDiNr165VQkKCkpOTtXv3bkVERCg2NlanTp2qsH9WVpaGDRumDz/8UNnZ2bLb7brrrrt0/PjxK548AACo/2yWZVnuDIiKilKPHj20ZMkSSVJpaansdrsmTpyoqVOnVju+pKRETZo00ZIlSxQfH+/ScxYWFiowMFAFBQUKCAhwZ7rVstlsNbq/Mm5+W2tcbdRluibJM+viGHSd6Zokz6yLY9B1pmuS6lddrv79dmtl5MKFC9q1a5diYmJ+2IGXl2JiYpSdne3SPs6fP6/vv/9eTZs2rbRPcXGxCgsLnTYAAOCZ3Aoj+fn5KikpUUhIiFN7SEiIcnNzXdrHlClT1LJlS6dA81MpKSkKDAx0bHa73Z1pAgCAeqRO300zd+5crVmzRm+99Zb8/Pwq7ZeYmKiCggLHduzYsTqcJQAAqEsN3OkcHBwsb29v5eXlObXn5eUpNDS0yrHz58/X3Llz9fe//10333xzlX19fX3l6+vrztQAAEA95dbKiI+Pj7p166bMzExHW2lpqTIzMxUdHV3puJdeekmzZs3Sli1b1L1798ufLQAA8DhurYxIUkJCgkaOHKnu3burZ8+eWrx4sYqKijR69GhJUnx8vMLCwpSSkiJJmjdvnpKSkpSRkaHw8HDHtSX+/v7y9/evwVIAAEB95HYYiYuL0+nTp5WUlKTc3FxFRkZqy5Ytjotajx49Ki+vHxZcli1bpgsXLuiBBx5w2k9ycrKef/75K5s9AACo99y+z4gJ3GfEffXpfeju8MS6OAZdZ7omyTPr4hh0nemapPpVV63cZwQAAKCmEUYAAIBRhBEAAGAUYQQAABhFGAEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGAUYQQAABhFGAEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGAUYQQAABhFGAEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGAUYQQAABhFGAEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGAUYQQAABhFGAEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYdVlhZOnSpQoPD5efn5+ioqK0c+fOKvuvX79eHTt2lJ+fn7p06aJ33333siYLAAA8j9thZO3atUpISFBycrJ2796tiIgIxcbG6tSpUxX23759u4YNG6axY8dqz549GjRokAYNGqQvvvjiiicPAADqP5tlWZY7A6KiotSjRw8tWbJEklRaWiq73a6JEydq6tSp5frHxcWpqKhImzdvdrT98pe/VGRkpFJTU116zsLCQgUGBqqgoEABAQHuTLdaNputRvdXxs1va42rjbpM1yR5Zl0cg64zXZPkmXVxDLrOdE1S/arL1b/fDdzZ6YULF7Rr1y4lJiY62ry8vBQTE6Ps7OwKx2RnZyshIcGpLTY2Vhs3bqz0eYqLi1VcXOz4uqCgQNKlouqL+jRXV3liTRJ11SeeWJNEXfWJJ9Yk1V5dZfutLuy4FUby8/NVUlKikJAQp/aQkBDt27evwjG5ubkV9s/Nza30eVJSUvTCCy+Ua7fb7e5M16jAwEDTU6hxnliTRF31iSfWJFFXfeKJNUm1X9e5c+eqfA63wkhdSUxMdFpNKS0t1ZkzZ9SsWbNaW06sTmFhoex2u44dO1bjp4pM8sS6PLEmibrqE0+sSaKu+uRqqcmyLJ07d04tW7assp9bYSQ4OFje3t7Ky8tzas/Ly1NoaGiFY0JDQ93qL0m+vr7y9fV1agsKCnJnqrUmICDAYw7WH/PEujyxJom66hNPrEmirvrkaqjJlVUXt95N4+Pjo27duikzM9PRVlpaqszMTEVHR1c4Jjo62qm/JG3durXS/gAA4Nri9mmahIQEjRw5Ut27d1fPnj21ePFiFRUVafTo0ZKk+Ph4hYWFKSUlRZI0adIk3XnnnVqwYIHuvvturVmzRp9++qmWL19es5UAAIB6ye0wEhcXp9OnTyspKUm5ubmKjIzUli1bHBepHj16VF5ePyy49OrVSxkZGZo+fbqmTZumG2+8URs3blTnzp1rroo64Ovrq+Tk5HKnj+o7T6zLE2uSqKs+8cSaJOqqT+pbTW7fZwQAAKAm8dk0AADAKMIIAAAwijACAACMIowAAACjrtkwcvr0aU2YMEE///nP5evrq9DQUMXGxmrbtm0KDg7W3LlzKxw3a9YshYSE6Pvvv9eqVatks9l00003leu3fv162Ww2hYeH13IlPxg1apQGDRrk1LZhwwb5+flpwYIFGjVqlGw2W7naNm7c6HRn26ysLNlsNv3iF79QSUmJU9+goCCtWrWqtkpwS1k9NptNDRs2VOvWrfXss8/qu+++c/Qpe/zH22233WZw1tWr6OdYJjw83FFH48aN1aVLF7322mt1O0EXZGdny9vbW3fffbdT+5EjR2Sz2dS8eXOdO3fO6bHIyEg9//zzjq979+4tm82mNWvWOPVbvHhxnf5elZSUqFevXrr//vud2gsKCmS32/Xcc8852t544w317dtXTZo0UaNGjdShQweNGTNGe/bscfQpe90o2/z9/dWtWze9+eabdVaTVP73JyQkRP369VN6erpKS0sd/cqOuR07djiNnzx5snr37u34+vnnn5fNZtP48eOd+uXk5Mhms+nIkSO1VkdFvy9lr2Nff/11tfsoKSnRokWL1KVLF/n5+alJkyYaMGCAPvnkE6d+P/7ZeXt7q0mTJoqKitLMmTMdn6FmqoYVK1YoIiJC/v7+CgoKUteuXR232Chz5swZTZ48Wa1atZKPj49atmypMWPG6OjRo+Xm48qxUZOu2TAyePBg7dmzR6tXr9aBAwe0adMm9e7dWwUFBRoxYoRWrlxZboxlWVq1apXi4+PVsGFDSdJ1112nU6dOlfugwLS0NP385z+vk1oq89prr2n48OFatmyZnnrqKUmSn5+f5s2bp7Nnz1Y7/tChQ3r99ddre5pXpH///jp58qQOHTqkRYsW6dVXX1VycrJTn5UrV+rkyZOObdOmTYZmWzNmzpypkydP6osvvtCIESM0btw4vffee6an5SQtLU0TJ07URx99pBMnTpR7/Ny5c5o/f361+/Hz89P06dP1/fff18Y0XeLt7a1Vq1Zpy5Yt+vOf/+xonzhxopo2beo43qZMmaK4uDhFRkZq06ZN2r9/vzIyMtSmTRunDxeVLt0Vs+x43LNnj2JjYzV06FDt37+/Tmsr+/05cuSI3nvvPfXp00eTJk3SPffco4sXLzr6+fn5acqUKdXuz8/PT2lpafrPf/5Tm9OuUZZl6cEHH9TMmTM1adIk7d27V1lZWbLb7erdu3e5D3Ut+9n973//0/bt2/XII4/o9ddfV2RkZIXHel1IT0/X5MmT9cQTTygnJ0effPKJnn32WX3zzTeOPmfOnNEvf/lL/f3vf1dqaqoOHjyoNWvW6ODBg+rRo4cOHTrktE9Xj40aY12Dzp49a0mysrKyKnz8s88+syRZ//jHP5zaP/zwQ0uStXfvXsuyLGvlypVWYGCg9bvf/c56+OGHHf2OHTtm+fr6WlOnTrVatWpVa3X81MiRI617773XsizLmjdvnuXn52e9+eabTo/fc889VseOHa1nnnnG0f7WW29ZPz4Uyup85plnLLvdbn333XeOxwIDA62VK1fWei2u+HG9Ze6//36ra9eujq8lWW+99VbdTuwKVVRXmVatWlmLFi1yamvatKn15JNP1v7EXHTu3DnL39/f2rdvnxUXF2fNnj3b8djhw4cdx5a/v7+Vl5fneCwiIsJKTk52fH3nnXdao0ePtpo1a2YtXbrU0b5o0aI6/b0q8/LLL1tNmjSxTpw4YW3cuNFq2LChlZOTY1mWZWVnZ1uSrJdffrnCsaWlpY5/l71u/FhJSYnVsGFDa926dbU2/5+q7DjLzMy0JFkrVqywLOvSMffEE09YPj4+1jvvvOPoN2nSJOvOO+90fJ2cnGxFRERY/fr1s4YMGeJo37NnjyXJOnz4cJ3WUfY6dvbs2SrHr1mzxpJkbdq0qdxj999/v9WsWTPrm2++sSyr4p+dZVlWXl6eFRwcbA0fPvxySrjiGu69915r1KhRVfYZP368dd1111knT550aj9//rwVFhZm9e/fv9r5/PTYqEnX5MqIv7+//P39tXHjRhUXF5d7vEuXLurRo4fS09Od2leuXKlevXqpY8eOTu1jxozRunXrdP78eUmXlvL69+9f7tOK68qUKVM0a9Ysbd68Wffdd5/TY97e3pozZ47++Mc/6n//+1+V+5k8ebIuXryoP/7xj7U53RrzxRdfaPv27fLx8TE9lTpRWlqqN954Q2fPnr2qal63bp06duyoDh06aMSIEUpPTy/38eHDhg1Tu3btNHPmzCr3FRAQoOeee04zZ85UUVFRbU67WhMnTlRERIQeeughPfLII0pKSlJERIQk6S9/+Yv8/f312GOPVTi2qg/4LCkp0erVqyVJt9xyS81P3E19+/ZVRESE02mj1q1ba/z48UpMTKx2mX7u3Ll644039Omnn9b2VGtERkaG2rdvr4EDB5Z77KmnntJXX32lrVu3VrmP5s2ba/jw4dq0aVO5U9t1ITQ0VDt27NCXX35Z4eOlpaVas2aNhg8fXu5z4Ro1aqTHHntM77//vs6cOVPl81R0bNSUazKMNGjQQKtWrdLq1asVFBSkW2+9VdOmTdNnn33m6DN27FitX7/escx17tw5bdiwQWPGjCm3v65du6pNmzbasGGD41RORf3qwnvvvaeXXnpJf/3rX/WrX/2qwj733XefIiMjy53O+KnGjRsrOTlZKSkpV3Q+tDZt3rxZ/v7+8vPzU5cuXXTq1Ck988wzTn2GDRvmCKBlIbQ+mzJlivz9/eXr66sHHnhATZo00cMPP2x6Wg5paWkaMWKEpEtLvQUFBdq2bZtTn7Jrl5YvX67//ve/Ve7vsccek5+fnxYuXFhrc3aFzWbTsmXLlJmZqZCQEE2dOtXx2IEDB9SmTRs1aPDDTa0XLlzodNz9+HeooKDA0e7j46MJEyZo+fLlatu2bZ3WVJmOHTuWu8Zj+vTpOnz4sNOpqorccsstGjp0qEundWpK2evAj7cBAwa4NPbAgQMVXvcnydF+4MCBavfTsWNHnTt3Tl999ZXrE/+RK6khOTlZQUFBCg8PV4cOHTRq1CitW7fOERxPnz6tr7/+uso6LcvSwYMHq32uio6NmnBNhhHp0jUjJ06c0KZNm9S/f39lZWXplltucVycOWzYMJWUlGjdunWSpLVr18rLy0txcXEV7m/MmDFauXKltm3bpqKiIv3617+uq1Kc3HzzzQoPD1dycrLT+cKfmjdvnlavXq29e/dWub+xY8eqWbNmmjdvXk1PtUb06dNHOTk5+uc//6mRI0dq9OjRGjx4sFOfRYsWKScnx7H169fP0GxrxjPPPKOcnBx98MEHioqK0qJFi9SuXTvT05Ik7d+/Xzt37tSwYcMkXQr+cXFxSktLK9c3NjZWt912m2bMmFHlPn19fTVz5kzNnz9f+fn5tTJvV6Wnp6tx48Y6fPhwtSuLY8aMUU5Ojl599VUVFRU5rQ5df/31juNxz549mjNnjsaPH6+33367tktwiWVZ5VZzbrjhBj399NNKSkrShQsXqhz/4osv6h//+If+9re/1eY0HcpeB368uXNh909X7i5H2T6qWgWrypXU0KJFC2VnZ+vzzz/XpEmTdPHiRY0cOVL9+/d3WsmqqTovt8aqXLNhRLp0sVW/fv00Y8YMbd++XaNGjXKsFgQEBOiBBx5wXMi6cuVKDR06VP7+/hXua/jw4dqxY4eef/55PfTQQ07/Q6pLYWFhysrK0vHjx9W/f/9y71goc8cddyg2NrbchXU/1aBBA82ePVsvv/yysYuzqnLdddepXbt2ioiIUHp6uv75z3+W+8MXGhqqdu3aObbrrrvO0GxrRnBwsNq1a6fbb79d69ev1xNPPKH/+7//Mz0tSZdWRS5evKiWLVuqQYMGatCggZYtW6Y33nijwtW1uXPnau3atU7vNqnIiBEj1KpVK7344ou1NfVqbd++XYsWLdLmzZvVs2dPjR071vHifuONN+rQoUNOF9oGBQWpXbt2CgsLK7cvLy8vx/F48803KyEhQb17975qQv/evXvVunXrcu0JCQn69ttv9corr1Q5vm3btho3bpymTp1aI38Aq1P2OvDjraLve0Xat29f6X/Kytrbt29f7X727t2rgIAANWvWzPWJ/8iV1FCmc+fOeuyxx/SnP/1JW7du1datW7Vt2zbdcMMNCgoKqrJOm83m0n9qKjs2rtQ1HUZ+qlOnTk7npceOHauPP/5Ymzdv1vbt2zV27NhKxzZt2lS/+c1vtG3bNmOnaMq0atVK27ZtU25ubpWBZO7cuXr77bfLvRPop4YMGaJf/OIXeuGFF2pjujXGy8tL06ZN0/Tp0/Xtt9+ank6dsNvtiouLqzZU1oWLFy/q9ddf14IFC5z+d/fvf/9bLVu21F/+8pdyY3r27Kn777/f6ZRHRby8vJSSkqJly5bV2ltEq3L+/HmNGjVKEyZMUJ8+fZSWlqadO3cqNTVV0qWV1G+++abaP9JV8fb2viqO2w8++ECff/55uRVG6dL1djNmzNDs2bMrfV0pk5SUpAMHDpR7a/bV5sEHH9R//vOfClelFixYoGbNmlW7mnrq1CllZGRo0KBBTh8Ua1KnTp0kSUVFRfLy8tLQoUOVkZGh3Nxcp35l4TI2NlZNmzatcp9VHRtX6ur4rtWxr776Sn379tWf/vQnffbZZzp8+LDWr1+vl156Sffee6+j3x133KF27dopPj5eHTt2VK9evarc76pVq5Sfn1/uAlcT7Ha7srKydOrUKcXGxqqwsLBcny5dumj48OH6wx/+UO3+5s6dq/T0dOMXEVZnyJAh8vb21tKlS01P5YoUFBSUW7I9duxYhX0nTZqkt99+2/gFg5s3b9bZs2c1duxYde7c2WkbPHhwhadqJGn27Nn64IMPqn1b6913362oqCi9+uqrtTH9KiUmJsqyLMc9esLDwzV//nw9++yzOnLkiKKjo/XUU0/pqaeeUkJCgj7++GN9+eWX2rFjh9LS0mSz2Zz+SFmWpdzcXOXm5urw4cNavny53n//fafXn7pQXFys3NxcHT9+XLt379acOXN077336p577lF8fHyFYx555BEFBgYqIyOjyn2HhIQoISHBpdcXkx588EHdd999GjlypNLS0nTkyBF99tlnevTRR7Vp0ya99tprTqupZT+7kydPau/evUpPT1evXr0UGBhY6f2patuECRM0a9YsffLJJ47jLj4+XjfccIOio6MlSXPmzFFoaKj69eun9957T8eOHdNHH32k2NhYff/99+VeMy/n2LgS12QY8ff3d5xrv+OOO9S5c2fNmDFD48aN05IlSxz9bDabxowZo7Nnz7q02tGoUaPLXqKrDT/72c+UlZWl/Pz8SgPJzJkzXbqJTd++fdW3b9/aeX95DWrQoIF+97vf6aWXXrrqg1NVsrKy1LVrV6etspWpTp066a677lJSUlIdz9JZWlqaYmJiFBgYWO6xwYMH69NPP63wGGzfvr3GjBnjdLO6ysybN8+lfjVp27ZtWrp0qVauXKnGjRs72h999FH16tXLcbpm/vz5ysjI0J49e3TPPffoxhtv1JAhQ1RaWqrs7GwFBAQ4xhYWFqpFixZq0aKFbrrpJi1YsEAzZ850uoFaXdiyZYtatGih8PBw9e/fXx9++KH+8Ic/6K9//au8vb0rHNOwYUPNmjXLpZ/D008/Xemp7auFzWbTunXrNG3aNC1atEgdOnTQ7bffri+//FJZWVnlbkZW9rMLCwtTdHS0Xn31VY0cOVJ79uxRixYtjNQQExOjHTt2aMiQIWrfvr0GDx4sPz8/ZWZmOv4mNWvWTDt27FCfPn306KOPqm3btho6dKjatm2rf/3rX2rTpo3TPi/n2LgSNqsuTugBAABU4ppcGQEAAFcPwggAwGMNGDCg3P07yrY5c+aYnp5LPKGG6nCaBgDgsY4fP17pu5SaNm1a7TtIrgaeUEN1CCMAAMAoTtMAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjPp/4m7jnAhgXvsAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}